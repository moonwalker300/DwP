Y Mean 1.514292, Std 3.653528 
Observe confounder 3, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 19.191276
Rec Loss: 17.998802
KL Loss: 1.192473
Y Loss: 2.951977
T Loss: 12.094848
Epoch 99 
Overall Loss: 14.905462
Rec Loss: 13.815871
KL Loss: 1.089592
Y Loss: 0.817007
T Loss: 12.181856
Epoch 149 
Overall Loss: 13.930589
Rec Loss: 13.241475
KL Loss: 0.689113
Y Loss: 0.602734
T Loss: 12.036008
Epoch 199 
Overall Loss: 13.466986
Rec Loss: 12.923641
KL Loss: 0.543344
Y Loss: 0.516223
T Loss: 11.891196
Epoch 249 
Overall Loss: 13.322477
Rec Loss: 12.784488
KL Loss: 0.537989
Y Loss: 0.485466
T Loss: 11.813556
Epoch 299 
Overall Loss: 13.226671
Rec Loss: 12.693743
KL Loss: 0.532928
Y Loss: 0.474414
T Loss: 11.744916
Epoch 349 
Overall Loss: 13.160313
Rec Loss: 12.632242
KL Loss: 0.528071
Y Loss: 0.461530
T Loss: 11.709182
Epoch 399 
Overall Loss: 13.108952
Rec Loss: 12.579304
KL Loss: 0.529648
Y Loss: 0.450609
T Loss: 11.678087
Epoch 449 
Overall Loss: 13.018875
Rec Loss: 12.490500
KL Loss: 0.528375
Y Loss: 0.420349
T Loss: 11.649802
Epoch 499 
Overall Loss: 12.945968
Rec Loss: 12.423602
KL Loss: 0.522365
Y Loss: 0.387694
T Loss: 11.648215
Epoch 549 
Overall Loss: 12.849350
Rec Loss: 12.326577
KL Loss: 0.522773
Y Loss: 0.347224
T Loss: 11.632128
Epoch 599 
Overall Loss: 12.778513
Rec Loss: 12.263332
KL Loss: 0.515181
Y Loss: 0.327846
T Loss: 11.607640
Epoch 649 
Overall Loss: 12.714315
Rec Loss: 12.207586
KL Loss: 0.506729
Y Loss: 0.302945
T Loss: 11.601697
Epoch 699 
Overall Loss: 12.670081
Rec Loss: 12.180365
KL Loss: 0.489716
Y Loss: 0.292610
T Loss: 11.595144
Epoch 749 
Overall Loss: 12.630053
Rec Loss: 12.143988
KL Loss: 0.486065
Y Loss: 0.275489
T Loss: 11.593009
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.618852
Epoch 99
Rec Loss: 1.610960
Epoch 149
Rec Loss: 1.607576
Epoch 199
Rec Loss: 1.608271
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.975844
Epoch 99
Rec Loss: 9.972510
Epoch 149
Rec Loss: 9.977602
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.372848
Insample Error: 1.776374
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 28.010159
Rec Loss: 24.236312
KL Loss: 3.773848
Y Loss: 3.215682
T Loss: 12.222228
Epoch 99 
Overall Loss: 22.947838
Rec Loss: 19.864449
KL Loss: 3.083389
Y Loss: 0.985625
T Loss: 12.363771
Epoch 149 
Overall Loss: 21.471875
Rec Loss: 18.230555
KL Loss: 3.241320
Y Loss: 0.697353
T Loss: 12.059675
Epoch 199 
Overall Loss: 20.607031
Rec Loss: 17.143934
KL Loss: 3.463097
Y Loss: 0.541159
T Loss: 11.712863
Epoch 249 
Overall Loss: 20.132277
Rec Loss: 16.570522
KL Loss: 3.561755
Y Loss: 0.470601
T Loss: 11.578129
Epoch 299 
Overall Loss: 19.841000
Rec Loss: 16.042633
KL Loss: 3.798367
Y Loss: 0.450153
T Loss: 11.537759
Epoch 349 
Overall Loss: 19.655415
Rec Loss: 15.760360
KL Loss: 3.895055
Y Loss: 0.426761
T Loss: 11.515534
Epoch 399 
Overall Loss: 19.557938
Rec Loss: 15.656014
KL Loss: 3.901924
Y Loss: 0.415691
T Loss: 11.494032
Epoch 449 
Overall Loss: 19.370462
Rec Loss: 15.411357
KL Loss: 3.959105
Y Loss: 0.377930
T Loss: 11.475959
Epoch 499 
Overall Loss: 19.255124
Rec Loss: 15.168882
KL Loss: 4.086242
Y Loss: 0.340939
T Loss: 11.493631
Epoch 549 
Overall Loss: 19.177291
Rec Loss: 15.009536
KL Loss: 4.167755
Y Loss: 0.317165
T Loss: 11.497008
Epoch 599 
Overall Loss: 19.089689
Rec Loss: 14.866530
KL Loss: 4.223159
Y Loss: 0.297356
T Loss: 11.511409
Epoch 649 
Overall Loss: 19.035225
Rec Loss: 14.788893
KL Loss: 4.246332
Y Loss: 0.285091
T Loss: 11.509979
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.746856
Epoch 99
Rec Loss: 1.747615
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 7.347160
Epoch 99
Rec Loss: 7.337820
Epoch 149
Rec Loss: 7.351743
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.234904
Insample Error 2.560834
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.969342
Rec Loss: 16.595212
KL Loss: 1.374130
Y Loss: 2.277253
T Loss: 12.040706
Epoch 99 
Overall Loss: 14.873003
Rec Loss: 13.713022
KL Loss: 1.159981
Y Loss: 0.785417
T Loss: 12.142187
Epoch 149 
Overall Loss: 14.019975
Rec Loss: 13.250586
KL Loss: 0.769389
Y Loss: 0.612623
T Loss: 12.025340
Epoch 199 
Overall Loss: 13.487894
Rec Loss: 12.891208
KL Loss: 0.596686
Y Loss: 0.515327
T Loss: 11.860555
Epoch 249 
Overall Loss: 13.322027
Rec Loss: 12.735417
KL Loss: 0.586610
Y Loss: 0.485129
T Loss: 11.765160
Epoch 299 
Overall Loss: 13.228269
Rec Loss: 12.661046
KL Loss: 0.567224
Y Loss: 0.478754
T Loss: 11.703538
Epoch 349 
Overall Loss: 13.142147
Rec Loss: 12.573920
KL Loss: 0.568227
Y Loss: 0.454931
T Loss: 11.664057
Epoch 399 
Overall Loss: 13.059477
Rec Loss: 12.504830
KL Loss: 0.554647
Y Loss: 0.440840
T Loss: 11.623150
Epoch 449 
Overall Loss: 12.953619
Rec Loss: 12.401037
KL Loss: 0.552581
Y Loss: 0.403759
T Loss: 11.593520
Epoch 499 
Overall Loss: 12.857531
Rec Loss: 12.299656
KL Loss: 0.557875
Y Loss: 0.361207
T Loss: 11.577242
Epoch 549 
Overall Loss: 12.760370
Rec Loss: 12.185293
KL Loss: 0.575077
Y Loss: 0.313036
T Loss: 11.559220
Epoch 599 
Overall Loss: 12.696862
Rec Loss: 12.115809
KL Loss: 0.581053
Y Loss: 0.282653
T Loss: 11.550503
Epoch 649 
Overall Loss: 12.646008
Rec Loss: 12.076158
KL Loss: 0.569850
Y Loss: 0.262133
T Loss: 11.551893
Epoch 699 
Overall Loss: 12.593127
Rec Loss: 12.031703
KL Loss: 0.561423
Y Loss: 0.246174
T Loss: 11.539355
Epoch 749 
Overall Loss: 12.571753
Rec Loss: 12.031061
KL Loss: 0.540692
Y Loss: 0.240530
T Loss: 11.550001
Epoch 799 
Overall Loss: 12.555504
Rec Loss: 12.025388
KL Loss: 0.530116
Y Loss: 0.238242
T Loss: 11.548903
Epoch 849 
Overall Loss: 12.510140
Rec Loss: 11.990525
KL Loss: 0.519615
Y Loss: 0.224786
T Loss: 11.540952
Epoch 899 
Overall Loss: 12.502362
Rec Loss: 11.995589
KL Loss: 0.506773
Y Loss: 0.226985
T Loss: 11.541620
Epoch 949 
Overall Loss: 12.490280
Rec Loss: 11.982157
KL Loss: 0.508122
Y Loss: 0.222559
T Loss: 11.537039
Epoch 999 
Overall Loss: 12.444822
Rec Loss: 11.935072
KL Loss: 0.509750
Y Loss: 0.217172
T Loss: 11.500729
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.461487
Epoch 99
Rec Loss: 1.447710
Epoch 149
Rec Loss: 1.451700
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.999156
Epoch 99
Rec Loss: 9.994930
Epoch 149
Rec Loss: 9.990194
Epoch 199
Rec Loss: 9.992535
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.331020
Insample Error: 1.588805
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 28.402901
Rec Loss: 24.396089
KL Loss: 4.006812
Y Loss: 3.290282
T Loss: 12.247146
Epoch 99 
Overall Loss: 22.736132
Rec Loss: 19.486656
KL Loss: 3.249476
Y Loss: 0.942601
T Loss: 12.226453
Epoch 149 
Overall Loss: 21.074153
Rec Loss: 17.591143
KL Loss: 3.483010
Y Loss: 0.647979
T Loss: 11.794077
Epoch 199 
Overall Loss: 20.182349
Rec Loss: 16.235590
KL Loss: 3.946759
Y Loss: 0.534387
T Loss: 11.616109
Epoch 249 
Overall Loss: 19.900970
Rec Loss: 15.904875
KL Loss: 3.996095
Y Loss: 0.501646
T Loss: 11.548633
Epoch 299 
Overall Loss: 19.661869
Rec Loss: 15.741625
KL Loss: 3.920245
Y Loss: 0.469477
T Loss: 11.508935
Epoch 349 
Overall Loss: 19.519681
Rec Loss: 15.577307
KL Loss: 3.942375
Y Loss: 0.424210
T Loss: 11.495728
Epoch 399 
Overall Loss: 19.379900
Rec Loss: 15.436915
KL Loss: 3.942986
Y Loss: 0.369466
T Loss: 11.496341
Epoch 449 
Overall Loss: 19.247040
Rec Loss: 15.347483
KL Loss: 3.899557
Y Loss: 0.330164
T Loss: 11.483842
Epoch 499 
Overall Loss: 19.155360
Rec Loss: 15.302941
KL Loss: 3.852419
Y Loss: 0.301693
T Loss: 11.482524
Epoch 549 
Overall Loss: 19.081296
Rec Loss: 15.240051
KL Loss: 3.841245
Y Loss: 0.274425
T Loss: 11.485503
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.717641
Epoch 99
Rec Loss: 1.706517
Epoch 149
Rec Loss: 1.711700
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 7.454702
Epoch 99
Rec Loss: 7.432280
Epoch 149
Rec Loss: 7.421169
Epoch 199
Rec Loss: 7.419696
Epoch 249
Rec Loss: 7.434802
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.208369
Insample Error 2.568302
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.801800
Rec Loss: 16.290629
KL Loss: 1.511171
Y Loss: 2.114111
T Loss: 12.062407
Epoch 99 
Overall Loss: 14.709871
Rec Loss: 13.494936
KL Loss: 1.214934
Y Loss: 0.678118
T Loss: 12.138701
Epoch 149 
Overall Loss: 14.039585
Rec Loss: 13.103564
KL Loss: 0.936021
Y Loss: 0.547819
T Loss: 12.007926
Epoch 199 
Overall Loss: 13.500286
Rec Loss: 12.817271
KL Loss: 0.683015
Y Loss: 0.469427
T Loss: 11.878418
Epoch 249 
Overall Loss: 13.242487
Rec Loss: 12.621937
KL Loss: 0.620551
Y Loss: 0.430980
T Loss: 11.759976
Epoch 299 
Overall Loss: 13.131405
Rec Loss: 12.527018
KL Loss: 0.604386
Y Loss: 0.414738
T Loss: 11.697543
Epoch 349 
Overall Loss: 13.018188
Rec Loss: 12.413122
KL Loss: 0.605065
Y Loss: 0.378355
T Loss: 11.656413
Epoch 399 
Overall Loss: 12.946389
Rec Loss: 12.329056
KL Loss: 0.617333
Y Loss: 0.350132
T Loss: 11.628793
Epoch 449 
Overall Loss: 12.852847
Rec Loss: 12.209032
KL Loss: 0.643816
Y Loss: 0.310761
T Loss: 11.587509
Epoch 499 
Overall Loss: 12.789193
Rec Loss: 12.128229
KL Loss: 0.660964
Y Loss: 0.284456
T Loss: 11.559317
Epoch 549 
Overall Loss: 12.737295
Rec Loss: 12.075139
KL Loss: 0.662156
Y Loss: 0.263981
T Loss: 11.547177
Epoch 599 
Overall Loss: 12.681403
Rec Loss: 12.023841
KL Loss: 0.657562
Y Loss: 0.248758
T Loss: 11.526324
Epoch 649 
Overall Loss: 12.657112
Rec Loss: 12.010511
KL Loss: 0.646602
Y Loss: 0.242356
T Loss: 11.525799
Epoch 699 
Overall Loss: 12.620189
Rec Loss: 11.992796
KL Loss: 0.627393
Y Loss: 0.233968
T Loss: 11.524860
Epoch 749 
Overall Loss: 12.580592
Rec Loss: 11.970908
KL Loss: 0.609684
Y Loss: 0.225189
T Loss: 11.520529
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.604516
Epoch 99
Rec Loss: 1.601807
Epoch 149
Rec Loss: 1.597773
Epoch 199
Rec Loss: 1.599626
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.999341
Epoch 99
Rec Loss: 9.990642
Epoch 149
Rec Loss: 10.000528
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.309671
Insample Error: 1.951978
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 28.415154
Rec Loss: 24.678794
KL Loss: 3.736360
Y Loss: 3.427676
T Loss: 12.241620
Epoch 99 
Overall Loss: 22.667437
Rec Loss: 19.594575
KL Loss: 3.072862
Y Loss: 0.924036
T Loss: 12.311439
Epoch 149 
Overall Loss: 21.121689
Rec Loss: 18.222105
KL Loss: 2.899583
Y Loss: 0.602745
T Loss: 11.921561
Epoch 199 
Overall Loss: 20.258343
Rec Loss: 17.124309
KL Loss: 3.134035
Y Loss: 0.447948
T Loss: 11.633683
Epoch 249 
Overall Loss: 19.756048
Rec Loss: 16.258763
KL Loss: 3.497285
Y Loss: 0.391367
T Loss: 11.546285
Epoch 299 
Overall Loss: 19.542745
Rec Loss: 15.892701
KL Loss: 3.650044
Y Loss: 0.363832
T Loss: 11.502556
Epoch 349 
Overall Loss: 19.428571
Rec Loss: 15.782834
KL Loss: 3.645737
Y Loss: 0.345708
T Loss: 11.503348
Epoch 399 
Overall Loss: 19.269810
Rec Loss: 15.647807
KL Loss: 3.622004
Y Loss: 0.321057
T Loss: 11.492710
Epoch 449 
Overall Loss: 19.180397
Rec Loss: 15.555690
KL Loss: 3.624707
Y Loss: 0.282188
T Loss: 11.495980
Epoch 499 
Overall Loss: 19.122353
Rec Loss: 15.493534
KL Loss: 3.628818
Y Loss: 0.262038
T Loss: 11.497193
Epoch 549 
Overall Loss: 19.082471
Rec Loss: 15.451937
KL Loss: 3.630535
Y Loss: 0.260089
T Loss: 11.483675
Epoch 599 
Overall Loss: 19.005172
Rec Loss: 15.373128
KL Loss: 3.632044
Y Loss: 0.251530
T Loss: 11.469736
Epoch 649 
Overall Loss: 18.988938
Rec Loss: 15.334112
KL Loss: 3.654827
Y Loss: 0.255387
T Loss: 11.479920
Epoch 699 
Overall Loss: 18.929217
Rec Loss: 15.227708
KL Loss: 3.701510
Y Loss: 0.244914
T Loss: 11.465742
Epoch 749 
Overall Loss: 18.879090
Rec Loss: 15.137782
KL Loss: 3.741308
Y Loss: 0.243321
T Loss: 11.467197
Epoch 799 
Overall Loss: 18.789102
Rec Loss: 14.993690
KL Loss: 3.795412
Y Loss: 0.238535
T Loss: 11.457510
Epoch 849 
Overall Loss: 18.754639
Rec Loss: 14.920226
KL Loss: 3.834413
Y Loss: 0.240357
T Loss: 11.454644
Epoch 899 
Overall Loss: 18.700798
Rec Loss: 14.836060
KL Loss: 3.864738
Y Loss: 0.237787
T Loss: 11.452150
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.694322
Epoch 99
Rec Loss: 1.691537
Epoch 149
Rec Loss: 1.691797
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 7.377336
Epoch 99
Rec Loss: 7.357640
Epoch 149
Rec Loss: 7.353959
Epoch 199
Rec Loss: 7.335217
Epoch 249
Rec Loss: 7.350201
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.228919
Insample Error 2.344634
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 19.844829
Rec Loss: 18.637796
KL Loss: 1.207033
Y Loss: 3.263981
T Loss: 12.109833
Epoch 99 
Overall Loss: 14.939128
Rec Loss: 13.828328
KL Loss: 1.110800
Y Loss: 0.811838
T Loss: 12.204651
Epoch 149 
Overall Loss: 13.928044
Rec Loss: 13.185854
KL Loss: 0.742191
Y Loss: 0.554341
T Loss: 12.077172
Epoch 199 
Overall Loss: 13.436570
Rec Loss: 12.862449
KL Loss: 0.574121
Y Loss: 0.476268
T Loss: 11.909912
Epoch 249 
Overall Loss: 13.226967
Rec Loss: 12.659745
KL Loss: 0.567221
Y Loss: 0.434990
T Loss: 11.789765
Epoch 299 
Overall Loss: 13.111918
Rec Loss: 12.545173
KL Loss: 0.566745
Y Loss: 0.415452
T Loss: 11.714269
Epoch 349 
Overall Loss: 13.003733
Rec Loss: 12.417464
KL Loss: 0.586270
Y Loss: 0.387605
T Loss: 11.642255
Epoch 399 
Overall Loss: 12.910218
Rec Loss: 12.301284
KL Loss: 0.608934
Y Loss: 0.351891
T Loss: 11.597501
Epoch 449 
Overall Loss: 12.823378
Rec Loss: 12.195035
KL Loss: 0.628343
Y Loss: 0.308747
T Loss: 11.577540
Epoch 499 
Overall Loss: 12.746381
Rec Loss: 12.106949
KL Loss: 0.639432
Y Loss: 0.275965
T Loss: 11.555019
Epoch 549 
Overall Loss: 12.704231
Rec Loss: 12.066783
KL Loss: 0.637448
Y Loss: 0.258919
T Loss: 11.548945
Epoch 599 
Overall Loss: 12.677950
Rec Loss: 12.052947
KL Loss: 0.625003
Y Loss: 0.247148
T Loss: 11.558651
Epoch 649 
Overall Loss: 12.633709
Rec Loss: 12.025617
KL Loss: 0.608092
Y Loss: 0.238648
T Loss: 11.548321
Epoch 699 
Overall Loss: 12.606701
Rec Loss: 12.016758
KL Loss: 0.589944
Y Loss: 0.233678
T Loss: 11.549402
Epoch 749 
Overall Loss: 12.568653
Rec Loss: 11.994128
KL Loss: 0.574525
Y Loss: 0.220076
T Loss: 11.553976
Epoch 799 
Overall Loss: 12.546840
Rec Loss: 11.991082
KL Loss: 0.555758
Y Loss: 0.214033
T Loss: 11.563016
Epoch 849 
Overall Loss: 12.520287
Rec Loss: 11.989074
KL Loss: 0.531213
Y Loss: 0.209566
T Loss: 11.569941
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.556270
Epoch 99
Rec Loss: 1.551633
Epoch 149
Rec Loss: 1.558802
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.997804
Epoch 99
Rec Loss: 9.998213
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.306384
Insample Error: 1.689530
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 28.209988
Rec Loss: 24.482906
KL Loss: 3.727083
Y Loss: 3.328913
T Loss: 12.286519
Epoch 99 
Overall Loss: 22.800933
Rec Loss: 19.453425
KL Loss: 3.347508
Y Loss: 0.975849
T Loss: 12.416329
Epoch 149 
Overall Loss: 20.912963
Rec Loss: 16.966925
KL Loss: 3.946039
Y Loss: 0.619516
T Loss: 11.947805
Epoch 199 
Overall Loss: 20.238048
Rec Loss: 16.043921
KL Loss: 4.194128
Y Loss: 0.535185
T Loss: 11.684611
Epoch 249 
Overall Loss: 19.901773
Rec Loss: 15.676626
KL Loss: 4.225147
Y Loss: 0.468677
T Loss: 11.579344
Epoch 299 
Overall Loss: 19.692507
Rec Loss: 15.431791
KL Loss: 4.260716
Y Loss: 0.430565
T Loss: 11.533927
Epoch 349 
Overall Loss: 19.499815
Rec Loss: 15.205838
KL Loss: 4.293977
Y Loss: 0.392176
T Loss: 11.490132
Epoch 399 
Overall Loss: 19.406682
Rec Loss: 15.064788
KL Loss: 4.341894
Y Loss: 0.373663
T Loss: 11.466828
Epoch 449 
Overall Loss: 19.262004
Rec Loss: 14.859962
KL Loss: 4.402043
Y Loss: 0.331716
T Loss: 11.465355
Epoch 499 
Overall Loss: 19.183910
Rec Loss: 14.757041
KL Loss: 4.426869
Y Loss: 0.314014
T Loss: 11.471975
Epoch 549 
Overall Loss: 19.132385
Rec Loss: 14.696327
KL Loss: 4.436058
Y Loss: 0.303522
T Loss: 11.473424
Epoch 599 
Overall Loss: 19.043490
Rec Loss: 14.543292
KL Loss: 4.500199
Y Loss: 0.283106
T Loss: 11.461538
Epoch 649 
Overall Loss: 19.052206
Rec Loss: 14.524049
KL Loss: 4.528158
Y Loss: 0.270429
T Loss: 11.462181
Epoch 699 
Overall Loss: 18.993199
Rec Loss: 14.474403
KL Loss: 4.518795
Y Loss: 0.274414
T Loss: 11.465341
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.720715
Epoch 99
Rec Loss: 1.721412
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 7.283150
Epoch 99
Rec Loss: 7.284627
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.212582
Insample Error 2.596237
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 18.648175
Rec Loss: 17.494630
KL Loss: 1.153545
Y Loss: 2.699851
T Loss: 12.094929
Epoch 99 
Overall Loss: 14.765233
Rec Loss: 13.730352
KL Loss: 1.034881
Y Loss: 0.770866
T Loss: 12.188620
Epoch 149 
Overall Loss: 13.888638
Rec Loss: 13.181355
KL Loss: 0.707283
Y Loss: 0.566477
T Loss: 12.048402
Epoch 199 
Overall Loss: 13.503724
Rec Loss: 12.886372
KL Loss: 0.617351
Y Loss: 0.486652
T Loss: 11.913069
Epoch 249 
Overall Loss: 13.358806
Rec Loss: 12.753843
KL Loss: 0.604963
Y Loss: 0.459977
T Loss: 11.833888
Epoch 299 
Overall Loss: 13.234986
Rec Loss: 12.644527
KL Loss: 0.590460
Y Loss: 0.449449
T Loss: 11.745628
Epoch 349 
Overall Loss: 13.121187
Rec Loss: 12.533649
KL Loss: 0.587539
Y Loss: 0.430711
T Loss: 11.672227
Epoch 399 
Overall Loss: 12.993725
Rec Loss: 12.388685
KL Loss: 0.605040
Y Loss: 0.385077
T Loss: 11.618532
Epoch 449 
Overall Loss: 12.874729
Rec Loss: 12.235934
KL Loss: 0.638795
Y Loss: 0.330400
T Loss: 11.575134
Epoch 499 
Overall Loss: 12.801261
Rec Loss: 12.139589
KL Loss: 0.661672
Y Loss: 0.297320
T Loss: 11.544949
Epoch 549 
Overall Loss: 12.746190
Rec Loss: 12.080399
KL Loss: 0.665791
Y Loss: 0.274536
T Loss: 11.531325
Epoch 599 
Overall Loss: 12.716207
Rec Loss: 12.045044
KL Loss: 0.671163
Y Loss: 0.259822
T Loss: 11.525399
Epoch 649 
Overall Loss: 12.685323
Rec Loss: 12.023453
KL Loss: 0.661871
Y Loss: 0.251325
T Loss: 11.520803
Epoch 699 
Overall Loss: 12.657390
Rec Loss: 12.007952
KL Loss: 0.649438
Y Loss: 0.245403
T Loss: 11.517146
Epoch 749 
Overall Loss: 12.620819
Rec Loss: 11.991736
KL Loss: 0.629082
Y Loss: 0.240810
T Loss: 11.510117
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.592516
Epoch 99
Rec Loss: 1.594925
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.997081
Epoch 99
Rec Loss: 9.985695
Epoch 149
Rec Loss: 9.995637
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.311812
Insample Error: 2.112700
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 29.122983
Rec Loss: 25.533518
KL Loss: 3.589465
Y Loss: 3.833252
T Loss: 12.235946
Epoch 99 
Overall Loss: 23.222328
Rec Loss: 20.180835
KL Loss: 3.041494
Y Loss: 1.125798
T Loss: 12.364444
Epoch 149 
Overall Loss: 21.278499
Rec Loss: 17.989563
KL Loss: 3.288935
Y Loss: 0.686579
T Loss: 11.875467
Epoch 199 
Overall Loss: 20.211399
Rec Loss: 16.422588
KL Loss: 3.788812
Y Loss: 0.500825
T Loss: 11.649120
Epoch 249 
Overall Loss: 19.807741
Rec Loss: 15.914580
KL Loss: 3.893161
Y Loss: 0.441773
T Loss: 11.583390
Epoch 299 
Overall Loss: 19.624733
Rec Loss: 15.713314
KL Loss: 3.911419
Y Loss: 0.406352
T Loss: 11.563227
Epoch 349 
Overall Loss: 19.436912
Rec Loss: 15.528535
KL Loss: 3.908377
Y Loss: 0.361316
T Loss: 11.546465
Epoch 399 
Overall Loss: 19.288547
Rec Loss: 15.384275
KL Loss: 3.904272
Y Loss: 0.320260
T Loss: 11.528076
Epoch 449 
Overall Loss: 19.232372
Rec Loss: 15.339421
KL Loss: 3.892950
Y Loss: 0.295806
T Loss: 11.525338
Epoch 499 
Overall Loss: 19.161183
Rec Loss: 15.276673
KL Loss: 3.884509
Y Loss: 0.276797
T Loss: 11.515005
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.729407
Epoch 99
Rec Loss: 1.710737
Epoch 149
Rec Loss: 1.709419
Epoch 199
Rec Loss: 1.705697
Epoch 249
Rec Loss: 1.706913
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 7.451848
Epoch 99
Rec Loss: 7.435467
Epoch 149
Rec Loss: 7.432929
Epoch 199
Rec Loss: 7.438072
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.197130
Insample Error 2.583302
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 20.520429
Rec Loss: 19.366061
KL Loss: 1.154369
Y Loss: 3.641284
T Loss: 12.083492
Epoch 99 
Overall Loss: 15.168216
Rec Loss: 14.011897
KL Loss: 1.156319
Y Loss: 0.900762
T Loss: 12.210373
Epoch 149 
Overall Loss: 14.001655
Rec Loss: 13.231980
KL Loss: 0.769675
Y Loss: 0.586369
T Loss: 12.059243
Epoch 199 
Overall Loss: 13.464953
Rec Loss: 12.838249
KL Loss: 0.626704
Y Loss: 0.479390
T Loss: 11.879469
Epoch 249 
Overall Loss: 13.311255
Rec Loss: 12.706927
KL Loss: 0.604328
Y Loss: 0.454836
T Loss: 11.797255
Epoch 299 
Overall Loss: 13.175484
Rec Loss: 12.600068
KL Loss: 0.575416
Y Loss: 0.447313
T Loss: 11.705441
Epoch 349 
Overall Loss: 13.083107
Rec Loss: 12.529367
KL Loss: 0.553739
Y Loss: 0.435855
T Loss: 11.657657
Epoch 399 
Overall Loss: 12.994396
Rec Loss: 12.444722
KL Loss: 0.549675
Y Loss: 0.410401
T Loss: 11.623920
Epoch 449 
Overall Loss: 12.910155
Rec Loss: 12.359757
KL Loss: 0.550398
Y Loss: 0.376634
T Loss: 11.606489
Epoch 499 
Overall Loss: 12.814151
Rec Loss: 12.257776
KL Loss: 0.556375
Y Loss: 0.333930
T Loss: 11.589916
Epoch 549 
Overall Loss: 12.739805
Rec Loss: 12.177693
KL Loss: 0.562112
Y Loss: 0.294446
T Loss: 11.588801
Epoch 599 
Overall Loss: 12.672329
Rec Loss: 12.114484
KL Loss: 0.557844
Y Loss: 0.265722
T Loss: 11.583040
Epoch 649 
Overall Loss: 12.638734
Rec Loss: 12.090329
KL Loss: 0.548405
Y Loss: 0.253176
T Loss: 11.583976
Epoch 699 
Overall Loss: 12.598243
Rec Loss: 12.065677
KL Loss: 0.532566
Y Loss: 0.241184
T Loss: 11.583309
Epoch 749 
Overall Loss: 12.567421
Rec Loss: 12.048706
KL Loss: 0.518716
Y Loss: 0.231274
T Loss: 11.586158
Epoch 799 
Overall Loss: 12.534028
Rec Loss: 12.038500
KL Loss: 0.495528
Y Loss: 0.223223
T Loss: 11.592053
Epoch 849 
Overall Loss: 12.517013
Rec Loss: 12.035761
KL Loss: 0.481253
Y Loss: 0.222790
T Loss: 11.590180
Epoch 899 
Overall Loss: 12.491899
Rec Loss: 12.035187
KL Loss: 0.456712
Y Loss: 0.217295
T Loss: 11.600596
Epoch 949 
Overall Loss: 12.488913
Rec Loss: 12.038489
KL Loss: 0.450423
Y Loss: 0.219648
T Loss: 11.599194
Epoch 999 
Overall Loss: 12.464262
Rec Loss: 12.029797
KL Loss: 0.434465
Y Loss: 0.215822
T Loss: 11.598154
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.579529
Epoch 99
Rec Loss: 1.579690
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.991029
Epoch 99
Rec Loss: 9.984130
Epoch 149
Rec Loss: 9.990371
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.333284
Insample Error: 1.564540
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 30.643585
Rec Loss: 27.198592
KL Loss: 3.444993
Y Loss: 4.689830
T Loss: 12.235564
Epoch 99 
Overall Loss: 23.258155
Rec Loss: 20.076706
KL Loss: 3.181449
Y Loss: 1.097689
T Loss: 12.468242
Epoch 149 
Overall Loss: 21.124337
Rec Loss: 17.410900
KL Loss: 3.713438
Y Loss: 0.661068
T Loss: 12.127063
Epoch 199 
Overall Loss: 20.188135
Rec Loss: 16.035817
KL Loss: 4.152319
Y Loss: 0.515803
T Loss: 11.724294
Epoch 249 
Overall Loss: 19.895783
Rec Loss: 15.620797
KL Loss: 4.274987
Y Loss: 0.468568
T Loss: 11.641074
Epoch 299 
Overall Loss: 19.691964
Rec Loss: 15.310367
KL Loss: 4.381597
Y Loss: 0.429141
T Loss: 11.583926
Epoch 349 
Overall Loss: 19.518935
Rec Loss: 15.005349
KL Loss: 4.513586
Y Loss: 0.398387
T Loss: 11.560837
Epoch 399 
Overall Loss: 19.379652
Rec Loss: 14.691203
KL Loss: 4.688449
Y Loss: 0.368654
T Loss: 11.540606
Epoch 449 
Overall Loss: 19.252177
Rec Loss: 14.413104
KL Loss: 4.839073
Y Loss: 0.330409
T Loss: 11.525892
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.737611
Epoch 99
Rec Loss: 1.739371
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 7.170337
Epoch 99
Rec Loss: 7.169713
Epoch 149
Rec Loss: 7.159776
Epoch 199
Rec Loss: 7.163599
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.246333
Insample Error 2.633155
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.439854
Rec Loss: 16.201866
KL Loss: 1.237988
Y Loss: 2.065831
T Loss: 12.070204
Epoch 99 
Overall Loss: 14.547529
Rec Loss: 13.453249
KL Loss: 1.094281
Y Loss: 0.676191
T Loss: 12.100866
Epoch 149 
Overall Loss: 13.768378
Rec Loss: 12.980740
KL Loss: 0.787637
Y Loss: 0.483649
T Loss: 12.013442
Epoch 199 
Overall Loss: 13.331585
Rec Loss: 12.716713
KL Loss: 0.614872
Y Loss: 0.417418
T Loss: 11.881877
Epoch 249 
Overall Loss: 13.171246
Rec Loss: 12.563723
KL Loss: 0.607523
Y Loss: 0.388112
T Loss: 11.787499
Epoch 299 
Overall Loss: 13.058423
Rec Loss: 12.450024
KL Loss: 0.608399
Y Loss: 0.363689
T Loss: 11.722646
Epoch 349 
Overall Loss: 12.927107
Rec Loss: 12.305824
KL Loss: 0.621283
Y Loss: 0.329338
T Loss: 11.647147
Epoch 399 
Overall Loss: 12.836694
Rec Loss: 12.205423
KL Loss: 0.631271
Y Loss: 0.302923
T Loss: 11.599577
Epoch 449 
Overall Loss: 12.777031
Rec Loss: 12.119784
KL Loss: 0.657247
Y Loss: 0.280487
T Loss: 11.558810
Epoch 499 
Overall Loss: 12.731250
Rec Loss: 12.062283
KL Loss: 0.668968
Y Loss: 0.265179
T Loss: 11.531925
Epoch 549 
Overall Loss: 12.696782
Rec Loss: 12.037361
KL Loss: 0.659422
Y Loss: 0.256240
T Loss: 11.524880
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.620082
Epoch 99
Rec Loss: 1.615118
Epoch 149
Rec Loss: 1.617027
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.004094
Epoch 99
Rec Loss: 10.000593
Epoch 149
Rec Loss: 10.004729
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.329992
Insample Error: 2.259518
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 29.091491
Rec Loss: 25.421968
KL Loss: 3.669523
Y Loss: 3.814260
T Loss: 12.241479
Epoch 99 
Overall Loss: 23.097310
Rec Loss: 19.865840
KL Loss: 3.231470
Y Loss: 1.062149
T Loss: 12.436874
Epoch 149 
Overall Loss: 21.100362
Rec Loss: 17.403844
KL Loss: 3.696518
Y Loss: 0.662616
T Loss: 12.109527
Epoch 199 
Overall Loss: 20.226953
Rec Loss: 16.156574
KL Loss: 4.070379
Y Loss: 0.512900
T Loss: 11.757005
Epoch 249 
Overall Loss: 19.865834
Rec Loss: 15.766852
KL Loss: 4.098981
Y Loss: 0.442874
T Loss: 11.668269
Epoch 299 
Overall Loss: 19.638494
Rec Loss: 15.528532
KL Loss: 4.109962
Y Loss: 0.398508
T Loss: 11.607758
Epoch 349 
Overall Loss: 19.396743
Rec Loss: 15.167814
KL Loss: 4.228930
Y Loss: 0.351294
T Loss: 11.572040
Epoch 399 
Overall Loss: 19.246008
Rec Loss: 14.845675
KL Loss: 4.400333
Y Loss: 0.310122
T Loss: 11.540880
Epoch 449 
Overall Loss: 19.142626
Rec Loss: 14.643740
KL Loss: 4.498887
Y Loss: 0.290297
T Loss: 11.521243
Epoch 499 
Overall Loss: 19.081459
Rec Loss: 14.542916
KL Loss: 4.538542
Y Loss: 0.278590
T Loss: 11.501773
Epoch 549 
Overall Loss: 19.035941
Rec Loss: 14.475449
KL Loss: 4.560492
Y Loss: 0.273193
T Loss: 11.499938
Epoch 599 
Overall Loss: 18.971773
Rec Loss: 14.399205
KL Loss: 4.572569
Y Loss: 0.277032
T Loss: 11.476591
Epoch 649 
Overall Loss: 18.923958
Rec Loss: 14.339011
KL Loss: 4.584947
Y Loss: 0.266439
T Loss: 11.474189
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.712320
Epoch 99
Rec Loss: 1.692448
Epoch 149
Rec Loss: 1.700347
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 7.238430
Epoch 99
Rec Loss: 7.219182
Epoch 149
Rec Loss: 7.216630
Epoch 199
Rec Loss: 7.228477
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.229515
Insample Error 2.482843
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 19.192725
Rec Loss: 17.915752
KL Loss: 1.276972
Y Loss: 2.895154
T Loss: 12.125445
Epoch 99 
Overall Loss: 15.139336
Rec Loss: 13.947950
KL Loss: 1.191386
Y Loss: 0.859620
T Loss: 12.228711
Epoch 149 
Overall Loss: 14.061523
Rec Loss: 13.215768
KL Loss: 0.845755
Y Loss: 0.577283
T Loss: 12.061203
Epoch 199 
Overall Loss: 13.480877
Rec Loss: 12.802604
KL Loss: 0.678272
Y Loss: 0.468732
T Loss: 11.865141
Epoch 249 
Overall Loss: 13.266368
Rec Loss: 12.614047
KL Loss: 0.652321
Y Loss: 0.428615
T Loss: 11.756818
Epoch 299 
Overall Loss: 13.114653
Rec Loss: 12.483373
KL Loss: 0.631280
Y Loss: 0.403119
T Loss: 11.677134
Epoch 349 
Overall Loss: 12.969215
Rec Loss: 12.333921
KL Loss: 0.635295
Y Loss: 0.356658
T Loss: 11.620605
Epoch 399 
Overall Loss: 12.845690
Rec Loss: 12.196199
KL Loss: 0.649491
Y Loss: 0.312088
T Loss: 11.572022
Epoch 449 
Overall Loss: 12.773133
Rec Loss: 12.114651
KL Loss: 0.658482
Y Loss: 0.283707
T Loss: 11.547237
Epoch 499 
Overall Loss: 12.723214
Rec Loss: 12.059321
KL Loss: 0.663893
Y Loss: 0.259519
T Loss: 11.540282
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.632463
Epoch 99
Rec Loss: 1.631241
Epoch 149
Rec Loss: 1.624800
Epoch 199
Rec Loss: 1.627573
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.002780
Epoch 99
Rec Loss: 9.999956
Epoch 149
Rec Loss: 9.997897
Epoch 199
Rec Loss: 10.000478
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.326717
Insample Error: 2.237197
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 28.722876
Rec Loss: 24.952788
KL Loss: 3.770087
Y Loss: 3.545096
T Loss: 12.290274
Epoch 99 
Overall Loss: 23.038200
Rec Loss: 19.871817
KL Loss: 3.166383
Y Loss: 1.034047
T Loss: 12.459756
Epoch 149 
Overall Loss: 21.054263
Rec Loss: 17.225402
KL Loss: 3.828860
Y Loss: 0.681871
T Loss: 11.978501
Epoch 199 
Overall Loss: 20.179999
Rec Loss: 16.012107
KL Loss: 4.167892
Y Loss: 0.534765
T Loss: 11.664719
Epoch 249 
Overall Loss: 19.919284
Rec Loss: 15.706846
KL Loss: 4.212438
Y Loss: 0.496408
T Loss: 11.582542
Epoch 299 
Overall Loss: 19.728757
Rec Loss: 15.527008
KL Loss: 4.201748
Y Loss: 0.476853
T Loss: 11.530891
Epoch 349 
Overall Loss: 19.551197
Rec Loss: 15.298638
KL Loss: 4.252559
Y Loss: 0.427540
T Loss: 11.508057
Epoch 399 
Overall Loss: 19.387871
Rec Loss: 14.992683
KL Loss: 4.395188
Y Loss: 0.391029
T Loss: 11.479875
Epoch 449 
Overall Loss: 19.283889
Rec Loss: 14.747413
KL Loss: 4.536476
Y Loss: 0.360460
T Loss: 11.461639
Epoch 499 
Overall Loss: 19.208542
Rec Loss: 14.627528
KL Loss: 4.581015
Y Loss: 0.339868
T Loss: 11.447514
Epoch 549 
Overall Loss: 19.109062
Rec Loss: 14.508826
KL Loss: 4.600237
Y Loss: 0.308309
T Loss: 11.449319
Epoch 599 
Overall Loss: 19.085708
Rec Loss: 14.479830
KL Loss: 4.605877
Y Loss: 0.297839
T Loss: 11.449340
Epoch 649 
Overall Loss: 19.040440
Rec Loss: 14.502748
KL Loss: 4.537692
Y Loss: 0.287262
T Loss: 11.463157
Epoch 699 
Overall Loss: 18.984854
Rec Loss: 14.474248
KL Loss: 4.510607
Y Loss: 0.278518
T Loss: 11.453274
Epoch 749 
Overall Loss: 18.890277
Rec Loss: 14.450637
KL Loss: 4.439639
Y Loss: 0.263187
T Loss: 11.466157
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.716903
Epoch 99
Rec Loss: 1.711271
Epoch 149
Rec Loss: 1.701871
Epoch 199
Rec Loss: 1.712989
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 7.277499
Epoch 99
Rec Loss: 7.253372
Epoch 149
Rec Loss: 7.264521
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.228525
Insample Error 2.432082
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 18.263889
Rec Loss: 17.063872
KL Loss: 1.200017
Y Loss: 2.472644
T Loss: 12.118583
Epoch 99 
Overall Loss: 14.948578
Rec Loss: 13.904804
KL Loss: 1.043774
Y Loss: 0.855240
T Loss: 12.194324
Epoch 149 
Overall Loss: 13.960130
Rec Loss: 13.251926
KL Loss: 0.708205
Y Loss: 0.598287
T Loss: 12.055352
Epoch 199 
Overall Loss: 13.462431
Rec Loss: 12.892299
KL Loss: 0.570132
Y Loss: 0.500510
T Loss: 11.891280
Epoch 249 
Overall Loss: 13.265417
Rec Loss: 12.710881
KL Loss: 0.554536
Y Loss: 0.457617
T Loss: 11.795647
Epoch 299 
Overall Loss: 13.190338
Rec Loss: 12.647404
KL Loss: 0.542934
Y Loss: 0.454106
T Loss: 11.739193
Epoch 349 
Overall Loss: 13.089877
Rec Loss: 12.557975
KL Loss: 0.531903
Y Loss: 0.434595
T Loss: 11.688784
Epoch 399 
Overall Loss: 13.012225
Rec Loss: 12.487335
KL Loss: 0.524890
Y Loss: 0.416861
T Loss: 11.653614
Epoch 449 
Overall Loss: 12.914215
Rec Loss: 12.394342
KL Loss: 0.519873
Y Loss: 0.375301
T Loss: 11.643739
Epoch 499 
Overall Loss: 12.812743
Rec Loss: 12.298295
KL Loss: 0.514448
Y Loss: 0.336438
T Loss: 11.625419
Epoch 549 
Overall Loss: 12.733127
Rec Loss: 12.210195
KL Loss: 0.522932
Y Loss: 0.296562
T Loss: 11.617072
Epoch 599 
Overall Loss: 12.668854
Rec Loss: 12.147236
KL Loss: 0.521618
Y Loss: 0.271118
T Loss: 11.605000
Epoch 649 
Overall Loss: 12.617592
Rec Loss: 12.095777
KL Loss: 0.521816
Y Loss: 0.250557
T Loss: 11.594662
Epoch 699 
Overall Loss: 12.576643
Rec Loss: 12.063862
KL Loss: 0.512780
Y Loss: 0.234085
T Loss: 11.595693
Epoch 749 
Overall Loss: 12.550420
Rec Loss: 12.039832
KL Loss: 0.510588
Y Loss: 0.229348
T Loss: 11.581135
Epoch 799 
Overall Loss: 12.536056
Rec Loss: 12.030620
KL Loss: 0.505436
Y Loss: 0.227957
T Loss: 11.574705
Epoch 849 
Overall Loss: 12.501247
Rec Loss: 11.996578
KL Loss: 0.504668
Y Loss: 0.214838
T Loss: 11.566902
Epoch 899 
Overall Loss: 12.488374
Rec Loss: 11.982829
KL Loss: 0.505545
Y Loss: 0.214838
T Loss: 11.553152
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.518725
Epoch 99
Rec Loss: 1.521722
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.972791
Epoch 99
Rec Loss: 9.970757
Epoch 149
Rec Loss: 9.975783
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.317333
Insample Error: 1.652859
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 28.548592
Rec Loss: 24.280971
KL Loss: 4.267620
Y Loss: 3.271068
T Loss: 12.214826
Epoch 99 
Overall Loss: 23.034243
Rec Loss: 19.824696
KL Loss: 3.209547
Y Loss: 0.964887
T Loss: 12.438060
Epoch 149 
Overall Loss: 21.282429
Rec Loss: 17.516862
KL Loss: 3.765567
Y Loss: 0.669302
T Loss: 12.145613
Epoch 199 
Overall Loss: 20.331554
Rec Loss: 16.094451
KL Loss: 4.237103
Y Loss: 0.543405
T Loss: 11.775179
Epoch 249 
Overall Loss: 19.971317
Rec Loss: 15.658135
KL Loss: 4.313182
Y Loss: 0.505536
T Loss: 11.622248
Epoch 299 
Overall Loss: 19.708182
Rec Loss: 15.325527
KL Loss: 4.382655
Y Loss: 0.459981
T Loss: 11.557986
Epoch 349 
Overall Loss: 19.507968
Rec Loss: 14.945075
KL Loss: 4.562892
Y Loss: 0.421246
T Loss: 11.500181
Epoch 399 
Overall Loss: 19.353584
Rec Loss: 14.554472
KL Loss: 4.799111
Y Loss: 0.392205
T Loss: 11.470294
Epoch 449 
Overall Loss: 19.240931
Rec Loss: 14.307023
KL Loss: 4.933908
Y Loss: 0.350840
T Loss: 11.460976
Epoch 499 
Overall Loss: 19.182580
Rec Loss: 14.217711
KL Loss: 4.964870
Y Loss: 0.346088
T Loss: 11.455450
Epoch 549 
Overall Loss: 19.088770
Rec Loss: 14.092532
KL Loss: 4.996238
Y Loss: 0.334951
T Loss: 11.455147
Epoch 599 
Overall Loss: 19.042233
Rec Loss: 13.982996
KL Loss: 5.059237
Y Loss: 0.315656
T Loss: 11.467673
Epoch 649 
Overall Loss: 18.990904
Rec Loss: 13.886491
KL Loss: 5.104413
Y Loss: 0.305169
T Loss: 11.487895
Epoch 699 
Overall Loss: 18.935452
Rec Loss: 13.824775
KL Loss: 5.110676
Y Loss: 0.298431
T Loss: 11.487843
Epoch 749 
Overall Loss: 18.871240
Rec Loss: 13.727181
KL Loss: 5.144059
Y Loss: 0.297737
T Loss: 11.486758
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.720395
Epoch 99
Rec Loss: 1.715434
Epoch 149
Rec Loss: 1.719642
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.970718
Epoch 99
Rec Loss: 6.965061
Epoch 149
Rec Loss: 6.954709
Epoch 199
Rec Loss: 6.943691
Epoch 249
Rec Loss: 6.945568
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.256672
Insample Error 2.517711
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 19.175737
Rec Loss: 17.974244
KL Loss: 1.201493
Y Loss: 2.918748
T Loss: 12.136748
Epoch 99 
Overall Loss: 14.840965
Rec Loss: 13.728726
KL Loss: 1.112239
Y Loss: 0.760138
T Loss: 12.208450
Epoch 149 
Overall Loss: 13.943306
Rec Loss: 13.089048
KL Loss: 0.854258
Y Loss: 0.508651
T Loss: 12.071745
Epoch 199 
Overall Loss: 13.444374
Rec Loss: 12.773851
KL Loss: 0.670523
Y Loss: 0.423306
T Loss: 11.927240
Epoch 249 
Overall Loss: 13.247870
Rec Loss: 12.623091
KL Loss: 0.624779
Y Loss: 0.407663
T Loss: 11.807765
Epoch 299 
Overall Loss: 13.104610
Rec Loss: 12.492641
KL Loss: 0.611969
Y Loss: 0.378296
T Loss: 11.736049
Epoch 349 
Overall Loss: 13.010897
Rec Loss: 12.405146
KL Loss: 0.605752
Y Loss: 0.360818
T Loss: 11.683509
Epoch 399 
Overall Loss: 12.929614
Rec Loss: 12.306894
KL Loss: 0.622719
Y Loss: 0.331963
T Loss: 11.642969
Epoch 449 
Overall Loss: 12.851165
Rec Loss: 12.209158
KL Loss: 0.642008
Y Loss: 0.305109
T Loss: 11.598940
Epoch 499 
Overall Loss: 12.782402
Rec Loss: 12.127616
KL Loss: 0.654786
Y Loss: 0.278952
T Loss: 11.569712
Epoch 549 
Overall Loss: 12.744362
Rec Loss: 12.073004
KL Loss: 0.671358
Y Loss: 0.263396
T Loss: 11.546213
Epoch 599 
Overall Loss: 12.692313
Rec Loss: 12.029152
KL Loss: 0.663160
Y Loss: 0.251397
T Loss: 11.526358
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.622405
Epoch 99
Rec Loss: 1.615285
Epoch 149
Rec Loss: 1.612061
Epoch 199
Rec Loss: 1.612889
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.013798
Epoch 99
Rec Loss: 10.011229
Epoch 149
Rec Loss: 10.010974
Epoch 199
Rec Loss: 10.011431
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.309667
Insample Error: 2.187749
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 28.394553
Rec Loss: 24.750739
KL Loss: 3.643815
Y Loss: 3.527195
T Loss: 12.172748
Epoch 99 
Overall Loss: 23.024802
Rec Loss: 19.858998
KL Loss: 3.165804
Y Loss: 1.037025
T Loss: 12.383729
Epoch 149 
Overall Loss: 21.431120
Rec Loss: 18.112432
KL Loss: 3.318689
Y Loss: 0.718207
T Loss: 12.049633
Epoch 199 
Overall Loss: 20.196228
Rec Loss: 16.228585
KL Loss: 3.967643
Y Loss: 0.534474
T Loss: 11.674154
Epoch 249 
Overall Loss: 19.889745
Rec Loss: 15.842201
KL Loss: 4.047545
Y Loss: 0.489668
T Loss: 11.604399
Epoch 299 
Overall Loss: 19.655243
Rec Loss: 15.625490
KL Loss: 4.029754
Y Loss: 0.452175
T Loss: 11.553466
Epoch 349 
Overall Loss: 19.517837
Rec Loss: 15.458350
KL Loss: 4.059487
Y Loss: 0.412450
T Loss: 11.525300
Epoch 399 
Overall Loss: 19.407341
Rec Loss: 15.329782
KL Loss: 4.077559
Y Loss: 0.380480
T Loss: 11.516728
Epoch 449 
Overall Loss: 19.284421
Rec Loss: 15.197233
KL Loss: 4.087188
Y Loss: 0.353169
T Loss: 11.500894
Epoch 499 
Overall Loss: 19.215918
Rec Loss: 15.082151
KL Loss: 4.133767
Y Loss: 0.317045
T Loss: 11.491374
Epoch 549 
Overall Loss: 19.152662
Rec Loss: 14.991993
KL Loss: 4.160669
Y Loss: 0.306576
T Loss: 11.475401
Epoch 599 
Overall Loss: 19.092321
Rec Loss: 14.969345
KL Loss: 4.122977
Y Loss: 0.285545
T Loss: 11.487629
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.736031
Epoch 99
Rec Loss: 1.736199
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 7.346205
Epoch 99
Rec Loss: 7.342651
Epoch 149
Rec Loss: 7.340457
Epoch 199
Rec Loss: 7.328075
Epoch 249
Rec Loss: 7.329261
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.226274
Insample Error 2.611091
Ours, Train RMSE
0.3728, 
0.3310, 
0.3097, 
0.3064, 
0.3118, 
0.3333, 
0.3300, 
0.3267, 
0.3173, 
0.3097, 
1.7764, 
1.5888, 
1.9520, 
1.6895, 
2.1127, 
1.5645, 
2.2595, 
2.2372, 
1.6529, 
2.1877, 
2.5608, 
2.5683, 
2.3446, 
2.5962, 
2.5833, 
2.6332, 
2.4828, 
2.4321, 
2.5177, 
2.6111, 
Train, RMSE mean 0.3249 std 0.0186
Ours, RMSE mean 1.9021 std 0.2653, reconstruct confounder 1.5747 (0.0522) noise 9.9901 (0.0119)
CEVAE, RMSE mean 2.5330 std 0.0855, reconstruct confounder 1.7155 (0.0184) noise 7.2710 (0.1353)
Experiment Start!
Namespace(decay=0.0, l=5e-05, latdim=4, mask=0, nlayer=50, obsm=3, ycof=0.5, ylayer=50)
Y Mean 1.514292, Std 3.653528 
Observe confounder 3, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.768587
Rec Loss: 14.219322
KL Loss: 0.549265
Y Loss: 4.265050
T Loss: 12.086797
Epoch 99 
Overall Loss: 12.997985
Rec Loss: 12.669935
KL Loss: 0.328049
Y Loss: 1.554691
T Loss: 11.892590
Epoch 149 
Overall Loss: 12.456195
Rec Loss: 12.195660
KL Loss: 0.260535
Y Loss: 0.940126
T Loss: 11.725597
Epoch 199 
Overall Loss: 12.339708
Rec Loss: 12.082440
KL Loss: 0.257268
Y Loss: 0.796362
T Loss: 11.684259
Epoch 249 
Overall Loss: 12.298443
Rec Loss: 12.060443
KL Loss: 0.238000
Y Loss: 0.772855
T Loss: 11.674015
Epoch 299 
Overall Loss: 12.263880
Rec Loss: 12.039098
KL Loss: 0.224782
Y Loss: 0.756597
T Loss: 11.660800
Epoch 349 
Overall Loss: 12.243208
Rec Loss: 12.030968
KL Loss: 0.212240
Y Loss: 0.731801
T Loss: 11.665067
Epoch 399 
Overall Loss: 12.227781
Rec Loss: 12.023777
KL Loss: 0.204004
Y Loss: 0.722080
T Loss: 11.662737
Epoch 449 
Overall Loss: 12.197998
Rec Loss: 12.003169
KL Loss: 0.194829
Y Loss: 0.691539
T Loss: 11.657399
Epoch 499 
Overall Loss: 12.177662
Rec Loss: 11.991008
KL Loss: 0.186654
Y Loss: 0.653294
T Loss: 11.664361
Epoch 549 
Overall Loss: 12.138327
Rec Loss: 11.958465
KL Loss: 0.179862
Y Loss: 0.599634
T Loss: 11.658648
Epoch 599 
Overall Loss: 12.096523
Rec Loss: 11.922801
KL Loss: 0.173722
Y Loss: 0.559710
T Loss: 11.642946
Epoch 649 
Overall Loss: 12.073115
Rec Loss: 11.902093
KL Loss: 0.171022
Y Loss: 0.520212
T Loss: 11.641988
Epoch 699 
Overall Loss: 12.058551
Rec Loss: 11.888622
KL Loss: 0.169929
Y Loss: 0.502196
T Loss: 11.637524
Epoch 749 
Overall Loss: 12.027282
Rec Loss: 11.853696
KL Loss: 0.173586
Y Loss: 0.467190
T Loss: 11.620101
Epoch 799 
Overall Loss: 11.998027
Rec Loss: 11.821651
KL Loss: 0.176376
Y Loss: 0.436074
T Loss: 11.603614
Epoch 849 
Overall Loss: 11.986211
Rec Loss: 11.806950
KL Loss: 0.179261
Y Loss: 0.430273
T Loss: 11.591814
Epoch 899 
Overall Loss: 11.971133
Rec Loss: 11.787675
KL Loss: 0.183458
Y Loss: 0.421615
T Loss: 11.576868
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.457517
Epoch 99
Rec Loss: 1.458348
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.995231
Epoch 99
Rec Loss: 9.995786
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.555424
Insample Error: 1.394421
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.228674
Rec Loss: 20.764120
KL Loss: 1.464553
Y Loss: 5.817047
T Loss: 12.302766
Epoch 99 
Overall Loss: 20.076411
Rec Loss: 17.981708
KL Loss: 2.094703
Y Loss: 2.565504
T Loss: 12.053051
Epoch 149 
Overall Loss: 19.029121
Rec Loss: 16.177262
KL Loss: 2.851859
Y Loss: 1.773771
T Loss: 11.827667
Epoch 199 
Overall Loss: 18.596736
Rec Loss: 15.182444
KL Loss: 3.414292
Y Loss: 1.477687
T Loss: 11.740720
Epoch 249 
Overall Loss: 18.367170
Rec Loss: 14.718582
KL Loss: 3.648588
Y Loss: 1.323975
T Loss: 11.696023
Epoch 299 
Overall Loss: 18.191460
Rec Loss: 14.295483
KL Loss: 3.895977
Y Loss: 1.167477
T Loss: 11.655543
Epoch 349 
Overall Loss: 18.095661
Rec Loss: 13.993126
KL Loss: 4.102536
Y Loss: 1.058008
T Loss: 11.629836
Epoch 399 
Overall Loss: 17.921766
Rec Loss: 13.636675
KL Loss: 4.285091
Y Loss: 0.943999
T Loss: 11.610222
Epoch 449 
Overall Loss: 17.857665
Rec Loss: 13.408426
KL Loss: 4.449239
Y Loss: 0.896964
T Loss: 11.573279
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.766360
Epoch 99
Rec Loss: 1.770531
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.942394
Epoch 99
Rec Loss: 5.932848
Epoch 149
Rec Loss: 5.923602
Epoch 199
Rec Loss: 5.927947
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.684893
Insample Error 2.097146
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.484669
Rec Loss: 13.816952
KL Loss: 0.667717
Y Loss: 3.483594
T Loss: 12.075155
Epoch 99 
Overall Loss: 13.065843
Rec Loss: 12.629412
KL Loss: 0.436432
Y Loss: 1.478873
T Loss: 11.889976
Epoch 149 
Overall Loss: 12.499939
Rec Loss: 12.192809
KL Loss: 0.307130
Y Loss: 0.976568
T Loss: 11.704525
Epoch 199 
Overall Loss: 12.344145
Rec Loss: 12.056771
KL Loss: 0.287375
Y Loss: 0.789513
T Loss: 11.662014
Epoch 249 
Overall Loss: 12.306839
Rec Loss: 12.043873
KL Loss: 0.262966
Y Loss: 0.784236
T Loss: 11.651755
Epoch 299 
Overall Loss: 12.263922
Rec Loss: 12.024875
KL Loss: 0.239047
Y Loss: 0.764942
T Loss: 11.642404
Epoch 349 
Overall Loss: 12.233771
Rec Loss: 12.002195
KL Loss: 0.231575
Y Loss: 0.732866
T Loss: 11.635762
Epoch 399 
Overall Loss: 12.191731
Rec Loss: 11.970692
KL Loss: 0.221038
Y Loss: 0.700465
T Loss: 11.620460
Epoch 449 
Overall Loss: 12.152624
Rec Loss: 11.935720
KL Loss: 0.216904
Y Loss: 0.662586
T Loss: 11.604428
Epoch 499 
Overall Loss: 12.126984
Rec Loss: 11.907008
KL Loss: 0.219976
Y Loss: 0.628429
T Loss: 11.592793
Epoch 549 
Overall Loss: 12.084883
Rec Loss: 11.852969
KL Loss: 0.231915
Y Loss: 0.588084
T Loss: 11.558927
Epoch 599 
Overall Loss: 12.052463
Rec Loss: 11.809864
KL Loss: 0.242599
Y Loss: 0.555962
T Loss: 11.531882
Epoch 649 
Overall Loss: 12.016111
Rec Loss: 11.772166
KL Loss: 0.243945
Y Loss: 0.515755
T Loss: 11.514289
Epoch 699 
Overall Loss: 11.994658
Rec Loss: 11.753684
KL Loss: 0.240974
Y Loss: 0.489471
T Loss: 11.508949
Epoch 749 
Overall Loss: 11.977900
Rec Loss: 11.742543
KL Loss: 0.235357
Y Loss: 0.470881
T Loss: 11.507103
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.394686
Epoch 99
Rec Loss: 1.384066
Epoch 149
Rec Loss: 1.382403
Epoch 199
Rec Loss: 1.383310
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.989104
Epoch 99
Rec Loss: 9.984472
Epoch 149
Rec Loss: 9.989926
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.585241
Insample Error: 1.687595
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.140797
Rec Loss: 20.656353
KL Loss: 1.484443
Y Loss: 5.529588
T Loss: 12.312278
Epoch 99 
Overall Loss: 19.987050
Rec Loss: 17.999612
KL Loss: 1.987438
Y Loss: 2.437593
T Loss: 11.927372
Epoch 149 
Overall Loss: 19.258631
Rec Loss: 16.936043
KL Loss: 2.322588
Y Loss: 1.622706
T Loss: 11.687804
Epoch 199 
Overall Loss: 18.827022
Rec Loss: 16.105092
KL Loss: 2.721931
Y Loss: 1.340369
T Loss: 11.589102
Epoch 249 
Overall Loss: 18.671081
Rec Loss: 15.813335
KL Loss: 2.857745
Y Loss: 1.193750
T Loss: 11.564613
Epoch 299 
Overall Loss: 18.489839
Rec Loss: 15.539053
KL Loss: 2.950786
Y Loss: 1.190469
T Loss: 11.571836
Epoch 349 
Overall Loss: 18.308778
Rec Loss: 15.176222
KL Loss: 3.132555
Y Loss: 1.135502
T Loss: 11.604902
Epoch 399 
Overall Loss: 18.151004
Rec Loss: 14.866852
KL Loss: 3.284152
Y Loss: 1.020986
T Loss: 11.584403
Epoch 449 
Overall Loss: 18.016086
Rec Loss: 14.695691
KL Loss: 3.320394
Y Loss: 0.921669
T Loss: 11.571452
Epoch 499 
Overall Loss: 17.943465
Rec Loss: 14.589454
KL Loss: 3.354010
Y Loss: 0.848530
T Loss: 11.564280
Epoch 549 
Overall Loss: 17.902243
Rec Loss: 14.446626
KL Loss: 3.455617
Y Loss: 0.804148
T Loss: 11.544071
Epoch 599 
Overall Loss: 17.839853
Rec Loss: 14.278973
KL Loss: 3.560880
Y Loss: 0.773364
T Loss: 11.549370
Epoch 649 
Overall Loss: 17.819594
Rec Loss: 14.124203
KL Loss: 3.695391
Y Loss: 0.727039
T Loss: 11.538049
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.747155
Epoch 99
Rec Loss: 1.739973
Epoch 149
Rec Loss: 1.740589
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.146625
Epoch 99
Rec Loss: 6.144055
Epoch 149
Rec Loss: 6.122597
Epoch 199
Rec Loss: 6.135589
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.595202
Insample Error 2.044117
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.683885
Rec Loss: 14.031488
KL Loss: 0.652397
Y Loss: 3.857231
T Loss: 12.102872
Epoch 99 
Overall Loss: 13.032687
Rec Loss: 12.630691
KL Loss: 0.401996
Y Loss: 1.446309
T Loss: 11.907536
Epoch 149 
Overall Loss: 12.488880
Rec Loss: 12.194638
KL Loss: 0.294241
Y Loss: 0.948104
T Loss: 11.720587
Epoch 199 
Overall Loss: 12.353878
Rec Loss: 12.076253
KL Loss: 0.277624
Y Loss: 0.793695
T Loss: 11.679406
Epoch 249 
Overall Loss: 12.294911
Rec Loss: 12.046444
KL Loss: 0.248467
Y Loss: 0.766033
T Loss: 11.663427
Epoch 299 
Overall Loss: 12.262167
Rec Loss: 12.035238
KL Loss: 0.226929
Y Loss: 0.754844
T Loss: 11.657816
Epoch 349 
Overall Loss: 12.221741
Rec Loss: 12.010708
KL Loss: 0.211033
Y Loss: 0.720764
T Loss: 11.650326
Epoch 399 
Overall Loss: 12.221873
Rec Loss: 12.022874
KL Loss: 0.198999
Y Loss: 0.724379
T Loss: 11.660685
Epoch 449 
Overall Loss: 12.179496
Rec Loss: 11.991950
KL Loss: 0.187547
Y Loss: 0.679783
T Loss: 11.652058
Epoch 499 
Overall Loss: 12.154162
Rec Loss: 11.978043
KL Loss: 0.176120
Y Loss: 0.647315
T Loss: 11.654385
Epoch 549 
Overall Loss: 12.126938
Rec Loss: 11.962854
KL Loss: 0.164083
Y Loss: 0.602509
T Loss: 11.661600
Epoch 599 
Overall Loss: 12.097342
Rec Loss: 11.941612
KL Loss: 0.155731
Y Loss: 0.562340
T Loss: 11.660442
Epoch 649 
Overall Loss: 12.065109
Rec Loss: 11.919914
KL Loss: 0.145196
Y Loss: 0.527265
T Loss: 11.656281
Epoch 699 
Overall Loss: 12.045292
Rec Loss: 11.906149
KL Loss: 0.139144
Y Loss: 0.498801
T Loss: 11.656748
Epoch 749 
Overall Loss: 12.016852
Rec Loss: 11.879418
KL Loss: 0.137433
Y Loss: 0.468890
T Loss: 11.644974
Epoch 799 
Overall Loss: 11.997735
Rec Loss: 11.862700
KL Loss: 0.135035
Y Loss: 0.450194
T Loss: 11.637603
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.537975
Epoch 99
Rec Loss: 1.528546
Epoch 149
Rec Loss: 1.528554
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.974848
Epoch 99
Rec Loss: 9.972881
Epoch 149
Rec Loss: 9.973764
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.583380
Insample Error: 1.513865
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.914052
Rec Loss: 20.407258
KL Loss: 1.506795
Y Loss: 4.858930
T Loss: 12.326598
Epoch 99 
Overall Loss: 20.127183
Rec Loss: 18.213043
KL Loss: 1.914139
Y Loss: 2.338734
T Loss: 12.100960
Epoch 149 
Overall Loss: 19.110733
Rec Loss: 16.299722
KL Loss: 2.811012
Y Loss: 1.562564
T Loss: 11.833889
Epoch 199 
Overall Loss: 18.843435
Rec Loss: 15.776186
KL Loss: 3.067248
Y Loss: 1.360870
T Loss: 11.739401
Epoch 249 
Overall Loss: 18.660939
Rec Loss: 15.483010
KL Loss: 3.177929
Y Loss: 1.271871
T Loss: 11.671633
Epoch 299 
Overall Loss: 18.477786
Rec Loss: 15.064200
KL Loss: 3.413586
Y Loss: 1.191322
T Loss: 11.674250
Epoch 349 
Overall Loss: 18.229224
Rec Loss: 14.464276
KL Loss: 3.764948
Y Loss: 1.103607
T Loss: 11.649156
Epoch 399 
Overall Loss: 18.063426
Rec Loss: 13.993158
KL Loss: 4.070267
Y Loss: 1.010247
T Loss: 11.605217
Epoch 449 
Overall Loss: 17.917697
Rec Loss: 13.601352
KL Loss: 4.316346
Y Loss: 0.930851
T Loss: 11.577151
Epoch 499 
Overall Loss: 17.881524
Rec Loss: 13.337596
KL Loss: 4.543929
Y Loss: 0.900101
T Loss: 11.579555
Epoch 549 
Overall Loss: 17.814382
Rec Loss: 13.099701
KL Loss: 4.714681
Y Loss: 0.870617
T Loss: 11.562894
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.756810
Epoch 99
Rec Loss: 1.764603
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.892390
Epoch 99
Rec Loss: 5.897241
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.679928
Insample Error 2.155822
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.088935
Rec Loss: 14.610418
KL Loss: 0.478516
Y Loss: 5.006051
T Loss: 12.107393
Epoch 99 
Overall Loss: 13.011276
Rec Loss: 12.730481
KL Loss: 0.280795
Y Loss: 1.675814
T Loss: 11.892574
Epoch 149 
Overall Loss: 12.447270
Rec Loss: 12.203420
KL Loss: 0.243850
Y Loss: 0.923645
T Loss: 11.741597
Epoch 199 
Overall Loss: 12.333175
Rec Loss: 12.086462
KL Loss: 0.246713
Y Loss: 0.791304
T Loss: 11.690810
Epoch 249 
Overall Loss: 12.266453
Rec Loss: 12.033836
KL Loss: 0.232616
Y Loss: 0.746541
T Loss: 11.660566
Epoch 299 
Overall Loss: 12.242889
Rec Loss: 12.021538
KL Loss: 0.221351
Y Loss: 0.740380
T Loss: 11.651348
Epoch 349 
Overall Loss: 12.208532
Rec Loss: 11.998510
KL Loss: 0.210021
Y Loss: 0.718671
T Loss: 11.639175
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.664182
Epoch 99
Rec Loss: 1.659359
Epoch 149
Rec Loss: 1.661331
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.016544
Epoch 99
Rec Loss: 10.008993
Epoch 149
Rec Loss: 10.011890
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.683283
Insample Error: 2.289085
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.368348
Rec Loss: 20.938683
KL Loss: 1.429664
Y Loss: 6.199542
T Loss: 12.304838
Epoch 99 
Overall Loss: 20.281351
Rec Loss: 18.242671
KL Loss: 2.038680
Y Loss: 2.806277
T Loss: 12.083790
Epoch 149 
Overall Loss: 19.207773
Rec Loss: 16.446485
KL Loss: 2.761288
Y Loss: 1.802730
T Loss: 11.818728
Epoch 199 
Overall Loss: 18.861348
Rec Loss: 15.818197
KL Loss: 3.043150
Y Loss: 1.445564
T Loss: 11.686345
Epoch 249 
Overall Loss: 18.680485
Rec Loss: 15.540840
KL Loss: 3.139645
Y Loss: 1.347998
T Loss: 11.630956
Epoch 299 
Overall Loss: 18.496735
Rec Loss: 15.199801
KL Loss: 3.296934
Y Loss: 1.329393
T Loss: 11.642850
Epoch 349 
Overall Loss: 18.255866
Rec Loss: 14.639248
KL Loss: 3.616618
Y Loss: 1.174303
T Loss: 11.638304
Epoch 399 
Overall Loss: 18.076066
Rec Loss: 14.280288
KL Loss: 3.795778
Y Loss: 1.043632
T Loss: 11.622964
Epoch 449 
Overall Loss: 17.953196
Rec Loss: 13.950185
KL Loss: 4.003010
Y Loss: 0.950997
T Loss: 11.592004
Epoch 499 
Overall Loss: 17.867439
Rec Loss: 13.679156
KL Loss: 4.188283
Y Loss: 0.884296
T Loss: 11.570332
Epoch 549 
Overall Loss: 17.826427
Rec Loss: 13.476715
KL Loss: 4.349712
Y Loss: 0.869331
T Loss: 11.557293
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.758852
Epoch 99
Rec Loss: 1.751976
Epoch 149
Rec Loss: 1.753967
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.912028
Epoch 99
Rec Loss: 5.916473
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.642329
Insample Error 2.115161
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.481845
Rec Loss: 13.935008
KL Loss: 0.546836
Y Loss: 3.729327
T Loss: 12.070345
Epoch 99 
Overall Loss: 12.919707
Rec Loss: 12.615443
KL Loss: 0.304265
Y Loss: 1.460962
T Loss: 11.884962
Epoch 149 
Overall Loss: 12.456711
Rec Loss: 12.177256
KL Loss: 0.279455
Y Loss: 0.920541
T Loss: 11.716985
Epoch 199 
Overall Loss: 12.340468
Rec Loss: 12.069793
KL Loss: 0.270675
Y Loss: 0.802925
T Loss: 11.668331
Epoch 249 
Overall Loss: 12.302054
Rec Loss: 12.050984
KL Loss: 0.251071
Y Loss: 0.783695
T Loss: 11.659136
Epoch 299 
Overall Loss: 12.245995
Rec Loss: 12.011343
KL Loss: 0.234652
Y Loss: 0.753387
T Loss: 11.634649
Epoch 349 
Overall Loss: 12.227607
Rec Loss: 12.007584
KL Loss: 0.220023
Y Loss: 0.743024
T Loss: 11.636072
Epoch 399 
Overall Loss: 12.186231
Rec Loss: 11.976749
KL Loss: 0.209482
Y Loss: 0.695032
T Loss: 11.629233
Epoch 449 
Overall Loss: 12.165968
Rec Loss: 11.959598
KL Loss: 0.206370
Y Loss: 0.658275
T Loss: 11.630460
Epoch 499 
Overall Loss: 12.142403
Rec Loss: 11.944136
KL Loss: 0.198266
Y Loss: 0.643509
T Loss: 11.622382
Epoch 549 
Overall Loss: 12.113082
Rec Loss: 11.918024
KL Loss: 0.195057
Y Loss: 0.605205
T Loss: 11.615422
Epoch 599 
Overall Loss: 12.092119
Rec Loss: 11.899284
KL Loss: 0.192835
Y Loss: 0.570294
T Loss: 11.614137
Epoch 649 
Overall Loss: 12.049235
Rec Loss: 11.860724
KL Loss: 0.188511
Y Loss: 0.527802
T Loss: 11.596824
Epoch 699 
Overall Loss: 12.025365
Rec Loss: 11.838614
KL Loss: 0.186752
Y Loss: 0.490048
T Loss: 11.593590
Epoch 749 
Overall Loss: 11.996273
Rec Loss: 11.811139
KL Loss: 0.185134
Y Loss: 0.467253
T Loss: 11.577512
Epoch 799 
Overall Loss: 11.968326
Rec Loss: 11.781451
KL Loss: 0.186875
Y Loss: 0.448050
T Loss: 11.557426
Epoch 849 
Overall Loss: 11.952396
Rec Loss: 11.768607
KL Loss: 0.183789
Y Loss: 0.429352
T Loss: 11.553931
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.418243
Epoch 99
Rec Loss: 1.413459
Epoch 149
Rec Loss: 1.414549
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.972850
Epoch 99
Rec Loss: 9.972129
Epoch 149
Rec Loss: 9.984229
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.578634
Insample Error: 1.465699
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.200761
Rec Loss: 20.847051
KL Loss: 1.353710
Y Loss: 5.819768
T Loss: 12.305289
Epoch 99 
Overall Loss: 19.820292
Rec Loss: 17.976335
KL Loss: 1.843957
Y Loss: 2.115144
T Loss: 11.959344
Epoch 149 
Overall Loss: 18.972574
Rec Loss: 16.529012
KL Loss: 2.443562
Y Loss: 1.465401
T Loss: 11.743711
Epoch 199 
Overall Loss: 18.722419
Rec Loss: 16.026670
KL Loss: 2.695749
Y Loss: 1.224829
T Loss: 11.646219
Epoch 249 
Overall Loss: 18.622645
Rec Loss: 15.844933
KL Loss: 2.777712
Y Loss: 1.144571
T Loss: 11.604910
Epoch 299 
Overall Loss: 18.499037
Rec Loss: 15.656223
KL Loss: 2.842813
Y Loss: 1.126855
T Loss: 11.592266
Epoch 349 
Overall Loss: 18.371647
Rec Loss: 15.337581
KL Loss: 3.034067
Y Loss: 1.066818
T Loss: 11.609089
Epoch 399 
Overall Loss: 18.194768
Rec Loss: 14.869419
KL Loss: 3.325348
Y Loss: 1.021395
T Loss: 11.590034
Epoch 449 
Overall Loss: 18.050596
Rec Loss: 14.534530
KL Loss: 3.516066
Y Loss: 0.974069
T Loss: 11.580920
Epoch 499 
Overall Loss: 17.981099
Rec Loss: 14.341454
KL Loss: 3.639644
Y Loss: 0.919029
T Loss: 11.561414
Epoch 549 
Overall Loss: 17.870580
Rec Loss: 14.098809
KL Loss: 3.771771
Y Loss: 0.837618
T Loss: 11.539639
Epoch 599 
Overall Loss: 17.815293
Rec Loss: 13.929703
KL Loss: 3.885590
Y Loss: 0.756968
T Loss: 11.530863
Epoch 649 
Overall Loss: 17.778378
Rec Loss: 13.780438
KL Loss: 3.997939
Y Loss: 0.723842
T Loss: 11.532272
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.740290
Epoch 99
Rec Loss: 1.732212
Epoch 149
Rec Loss: 1.733036
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.075058
Epoch 99
Rec Loss: 6.044340
Epoch 149
Rec Loss: 6.049321
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.573354
Insample Error 2.153597
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.039283
Rec Loss: 14.596755
KL Loss: 0.442528
Y Loss: 5.117738
T Loss: 12.037887
Epoch 99 
Overall Loss: 13.097002
Rec Loss: 12.796225
KL Loss: 0.300777
Y Loss: 1.885426
T Loss: 11.853512
Epoch 149 
Overall Loss: 12.486918
Rec Loss: 12.206143
KL Loss: 0.280774
Y Loss: 0.967282
T Loss: 11.722502
Epoch 199 
Overall Loss: 12.335000
Rec Loss: 12.072529
KL Loss: 0.262471
Y Loss: 0.798930
T Loss: 11.673064
Epoch 249 
Overall Loss: 12.288075
Rec Loss: 12.046074
KL Loss: 0.242001
Y Loss: 0.764430
T Loss: 11.663859
Epoch 299 
Overall Loss: 12.238669
Rec Loss: 12.015188
KL Loss: 0.223481
Y Loss: 0.735665
T Loss: 11.647355
Epoch 349 
Overall Loss: 12.216202
Rec Loss: 12.007720
KL Loss: 0.208482
Y Loss: 0.715910
T Loss: 11.649765
Epoch 399 
Overall Loss: 12.180341
Rec Loss: 11.982615
KL Loss: 0.197725
Y Loss: 0.676905
T Loss: 11.644163
Epoch 449 
Overall Loss: 12.155988
Rec Loss: 11.968871
KL Loss: 0.187118
Y Loss: 0.647654
T Loss: 11.645044
Epoch 499 
Overall Loss: 12.125215
Rec Loss: 11.944399
KL Loss: 0.180816
Y Loss: 0.607040
T Loss: 11.640879
Epoch 549 
Overall Loss: 12.109042
Rec Loss: 11.933104
KL Loss: 0.175939
Y Loss: 0.579608
T Loss: 11.643300
Epoch 599 
Overall Loss: 12.066184
Rec Loss: 11.890272
KL Loss: 0.175912
Y Loss: 0.533636
T Loss: 11.623454
Epoch 649 
Overall Loss: 12.031506
Rec Loss: 11.847789
KL Loss: 0.183717
Y Loss: 0.502603
T Loss: 11.596488
Epoch 699 
Overall Loss: 12.006779
Rec Loss: 11.808865
KL Loss: 0.197913
Y Loss: 0.482413
T Loss: 11.567658
Epoch 749 
Overall Loss: 11.972618
Rec Loss: 11.763812
KL Loss: 0.208805
Y Loss: 0.449336
T Loss: 11.539144
Epoch 799 
Overall Loss: 11.955235
Rec Loss: 11.743471
KL Loss: 0.211764
Y Loss: 0.435606
T Loss: 11.525669
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.422412
Epoch 99
Rec Loss: 1.414433
Epoch 149
Rec Loss: 1.414247
Epoch 199
Rec Loss: 1.407154
Epoch 249
Rec Loss: 1.417269
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.988043
Epoch 99
Rec Loss: 9.992019
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.573080
Insample Error: 1.472950
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.995999
Rec Loss: 21.755190
KL Loss: 1.240810
Y Loss: 7.351851
T Loss: 12.413956
Epoch 99 
Overall Loss: 20.246015
Rec Loss: 18.365636
KL Loss: 1.880378
Y Loss: 3.004343
T Loss: 11.974017
Epoch 149 
Overall Loss: 19.087706
Rec Loss: 16.480250
KL Loss: 2.607456
Y Loss: 1.713709
T Loss: 11.747454
Epoch 199 
Overall Loss: 18.746944
Rec Loss: 15.935681
KL Loss: 2.811263
Y Loss: 1.337654
T Loss: 11.641098
Epoch 249 
Overall Loss: 18.560193
Rec Loss: 15.646918
KL Loss: 2.913275
Y Loss: 1.227970
T Loss: 11.616022
Epoch 299 
Overall Loss: 18.326912
Rec Loss: 15.179606
KL Loss: 3.147307
Y Loss: 1.176280
T Loss: 11.624158
Epoch 349 
Overall Loss: 18.133448
Rec Loss: 14.778484
KL Loss: 3.354964
Y Loss: 1.037188
T Loss: 11.616420
Epoch 399 
Overall Loss: 18.002553
Rec Loss: 14.578237
KL Loss: 3.424316
Y Loss: 0.903877
T Loss: 11.592368
Epoch 449 
Overall Loss: 17.928735
Rec Loss: 14.436793
KL Loss: 3.491941
Y Loss: 0.814868
T Loss: 11.573683
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.743165
Epoch 99
Rec Loss: 1.741503
Epoch 149
Rec Loss: 1.741218
Epoch 199
Rec Loss: 1.742424
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.278165
Epoch 99
Rec Loss: 6.276712
Epoch 149
Rec Loss: 6.268126
Epoch 199
Rec Loss: 6.278966
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.634878
Insample Error 2.002430
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.252665
Rec Loss: 13.565162
KL Loss: 0.687503
Y Loss: 2.977981
T Loss: 12.076171
Epoch 99 
Overall Loss: 12.992238
Rec Loss: 12.477819
KL Loss: 0.514419
Y Loss: 1.150458
T Loss: 11.902590
Epoch 149 
Overall Loss: 12.472222
Rec Loss: 12.123805
KL Loss: 0.348417
Y Loss: 0.815362
T Loss: 11.716124
Epoch 199 
Overall Loss: 12.311098
Rec Loss: 11.992810
KL Loss: 0.318288
Y Loss: 0.696582
T Loss: 11.644519
Epoch 249 
Overall Loss: 12.269873
Rec Loss: 11.972503
KL Loss: 0.297370
Y Loss: 0.689042
T Loss: 11.627982
Epoch 299 
Overall Loss: 12.242065
Rec Loss: 11.962183
KL Loss: 0.279882
Y Loss: 0.676286
T Loss: 11.624039
Epoch 349 
Overall Loss: 12.192280
Rec Loss: 11.920274
KL Loss: 0.272006
Y Loss: 0.632265
T Loss: 11.604142
Epoch 399 
Overall Loss: 12.172531
Rec Loss: 11.913634
KL Loss: 0.258896
Y Loss: 0.612258
T Loss: 11.607505
Epoch 449 
Overall Loss: 12.159073
Rec Loss: 11.904276
KL Loss: 0.254797
Y Loss: 0.592039
T Loss: 11.608256
Epoch 499 
Overall Loss: 12.133580
Rec Loss: 11.883272
KL Loss: 0.250308
Y Loss: 0.562290
T Loss: 11.602127
Epoch 549 
Overall Loss: 12.108548
Rec Loss: 11.867923
KL Loss: 0.240625
Y Loss: 0.545063
T Loss: 11.595391
Epoch 599 
Overall Loss: 12.083133
Rec Loss: 11.845488
KL Loss: 0.237646
Y Loss: 0.520536
T Loss: 11.585220
Epoch 649 
Overall Loss: 12.061049
Rec Loss: 11.828046
KL Loss: 0.233003
Y Loss: 0.497299
T Loss: 11.579396
Epoch 699 
Overall Loss: 12.023973
Rec Loss: 11.800359
KL Loss: 0.223614
Y Loss: 0.472010
T Loss: 11.564354
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.476962
Epoch 99
Rec Loss: 1.475997
Epoch 149
Rec Loss: 1.473109
Epoch 199
Rec Loss: 1.473932
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.002615
Epoch 99
Rec Loss: 10.004299
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.540415
Insample Error: 1.794064
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.064389
Rec Loss: 20.544372
KL Loss: 1.520018
Y Loss: 5.328658
T Loss: 12.329479
Epoch 99 
Overall Loss: 20.196728
Rec Loss: 18.073103
KL Loss: 2.123624
Y Loss: 2.638348
T Loss: 12.110434
Epoch 149 
Overall Loss: 19.142206
Rec Loss: 16.163652
KL Loss: 2.978554
Y Loss: 1.702411
T Loss: 11.790670
Epoch 199 
Overall Loss: 18.819683
Rec Loss: 15.688127
KL Loss: 3.131556
Y Loss: 1.438014
T Loss: 11.675955
Epoch 249 
Overall Loss: 18.647024
Rec Loss: 15.430213
KL Loss: 3.216811
Y Loss: 1.358384
T Loss: 11.653366
Epoch 299 
Overall Loss: 18.455305
Rec Loss: 15.064068
KL Loss: 3.391236
Y Loss: 1.315033
T Loss: 11.636778
Epoch 349 
Overall Loss: 18.239150
Rec Loss: 14.676716
KL Loss: 3.562434
Y Loss: 1.157193
T Loss: 11.631064
Epoch 399 
Overall Loss: 18.060569
Rec Loss: 14.370523
KL Loss: 3.690047
Y Loss: 1.049069
T Loss: 11.598801
Epoch 449 
Overall Loss: 18.035187
Rec Loss: 14.274606
KL Loss: 3.760581
Y Loss: 1.012733
T Loss: 11.591792
Epoch 499 
Overall Loss: 17.941058
Rec Loss: 14.112906
KL Loss: 3.828152
Y Loss: 0.960127
T Loss: 11.584226
Epoch 549 
Overall Loss: 17.860998
Rec Loss: 13.934963
KL Loss: 3.926036
Y Loss: 0.922073
T Loss: 11.563999
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.770066
Epoch 99
Rec Loss: 1.755756
Epoch 149
Rec Loss: 1.760463
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.145173
Epoch 99
Rec Loss: 6.130736
Epoch 149
Rec Loss: 6.139314
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.669272
Insample Error 2.139214
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.835968
Rec Loss: 14.356237
KL Loss: 0.479731
Y Loss: 4.543635
T Loss: 12.084420
Epoch 99 
Overall Loss: 13.157571
Rec Loss: 12.815626
KL Loss: 0.341946
Y Loss: 1.856635
T Loss: 11.887308
Epoch 149 
Overall Loss: 12.532325
Rec Loss: 12.231348
KL Loss: 0.300977
Y Loss: 1.032319
T Loss: 11.715188
Epoch 199 
Overall Loss: 12.353998
Rec Loss: 12.067972
KL Loss: 0.286027
Y Loss: 0.797182
T Loss: 11.669381
Epoch 249 
Overall Loss: 12.273618
Rec Loss: 12.014390
KL Loss: 0.259228
Y Loss: 0.736898
T Loss: 11.645941
Epoch 299 
Overall Loss: 12.234114
Rec Loss: 11.994803
KL Loss: 0.239310
Y Loss: 0.720568
T Loss: 11.634519
Epoch 349 
Overall Loss: 12.206148
Rec Loss: 11.979188
KL Loss: 0.226961
Y Loss: 0.690322
T Loss: 11.634027
Epoch 399 
Overall Loss: 12.165277
Rec Loss: 11.947588
KL Loss: 0.217688
Y Loss: 0.647891
T Loss: 11.623643
Epoch 449 
Overall Loss: 12.138183
Rec Loss: 11.928502
KL Loss: 0.209681
Y Loss: 0.622860
T Loss: 11.617072
Epoch 499 
Overall Loss: 12.121257
Rec Loss: 11.916703
KL Loss: 0.204554
Y Loss: 0.586038
T Loss: 11.623684
Epoch 549 
Overall Loss: 12.090105
Rec Loss: 11.893508
KL Loss: 0.196597
Y Loss: 0.559854
T Loss: 11.613581
Epoch 599 
Overall Loss: 12.065680
Rec Loss: 11.878192
KL Loss: 0.187488
Y Loss: 0.526805
T Loss: 11.614790
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.620715
Epoch 99
Rec Loss: 1.619211
Epoch 149
Rec Loss: 1.612517
Epoch 199
Rec Loss: 1.616826
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.005208
Epoch 99
Rec Loss: 9.994338
Epoch 149
Rec Loss: 9.998619
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.607699
Insample Error: 1.855285
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.953513
Rec Loss: 20.486270
KL Loss: 1.467242
Y Loss: 5.267372
T Loss: 12.286956
Epoch 99 
Overall Loss: 19.981483
Rec Loss: 17.949666
KL Loss: 2.031816
Y Loss: 2.422064
T Loss: 12.043770
Epoch 149 
Overall Loss: 19.290479
Rec Loss: 16.867026
KL Loss: 2.423453
Y Loss: 1.838586
T Loss: 11.877581
Epoch 199 
Overall Loss: 18.692540
Rec Loss: 15.696942
KL Loss: 2.995598
Y Loss: 1.502539
T Loss: 11.744268
Epoch 249 
Overall Loss: 18.365072
Rec Loss: 15.021351
KL Loss: 3.343720
Y Loss: 1.282311
T Loss: 11.677115
Epoch 299 
Overall Loss: 18.178866
Rec Loss: 14.746948
KL Loss: 3.431918
Y Loss: 1.137491
T Loss: 11.617425
Epoch 349 
Overall Loss: 18.074703
Rec Loss: 14.547893
KL Loss: 3.526810
Y Loss: 1.003456
T Loss: 11.597383
Epoch 399 
Overall Loss: 17.949436
Rec Loss: 14.326793
KL Loss: 3.622643
Y Loss: 0.894831
T Loss: 11.580461
Epoch 449 
Overall Loss: 17.879545
Rec Loss: 14.174344
KL Loss: 3.705201
Y Loss: 0.839363
T Loss: 11.562917
Epoch 499 
Overall Loss: 17.845249
Rec Loss: 14.017139
KL Loss: 3.828110
Y Loss: 0.787886
T Loss: 11.544627
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.745797
Epoch 99
Rec Loss: 1.741835
Epoch 149
Rec Loss: 1.741528
Epoch 199
Rec Loss: 1.733159
Epoch 249
Rec Loss: 1.743621
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.106928
Epoch 99
Rec Loss: 6.111127
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.652729
Insample Error 2.167348
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.339672
Rec Loss: 13.828544
KL Loss: 0.511128
Y Loss: 3.492378
T Loss: 12.082354
Epoch 99 
Overall Loss: 12.980021
Rec Loss: 12.668985
KL Loss: 0.311036
Y Loss: 1.553691
T Loss: 11.892139
Epoch 149 
Overall Loss: 12.462810
Rec Loss: 12.193612
KL Loss: 0.269198
Y Loss: 0.925690
T Loss: 11.730768
Epoch 199 
Overall Loss: 12.348020
Rec Loss: 12.082012
KL Loss: 0.266008
Y Loss: 0.793804
T Loss: 11.685110
Epoch 249 
Overall Loss: 12.280932
Rec Loss: 12.037468
KL Loss: 0.243463
Y Loss: 0.743143
T Loss: 11.665897
Epoch 299 
Overall Loss: 12.268045
Rec Loss: 12.042708
KL Loss: 0.225337
Y Loss: 0.745458
T Loss: 11.669979
Epoch 349 
Overall Loss: 12.228927
Rec Loss: 12.018514
KL Loss: 0.210413
Y Loss: 0.723868
T Loss: 11.656580
Epoch 399 
Overall Loss: 12.199944
Rec Loss: 11.999292
KL Loss: 0.200652
Y Loss: 0.704664
T Loss: 11.646960
Epoch 449 
Overall Loss: 12.167317
Rec Loss: 11.975791
KL Loss: 0.191526
Y Loss: 0.655850
T Loss: 11.647866
Epoch 499 
Overall Loss: 12.137523
Rec Loss: 11.954468
KL Loss: 0.183055
Y Loss: 0.620398
T Loss: 11.644269
Epoch 549 
Overall Loss: 12.103883
Rec Loss: 11.926806
KL Loss: 0.177077
Y Loss: 0.592127
T Loss: 11.630743
Epoch 599 
Overall Loss: 12.078272
Rec Loss: 11.905969
KL Loss: 0.172303
Y Loss: 0.559410
T Loss: 11.626264
Epoch 649 
Overall Loss: 12.050064
Rec Loss: 11.874001
KL Loss: 0.176063
Y Loss: 0.533631
T Loss: 11.607185
Epoch 699 
Overall Loss: 12.023266
Rec Loss: 11.842166
KL Loss: 0.181100
Y Loss: 0.501515
T Loss: 11.591408
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.501998
Epoch 99
Rec Loss: 1.489091
Epoch 149
Rec Loss: 1.491197
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.993580
Epoch 99
Rec Loss: 9.990668
Epoch 149
Rec Loss: 9.981244
Epoch 199
Rec Loss: 9.975704
Epoch 249
Rec Loss: 9.989193
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.613376
Insample Error: 1.749304
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.280312
Rec Loss: 20.837082
KL Loss: 1.443230
Y Loss: 5.747753
T Loss: 12.330877
Epoch 99 
Overall Loss: 20.217567
Rec Loss: 18.363170
KL Loss: 1.854398
Y Loss: 2.389007
T Loss: 12.048224
Epoch 149 
Overall Loss: 19.245269
Rec Loss: 16.837788
KL Loss: 2.407481
Y Loss: 1.492957
T Loss: 11.738468
Epoch 199 
Overall Loss: 18.923408
Rec Loss: 16.373277
KL Loss: 2.550131
Y Loss: 1.314338
T Loss: 11.648847
Epoch 249 
Overall Loss: 18.604360
Rec Loss: 15.654212
KL Loss: 2.950148
Y Loss: 1.253305
T Loss: 11.619921
Epoch 299 
Overall Loss: 18.370542
Rec Loss: 15.086283
KL Loss: 3.284258
Y Loss: 1.226976
T Loss: 11.611504
Epoch 349 
Overall Loss: 18.202052
Rec Loss: 14.761477
KL Loss: 3.440575
Y Loss: 1.088188
T Loss: 11.598897
Epoch 399 
Overall Loss: 18.043177
Rec Loss: 14.509536
KL Loss: 3.533640
Y Loss: 0.979411
T Loss: 11.587540
Epoch 449 
Overall Loss: 17.964616
Rec Loss: 14.309140
KL Loss: 3.655475
Y Loss: 0.941722
T Loss: 11.569665
Epoch 499 
Overall Loss: 17.885076
Rec Loss: 14.070315
KL Loss: 3.814761
Y Loss: 0.873592
T Loss: 11.560184
Epoch 549 
Overall Loss: 17.821361
Rec Loss: 13.860092
KL Loss: 3.961269
Y Loss: 0.823418
T Loss: 11.543504
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.747816
Epoch 99
Rec Loss: 1.737542
Epoch 149
Rec Loss: 1.738900
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.070058
Epoch 99
Rec Loss: 6.065155
Epoch 149
Rec Loss: 6.064645
Epoch 199
Rec Loss: 6.059095
Epoch 249
Rec Loss: 6.066671
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.651825
Insample Error 2.170875
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.682596
Rec Loss: 14.161000
KL Loss: 0.521597
Y Loss: 4.145847
T Loss: 12.088076
Epoch 99 
Overall Loss: 13.051793
Rec Loss: 12.701814
KL Loss: 0.349979
Y Loss: 1.616549
T Loss: 11.893540
Epoch 149 
Overall Loss: 12.471318
Rec Loss: 12.201769
KL Loss: 0.269549
Y Loss: 0.959292
T Loss: 11.722123
Epoch 199 
Overall Loss: 12.339594
Rec Loss: 12.072953
KL Loss: 0.266641
Y Loss: 0.781200
T Loss: 11.682354
Epoch 249 
Overall Loss: 12.286075
Rec Loss: 12.037838
KL Loss: 0.248238
Y Loss: 0.755212
T Loss: 11.660232
Epoch 299 
Overall Loss: 12.253017
Rec Loss: 12.017791
KL Loss: 0.235226
Y Loss: 0.735084
T Loss: 11.650249
Epoch 349 
Overall Loss: 12.211963
Rec Loss: 11.986852
KL Loss: 0.225111
Y Loss: 0.699205
T Loss: 11.637249
Epoch 399 
Overall Loss: 12.182484
Rec Loss: 11.958699
KL Loss: 0.223785
Y Loss: 0.659343
T Loss: 11.629028
Epoch 449 
Overall Loss: 12.152609
Rec Loss: 11.923982
KL Loss: 0.228627
Y Loss: 0.637960
T Loss: 11.605002
Epoch 499 
Overall Loss: 12.120645
Rec Loss: 11.884636
KL Loss: 0.236009
Y Loss: 0.605761
T Loss: 11.581755
Epoch 549 
Overall Loss: 12.093214
Rec Loss: 11.855036
KL Loss: 0.238178
Y Loss: 0.583134
T Loss: 11.563469
Epoch 599 
Overall Loss: 12.053447
Rec Loss: 11.823442
KL Loss: 0.230005
Y Loss: 0.544512
T Loss: 11.551186
Epoch 649 
Overall Loss: 12.034755
Rec Loss: 11.813198
KL Loss: 0.221557
Y Loss: 0.514391
T Loss: 11.556003
Epoch 699 
Overall Loss: 12.003803
Rec Loss: 11.791041
KL Loss: 0.212762
Y Loss: 0.477182
T Loss: 11.552450
Epoch 749 
Overall Loss: 11.987850
Rec Loss: 11.784106
KL Loss: 0.203744
Y Loss: 0.452879
T Loss: 11.557667
Epoch 799 
Overall Loss: 11.960842
Rec Loss: 11.761642
KL Loss: 0.199199
Y Loss: 0.426030
T Loss: 11.548627
Epoch 849 
Overall Loss: 11.959259
Rec Loss: 11.763002
KL Loss: 0.196258
Y Loss: 0.416580
T Loss: 11.554711
Epoch 899 
Overall Loss: 11.949920
Rec Loss: 11.754269
KL Loss: 0.195651
Y Loss: 0.409079
T Loss: 11.549730
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.392623
Epoch 99
Rec Loss: 1.382739
Epoch 149
Rec Loss: 1.386084
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.010268
Epoch 99
Rec Loss: 10.013861
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.550516
Insample Error: 1.368568
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.428527
Rec Loss: 21.098578
KL Loss: 1.329950
Y Loss: 6.291275
T Loss: 12.328912
Epoch 99 
Overall Loss: 20.165633
Rec Loss: 18.292235
KL Loss: 1.873398
Y Loss: 2.584253
T Loss: 11.968165
Epoch 149 
Overall Loss: 19.295130
Rec Loss: 17.018232
KL Loss: 2.276898
Y Loss: 1.529816
T Loss: 11.685855
Epoch 199 
Overall Loss: 18.821001
Rec Loss: 16.080266
KL Loss: 2.740735
Y Loss: 1.284018
T Loss: 11.586179
Epoch 249 
Overall Loss: 18.682904
Rec Loss: 15.826196
KL Loss: 2.856708
Y Loss: 1.161608
T Loss: 11.565175
Epoch 299 
Overall Loss: 18.527902
Rec Loss: 15.659977
KL Loss: 2.867925
Y Loss: 1.054888
T Loss: 11.540057
Epoch 349 
Overall Loss: 18.432845
Rec Loss: 15.499583
KL Loss: 2.933262
Y Loss: 1.005252
T Loss: 11.532596
Epoch 399 
Overall Loss: 18.329149
Rec Loss: 15.298987
KL Loss: 3.030162
Y Loss: 0.969840
T Loss: 11.542738
Epoch 449 
Overall Loss: 18.130093
Rec Loss: 14.929918
KL Loss: 3.200175
Y Loss: 0.919156
T Loss: 11.561627
Epoch 499 
Overall Loss: 17.989506
Rec Loss: 14.611388
KL Loss: 3.378118
Y Loss: 0.852590
T Loss: 11.556580
Epoch 549 
Overall Loss: 17.893154
Rec Loss: 14.410471
KL Loss: 3.482684
Y Loss: 0.819192
T Loss: 11.548104
Epoch 599 
Overall Loss: 17.827141
Rec Loss: 14.234885
KL Loss: 3.592257
Y Loss: 0.741711
T Loss: 11.552914
Epoch 649 
Overall Loss: 17.772345
Rec Loss: 14.066212
KL Loss: 3.706133
Y Loss: 0.730216
T Loss: 11.533755
Epoch 699 
Overall Loss: 17.749991
Rec Loss: 13.891782
KL Loss: 3.858210
Y Loss: 0.698000
T Loss: 11.544113
Epoch 749 
Overall Loss: 17.736285
Rec Loss: 13.729461
KL Loss: 4.006824
Y Loss: 0.690696
T Loss: 11.540499
Epoch 799 
Overall Loss: 17.678477
Rec Loss: 13.540952
KL Loss: 4.137524
Y Loss: 0.657410
T Loss: 11.526202
Epoch 849 
Overall Loss: 17.687266
Rec Loss: 13.438625
KL Loss: 4.248641
Y Loss: 0.660313
T Loss: 11.533182
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.734509
Epoch 99
Rec Loss: 1.733855
Epoch 149
Rec Loss: 1.732386
Epoch 199
Rec Loss: 1.725560
Epoch 249
Rec Loss: 1.728478
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.983699
Epoch 99
Rec Loss: 5.989677
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.530149
Insample Error 1.876260
Ours, Train RMSE
0.5554, 
0.5852, 
0.5834, 
0.6833, 
0.5786, 
0.5731, 
0.5404, 
0.6077, 
0.6134, 
0.5505, 
Ours, Insample RMSE
1.3944, 
1.6876, 
1.5139, 
2.2891, 
1.4657, 
1.4730, 
1.7941, 
1.8553, 
1.7493, 
1.3686, 
CEVAE, Insample RMSE
2.0971, 
2.0441, 
2.1558, 
2.1152, 
2.1536, 
2.0024, 
2.1392, 
2.1673, 
2.1709, 
1.8763, 
Train, RMSE mean 0.5871 std 0.0390
Ours, RMSE mean 1.6591 std 0.2665, reconstruct confounder 1.4806 (0.0902) noise 9.9905 (0.0135)
CEVAE, RMSE mean 2.0922 std 0.0891, reconstruct confounder 1.7441 (0.0124) noise 6.0444 (0.1125)
Experiment Start!
Namespace(decay=0.0, l=5e-05, latdim=4, mask=5, nlayer=50, obsm=3, ycof=0.5, ylayer=50)
Y Mean 1.514292, Std 3.653528 
Observe confounder 3, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.603417
Rec Loss: 14.096018
KL Loss: 0.507399
Y Loss: 4.067295
T Loss: 12.062370
Epoch 99 
Overall Loss: 12.925764
Rec Loss: 12.636268
KL Loss: 0.289497
Y Loss: 1.519690
T Loss: 11.876422
Epoch 149 
Overall Loss: 12.440379
Rec Loss: 12.182245
KL Loss: 0.258133
Y Loss: 0.915503
T Loss: 11.724494
Epoch 199 
Overall Loss: 12.335069
Rec Loss: 12.082262
KL Loss: 0.252807
Y Loss: 0.791215
T Loss: 11.686655
Epoch 249 
Overall Loss: 12.295701
Rec Loss: 12.063224
KL Loss: 0.232478
Y Loss: 0.771711
T Loss: 11.677368
Epoch 299 
Overall Loss: 12.259327
Rec Loss: 12.041349
KL Loss: 0.217977
Y Loss: 0.753643
T Loss: 11.664528
Epoch 349 
Overall Loss: 12.238141
Rec Loss: 12.033869
KL Loss: 0.204272
Y Loss: 0.728617
T Loss: 11.669560
Epoch 399 
Overall Loss: 12.220014
Rec Loss: 12.025197
KL Loss: 0.194817
Y Loss: 0.716012
T Loss: 11.667191
Epoch 449 
Overall Loss: 12.188524
Rec Loss: 12.004172
KL Loss: 0.184352
Y Loss: 0.684853
T Loss: 11.661746
Epoch 499 
Overall Loss: 12.166318
Rec Loss: 11.991375
KL Loss: 0.174944
Y Loss: 0.646129
T Loss: 11.668310
Epoch 549 
Overall Loss: 12.127205
Rec Loss: 11.959753
KL Loss: 0.167452
Y Loss: 0.593461
T Loss: 11.663022
Epoch 599 
Overall Loss: 12.081886
Rec Loss: 11.919968
KL Loss: 0.161918
Y Loss: 0.553449
T Loss: 11.643244
Epoch 649 
Overall Loss: 12.055643
Rec Loss: 11.893780
KL Loss: 0.161863
Y Loss: 0.516181
T Loss: 11.635690
Epoch 699 
Overall Loss: 12.041732
Rec Loss: 11.876177
KL Loss: 0.165555
Y Loss: 0.498956
T Loss: 11.626699
Epoch 749 
Overall Loss: 12.004726
Rec Loss: 11.833026
KL Loss: 0.171700
Y Loss: 0.466341
T Loss: 11.599856
Epoch 799 
Overall Loss: 11.975682
Rec Loss: 11.802120
KL Loss: 0.173562
Y Loss: 0.436384
T Loss: 11.583928
Epoch 849 
Overall Loss: 11.967197
Rec Loss: 11.793670
KL Loss: 0.173527
Y Loss: 0.430560
T Loss: 11.578390
Epoch 899 
Overall Loss: 11.949518
Rec Loss: 11.774733
KL Loss: 0.174785
Y Loss: 0.421480
T Loss: 11.563993
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.342949
Epoch 99
Rec Loss: 1.334887
Epoch 149
Rec Loss: 1.342492
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.984028
Epoch 99
Rec Loss: 4.978834
Epoch 149
Rec Loss: 4.972393
Epoch 199
Rec Loss: 4.976661
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.569755
Insample Error: 1.388081
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 8.020652
Rec Loss: 2.511920
KL Loss: 5.508732
Y Loss: 5.400793
T Loss: 12.244002
X Loss: -12.432478
Epoch 99 
Overall Loss: -6.979126
Rec Loss: -14.681513
KL Loss: 7.702387
Y Loss: 2.645401
T Loss: 11.812201
X Loss: -27.816415
Epoch 149 
Overall Loss: -10.643555
Rec Loss: -19.510623
KL Loss: 8.867068
Y Loss: 1.912957
T Loss: 11.734780
X Loss: -32.201882
Epoch 199 
Overall Loss: -12.013188
Rec Loss: -21.095336
KL Loss: 9.082149
Y Loss: 1.572105
T Loss: 11.694721
X Loss: -33.576110
Epoch 249 
Overall Loss: -13.043318
Rec Loss: -22.678000
KL Loss: 9.634683
Y Loss: 1.351740
T Loss: 11.618241
X Loss: -34.972112
Epoch 299 
Overall Loss: -12.493119
Rec Loss: -22.220745
KL Loss: 9.727626
Y Loss: 1.148734
T Loss: 11.584996
X Loss: -34.380107
Epoch 349 
Overall Loss: -13.207540
Rec Loss: -23.324503
KL Loss: 10.116963
Y Loss: 1.018627
T Loss: 11.538689
X Loss: -35.372506
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.825921
Epoch 99
Rec Loss: 1.829248
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.999022
Epoch 99
Rec Loss: 4.997407
Epoch 149
Rec Loss: 4.996686
Epoch 199
Rec Loss: 5.000078
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.790227
Insample Error 2.184596
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.370653
Rec Loss: 13.731945
KL Loss: 0.638708
Y Loss: 3.351538
T Loss: 12.056176
Epoch 99 
Overall Loss: 13.001863
Rec Loss: 12.597262
KL Loss: 0.404601
Y Loss: 1.445956
T Loss: 11.874284
Epoch 149 
Overall Loss: 12.481243
Rec Loss: 12.177920
KL Loss: 0.303324
Y Loss: 0.947980
T Loss: 11.703930
Epoch 199 
Overall Loss: 12.338208
Rec Loss: 12.055263
KL Loss: 0.282945
Y Loss: 0.781319
T Loss: 11.664604
Epoch 249 
Overall Loss: 12.303669
Rec Loss: 12.045678
KL Loss: 0.257991
Y Loss: 0.779684
T Loss: 11.655836
Epoch 299 
Overall Loss: 12.259571
Rec Loss: 12.025366
KL Loss: 0.234205
Y Loss: 0.759249
T Loss: 11.645742
Epoch 349 
Overall Loss: 12.228421
Rec Loss: 12.000567
KL Loss: 0.227854
Y Loss: 0.726539
T Loss: 11.637297
Epoch 399 
Overall Loss: 12.183966
Rec Loss: 11.963952
KL Loss: 0.220014
Y Loss: 0.694622
T Loss: 11.616640
Epoch 449 
Overall Loss: 12.139368
Rec Loss: 11.917670
KL Loss: 0.221698
Y Loss: 0.655825
T Loss: 11.589758
Epoch 499 
Overall Loss: 12.105858
Rec Loss: 11.872542
KL Loss: 0.233316
Y Loss: 0.623180
T Loss: 11.560952
Epoch 549 
Overall Loss: 12.065395
Rec Loss: 11.820371
KL Loss: 0.245024
Y Loss: 0.585167
T Loss: 11.527788
Epoch 599 
Overall Loss: 12.039663
Rec Loss: 11.799345
KL Loss: 0.240318
Y Loss: 0.553376
T Loss: 11.522657
Epoch 649 
Overall Loss: 12.009424
Rec Loss: 11.778237
KL Loss: 0.231188
Y Loss: 0.514681
T Loss: 11.520896
Epoch 699 
Overall Loss: 11.989935
Rec Loss: 11.765631
KL Loss: 0.224305
Y Loss: 0.488467
T Loss: 11.521397
Epoch 749 
Overall Loss: 11.972394
Rec Loss: 11.755364
KL Loss: 0.217030
Y Loss: 0.471065
T Loss: 11.519831
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.350651
Epoch 99
Rec Loss: 1.347591
Epoch 149
Rec Loss: 1.351523
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.981514
Epoch 99
Rec Loss: 4.984259
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.592811
Insample Error: 1.680606
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 12.552439
Rec Loss: 8.819333
KL Loss: 3.733107
Y Loss: 8.172819
T Loss: 12.884010
X Loss: -8.151088
Epoch 99 
Overall Loss: -6.003044
Rec Loss: -13.730329
KL Loss: 7.727285
Y Loss: 6.284544
T Loss: 11.857339
X Loss: -28.729940
Epoch 149 
Overall Loss: -8.991316
Rec Loss: -17.465076
KL Loss: 8.473760
Y Loss: 3.872469
T Loss: 11.726272
X Loss: -31.127581
Epoch 199 
Overall Loss: -13.134956
Rec Loss: -22.299172
KL Loss: 9.164216
Y Loss: 3.175504
T Loss: 11.677476
X Loss: -35.564400
Epoch 249 
Overall Loss: -13.711632
Rec Loss: -23.026702
KL Loss: 9.315070
Y Loss: 2.736066
T Loss: 11.668857
X Loss: -36.063593
Epoch 299 
Overall Loss: -14.666091
Rec Loss: -24.126095
KL Loss: 9.460003
Y Loss: 2.291477
T Loss: 11.655947
X Loss: -36.927779
Epoch 349 
Overall Loss: -16.522401
Rec Loss: -26.336894
KL Loss: 9.814493
Y Loss: 1.703930
T Loss: 11.615410
X Loss: -38.804268
Epoch 399 
Overall Loss: -16.323687
Rec Loss: -26.080857
KL Loss: 9.757170
Y Loss: 1.259664
T Loss: 11.585497
X Loss: -38.296186
Epoch 449 
Overall Loss: -16.518969
Rec Loss: -26.680077
KL Loss: 10.161108
Y Loss: 1.009501
T Loss: 11.537537
X Loss: -38.722364
Epoch 499 
Overall Loss: -17.384661
Rec Loss: -27.246314
KL Loss: 9.861654
Y Loss: 0.986603
T Loss: 11.544982
X Loss: -39.284599
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.823199
Epoch 99
Rec Loss: 1.812392
Epoch 149
Rec Loss: 1.811203
Epoch 199
Rec Loss: 1.818777
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.997148
Epoch 99
Rec Loss: 4.997706
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.582905
Insample Error 1.931350
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.580572
Rec Loss: 13.940422
KL Loss: 0.640150
Y Loss: 3.719651
T Loss: 12.080596
Epoch 99 
Overall Loss: 13.003872
Rec Loss: 12.606941
KL Loss: 0.396931
Y Loss: 1.424176
T Loss: 11.894853
Epoch 149 
Overall Loss: 12.491252
Rec Loss: 12.188878
KL Loss: 0.302375
Y Loss: 0.950120
T Loss: 11.713818
Epoch 199 
Overall Loss: 12.356846
Rec Loss: 12.071884
KL Loss: 0.284962
Y Loss: 0.790525
T Loss: 11.676622
Epoch 249 
Overall Loss: 12.296547
Rec Loss: 12.042986
KL Loss: 0.253560
Y Loss: 0.760320
T Loss: 11.662826
Epoch 299 
Overall Loss: 12.262986
Rec Loss: 12.033025
KL Loss: 0.229960
Y Loss: 0.749987
T Loss: 11.658032
Epoch 349 
Overall Loss: 12.223574
Rec Loss: 12.010056
KL Loss: 0.213518
Y Loss: 0.717273
T Loss: 11.651420
Epoch 399 
Overall Loss: 12.222393
Rec Loss: 12.020588
KL Loss: 0.201806
Y Loss: 0.721277
T Loss: 11.659949
Epoch 449 
Overall Loss: 12.178337
Rec Loss: 11.988032
KL Loss: 0.190305
Y Loss: 0.673517
T Loss: 11.651273
Epoch 499 
Overall Loss: 12.152427
Rec Loss: 11.973412
KL Loss: 0.179015
Y Loss: 0.639696
T Loss: 11.653564
Epoch 549 
Overall Loss: 12.123410
Rec Loss: 11.956152
KL Loss: 0.167258
Y Loss: 0.594493
T Loss: 11.658905
Epoch 599 
Overall Loss: 12.093791
Rec Loss: 11.934546
KL Loss: 0.159246
Y Loss: 0.553777
T Loss: 11.657658
Epoch 649 
Overall Loss: 12.060865
Rec Loss: 11.911907
KL Loss: 0.148958
Y Loss: 0.519450
T Loss: 11.652182
Epoch 699 
Overall Loss: 12.041808
Rec Loss: 11.898289
KL Loss: 0.143520
Y Loss: 0.490926
T Loss: 11.652825
Epoch 749 
Overall Loss: 12.012901
Rec Loss: 11.871644
KL Loss: 0.141258
Y Loss: 0.461842
T Loss: 11.640722
Epoch 799 
Overall Loss: 11.993241
Rec Loss: 11.855708
KL Loss: 0.137534
Y Loss: 0.445105
T Loss: 11.633155
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.524391
Epoch 99
Rec Loss: 1.522196
Epoch 149
Rec Loss: 1.516315
Epoch 199
Rec Loss: 1.519010
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.988578
Epoch 99
Rec Loss: 4.981569
Epoch 149
Rec Loss: 4.980567
Epoch 199
Rec Loss: 4.985665
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.584468
Insample Error: 1.507973
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 11.323819
Rec Loss: 6.724028
KL Loss: 4.599791
Y Loss: 6.329667
T Loss: 12.335502
X Loss: -8.776308
Epoch 99 
Overall Loss: -7.262041
Rec Loss: -15.120330
KL Loss: 7.858288
Y Loss: 2.925603
T Loss: 11.836775
X Loss: -28.419905
Epoch 149 
Overall Loss: -11.519817
Rec Loss: -19.994398
KL Loss: 8.474581
Y Loss: 2.048315
T Loss: 11.733963
X Loss: -32.752518
Epoch 199 
Overall Loss: -12.728185
Rec Loss: -21.643410
KL Loss: 8.915226
Y Loss: 1.741167
T Loss: 11.685310
X Loss: -34.199304
Epoch 249 
Overall Loss: -15.015402
Rec Loss: -24.041928
KL Loss: 9.026526
Y Loss: 1.434973
T Loss: 11.670473
X Loss: -36.429888
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.850261
Epoch 99
Rec Loss: 1.859962
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.997177
Epoch 99
Rec Loss: 4.998191
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.976092
Insample Error 2.262220
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.989179
Rec Loss: 14.533453
KL Loss: 0.455726
Y Loss: 4.888472
T Loss: 12.089217
Epoch 99 
Overall Loss: 12.964526
Rec Loss: 12.704700
KL Loss: 0.259826
Y Loss: 1.635593
T Loss: 11.886903
Epoch 149 
Overall Loss: 12.437640
Rec Loss: 12.197649
KL Loss: 0.239991
Y Loss: 0.908401
T Loss: 11.743448
Epoch 199 
Overall Loss: 12.329139
Rec Loss: 12.087739
KL Loss: 0.241401
Y Loss: 0.790894
T Loss: 11.692291
Epoch 249 
Overall Loss: 12.263609
Rec Loss: 12.036494
KL Loss: 0.227115
Y Loss: 0.747137
T Loss: 11.662926
Epoch 299 
Overall Loss: 12.239131
Rec Loss: 12.023697
KL Loss: 0.215435
Y Loss: 0.739584
T Loss: 11.653904
Epoch 349 
Overall Loss: 12.204224
Rec Loss: 12.000721
KL Loss: 0.203503
Y Loss: 0.717635
T Loss: 11.641903
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.654687
Epoch 99
Rec Loss: 1.657766
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.993804
Epoch 99
Rec Loss: 4.992289
Epoch 149
Rec Loss: 4.990918
Epoch 199
Rec Loss: 4.987944
Epoch 249
Rec Loss: 4.990542
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.687431
Insample Error: 2.285777
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 10.254221
Rec Loss: 5.742744
KL Loss: 4.511477
Y Loss: 8.620794
T Loss: 13.129218
X Loss: -11.696870
Epoch 99 
Overall Loss: -6.437936
Rec Loss: -13.975966
KL Loss: 7.538031
Y Loss: 5.625900
T Loss: 12.034148
X Loss: -28.823065
Epoch 149 
Overall Loss: -11.316641
Rec Loss: -19.450444
KL Loss: 8.133804
Y Loss: 3.462235
T Loss: 11.852461
X Loss: -33.034023
Epoch 199 
Overall Loss: -11.566586
Rec Loss: -19.332042
KL Loss: 7.765455
Y Loss: 2.831538
T Loss: 11.779813
X Loss: -32.527623
Epoch 249 
Overall Loss: -13.339866
Rec Loss: -21.920443
KL Loss: 8.580576
Y Loss: 2.462192
T Loss: 11.709565
X Loss: -34.861104
Epoch 299 
Overall Loss: -14.878911
Rec Loss: -23.732739
KL Loss: 8.853828
Y Loss: 2.080145
T Loss: 11.649150
X Loss: -36.421961
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.923089
Epoch 99
Rec Loss: 1.900605
Epoch 149
Rec Loss: 1.899844
Epoch 199
Rec Loss: 1.901069
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.995390
Epoch 99
Rec Loss: 4.996735
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 1.222587
Insample Error 2.702811
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.379156
Rec Loss: 13.863889
KL Loss: 0.515267
Y Loss: 3.630593
T Loss: 12.048593
Epoch 99 
Overall Loss: 12.868541
Rec Loss: 12.586035
KL Loss: 0.282505
Y Loss: 1.432515
T Loss: 11.869778
Epoch 149 
Overall Loss: 12.450332
Rec Loss: 12.171367
KL Loss: 0.278965
Y Loss: 0.909749
T Loss: 11.716493
Epoch 199 
Overall Loss: 12.340586
Rec Loss: 12.071835
KL Loss: 0.268751
Y Loss: 0.803736
T Loss: 11.669966
Epoch 249 
Overall Loss: 12.301450
Rec Loss: 12.054100
KL Loss: 0.247350
Y Loss: 0.785013
T Loss: 11.661594
Epoch 299 
Overall Loss: 12.243731
Rec Loss: 12.013468
KL Loss: 0.230263
Y Loss: 0.753462
T Loss: 11.636737
Epoch 349 
Overall Loss: 12.224662
Rec Loss: 12.009192
KL Loss: 0.215469
Y Loss: 0.742599
T Loss: 11.637893
Epoch 399 
Overall Loss: 12.181127
Rec Loss: 11.975329
KL Loss: 0.205797
Y Loss: 0.694419
T Loss: 11.628119
Epoch 449 
Overall Loss: 12.160813
Rec Loss: 11.957216
KL Loss: 0.203598
Y Loss: 0.659127
T Loss: 11.627652
Epoch 499 
Overall Loss: 12.133547
Rec Loss: 11.936545
KL Loss: 0.197002
Y Loss: 0.641920
T Loss: 11.615585
Epoch 549 
Overall Loss: 12.103207
Rec Loss: 11.907137
KL Loss: 0.196070
Y Loss: 0.603974
T Loss: 11.605150
Epoch 599 
Overall Loss: 12.078353
Rec Loss: 11.881496
KL Loss: 0.196856
Y Loss: 0.571672
T Loss: 11.595660
Epoch 649 
Overall Loss: 12.033409
Rec Loss: 11.836085
KL Loss: 0.197324
Y Loss: 0.531355
T Loss: 11.570408
Epoch 699 
Overall Loss: 12.004698
Rec Loss: 11.804392
KL Loss: 0.200306
Y Loss: 0.494965
T Loss: 11.556910
Epoch 749 
Overall Loss: 11.976170
Rec Loss: 11.778621
KL Loss: 0.197549
Y Loss: 0.470783
T Loss: 11.543230
Epoch 799 
Overall Loss: 11.953335
Rec Loss: 11.760339
KL Loss: 0.192996
Y Loss: 0.451103
T Loss: 11.534787
Epoch 849 
Overall Loss: 11.937542
Rec Loss: 11.753738
KL Loss: 0.183803
Y Loss: 0.431896
T Loss: 11.537790
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.330419
Epoch 99
Rec Loss: 1.322438
Epoch 149
Rec Loss: 1.328960
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.986164
Epoch 99
Rec Loss: 4.979001
Epoch 149
Rec Loss: 4.980057
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.587617
Insample Error: 1.484441
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 9.844967
Rec Loss: 5.331809
KL Loss: 4.513158
Y Loss: 6.759671
T Loss: 12.461661
X Loss: -10.509688
Epoch 99 
Overall Loss: -7.763990
Rec Loss: -15.133206
KL Loss: 7.369217
Y Loss: 2.921390
T Loss: 11.822676
X Loss: -28.416577
Epoch 149 
Overall Loss: -12.043621
Rec Loss: -20.209269
KL Loss: 8.165648
Y Loss: 1.969857
T Loss: 11.731782
X Loss: -32.925980
Epoch 199 
Overall Loss: -14.163018
Rec Loss: -22.584538
KL Loss: 8.421521
Y Loss: 1.478423
T Loss: 11.699133
X Loss: -35.022882
Epoch 249 
Overall Loss: -14.716301
Rec Loss: -23.723892
KL Loss: 9.007592
Y Loss: 1.119979
T Loss: 11.628755
X Loss: -35.912637
Epoch 299 
Overall Loss: -16.188401
Rec Loss: -25.450816
KL Loss: 9.262415
Y Loss: 0.860623
T Loss: 11.588699
X Loss: -37.469828
Epoch 349 
Overall Loss: -17.742755
Rec Loss: -26.596741
KL Loss: 8.853986
Y Loss: 0.820041
T Loss: 11.580024
X Loss: -38.586786
Epoch 399 
Overall Loss: -17.190261
Rec Loss: -26.676343
KL Loss: 9.486082
Y Loss: 0.702545
T Loss: 11.522487
X Loss: -38.550101
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.754751
Epoch 99
Rec Loss: 1.745147
Epoch 149
Rec Loss: 1.751988
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.997425
Epoch 99
Rec Loss: 4.997005
Epoch 149
Rec Loss: 4.994846
Epoch 199
Rec Loss: 4.994050
Epoch 249
Rec Loss: 4.994881
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.526329
Insample Error 2.042503
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.942278
Rec Loss: 14.517095
KL Loss: 0.425183
Y Loss: 4.991423
T Loss: 12.021384
Epoch 99 
Overall Loss: 13.046935
Rec Loss: 12.763102
KL Loss: 0.283833
Y Loss: 1.840422
T Loss: 11.842891
Epoch 149 
Overall Loss: 12.475901
Rec Loss: 12.195637
KL Loss: 0.280264
Y Loss: 0.949620
T Loss: 11.720828
Epoch 199 
Overall Loss: 12.331823
Rec Loss: 12.071296
KL Loss: 0.260527
Y Loss: 0.792576
T Loss: 11.675008
Epoch 249 
Overall Loss: 12.285349
Rec Loss: 12.046529
KL Loss: 0.238820
Y Loss: 0.759246
T Loss: 11.666906
Epoch 299 
Overall Loss: 12.236938
Rec Loss: 12.016997
KL Loss: 0.219941
Y Loss: 0.731824
T Loss: 11.651085
Epoch 349 
Overall Loss: 12.213741
Rec Loss: 12.008226
KL Loss: 0.205514
Y Loss: 0.711985
T Loss: 11.652234
Epoch 399 
Overall Loss: 12.175869
Rec Loss: 11.981271
KL Loss: 0.194598
Y Loss: 0.672983
T Loss: 11.644780
Epoch 449 
Overall Loss: 12.149171
Rec Loss: 11.964315
KL Loss: 0.184855
Y Loss: 0.642100
T Loss: 11.643265
Epoch 499 
Overall Loss: 12.116591
Rec Loss: 11.935920
KL Loss: 0.180670
Y Loss: 0.601177
T Loss: 11.635331
Epoch 549 
Overall Loss: 12.097862
Rec Loss: 11.918663
KL Loss: 0.179198
Y Loss: 0.572924
T Loss: 11.632201
Epoch 599 
Overall Loss: 12.050873
Rec Loss: 11.865612
KL Loss: 0.185260
Y Loss: 0.527913
T Loss: 11.601656
Epoch 649 
Overall Loss: 12.010617
Rec Loss: 11.810703
KL Loss: 0.199914
Y Loss: 0.498305
T Loss: 11.561551
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.453741
Epoch 99
Rec Loss: 1.453741
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.974155
Epoch 99
Rec Loss: 4.967612
Epoch 149
Rec Loss: 4.972263
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.598516
Insample Error: 1.699813
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 10.818457
Rec Loss: 6.321579
KL Loss: 4.496878
Y Loss: 6.882157
T Loss: 12.421538
X Loss: -9.541038
Epoch 99 
Overall Loss: -6.997329
Rec Loss: -14.669561
KL Loss: 7.672232
Y Loss: 3.490825
T Loss: 11.824627
X Loss: -28.239600
Epoch 149 
Overall Loss: -9.045304
Rec Loss: -17.703927
KL Loss: 8.658623
Y Loss: 2.184568
T Loss: 11.714767
X Loss: -30.510978
Epoch 199 
Overall Loss: -12.965463
Rec Loss: -22.150865
KL Loss: 9.185402
Y Loss: 1.646669
T Loss: 11.652742
X Loss: -34.626943
Epoch 249 
Overall Loss: -14.183340
Rec Loss: -23.766348
KL Loss: 9.583008
Y Loss: 1.150137
T Loss: 11.601418
X Loss: -35.942835
Epoch 299 
Overall Loss: -15.194103
Rec Loss: -25.032038
KL Loss: 9.837935
Y Loss: 0.830029
T Loss: 11.540894
X Loss: -36.987946
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.783700
Epoch 99
Rec Loss: 1.778708
Epoch 149
Rec Loss: 1.771715
Epoch 199
Rec Loss: 1.763099
Epoch 249
Rec Loss: 1.770770
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.998413
Epoch 99
Rec Loss: 4.998259
Epoch 149
Rec Loss: 4.997755
Epoch 199
Rec Loss: 4.996468
Epoch 249
Rec Loss: 4.997480
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.554683
Insample Error 2.144131
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.162778
Rec Loss: 13.500179
KL Loss: 0.662600
Y Loss: 2.888122
T Loss: 12.056118
Epoch 99 
Overall Loss: 12.930520
Rec Loss: 12.468712
KL Loss: 0.461808
Y Loss: 1.158129
T Loss: 11.889648
Epoch 149 
Overall Loss: 12.443529
Rec Loss: 12.117213
KL Loss: 0.326315
Y Loss: 0.804284
T Loss: 11.715071
Epoch 199 
Overall Loss: 12.304923
Rec Loss: 11.996493
KL Loss: 0.308430
Y Loss: 0.695617
T Loss: 11.648684
Epoch 249 
Overall Loss: 12.266870
Rec Loss: 11.977429
KL Loss: 0.289441
Y Loss: 0.691428
T Loss: 11.631716
Epoch 299 
Overall Loss: 12.238011
Rec Loss: 11.964934
KL Loss: 0.273077
Y Loss: 0.677627
T Loss: 11.626120
Epoch 349 
Overall Loss: 12.186332
Rec Loss: 11.919582
KL Loss: 0.266749
Y Loss: 0.631208
T Loss: 11.603978
Epoch 399 
Overall Loss: 12.165986
Rec Loss: 11.910325
KL Loss: 0.255661
Y Loss: 0.610252
T Loss: 11.605199
Epoch 449 
Overall Loss: 12.152009
Rec Loss: 11.898768
KL Loss: 0.253241
Y Loss: 0.588881
T Loss: 11.604328
Epoch 499 
Overall Loss: 12.122302
Rec Loss: 11.870216
KL Loss: 0.252086
Y Loss: 0.558961
T Loss: 11.590736
Epoch 549 
Overall Loss: 12.094284
Rec Loss: 11.849587
KL Loss: 0.244696
Y Loss: 0.542565
T Loss: 11.578305
Epoch 599 
Overall Loss: 12.068530
Rec Loss: 11.827408
KL Loss: 0.241121
Y Loss: 0.519632
T Loss: 11.567592
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.499595
Epoch 99
Rec Loss: 1.503807
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.990199
Epoch 99
Rec Loss: 4.984748
Epoch 149
Rec Loss: 4.982142
Epoch 199
Rec Loss: 4.983053
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.559084
Insample Error: 1.943089
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 11.583961
Rec Loss: 7.450892
KL Loss: 4.133069
Y Loss: 8.073268
T Loss: 12.872708
X Loss: -9.458450
Epoch 99 
Overall Loss: -4.354644
Rec Loss: -11.361057
KL Loss: 7.006413
Y Loss: 6.469691
T Loss: 11.955651
X Loss: -26.551553
Epoch 149 
Overall Loss: -10.247470
Rec Loss: -18.194842
KL Loss: 7.947372
Y Loss: 3.800063
T Loss: 11.840793
X Loss: -31.935667
Epoch 199 
Overall Loss: -11.875118
Rec Loss: -20.265491
KL Loss: 8.390372
Y Loss: 2.874615
T Loss: 11.792701
X Loss: -33.495499
Epoch 249 
Overall Loss: -13.348276
Rec Loss: -21.598649
KL Loss: 8.250373
Y Loss: 2.436591
T Loss: 11.776995
X Loss: -34.593939
Epoch 299 
Overall Loss: -13.748946
Rec Loss: -22.597473
KL Loss: 8.848527
Y Loss: 2.086723
T Loss: 11.722764
X Loss: -35.363600
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.988220
Epoch 99
Rec Loss: 1.967729
Epoch 149
Rec Loss: 1.964792
Epoch 199
Rec Loss: 1.966620
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.996220
Epoch 99
Rec Loss: 4.997762
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 1.152729
Insample Error 2.428126
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.747702
Rec Loss: 14.287219
KL Loss: 0.460484
Y Loss: 4.445523
T Loss: 12.064457
Epoch 99 
Overall Loss: 13.104828
Rec Loss: 12.782765
KL Loss: 0.322063
Y Loss: 1.806766
T Loss: 11.879383
Epoch 149 
Overall Loss: 12.517728
Rec Loss: 12.217768
KL Loss: 0.299960
Y Loss: 1.005280
T Loss: 11.715129
Epoch 199 
Overall Loss: 12.350429
Rec Loss: 12.065658
KL Loss: 0.284772
Y Loss: 0.792303
T Loss: 11.669506
Epoch 249 
Overall Loss: 12.270132
Rec Loss: 12.012888
KL Loss: 0.257244
Y Loss: 0.733010
T Loss: 11.646383
Epoch 299 
Overall Loss: 12.229989
Rec Loss: 11.993821
KL Loss: 0.236168
Y Loss: 0.716342
T Loss: 11.635650
Epoch 349 
Overall Loss: 12.200809
Rec Loss: 11.977375
KL Loss: 0.223434
Y Loss: 0.686107
T Loss: 11.634322
Epoch 399 
Overall Loss: 12.158229
Rec Loss: 11.944469
KL Loss: 0.213759
Y Loss: 0.643559
T Loss: 11.622690
Epoch 449 
Overall Loss: 12.131674
Rec Loss: 11.926530
KL Loss: 0.205144
Y Loss: 0.619505
T Loss: 11.616777
Epoch 499 
Overall Loss: 12.115534
Rec Loss: 11.915779
KL Loss: 0.199754
Y Loss: 0.583167
T Loss: 11.624196
Epoch 549 
Overall Loss: 12.084096
Rec Loss: 11.892464
KL Loss: 0.191633
Y Loss: 0.557425
T Loss: 11.613751
Epoch 599 
Overall Loss: 12.059345
Rec Loss: 11.877802
KL Loss: 0.181542
Y Loss: 0.524821
T Loss: 11.615392
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.609525
Epoch 99
Rec Loss: 1.611121
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.978981
Epoch 99
Rec Loss: 4.980489
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.613031
Insample Error: 1.839821
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 9.311962
Rec Loss: 3.978076
KL Loss: 5.333885
Y Loss: 5.622757
T Loss: 12.236056
X Loss: -11.069359
Epoch 99 
Overall Loss: -7.923246
Rec Loss: -15.549122
KL Loss: 7.625876
Y Loss: 2.814789
T Loss: 11.895416
X Loss: -28.851933
Epoch 149 
Overall Loss: -11.908586
Rec Loss: -19.964336
KL Loss: 8.055750
Y Loss: 2.138171
T Loss: 11.778827
X Loss: -32.812248
Epoch 199 
Overall Loss: -13.983652
Rec Loss: -22.493424
KL Loss: 8.509772
Y Loss: 1.649290
T Loss: 11.708064
X Loss: -35.026132
Epoch 249 
Overall Loss: -15.358416
Rec Loss: -24.037851
KL Loss: 8.679435
Y Loss: 1.311741
T Loss: 11.661337
X Loss: -36.355058
Epoch 299 
Overall Loss: -16.307282
Rec Loss: -25.198815
KL Loss: 8.891533
Y Loss: 1.047324
T Loss: 11.626703
X Loss: -37.349180
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.829887
Epoch 99
Rec Loss: 1.824155
Epoch 149
Rec Loss: 1.825317
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.998551
Epoch 99
Rec Loss: 4.998944
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.794100
Insample Error 2.066380
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.273690
Rec Loss: 13.785034
KL Loss: 0.488656
Y Loss: 3.426661
T Loss: 12.071704
Epoch 99 
Overall Loss: 12.933954
Rec Loss: 12.645916
KL Loss: 0.288038
Y Loss: 1.529482
T Loss: 11.881175
Epoch 149 
Overall Loss: 12.447230
Rec Loss: 12.180996
KL Loss: 0.266234
Y Loss: 0.906381
T Loss: 11.727806
Epoch 199 
Overall Loss: 12.340501
Rec Loss: 12.078416
KL Loss: 0.262085
Y Loss: 0.788020
T Loss: 11.684406
Epoch 249 
Overall Loss: 12.275700
Rec Loss: 12.035959
KL Loss: 0.239741
Y Loss: 0.740666
T Loss: 11.665625
Epoch 299 
Overall Loss: 12.262688
Rec Loss: 12.040439
KL Loss: 0.222249
Y Loss: 0.741441
T Loss: 11.669719
Epoch 349 
Overall Loss: 12.222834
Rec Loss: 12.014738
KL Loss: 0.208097
Y Loss: 0.719927
T Loss: 11.654774
Epoch 399 
Overall Loss: 12.191352
Rec Loss: 11.992401
KL Loss: 0.198951
Y Loss: 0.698414
T Loss: 11.643194
Epoch 449 
Overall Loss: 12.157151
Rec Loss: 11.966142
KL Loss: 0.191008
Y Loss: 0.648100
T Loss: 11.642092
Epoch 499 
Overall Loss: 12.126238
Rec Loss: 11.943272
KL Loss: 0.182966
Y Loss: 0.613513
T Loss: 11.636515
Epoch 549 
Overall Loss: 12.090477
Rec Loss: 11.913469
KL Loss: 0.177008
Y Loss: 0.584743
T Loss: 11.621098
Epoch 599 
Overall Loss: 12.067803
Rec Loss: 11.896152
KL Loss: 0.171650
Y Loss: 0.553308
T Loss: 11.619498
Epoch 649 
Overall Loss: 12.042196
Rec Loss: 11.868348
KL Loss: 0.173848
Y Loss: 0.528611
T Loss: 11.604042
Epoch 699 
Overall Loss: 12.016037
Rec Loss: 11.838855
KL Loss: 0.177182
Y Loss: 0.495659
T Loss: 11.591026
Epoch 749 
Overall Loss: 11.979981
Rec Loss: 11.798319
KL Loss: 0.181662
Y Loss: 0.476026
T Loss: 11.560306
Epoch 799 
Overall Loss: 11.962110
Rec Loss: 11.780231
KL Loss: 0.181879
Y Loss: 0.462520
T Loss: 11.548971
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.370996
Epoch 99
Rec Loss: 1.366217
Epoch 149
Rec Loss: 1.359043
Epoch 199
Rec Loss: 1.364662
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.983603
Epoch 99
Rec Loss: 4.983716
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.596842
Insample Error: 1.542760
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 11.212934
Rec Loss: 6.578239
KL Loss: 4.634695
Y Loss: 8.815180
T Loss: 12.638928
X Loss: -10.468280
Epoch 99 
Overall Loss: -7.344368
Rec Loss: -15.170090
KL Loss: 7.825721
Y Loss: 4.788264
T Loss: 11.840140
X Loss: -29.404362
Epoch 149 
Overall Loss: -11.572036
Rec Loss: -20.338087
KL Loss: 8.766051
Y Loss: 2.526110
T Loss: 11.723221
X Loss: -33.324364
Epoch 199 
Overall Loss: -13.973925
Rec Loss: -23.132932
KL Loss: 9.159007
Y Loss: 1.792110
T Loss: 11.633217
X Loss: -35.662204
Epoch 249 
Overall Loss: -14.958685
Rec Loss: -24.523627
KL Loss: 9.564941
Y Loss: 1.362209
T Loss: 11.565097
X Loss: -36.769828
Epoch 299 
Overall Loss: -16.317515
Rec Loss: -26.029456
KL Loss: 9.711941
Y Loss: 1.026124
T Loss: 11.519718
X Loss: -38.062235
Epoch 349 
Overall Loss: -17.071783
Rec Loss: -26.998081
KL Loss: 9.926299
Y Loss: 0.832815
T Loss: 11.475897
X Loss: -38.890385
Epoch 399 
Overall Loss: -17.345908
Rec Loss: -27.457301
KL Loss: 10.111392
Y Loss: 0.733555
T Loss: 11.457391
X Loss: -39.281470
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.818131
Epoch 99
Rec Loss: 1.812056
Epoch 149
Rec Loss: 1.811548
Epoch 199
Rec Loss: 1.809205
Epoch 249
Rec Loss: 1.804044
Epoch 299
Rec Loss: 1.797650
Epoch 349
Rec Loss: 1.793625
Epoch 399
Rec Loss: 1.791281
Epoch 449
Rec Loss: 1.794079
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.996828
Epoch 99
Rec Loss: 4.998543
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.601158
Insample Error 2.345414
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.595711
Rec Loss: 14.097241
KL Loss: 0.498469
Y Loss: 4.068323
T Loss: 12.063080
Epoch 99 
Overall Loss: 12.998841
Rec Loss: 12.678615
KL Loss: 0.320225
Y Loss: 1.591280
T Loss: 11.882975
Epoch 149 
Overall Loss: 12.457109
Rec Loss: 12.188440
KL Loss: 0.268669
Y Loss: 0.935502
T Loss: 11.720689
Epoch 199 
Overall Loss: 12.334566
Rec Loss: 12.069882
KL Loss: 0.264684
Y Loss: 0.776799
T Loss: 11.681482
Epoch 249 
Overall Loss: 12.280058
Rec Loss: 12.034896
KL Loss: 0.245162
Y Loss: 0.752645
T Loss: 11.658573
Epoch 299 
Overall Loss: 12.246058
Rec Loss: 12.012909
KL Loss: 0.233149
Y Loss: 0.732437
T Loss: 11.646690
Epoch 349 
Overall Loss: 12.201421
Rec Loss: 11.975690
KL Loss: 0.225730
Y Loss: 0.696085
T Loss: 11.627648
Epoch 399 
Overall Loss: 12.165730
Rec Loss: 11.936418
KL Loss: 0.229312
Y Loss: 0.655672
T Loss: 11.608582
Epoch 449 
Overall Loss: 12.134735
Rec Loss: 11.898020
KL Loss: 0.236715
Y Loss: 0.635902
T Loss: 11.580069
Epoch 499 
Overall Loss: 12.107004
Rec Loss: 11.869767
KL Loss: 0.237236
Y Loss: 0.605413
T Loss: 11.567061
Epoch 549 
Overall Loss: 12.081805
Rec Loss: 11.850894
KL Loss: 0.230911
Y Loss: 0.581462
T Loss: 11.560163
Epoch 599 
Overall Loss: 12.043048
Rec Loss: 11.824059
KL Loss: 0.218989
Y Loss: 0.541947
T Loss: 11.553086
Epoch 649 
Overall Loss: 12.025694
Rec Loss: 11.814857
KL Loss: 0.210837
Y Loss: 0.511584
T Loss: 11.559065
Epoch 699 
Overall Loss: 11.994135
Rec Loss: 11.790284
KL Loss: 0.203851
Y Loss: 0.474415
T Loss: 11.553077
Epoch 749 
Overall Loss: 11.978188
Rec Loss: 11.779186
KL Loss: 0.199002
Y Loss: 0.448243
T Loss: 11.555064
Epoch 799 
Overall Loss: 11.951135
Rec Loss: 11.754461
KL Loss: 0.196673
Y Loss: 0.421898
T Loss: 11.543512
Epoch 849 
Overall Loss: 11.949934
Rec Loss: 11.756289
KL Loss: 0.193644
Y Loss: 0.412588
T Loss: 11.549995
Epoch 899 
Overall Loss: 11.940519
Rec Loss: 11.748910
KL Loss: 0.191609
Y Loss: 0.404975
T Loss: 11.546422
Epoch 949 
Overall Loss: 11.923927
Rec Loss: 11.733925
KL Loss: 0.190001
Y Loss: 0.398121
T Loss: 11.534865
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.332412
Epoch 99
Rec Loss: 1.327412
Epoch 149
Rec Loss: 1.328623
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.984676
Epoch 99
Rec Loss: 4.980322
Epoch 149
Rec Loss: 4.981538
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.558564
Insample Error: 1.329533
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 8.961350
Rec Loss: 4.268061
KL Loss: 4.693289
Y Loss: 5.682432
T Loss: 12.396979
X Loss: -10.970135
Epoch 99 
Overall Loss: -5.306377
Rec Loss: -12.184233
KL Loss: 6.877856
Y Loss: 2.406760
T Loss: 11.886845
X Loss: -25.274459
Epoch 149 
Overall Loss: -9.267823
Rec Loss: -17.035840
KL Loss: 7.768017
Y Loss: 1.752243
T Loss: 11.775552
X Loss: -29.687514
Epoch 199 
Overall Loss: -13.555418
Rec Loss: -21.851263
KL Loss: 8.295844
Y Loss: 1.446480
T Loss: 11.652348
X Loss: -34.226851
Epoch 249 
Overall Loss: -14.812649
Rec Loss: -23.495986
KL Loss: 8.683337
Y Loss: 1.245899
T Loss: 11.572369
X Loss: -35.691303
Epoch 299 
Overall Loss: -15.492279
Rec Loss: -24.343580
KL Loss: 8.851301
Y Loss: 1.048689
T Loss: 11.526911
X Loss: -36.394836
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.849803
Epoch 99
Rec Loss: 1.840774
Epoch 149
Rec Loss: 1.837924
Epoch 199
Rec Loss: 1.826418
Epoch 249
Rec Loss: 1.822831
Epoch 299
Rec Loss: 1.820987
Epoch 349
Rec Loss: 1.820280
Epoch 399
Rec Loss: 1.812779
Epoch 449
Rec Loss: 1.820473
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.994640
Epoch 99
Rec Loss: 4.989736
Epoch 149
Rec Loss: 4.993668
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.802061
Insample Error 2.372977
Ours, Train RMSE
0.5698, 
0.5928, 
0.5845, 
0.6874, 
0.5876, 
0.5985, 
0.5591, 
0.6130, 
0.5968, 
0.5586, 
CEVAE, Train RMSE
0.7902, 
0.5829, 
0.9761, 
1.2226, 
0.5263, 
0.5547, 
1.1527, 
0.7941, 
0.6012, 
0.8021, 
Ours, Insample RMSE
1.3881, 
1.6806, 
1.5080, 
2.2858, 
1.4844, 
1.6998, 
1.9431, 
1.8398, 
1.5428, 
1.3295, 
CEVAE, Insample RMSE
2.1846, 
1.9314, 
2.2622, 
2.7028, 
2.0425, 
2.1441, 
2.4281, 
2.0664, 
2.3454, 
2.3730, 
Train, RMSE mean 0.5948 std 0.0351
CEVAE, RMSE mean 0.8003 std 0.2358
Ours, RMSE mean 1.6702 std 0.2749, reconstruct confounder 1.4425 (0.1170) noise 4.9794 (0.0054)
CEVAE, RMSE mean 2.2481 std 0.2133, reconstruct confounder 1.8288 (0.0611) noise 4.9958 (0.0023)
