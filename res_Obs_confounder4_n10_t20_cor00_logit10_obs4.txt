Experiment Start!
Namespace(decay=0.0, l=5e-05, latdim=4, mask=0, nlayer=50, obsm=4, ycof=0.5, ylayer=50)
Y Mean -0.063601, Std 1.481582 
Observe confounder 4, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 13.700073
Rec Loss: 13.506984
KL Loss: 0.193089
Y Loss: 0.885231
T Loss: 13.064368
Epoch 99 
Overall Loss: 11.936159
Rec Loss: 11.492503
KL Loss: 0.443656
Y Loss: 0.799967
T Loss: 11.092520
Epoch 149 
Overall Loss: 11.453104
Rec Loss: 11.080487
KL Loss: 0.372617
Y Loss: 0.664714
T Loss: 10.748130
Epoch 199 
Overall Loss: 11.323271
Rec Loss: 11.067295
KL Loss: 0.255976
Y Loss: 0.581549
T Loss: 10.776520
Epoch 249 
Overall Loss: 11.014400
Rec Loss: 10.782913
KL Loss: 0.231487
Y Loss: 0.503864
T Loss: 10.530981
Epoch 299 
Overall Loss: 10.559576
Rec Loss: 10.308613
KL Loss: 0.250964
Y Loss: 0.429361
T Loss: 10.093932
Epoch 349 
Overall Loss: 10.491721
Rec Loss: 10.277556
KL Loss: 0.214166
Y Loss: 0.370004
T Loss: 10.092554
Epoch 399 
Overall Loss: 10.455071
Rec Loss: 10.261652
KL Loss: 0.193420
Y Loss: 0.309537
T Loss: 10.106883
Epoch 449 
Overall Loss: 10.412198
Rec Loss: 10.235449
KL Loss: 0.176748
Y Loss: 0.261157
T Loss: 10.104870
Epoch 499 
Overall Loss: 10.379140
Rec Loss: 10.218239
KL Loss: 0.160901
Y Loss: 0.210045
T Loss: 10.113217
Epoch 549 
Overall Loss: 10.360581
Rec Loss: 10.210804
KL Loss: 0.149778
Y Loss: 0.175890
T Loss: 10.122859
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 0.140527
Epoch 99
Rec Loss: 0.135899
Epoch 149
Rec Loss: 0.135497
Epoch 199
Rec Loss: 0.137113
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.130351
Epoch 99
Rec Loss: 10.119215
Epoch 149
Rec Loss: 10.114560
Epoch 199
Rec Loss: 10.116000
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.359321
Insample Error: 0.657181
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 16.246021
Rec Loss: 14.066205
KL Loss: 2.179816
Y Loss: 1.381116
T Loss: 13.828201
X Loss: -0.452554
Epoch 99 
Overall Loss: -1.005901
Rec Loss: -10.168347
KL Loss: 9.162446
Y Loss: 1.185482
T Loss: 13.708926
X Loss: -24.470015
Epoch 149 
Overall Loss: -5.640969
Rec Loss: -15.699200
KL Loss: 10.058231
Y Loss: 1.160011
T Loss: 13.639819
X Loss: -29.919025
Epoch 199 
Overall Loss: -7.976003
Rec Loss: -19.096346
KL Loss: 11.120343
Y Loss: 1.133279
T Loss: 13.588684
X Loss: -33.251670
Epoch 249 
Overall Loss: -10.145871
Rec Loss: -22.187842
KL Loss: 12.041971
Y Loss: 1.085235
T Loss: 13.518766
X Loss: -36.249225
Epoch 299 
Overall Loss: -11.491141
Rec Loss: -24.229833
KL Loss: 12.738693
Y Loss: 1.035944
T Loss: 13.428525
X Loss: -38.176330
Epoch 349 
Overall Loss: -12.756747
Rec Loss: -25.965603
KL Loss: 13.208856
Y Loss: 0.973167
T Loss: 13.259197
X Loss: -39.711384
Epoch 399 
Overall Loss: -13.989233
Rec Loss: -27.566615
KL Loss: 13.577383
Y Loss: 0.903211
T Loss: 13.114895
X Loss: -41.133117
Epoch 449 
Overall Loss: -14.875810
Rec Loss: -28.752690
KL Loss: 13.876879
Y Loss: 0.846658
T Loss: 12.928191
X Loss: -42.104209
Epoch 499 
Overall Loss: -15.536560
Rec Loss: -29.651948
KL Loss: 14.115388
Y Loss: 0.791201
T Loss: 12.785360
X Loss: -42.832908
Epoch 549 
Overall Loss: -15.746901
Rec Loss: -30.018684
KL Loss: 14.271783
Y Loss: 0.750283
T Loss: 12.675699
X Loss: -43.069524
Epoch 599 
Overall Loss: -16.855672
Rec Loss: -31.313377
KL Loss: 14.457705
Y Loss: 0.720598
T Loss: 12.532717
X Loss: -44.206392
Epoch 649 
Overall Loss: -17.435889
Rec Loss: -32.067527
KL Loss: 14.631639
Y Loss: 0.691416
T Loss: 12.436241
X Loss: -44.849476
Epoch 699 
Overall Loss: -18.046208
Rec Loss: -32.754746
KL Loss: 14.708538
Y Loss: 0.673547
T Loss: 12.361999
X Loss: -45.453518
Epoch 749 
Overall Loss: -18.402065
Rec Loss: -33.341824
KL Loss: 14.939759
Y Loss: 0.655152
T Loss: 12.286541
X Loss: -45.955942
Epoch 799 
Overall Loss: -18.777644
Rec Loss: -33.888881
KL Loss: 15.111237
Y Loss: 0.640607
T Loss: 12.172410
X Loss: -46.381595
Epoch 849 
Overall Loss: -19.434632
Rec Loss: -34.641416
KL Loss: 15.206783
Y Loss: 0.619920
T Loss: 12.094012
X Loss: -47.045387
Epoch 899 
Overall Loss: -19.707276
Rec Loss: -35.007036
KL Loss: 15.299760
Y Loss: 0.612080
T Loss: 12.049138
X Loss: -47.362214
Epoch 949 
Overall Loss: -20.037868
Rec Loss: -35.361614
KL Loss: 15.323746
Y Loss: 0.601801
T Loss: 11.990096
X Loss: -47.652611
Epoch 999 
Overall Loss: -20.630781
Rec Loss: -36.081753
KL Loss: 15.450972
Y Loss: 0.604447
T Loss: 11.923394
X Loss: -48.307370
Epoch 1049 
Overall Loss: -20.581028
Rec Loss: -36.101460
KL Loss: 15.520432
Y Loss: 0.594592
T Loss: 11.890291
X Loss: -48.289048
Epoch 1099 
Overall Loss: -21.205708
Rec Loss: -36.793875
KL Loss: 15.588167
Y Loss: 0.592575
T Loss: 11.822631
X Loss: -48.912794
Epoch 1149 
Overall Loss: -21.086817
Rec Loss: -36.717685
KL Loss: 15.630869
Y Loss: 0.584845
T Loss: 11.783360
X Loss: -48.793468
Epoch 1199 
Overall Loss: -21.692908
Rec Loss: -37.432017
KL Loss: 15.739110
Y Loss: 0.586650
T Loss: 11.731949
X Loss: -49.457291
Epoch 1249 
Overall Loss: -21.965501
Rec Loss: -37.712677
KL Loss: 15.747175
Y Loss: 0.587008
T Loss: 11.711038
X Loss: -49.717219
Epoch 1299 
Overall Loss: -22.335386
Rec Loss: -38.130280
KL Loss: 15.794894
Y Loss: 0.590069
T Loss: 11.709961
X Loss: -50.135277
Epoch 1349 
Overall Loss: -22.545615
Rec Loss: -38.460687
KL Loss: 15.915072
Y Loss: 0.577786
T Loss: 11.648203
X Loss: -50.397782
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.654606
Epoch 99
Rec Loss: 2.626743
Epoch 149
Rec Loss: 2.623778
Epoch 199
Rec Loss: 2.631040
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.003326
Epoch 99
Rec Loss: 0.001485
Epoch 149
Rec Loss: 0.001043
Epoch 199
Rec Loss: 0.000642
Epoch 249
Rec Loss: 0.000646
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.695523
Insample Error 1.275802
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 13.827380
Rec Loss: 13.618134
KL Loss: 0.209246
Y Loss: 1.129771
T Loss: 13.053248
Epoch 99 
Overall Loss: 12.287985
Rec Loss: 11.892841
KL Loss: 0.395145
Y Loss: 0.837598
T Loss: 11.474042
Epoch 149 
Overall Loss: 11.478647
Rec Loss: 11.081525
KL Loss: 0.397122
Y Loss: 0.705183
T Loss: 10.728933
Epoch 199 
Overall Loss: 10.832389
Rec Loss: 10.443635
KL Loss: 0.388754
Y Loss: 0.604227
T Loss: 10.141522
Epoch 249 
Overall Loss: 10.631873
Rec Loss: 10.317067
KL Loss: 0.314806
Y Loss: 0.514164
T Loss: 10.059985
Epoch 299 
Overall Loss: 10.549058
Rec Loss: 10.293553
KL Loss: 0.255505
Y Loss: 0.446000
T Loss: 10.070553
Epoch 349 
Overall Loss: 10.509175
Rec Loss: 10.285060
KL Loss: 0.224115
Y Loss: 0.382037
T Loss: 10.094041
Epoch 399 
Overall Loss: 10.450509
Rec Loss: 10.252235
KL Loss: 0.198274
Y Loss: 0.306926
T Loss: 10.098772
Epoch 449 
Overall Loss: 10.410118
Rec Loss: 10.229252
KL Loss: 0.180866
Y Loss: 0.243510
T Loss: 10.107498
Epoch 499 
Overall Loss: 10.375835
Rec Loss: 10.211455
KL Loss: 0.164379
Y Loss: 0.191073
T Loss: 10.115919
Epoch 549 
Overall Loss: 10.356956
Rec Loss: 10.206606
KL Loss: 0.150350
Y Loss: 0.153366
T Loss: 10.129923
Epoch 599 
Overall Loss: 10.335383
Rec Loss: 10.194602
KL Loss: 0.140781
Y Loss: 0.133099
T Loss: 10.128052
Epoch 649 
Overall Loss: 10.319387
Rec Loss: 10.189507
KL Loss: 0.129880
Y Loss: 0.114863
T Loss: 10.132076
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 0.119222
Epoch 99
Rec Loss: 0.115494
Epoch 149
Rec Loss: 0.114632
Epoch 199
Rec Loss: 0.113480
Epoch 249
Rec Loss: 0.111079
Epoch 299
Rec Loss: 0.112037
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.146016
Epoch 99
Rec Loss: 10.135164
Epoch 149
Rec Loss: 10.118216
Epoch 199
Rec Loss: 10.110679
Epoch 249
Rec Loss: 10.096857
Epoch 299
Rec Loss: 10.095596
Epoch 349
Rec Loss: 10.082589
Epoch 399
Rec Loss: 10.084520
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.276538
Insample Error: 0.522794
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 13.556779
Rec Loss: 9.632060
KL Loss: 3.924719
Y Loss: 1.360886
T Loss: 13.755463
X Loss: -4.803847
Epoch 99 
Overall Loss: 0.226052
Rec Loss: -9.653598
KL Loss: 9.879651
Y Loss: 1.127653
T Loss: 13.454552
X Loss: -23.671976
Epoch 149 
Overall Loss: -3.718710
Rec Loss: -14.784571
KL Loss: 11.065861
Y Loss: 0.977984
T Loss: 13.025462
X Loss: -28.299025
Epoch 199 
Overall Loss: -6.166902
Rec Loss: -18.488982
KL Loss: 12.322080
Y Loss: 0.786862
T Loss: 12.758860
X Loss: -31.641273
Epoch 249 
Overall Loss: -7.801162
Rec Loss: -21.144752
KL Loss: 13.343591
Y Loss: 0.561079
T Loss: 12.585264
X Loss: -34.010557
Epoch 299 
Overall Loss: -9.231406
Rec Loss: -23.351784
KL Loss: 14.120378
Y Loss: 0.406404
T Loss: 12.432446
X Loss: -35.987432
Epoch 349 
Overall Loss: -10.228516
Rec Loss: -24.965962
KL Loss: 14.737445
Y Loss: 0.345246
T Loss: 12.268677
X Loss: -37.407262
Epoch 399 
Overall Loss: -11.165364
Rec Loss: -26.336485
KL Loss: 15.171121
Y Loss: 0.308671
T Loss: 12.146660
X Loss: -38.637481
Epoch 449 
Overall Loss: -12.090516
Rec Loss: -27.600183
KL Loss: 15.509666
Y Loss: 0.277464
T Loss: 12.015966
X Loss: -39.754881
Epoch 499 
Overall Loss: -12.642650
Rec Loss: -28.445421
KL Loss: 15.802770
Y Loss: 0.285354
T Loss: 11.939926
X Loss: -40.528023
Epoch 549 
Overall Loss: -9.916029
Rec Loss: -25.946043
KL Loss: 16.030013
Y Loss: 0.283849
T Loss: 11.880308
X Loss: -37.968273
Epoch 599 
Overall Loss: -13.780277
Rec Loss: -29.973258
KL Loss: 16.192981
Y Loss: 0.256571
T Loss: 11.796379
X Loss: -41.897921
Epoch 649 
Overall Loss: -14.146201
Rec Loss: -30.551302
KL Loss: 16.405102
Y Loss: 0.251879
T Loss: 11.738780
X Loss: -42.416021
Epoch 699 
Overall Loss: -14.667360
Rec Loss: -31.220973
KL Loss: 16.553613
Y Loss: 0.241757
T Loss: 11.661762
X Loss: -43.003614
Epoch 749 
Overall Loss: -15.043917
Rec Loss: -31.714486
KL Loss: 16.670569
Y Loss: 0.231623
T Loss: 11.623591
X Loss: -43.453888
Epoch 799 
Overall Loss: -15.579012
Rec Loss: -32.510196
KL Loss: 16.931183
Y Loss: 0.218460
T Loss: 11.555156
X Loss: -44.174581
Epoch 849 
Overall Loss: -15.894428
Rec Loss: -32.835911
KL Loss: 16.941483
Y Loss: 0.220706
T Loss: 11.492020
X Loss: -44.438283
Epoch 899 
Overall Loss: -16.324729
Rec Loss: -33.383199
KL Loss: 17.058471
Y Loss: 0.224639
T Loss: 11.425610
X Loss: -44.921129
Epoch 949 
Overall Loss: -16.658197
Rec Loss: -33.870969
KL Loss: 17.212772
Y Loss: 0.209339
T Loss: 11.361843
X Loss: -45.337482
Epoch 999 
Overall Loss: -16.984082
Rec Loss: -34.291012
KL Loss: 17.306930
Y Loss: 0.201169
T Loss: 11.319098
X Loss: -45.710695
Epoch 1049 
Overall Loss: -17.254965
Rec Loss: -34.686414
KL Loss: 17.431450
Y Loss: 0.207495
T Loss: 11.268704
X Loss: -46.058866
Epoch 1099 
Overall Loss: -17.740784
Rec Loss: -35.219666
KL Loss: 17.478882
Y Loss: 0.201872
T Loss: 11.234150
X Loss: -46.554751
Epoch 1149 
Overall Loss: -17.927145
Rec Loss: -35.407867
KL Loss: 17.480722
Y Loss: 0.205539
T Loss: 11.201465
X Loss: -46.712102
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.531650
Epoch 99
Rec Loss: 2.516152
Epoch 149
Rec Loss: 2.518040
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.002955
Epoch 99
Rec Loss: 0.002067
Epoch 149
Rec Loss: 0.001878
Epoch 199
Rec Loss: 0.001990
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.385775
Insample Error 2.761910
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 13.834087
Rec Loss: 13.628264
KL Loss: 0.205823
Y Loss: 1.041906
T Loss: 13.107311
Epoch 99 
Overall Loss: 11.923059
Rec Loss: 11.475159
KL Loss: 0.447900
Y Loss: 0.845600
T Loss: 11.052360
Epoch 149 
Overall Loss: 10.955932
Rec Loss: 10.490890
KL Loss: 0.465041
Y Loss: 0.682718
T Loss: 10.149532
Epoch 199 
Overall Loss: 10.653447
Rec Loss: 10.295110
KL Loss: 0.358337
Y Loss: 0.541609
T Loss: 10.024306
Epoch 249 
Overall Loss: 10.554675
Rec Loss: 10.265915
KL Loss: 0.288760
Y Loss: 0.451232
T Loss: 10.040299
Epoch 299 
Overall Loss: 10.498869
Rec Loss: 10.252952
KL Loss: 0.245917
Y Loss: 0.385017
T Loss: 10.060443
Epoch 349 
Overall Loss: 10.466506
Rec Loss: 10.246852
KL Loss: 0.219654
Y Loss: 0.334291
T Loss: 10.079706
Epoch 399 
Overall Loss: 10.418407
Rec Loss: 10.223177
KL Loss: 0.195229
Y Loss: 0.274923
T Loss: 10.085716
Epoch 449 
Overall Loss: 10.390750
Rec Loss: 10.214919
KL Loss: 0.175830
Y Loss: 0.215988
T Loss: 10.106925
Epoch 499 
Overall Loss: 10.370023
Rec Loss: 10.208365
KL Loss: 0.161658
Y Loss: 0.170940
T Loss: 10.122894
Epoch 549 
Overall Loss: 10.338139
Rec Loss: 10.191012
KL Loss: 0.147127
Y Loss: 0.137079
T Loss: 10.122473
Epoch 599 
Overall Loss: 10.324456
Rec Loss: 10.188354
KL Loss: 0.136102
Y Loss: 0.118777
T Loss: 10.128966
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 0.124638
Epoch 99
Rec Loss: 0.118255
Epoch 149
Rec Loss: 0.118946
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.149512
Epoch 99
Rec Loss: 10.131259
Epoch 149
Rec Loss: 10.115144
Epoch 199
Rec Loss: 10.110788
Epoch 249
Rec Loss: 10.088412
Epoch 299
Rec Loss: 10.081444
Epoch 349
Rec Loss: 10.085404
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.284436
Insample Error: 0.524846
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 13.943149
Rec Loss: 10.224191
KL Loss: 3.718959
Y Loss: 1.247764
T Loss: 13.739783
X Loss: -4.139474
Epoch 99 
Overall Loss: -1.267179
Rec Loss: -11.040761
KL Loss: 9.773582
Y Loss: 0.834032
T Loss: 13.224978
X Loss: -24.682756
Epoch 149 
Overall Loss: -6.186808
Rec Loss: -16.958750
KL Loss: 10.771942
Y Loss: 0.665117
T Loss: 13.023381
X Loss: -30.314690
Epoch 199 
Overall Loss: -8.873096
Rec Loss: -20.461685
KL Loss: 11.588589
Y Loss: 0.509724
T Loss: 12.898412
X Loss: -33.614959
Epoch 249 
Overall Loss: -10.696974
Rec Loss: -22.822999
KL Loss: 12.126024
Y Loss: 0.451567
T Loss: 12.823800
X Loss: -35.872583
Epoch 299 
Overall Loss: -11.910058
Rec Loss: -24.395456
KL Loss: 12.485398
Y Loss: 0.428361
T Loss: 12.753442
X Loss: -37.363079
Epoch 349 
Overall Loss: -13.061998
Rec Loss: -25.845190
KL Loss: 12.783192
Y Loss: 0.403203
T Loss: 12.679612
X Loss: -38.726402
Epoch 399 
Overall Loss: -13.983078
Rec Loss: -27.065966
KL Loss: 13.082887
Y Loss: 0.392387
T Loss: 12.579470
X Loss: -39.841628
Epoch 449 
Overall Loss: -14.848115
Rec Loss: -28.180092
KL Loss: 13.331977
Y Loss: 0.385829
T Loss: 12.449678
X Loss: -40.822685
Epoch 499 
Overall Loss: -15.480578
Rec Loss: -29.086140
KL Loss: 13.605562
Y Loss: 0.382471
T Loss: 12.285423
X Loss: -41.562798
Epoch 549 
Overall Loss: -16.402836
Rec Loss: -30.176286
KL Loss: 13.773449
Y Loss: 0.391688
T Loss: 12.164266
X Loss: -42.536396
Epoch 599 
Overall Loss: -16.785989
Rec Loss: -30.715579
KL Loss: 13.929590
Y Loss: 0.404555
T Loss: 12.071415
X Loss: -42.989271
Epoch 649 
Overall Loss: -17.540739
Rec Loss: -31.578626
KL Loss: 14.037887
Y Loss: 0.426773
T Loss: 11.975441
X Loss: -43.767453
Epoch 699 
Overall Loss: -18.215707
Rec Loss: -32.319827
KL Loss: 14.104120
Y Loss: 0.431156
T Loss: 11.904352
X Loss: -44.439756
Epoch 749 
Overall Loss: -18.686102
Rec Loss: -32.915152
KL Loss: 14.229049
Y Loss: 0.441678
T Loss: 11.832309
X Loss: -44.968300
Epoch 799 
Overall Loss: -19.161340
Rec Loss: -33.461029
KL Loss: 14.299690
Y Loss: 0.466183
T Loss: 11.761325
X Loss: -45.455445
Epoch 849 
Overall Loss: -19.674670
Rec Loss: -34.033867
KL Loss: 14.359197
Y Loss: 0.465598
T Loss: 11.705625
X Loss: -45.972291
Epoch 899 
Overall Loss: -20.164582
Rec Loss: -34.543435
KL Loss: 14.378853
Y Loss: 0.473144
T Loss: 11.664800
X Loss: -46.444807
Epoch 949 
Overall Loss: -20.372023
Rec Loss: -34.923241
KL Loss: 14.551218
Y Loss: 0.485243
T Loss: 11.569260
X Loss: -46.735122
Epoch 999 
Overall Loss: -20.891952
Rec Loss: -35.508578
KL Loss: 14.616627
Y Loss: 0.482449
T Loss: 11.518433
X Loss: -47.268235
Epoch 1049 
Overall Loss: -20.955665
Rec Loss: -35.676190
KL Loss: 14.720524
Y Loss: 0.485071
T Loss: 11.477510
X Loss: -47.396235
Epoch 1099 
Overall Loss: -21.597182
Rec Loss: -36.391420
KL Loss: 14.794236
Y Loss: 0.478693
T Loss: 11.443223
X Loss: -48.073988
Epoch 1149 
Overall Loss: -21.763050
Rec Loss: -36.616816
KL Loss: 14.853765
Y Loss: 0.491667
T Loss: 11.413027
X Loss: -48.275676
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.502994
Epoch 99
Rec Loss: 2.482621
Epoch 149
Rec Loss: 2.484442
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.003618
Epoch 99
Rec Loss: 0.001660
Epoch 149
Rec Loss: 0.002201
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.566808
Insample Error 1.200329
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 13.762258
Rec Loss: 13.589208
KL Loss: 0.173050
Y Loss: 1.013221
T Loss: 13.082598
Epoch 99 
Overall Loss: 12.542194
Rec Loss: 12.225513
KL Loss: 0.316681
Y Loss: 0.908492
T Loss: 11.771267
Epoch 149 
Overall Loss: 12.058655
Rec Loss: 11.761345
KL Loss: 0.297310
Y Loss: 0.773936
T Loss: 11.374378
Epoch 199 
Overall Loss: 11.550784
Rec Loss: 11.276612
KL Loss: 0.274171
Y Loss: 0.645048
T Loss: 10.954089
Epoch 249 
Overall Loss: 11.195458
Rec Loss: 10.943383
KL Loss: 0.252075
Y Loss: 0.542542
T Loss: 10.672113
Epoch 299 
Overall Loss: 10.600050
Rec Loss: 10.316535
KL Loss: 0.283514
Y Loss: 0.455592
T Loss: 10.088739
Epoch 349 
Overall Loss: 10.524368
Rec Loss: 10.293223
KL Loss: 0.231144
Y Loss: 0.396847
T Loss: 10.094800
Epoch 399 
Overall Loss: 10.475615
Rec Loss: 10.271985
KL Loss: 0.203630
Y Loss: 0.347261
T Loss: 10.098355
Epoch 449 
Overall Loss: 10.437126
Rec Loss: 10.250309
KL Loss: 0.186817
Y Loss: 0.286558
T Loss: 10.107030
Epoch 499 
Overall Loss: 10.391242
Rec Loss: 10.221204
KL Loss: 0.170038
Y Loss: 0.230694
T Loss: 10.105858
Epoch 549 
Overall Loss: 10.367208
Rec Loss: 10.211058
KL Loss: 0.156149
Y Loss: 0.177757
T Loss: 10.122180
Epoch 599 
Overall Loss: 10.343833
Rec Loss: 10.197564
KL Loss: 0.146269
Y Loss: 0.139992
T Loss: 10.127568
Epoch 649 
Overall Loss: 10.333311
Rec Loss: 10.197816
KL Loss: 0.135494
Y Loss: 0.121022
T Loss: 10.137306
Epoch 699 
Overall Loss: 10.323035
Rec Loss: 10.195084
KL Loss: 0.127951
Y Loss: 0.106886
T Loss: 10.141641
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 0.118290
Epoch 99
Rec Loss: 0.115091
Epoch 149
Rec Loss: 0.114429
Epoch 199
Rec Loss: 0.114245
Epoch 249
Rec Loss: 0.114145
Epoch 299
Rec Loss: 0.115075
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.138478
Epoch 99
Rec Loss: 10.122802
Epoch 149
Rec Loss: 10.114462
Epoch 199
Rec Loss: 10.114861
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.275093
Insample Error: 0.564504
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 14.470043
Rec Loss: 11.282624
KL Loss: 3.187419
Y Loss: 1.320092
T Loss: 13.751552
X Loss: -3.128974
Epoch 99 
Overall Loss: -2.090647
Rec Loss: -11.635623
KL Loss: 9.544976
Y Loss: 1.239159
T Loss: 13.697261
X Loss: -25.952463
Epoch 149 
Overall Loss: -4.925022
Rec Loss: -14.934366
KL Loss: 10.009344
Y Loss: 1.208958
T Loss: 13.629540
X Loss: -29.168385
Epoch 199 
Overall Loss: -7.056591
Rec Loss: -17.798164
KL Loss: 10.741574
Y Loss: 1.175776
T Loss: 13.569769
X Loss: -31.955822
Epoch 249 
Overall Loss: -8.366814
Rec Loss: -19.673861
KL Loss: 11.307046
Y Loss: 1.136162
T Loss: 13.527478
X Loss: -33.769420
Epoch 299 
Overall Loss: -9.530846
Rec Loss: -21.284042
KL Loss: 11.753195
Y Loss: 1.076775
T Loss: 13.438108
X Loss: -35.260536
Epoch 349 
Overall Loss: -10.472978
Rec Loss: -22.597281
KL Loss: 12.124303
Y Loss: 1.014828
T Loss: 13.372380
X Loss: -36.477075
Epoch 399 
Overall Loss: -11.522124
Rec Loss: -23.978534
KL Loss: 12.456410
Y Loss: 0.959883
T Loss: 13.247154
X Loss: -37.705631
Epoch 449 
Overall Loss: -12.383494
Rec Loss: -25.136094
KL Loss: 12.752600
Y Loss: 0.916628
T Loss: 13.092723
X Loss: -38.687132
Epoch 499 
Overall Loss: -12.910958
Rec Loss: -25.940785
KL Loss: 13.029827
Y Loss: 0.880480
T Loss: 12.945770
X Loss: -39.326795
Epoch 549 
Overall Loss: -13.777768
Rec Loss: -27.053816
KL Loss: 13.276047
Y Loss: 0.856292
T Loss: 12.784269
X Loss: -40.266231
Epoch 599 
Overall Loss: -14.461515
Rec Loss: -27.910305
KL Loss: 13.448791
Y Loss: 0.835932
T Loss: 12.668924
X Loss: -40.997197
Epoch 649 
Overall Loss: -15.224984
Rec Loss: -28.840239
KL Loss: 13.615256
Y Loss: 0.818109
T Loss: 12.597061
X Loss: -41.846356
Epoch 699 
Overall Loss: -15.745439
Rec Loss: -29.547911
KL Loss: 13.802472
Y Loss: 0.804529
T Loss: 12.481699
X Loss: -42.431874
Epoch 749 
Overall Loss: -16.010574
Rec Loss: -29.978710
KL Loss: 13.968136
Y Loss: 0.790464
T Loss: 12.406220
X Loss: -42.780161
Epoch 799 
Overall Loss: -16.566756
Rec Loss: -30.624730
KL Loss: 14.057974
Y Loss: 0.780435
T Loss: 12.379982
X Loss: -43.394929
Epoch 849 
Overall Loss: -17.140861
Rec Loss: -31.338705
KL Loss: 14.197843
Y Loss: 0.771825
T Loss: 12.272674
X Loss: -43.997291
Epoch 899 
Overall Loss: -17.418108
Rec Loss: -31.772021
KL Loss: 14.353913
Y Loss: 0.762856
T Loss: 12.212455
X Loss: -44.365905
Epoch 949 
Overall Loss: -17.999229
Rec Loss: -32.448896
KL Loss: 14.449667
Y Loss: 0.755248
T Loss: 12.147758
X Loss: -44.974278
Epoch 999 
Overall Loss: -18.370589
Rec Loss: -32.949434
KL Loss: 14.578844
Y Loss: 0.748723
T Loss: 12.045936
X Loss: -45.369730
Epoch 1049 
Overall Loss: -18.549354
Rec Loss: -33.224774
KL Loss: 14.675420
Y Loss: 0.740214
T Loss: 11.976378
X Loss: -45.571258
Epoch 1099 
Overall Loss: -19.046521
Rec Loss: -33.847792
KL Loss: 14.801271
Y Loss: 0.735106
T Loss: 11.869035
X Loss: -46.084378
Epoch 1149 
Overall Loss: -19.476633
Rec Loss: -34.395059
KL Loss: 14.918427
Y Loss: 0.727733
T Loss: 11.822761
X Loss: -46.581687
Epoch 1199 
Overall Loss: -19.698764
Rec Loss: -34.717985
KL Loss: 15.019220
Y Loss: 0.725878
T Loss: 11.761851
X Loss: -46.842775
Epoch 1249 
Overall Loss: -19.816754
Rec Loss: -34.849726
KL Loss: 15.032973
Y Loss: 0.722832
T Loss: 11.715483
X Loss: -46.926626
Epoch 1299 
Overall Loss: -20.274132
Rec Loss: -35.398310
KL Loss: 15.124178
Y Loss: 0.719523
T Loss: 11.657205
X Loss: -47.415276
Epoch 1349 
Overall Loss: -20.409815
Rec Loss: -35.653527
KL Loss: 15.243712
Y Loss: 0.715179
T Loss: 11.635523
X Loss: -47.646638
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.704625
Epoch 99
Rec Loss: 2.683273
Epoch 149
Rec Loss: 2.690025
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.005204
Epoch 99
Rec Loss: 0.003649
Epoch 149
Rec Loss: 0.001950
Epoch 199
Rec Loss: 0.001770
Epoch 249
Rec Loss: 0.002285
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.842079
Insample Error 1.633641
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 13.966021
Rec Loss: 13.788693
KL Loss: 0.177327
Y Loss: 1.023448
T Loss: 13.276970
Epoch 99 
Overall Loss: 12.385883
Rec Loss: 12.018667
KL Loss: 0.367216
Y Loss: 0.834473
T Loss: 11.601430
Epoch 149 
Overall Loss: 11.537982
Rec Loss: 11.165445
KL Loss: 0.372537
Y Loss: 0.723703
T Loss: 10.803593
Epoch 199 
Overall Loss: 11.399141
Rec Loss: 11.133945
KL Loss: 0.265196
Y Loss: 0.636839
T Loss: 10.815525
Epoch 249 
Overall Loss: 11.293154
Rec Loss: 11.090415
KL Loss: 0.202739
Y Loss: 0.573753
T Loss: 10.803539
Epoch 299 
Overall Loss: 10.992741
Rec Loss: 10.794948
KL Loss: 0.197793
Y Loss: 0.488377
T Loss: 10.550759
Epoch 349 
Overall Loss: 10.534516
Rec Loss: 10.309355
KL Loss: 0.225161
Y Loss: 0.398937
T Loss: 10.109887
Epoch 399 
Overall Loss: 10.476983
Rec Loss: 10.282561
KL Loss: 0.194422
Y Loss: 0.325286
T Loss: 10.119918
Epoch 449 
Overall Loss: 10.439454
Rec Loss: 10.262112
KL Loss: 0.177342
Y Loss: 0.266995
T Loss: 10.128614
Epoch 499 
Overall Loss: 10.401291
Rec Loss: 10.238101
KL Loss: 0.163190
Y Loss: 0.221487
T Loss: 10.127358
Epoch 549 
Overall Loss: 10.382768
Rec Loss: 10.231518
KL Loss: 0.151250
Y Loss: 0.184633
T Loss: 10.139202
Epoch 599 
Overall Loss: 10.354749
Rec Loss: 10.215519
KL Loss: 0.139230
Y Loss: 0.156983
T Loss: 10.137027
Epoch 649 
Overall Loss: 10.334280
Rec Loss: 10.202344
KL Loss: 0.131936
Y Loss: 0.129880
T Loss: 10.137404
Epoch 699 
Overall Loss: 10.327817
Rec Loss: 10.204316
KL Loss: 0.123502
Y Loss: 0.116011
T Loss: 10.146310
Epoch 749 
Overall Loss: 10.320238
Rec Loss: 10.202616
KL Loss: 0.117622
Y Loss: 0.104546
T Loss: 10.150343
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 0.107412
Epoch 99
Rec Loss: 0.102287
Epoch 149
Rec Loss: 0.100435
Epoch 199
Rec Loss: 0.100894
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.146661
Epoch 99
Rec Loss: 10.141279
Epoch 149
Rec Loss: 10.115299
Epoch 199
Rec Loss: 10.116190
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.257331
Insample Error: 0.489038
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 15.058214
Rec Loss: 12.004571
KL Loss: 3.053643
Y Loss: 1.021066
T Loss: 13.626525
X Loss: -2.132486
Epoch 99 
Overall Loss: 0.590684
Rec Loss: -8.455055
KL Loss: 9.045739
Y Loss: 0.784832
T Loss: 13.301878
X Loss: -22.149349
Epoch 149 
Overall Loss: -3.723386
Rec Loss: -13.341897
KL Loss: 9.618511
Y Loss: 0.804056
T Loss: 13.229390
X Loss: -26.973314
Epoch 199 
Overall Loss: -7.313880
Rec Loss: -17.779741
KL Loss: 10.465861
Y Loss: 0.799899
T Loss: 13.191630
X Loss: -31.371321
Epoch 249 
Overall Loss: -9.065240
Rec Loss: -20.358977
KL Loss: 11.293737
Y Loss: 0.748107
T Loss: 13.131259
X Loss: -33.864290
Epoch 299 
Overall Loss: -11.636602
Rec Loss: -23.436690
KL Loss: 11.800088
Y Loss: 0.696214
T Loss: 13.068947
X Loss: -36.853744
Epoch 349 
Overall Loss: -12.903604
Rec Loss: -25.041451
KL Loss: 12.137846
Y Loss: 0.656359
T Loss: 13.011602
X Loss: -38.381232
Epoch 399 
Overall Loss: -13.908643
Rec Loss: -26.363107
KL Loss: 12.454464
Y Loss: 0.601185
T Loss: 12.949837
X Loss: -39.613535
Epoch 449 
Overall Loss: -14.988772
Rec Loss: -27.553079
KL Loss: 12.564307
Y Loss: 0.588720
T Loss: 12.880852
X Loss: -40.728291
Epoch 499 
Overall Loss: -15.933343
Rec Loss: -28.637713
KL Loss: 12.704370
Y Loss: 0.583681
T Loss: 12.819255
X Loss: -41.748811
Epoch 549 
Overall Loss: -16.717578
Rec Loss: -29.564503
KL Loss: 12.846924
Y Loss: 0.567968
T Loss: 12.747535
X Loss: -42.596022
Epoch 599 
Overall Loss: -17.216913
Rec Loss: -30.210824
KL Loss: 12.993910
Y Loss: 0.546814
T Loss: 12.688788
X Loss: -43.173019
Epoch 649 
Overall Loss: -17.917314
Rec Loss: -31.010202
KL Loss: 13.092887
Y Loss: 0.554306
T Loss: 12.643226
X Loss: -43.930580
Epoch 699 
Overall Loss: -18.526462
Rec Loss: -31.704517
KL Loss: 13.178055
Y Loss: 0.543521
T Loss: 12.604983
X Loss: -44.581260
Epoch 749 
Overall Loss: -19.026080
Rec Loss: -32.303600
KL Loss: 13.277519
Y Loss: 0.528911
T Loss: 12.576182
X Loss: -45.144236
Epoch 799 
Overall Loss: -19.362388
Rec Loss: -32.766565
KL Loss: 13.404177
Y Loss: 0.542994
T Loss: 12.551566
X Loss: -45.589628
Epoch 849 
Overall Loss: -19.937905
Rec Loss: -33.388735
KL Loss: 13.450830
Y Loss: 0.541282
T Loss: 12.530167
X Loss: -46.189543
Epoch 899 
Overall Loss: -20.232001
Rec Loss: -33.830126
KL Loss: 13.598124
Y Loss: 0.535072
T Loss: 12.493669
X Loss: -46.591330
Epoch 949 
Overall Loss: -20.478375
Rec Loss: -34.088528
KL Loss: 13.610154
Y Loss: 0.528496
T Loss: 12.488008
X Loss: -46.840785
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 3.170150
Epoch 99
Rec Loss: 3.163113
Epoch 149
Rec Loss: 3.167971
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.003711
Epoch 99
Rec Loss: 0.002354
Epoch 149
Rec Loss: 0.001800
Epoch 199
Rec Loss: 0.001607
Epoch 249
Rec Loss: 0.001970
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.625279
Insample Error 1.200033
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 13.930341
Rec Loss: 13.758412
KL Loss: 0.171929
Y Loss: 1.095708
T Loss: 13.210558
Epoch 99 
Overall Loss: 12.421153
Rec Loss: 12.029432
KL Loss: 0.391722
Y Loss: 0.848018
T Loss: 11.605423
Epoch 149 
Overall Loss: 11.555672
Rec Loss: 11.166101
KL Loss: 0.389570
Y Loss: 0.725831
T Loss: 10.803186
Epoch 199 
Overall Loss: 11.388699
Rec Loss: 11.124686
KL Loss: 0.264013
Y Loss: 0.618159
T Loss: 10.815607
Epoch 249 
Overall Loss: 11.290062
Rec Loss: 11.086387
KL Loss: 0.203674
Y Loss: 0.554845
T Loss: 10.808965
Epoch 299 
Overall Loss: 11.059773
Rec Loss: 10.861317
KL Loss: 0.198456
Y Loss: 0.500425
T Loss: 10.611105
Epoch 349 
Overall Loss: 10.537359
Rec Loss: 10.301417
KL Loss: 0.235941
Y Loss: 0.415088
T Loss: 10.093873
Epoch 399 
Overall Loss: 10.495447
Rec Loss: 10.288981
KL Loss: 0.206466
Y Loss: 0.357629
T Loss: 10.110167
Epoch 449 
Overall Loss: 10.444769
Rec Loss: 10.257843
KL Loss: 0.186926
Y Loss: 0.296705
T Loss: 10.109491
Epoch 499 
Overall Loss: 10.403564
Rec Loss: 10.231532
KL Loss: 0.172032
Y Loss: 0.244361
T Loss: 10.109351
Epoch 549 
Overall Loss: 10.374085
Rec Loss: 10.215607
KL Loss: 0.158478
Y Loss: 0.198664
T Loss: 10.116275
Epoch 599 
Overall Loss: 10.349439
Rec Loss: 10.202818
KL Loss: 0.146621
Y Loss: 0.159972
T Loss: 10.122832
Epoch 649 
Overall Loss: 10.338425
Rec Loss: 10.201495
KL Loss: 0.136930
Y Loss: 0.134754
T Loss: 10.134118
Epoch 699 
Overall Loss: 10.327618
Rec Loss: 10.199087
KL Loss: 0.128531
Y Loss: 0.115892
T Loss: 10.141141
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 0.115811
Epoch 99
Rec Loss: 0.113878
Epoch 149
Rec Loss: 0.111985
Epoch 199
Rec Loss: 0.110422
Epoch 249
Rec Loss: 0.112270
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.134407
Epoch 99
Rec Loss: 10.135941
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.278309
Insample Error: 0.537044
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 15.824206
Rec Loss: 13.176741
KL Loss: 2.647465
Y Loss: 1.135351
T Loss: 13.685985
X Loss: -1.076919
Epoch 99 
Overall Loss: -0.792570
Rec Loss: -9.189674
KL Loss: 8.397104
Y Loss: 1.154454
T Loss: 13.622969
X Loss: -23.389870
Epoch 149 
Overall Loss: -5.273780
Rec Loss: -14.141116
KL Loss: 8.867336
Y Loss: 1.168431
T Loss: 13.342472
X Loss: -28.067804
Epoch 199 
Overall Loss: -8.252698
Rec Loss: -17.613767
KL Loss: 9.361069
Y Loss: 1.160895
T Loss: 13.190763
X Loss: -31.384977
Epoch 249 
Overall Loss: -10.110834
Rec Loss: -20.015304
KL Loss: 9.904470
Y Loss: 1.133119
T Loss: 13.064199
X Loss: -33.646063
Epoch 299 
Overall Loss: -11.749224
Rec Loss: -22.199363
KL Loss: 10.450138
Y Loss: 1.088399
T Loss: 12.974663
X Loss: -35.718224
Epoch 349 
Overall Loss: -13.163415
Rec Loss: -24.057699
KL Loss: 10.894285
Y Loss: 1.033885
T Loss: 12.910897
X Loss: -37.485540
Epoch 399 
Overall Loss: -14.159477
Rec Loss: -25.365403
KL Loss: 11.205926
Y Loss: 0.976644
T Loss: 12.851402
X Loss: -38.705127
Epoch 449 
Overall Loss: -15.173154
Rec Loss: -26.726648
KL Loss: 11.553493
Y Loss: 0.925596
T Loss: 12.774462
X Loss: -39.963907
Epoch 499 
Overall Loss: -15.911604
Rec Loss: -27.706402
KL Loss: 11.794798
Y Loss: 0.881605
T Loss: 12.674242
X Loss: -40.821447
Epoch 549 
Overall Loss: -16.654322
Rec Loss: -28.710898
KL Loss: 12.056576
Y Loss: 0.842030
T Loss: 12.566355
X Loss: -41.698268
Epoch 599 
Overall Loss: -17.409847
Rec Loss: -29.727802
KL Loss: 12.317954
Y Loss: 0.806618
T Loss: 12.415492
X Loss: -42.546602
Epoch 649 
Overall Loss: -17.984084
Rec Loss: -30.519747
KL Loss: 12.535663
Y Loss: 0.775155
T Loss: 12.277201
X Loss: -43.184525
Epoch 699 
Overall Loss: -18.379587
Rec Loss: -31.052028
KL Loss: 12.672441
Y Loss: 0.751013
T Loss: 12.135211
X Loss: -43.562745
Epoch 749 
Overall Loss: -18.835622
Rec Loss: -31.719395
KL Loss: 12.883774
Y Loss: 0.729982
T Loss: 12.025373
X Loss: -44.109758
Epoch 799 
Overall Loss: -19.120300
Rec Loss: -32.104721
KL Loss: 12.984422
Y Loss: 0.706990
T Loss: 11.925632
X Loss: -44.383848
Epoch 849 
Overall Loss: -19.848733
Rec Loss: -32.896662
KL Loss: 13.047930
Y Loss: 0.691554
T Loss: 11.805567
X Loss: -45.048007
Epoch 899 
Overall Loss: -19.940407
Rec Loss: -33.159391
KL Loss: 13.218984
Y Loss: 0.668972
T Loss: 11.743120
X Loss: -45.236997
Epoch 949 
Overall Loss: -20.346591
Rec Loss: -33.529734
KL Loss: 13.183143
Y Loss: 0.665885
T Loss: 11.691753
X Loss: -45.554431
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.681494
Epoch 99
Rec Loss: 2.684121
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.015646
Epoch 99
Rec Loss: 0.005431
Epoch 149
Rec Loss: 0.007062
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.786395
Insample Error 1.465343
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 13.901488
Rec Loss: 13.709528
KL Loss: 0.191960
Y Loss: 0.939717
T Loss: 13.239670
Epoch 99 
Overall Loss: 12.543987
Rec Loss: 12.215656
KL Loss: 0.328331
Y Loss: 0.803719
T Loss: 11.813796
Epoch 149 
Overall Loss: 11.595157
Rec Loss: 11.228211
KL Loss: 0.366946
Y Loss: 0.692156
T Loss: 10.882133
Epoch 199 
Overall Loss: 11.196442
Rec Loss: 10.889185
KL Loss: 0.307257
Y Loss: 0.589103
T Loss: 10.594634
Epoch 249 
Overall Loss: 10.643967
Rec Loss: 10.339697
KL Loss: 0.304269
Y Loss: 0.510415
T Loss: 10.084490
Epoch 299 
Overall Loss: 10.552062
Rec Loss: 10.296363
KL Loss: 0.255699
Y Loss: 0.429867
T Loss: 10.081429
Epoch 349 
Overall Loss: 10.499123
Rec Loss: 10.272387
KL Loss: 0.226735
Y Loss: 0.350014
T Loss: 10.097381
Epoch 399 
Overall Loss: 10.448978
Rec Loss: 10.246208
KL Loss: 0.202770
Y Loss: 0.288889
T Loss: 10.101763
Epoch 449 
Overall Loss: 10.423248
Rec Loss: 10.239752
KL Loss: 0.183497
Y Loss: 0.234708
T Loss: 10.122397
Epoch 499 
Overall Loss: 10.380817
Rec Loss: 10.212526
KL Loss: 0.168292
Y Loss: 0.191651
T Loss: 10.116700
Epoch 549 
Overall Loss: 10.358921
Rec Loss: 10.203894
KL Loss: 0.155027
Y Loss: 0.152899
T Loss: 10.127444
Epoch 599 
Overall Loss: 10.339269
Rec Loss: 10.197369
KL Loss: 0.141900
Y Loss: 0.131510
T Loss: 10.131614
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 0.124069
Epoch 99
Rec Loss: 0.122468
Epoch 149
Rec Loss: 0.121330
Epoch 199
Rec Loss: 0.121203
Epoch 249
Rec Loss: 0.120996
Epoch 299
Rec Loss: 0.123592
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.137368
Epoch 99
Rec Loss: 10.129110
Epoch 149
Rec Loss: 10.127612
Epoch 199
Rec Loss: 10.110853
Epoch 249
Rec Loss: 10.103458
Epoch 299
Rec Loss: 10.088703
Epoch 349
Rec Loss: 10.075611
Epoch 399
Rec Loss: 10.099783
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.285085
Insample Error: 0.566868
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 16.511260
Rec Loss: 14.338412
KL Loss: 2.172848
Y Loss: 1.284995
T Loss: 13.714076
X Loss: -0.018161
Epoch 99 
Overall Loss: 0.622200
Rec Loss: -8.835177
KL Loss: 9.457376
Y Loss: 1.182939
T Loss: 13.389272
X Loss: -22.815918
Epoch 149 
Overall Loss: -3.782971
Rec Loss: -14.150922
KL Loss: 10.367952
Y Loss: 1.163222
T Loss: 13.206225
X Loss: -27.938759
Epoch 199 
Overall Loss: -6.223040
Rec Loss: -17.435367
KL Loss: 11.212327
Y Loss: 1.140414
T Loss: 13.152562
X Loss: -31.158136
Epoch 249 
Overall Loss: -8.376715
Rec Loss: -20.378134
KL Loss: 12.001419
Y Loss: 1.086776
T Loss: 13.042115
X Loss: -33.963637
Epoch 299 
Overall Loss: -9.797309
Rec Loss: -22.375104
KL Loss: 12.577794
Y Loss: 1.006577
T Loss: 12.870552
X Loss: -35.748944
Epoch 349 
Overall Loss: -11.144400
Rec Loss: -24.085263
KL Loss: 12.940863
Y Loss: 0.929662
T Loss: 12.739742
X Loss: -37.289837
Epoch 399 
Overall Loss: -11.943134
Rec Loss: -25.139332
KL Loss: 13.196197
Y Loss: 0.857582
T Loss: 12.593356
X Loss: -38.161479
Epoch 449 
Overall Loss: -12.922195
Rec Loss: -26.413048
KL Loss: 13.490853
Y Loss: 0.792062
T Loss: 12.462196
X Loss: -39.271275
Epoch 499 
Overall Loss: -13.705079
Rec Loss: -27.390341
KL Loss: 13.685261
Y Loss: 0.744741
T Loss: 12.304867
X Loss: -40.067578
Epoch 549 
Overall Loss: -14.146863
Rec Loss: -27.958971
KL Loss: 13.812107
Y Loss: 0.718371
T Loss: 12.184348
X Loss: -40.502505
Epoch 599 
Overall Loss: -14.830758
Rec Loss: -28.869307
KL Loss: 14.038550
Y Loss: 0.680685
T Loss: 12.057817
X Loss: -41.267467
Epoch 649 
Overall Loss: -15.780676
Rec Loss: -29.935875
KL Loss: 14.155199
Y Loss: 0.669065
T Loss: 11.944055
X Loss: -42.214463
Epoch 699 
Overall Loss: -16.180504
Rec Loss: -30.427009
KL Loss: 14.246506
Y Loss: 0.653577
T Loss: 11.875336
X Loss: -42.629134
Epoch 749 
Overall Loss: -16.778601
Rec Loss: -31.240451
KL Loss: 14.461851
Y Loss: 0.625866
T Loss: 11.799817
X Loss: -43.353202
Epoch 799 
Overall Loss: -17.335606
Rec Loss: -31.905278
KL Loss: 14.569672
Y Loss: 0.600332
T Loss: 11.754517
X Loss: -43.959961
Epoch 849 
Overall Loss: -17.316692
Rec Loss: -31.935890
KL Loss: 14.619198
Y Loss: 0.596440
T Loss: 11.717670
X Loss: -43.951781
Epoch 899 
Overall Loss: -17.985509
Rec Loss: -32.741380
KL Loss: 14.755872
Y Loss: 0.582014
T Loss: 11.656005
X Loss: -44.688393
Epoch 949 
Overall Loss: -18.127259
Rec Loss: -32.982623
KL Loss: 14.855363
Y Loss: 0.577349
T Loss: 11.630100
X Loss: -44.901396
Epoch 999 
Overall Loss: -18.599178
Rec Loss: -33.511583
KL Loss: 14.912405
Y Loss: 0.568605
T Loss: 11.588758
X Loss: -45.384645
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.603805
Epoch 99
Rec Loss: 2.594380
Epoch 149
Rec Loss: 2.600720
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.005231
Epoch 99
Rec Loss: 0.002724
Epoch 149
Rec Loss: 0.002312
Epoch 199
Rec Loss: 0.002543
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.681714
Insample Error 1.273888
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 13.749337
Rec Loss: 13.570995
KL Loss: 0.178343
Y Loss: 0.989581
T Loss: 13.076204
Epoch 99 
Overall Loss: 12.010392
Rec Loss: 11.565089
KL Loss: 0.445303
Y Loss: 0.804895
T Loss: 11.162642
Epoch 149 
Overall Loss: 11.555780
Rec Loss: 11.176879
KL Loss: 0.378901
Y Loss: 0.694741
T Loss: 10.829509
Epoch 199 
Overall Loss: 11.308095
Rec Loss: 11.040494
KL Loss: 0.267601
Y Loss: 0.584676
T Loss: 10.748156
Epoch 249 
Overall Loss: 10.660001
Rec Loss: 10.365890
KL Loss: 0.294111
Y Loss: 0.495907
T Loss: 10.117936
Epoch 299 
Overall Loss: 10.549647
Rec Loss: 10.299758
KL Loss: 0.249889
Y Loss: 0.423650
T Loss: 10.087933
Epoch 349 
Overall Loss: 10.500795
Rec Loss: 10.279954
KL Loss: 0.220842
Y Loss: 0.360846
T Loss: 10.099530
Epoch 399 
Overall Loss: 10.460087
Rec Loss: 10.260825
KL Loss: 0.199261
Y Loss: 0.313172
T Loss: 10.104239
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 0.174779
Epoch 99
Rec Loss: 0.170358
Epoch 149
Rec Loss: 0.170341
Epoch 199
Rec Loss: 0.171604
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.134075
Epoch 99
Rec Loss: 10.123240
Epoch 149
Rec Loss: 10.127567
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.469069
Insample Error: 0.785278
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 14.375993
Rec Loss: 11.067701
KL Loss: 3.308292
Y Loss: 1.336876
T Loss: 13.598159
X Loss: -3.198896
Epoch 99 
Overall Loss: -2.287513
Rec Loss: -10.560682
KL Loss: 8.273169
Y Loss: 1.050501
T Loss: 13.227755
X Loss: -24.313687
Epoch 149 
Overall Loss: -6.658293
Rec Loss: -15.643171
KL Loss: 8.984878
Y Loss: 1.076131
T Loss: 13.189388
X Loss: -29.370625
Epoch 199 
Overall Loss: -9.478327
Rec Loss: -19.255249
KL Loss: 9.776922
Y Loss: 1.068467
T Loss: 13.146578
X Loss: -32.936061
Epoch 249 
Overall Loss: -11.468702
Rec Loss: -21.981973
KL Loss: 10.513271
Y Loss: 1.037522
T Loss: 13.119936
X Loss: -35.620669
Epoch 299 
Overall Loss: -12.988594
Rec Loss: -24.048643
KL Loss: 11.060050
Y Loss: 0.982051
T Loss: 13.068724
X Loss: -37.608394
Epoch 349 
Overall Loss: -14.078540
Rec Loss: -25.477964
KL Loss: 11.399424
Y Loss: 0.943977
T Loss: 13.030943
X Loss: -38.980895
Epoch 399 
Overall Loss: -15.035985
Rec Loss: -26.878138
KL Loss: 11.842152
Y Loss: 0.890374
T Loss: 12.981675
X Loss: -40.305000
Epoch 449 
Overall Loss: -15.781669
Rec Loss: -27.835808
KL Loss: 12.054140
Y Loss: 0.849154
T Loss: 12.961211
X Loss: -41.221595
Epoch 499 
Overall Loss: -16.513962
Rec Loss: -28.852753
KL Loss: 12.338791
Y Loss: 0.822315
T Loss: 12.926154
X Loss: -42.190064
Epoch 549 
Overall Loss: -17.219118
Rec Loss: -29.656999
KL Loss: 12.437880
Y Loss: 0.791881
T Loss: 12.894054
X Loss: -42.946993
Epoch 599 
Overall Loss: -17.806865
Rec Loss: -30.534498
KL Loss: 12.727634
Y Loss: 0.773009
T Loss: 12.845613
X Loss: -43.766617
Epoch 649 
Overall Loss: -18.039973
Rec Loss: -30.836670
KL Loss: 12.796697
Y Loss: 0.758581
T Loss: 12.790386
X Loss: -44.006347
Epoch 699 
Overall Loss: -18.764050
Rec Loss: -31.809758
KL Loss: 13.045708
Y Loss: 0.739082
T Loss: 12.689254
X Loss: -44.868553
Epoch 749 
Overall Loss: -19.315718
Rec Loss: -32.602889
KL Loss: 13.287172
Y Loss: 0.731409
T Loss: 12.610786
X Loss: -45.579379
Epoch 799 
Overall Loss: -19.602053
Rec Loss: -32.997908
KL Loss: 13.395854
Y Loss: 0.713582
T Loss: 12.529557
X Loss: -45.884256
Epoch 849 
Overall Loss: -20.017188
Rec Loss: -33.497177
KL Loss: 13.479989
Y Loss: 0.702986
T Loss: 12.473763
X Loss: -46.322432
Epoch 899 
Overall Loss: -20.582518
Rec Loss: -34.237041
KL Loss: 13.654523
Y Loss: 0.697160
T Loss: 12.358315
X Loss: -46.943936
Epoch 949 
Overall Loss: -20.381889
Rec Loss: -34.039939
KL Loss: 13.658050
Y Loss: 0.696664
T Loss: 12.318909
X Loss: -46.707181
Epoch 999 
Overall Loss: -21.101329
Rec Loss: -35.053278
KL Loss: 13.951948
Y Loss: 0.687951
T Loss: 12.233407
X Loss: -47.630659
Epoch 1049 
Overall Loss: -21.478991
Rec Loss: -35.467317
KL Loss: 13.988325
Y Loss: 0.681262
T Loss: 12.162620
X Loss: -47.970567
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 3.015035
Epoch 99
Rec Loss: 2.987571
Epoch 149
Rec Loss: 2.994399
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.004867
Epoch 99
Rec Loss: 0.003324
Epoch 149
Rec Loss: 0.001916
Epoch 199
Rec Loss: 0.002700
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.794877
Insample Error 1.432559
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.055997
Rec Loss: 13.892474
KL Loss: 0.163523
Y Loss: 1.104346
T Loss: 13.340301
Epoch 99 
Overall Loss: 12.422325
Rec Loss: 12.059388
KL Loss: 0.362937
Y Loss: 0.846148
T Loss: 11.636314
Epoch 149 
Overall Loss: 11.608378
Rec Loss: 11.226040
KL Loss: 0.382338
Y Loss: 0.714682
T Loss: 10.868699
Epoch 199 
Overall Loss: 11.411427
Rec Loss: 11.142656
KL Loss: 0.268771
Y Loss: 0.622976
T Loss: 10.831168
Epoch 249 
Overall Loss: 11.333388
Rec Loss: 11.121804
KL Loss: 0.211584
Y Loss: 0.564698
T Loss: 10.839455
Epoch 299 
Overall Loss: 11.247853
Rec Loss: 11.067202
KL Loss: 0.180651
Y Loss: 0.529513
T Loss: 10.802446
Epoch 349 
Overall Loss: 10.747611
Rec Loss: 10.531512
KL Loss: 0.216100
Y Loss: 0.468846
T Loss: 10.297089
Epoch 399 
Overall Loss: 10.524298
Rec Loss: 10.313704
KL Loss: 0.210594
Y Loss: 0.403126
T Loss: 10.112142
Epoch 449 
Overall Loss: 10.474237
Rec Loss: 10.283533
KL Loss: 0.190704
Y Loss: 0.344230
T Loss: 10.111418
Epoch 499 
Overall Loss: 10.432826
Rec Loss: 10.257372
KL Loss: 0.175453
Y Loss: 0.280233
T Loss: 10.117256
Epoch 549 
Overall Loss: 10.401506
Rec Loss: 10.239876
KL Loss: 0.161629
Y Loss: 0.230149
T Loss: 10.124802
Epoch 599 
Overall Loss: 10.368765
Rec Loss: 10.220339
KL Loss: 0.148426
Y Loss: 0.185448
T Loss: 10.127615
Epoch 649 
Overall Loss: 10.343357
Rec Loss: 10.204343
KL Loss: 0.139014
Y Loss: 0.151839
T Loss: 10.128423
Epoch 699 
Overall Loss: 10.335058
Rec Loss: 10.206296
KL Loss: 0.128762
Y Loss: 0.131232
T Loss: 10.140680
Epoch 749 
Overall Loss: 10.310575
Rec Loss: 10.188730
KL Loss: 0.121846
Y Loss: 0.112737
T Loss: 10.132361
Epoch 799 
Overall Loss: 10.313941
Rec Loss: 10.198465
KL Loss: 0.115476
Y Loss: 0.100648
T Loss: 10.148141
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 0.111300
Epoch 99
Rec Loss: 0.105264
Epoch 149
Rec Loss: 0.104981
Epoch 199
Rec Loss: 0.104554
Epoch 249
Rec Loss: 0.106074
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.133765
Epoch 99
Rec Loss: 10.131207
Epoch 149
Rec Loss: 10.127727
Epoch 199
Rec Loss: 10.090764
Epoch 249
Rec Loss: 10.085529
Epoch 299
Rec Loss: 10.091187
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.269762
Insample Error: 0.566913
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 16.225583
Rec Loss: 13.782175
KL Loss: 2.443409
Y Loss: 1.399472
T Loss: 13.748468
X Loss: -0.666029
Epoch 99 
Overall Loss: -1.574313
Rec Loss: -10.062164
KL Loss: 8.487851
Y Loss: 1.076039
T Loss: 13.397796
X Loss: -23.997980
Epoch 149 
Overall Loss: -5.777047
Rec Loss: -14.971016
KL Loss: 9.193968
Y Loss: 1.030185
T Loss: 13.226441
X Loss: -28.712550
Epoch 199 
Overall Loss: -8.166484
Rec Loss: -18.015312
KL Loss: 9.848828
Y Loss: 0.996990
T Loss: 13.139320
X Loss: -31.653127
Epoch 249 
Overall Loss: -9.798586
Rec Loss: -20.241566
KL Loss: 10.442981
Y Loss: 0.952020
T Loss: 13.063025
X Loss: -33.780602
Epoch 299 
Overall Loss: -10.967076
Rec Loss: -21.795971
KL Loss: 10.828894
Y Loss: 0.892674
T Loss: 12.981811
X Loss: -35.224119
Epoch 349 
Overall Loss: -11.895892
Rec Loss: -23.101768
KL Loss: 11.205875
Y Loss: 0.845113
T Loss: 12.908380
X Loss: -36.432705
Epoch 399 
Overall Loss: -13.016744
Rec Loss: -24.526818
KL Loss: 11.510074
Y Loss: 0.808083
T Loss: 12.818137
X Loss: -37.748996
Epoch 449 
Overall Loss: -13.670926
Rec Loss: -25.437105
KL Loss: 11.766178
Y Loss: 0.771452
T Loss: 12.697823
X Loss: -38.520653
Epoch 499 
Overall Loss: -14.293713
Rec Loss: -26.369656
KL Loss: 12.075943
Y Loss: 0.740029
T Loss: 12.547455
X Loss: -39.287125
Epoch 549 
Overall Loss: -15.038448
Rec Loss: -27.382058
KL Loss: 12.343609
Y Loss: 0.703686
T Loss: 12.358644
X Loss: -40.092545
Epoch 599 
Overall Loss: -15.710012
Rec Loss: -28.332691
KL Loss: 12.622679
Y Loss: 0.670661
T Loss: 12.140807
X Loss: -40.808829
Epoch 649 
Overall Loss: -16.389194
Rec Loss: -29.208492
KL Loss: 12.819297
Y Loss: 0.652860
T Loss: 11.959005
X Loss: -41.493928
Epoch 699 
Overall Loss: -16.921367
Rec Loss: -29.898514
KL Loss: 12.977147
Y Loss: 0.631448
T Loss: 11.819543
X Loss: -42.033781
Epoch 749 
Overall Loss: -17.517857
Rec Loss: -30.676205
KL Loss: 13.158347
Y Loss: 0.613114
T Loss: 11.691764
X Loss: -42.674526
Epoch 799 
Overall Loss: -17.727244
Rec Loss: -30.868488
KL Loss: 13.141244
Y Loss: 0.616513
T Loss: 11.629699
X Loss: -42.806444
Epoch 849 
Overall Loss: -18.252797
Rec Loss: -31.589733
KL Loss: 13.336937
Y Loss: 0.604738
T Loss: 11.565993
X Loss: -43.458096
Epoch 899 
Overall Loss: -18.681261
Rec Loss: -32.137002
KL Loss: 13.455740
Y Loss: 0.593748
T Loss: 11.509371
X Loss: -43.943246
Epoch 949 
Overall Loss: -18.935946
Rec Loss: -32.483167
KL Loss: 13.547221
Y Loss: 0.591545
T Loss: 11.486112
X Loss: -44.265051
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.665562
Epoch 99
Rec Loss: 2.667654
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.009340
Epoch 99
Rec Loss: 0.007429
Epoch 149
Rec Loss: 0.011136
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.686830
Insample Error 1.209563
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 13.770321
Rec Loss: 13.580068
KL Loss: 0.190254
Y Loss: 0.996336
T Loss: 13.081899
Epoch 99 
Overall Loss: 12.241209
Rec Loss: 11.817038
KL Loss: 0.424170
Y Loss: 0.778225
T Loss: 11.427926
Epoch 149 
Overall Loss: 11.522162
Rec Loss: 11.124291
KL Loss: 0.397871
Y Loss: 0.672196
T Loss: 10.788193
Epoch 199 
Overall Loss: 11.279066
Rec Loss: 10.993734
KL Loss: 0.285332
Y Loss: 0.588656
T Loss: 10.699406
Epoch 249 
Overall Loss: 10.638161
Rec Loss: 10.332399
KL Loss: 0.305762
Y Loss: 0.485826
T Loss: 10.089485
Epoch 299 
Overall Loss: 10.527850
Rec Loss: 10.282004
KL Loss: 0.245846
Y Loss: 0.401158
T Loss: 10.081425
Epoch 349 
Overall Loss: 10.490385
Rec Loss: 10.277016
KL Loss: 0.213369
Y Loss: 0.348777
T Loss: 10.102627
Epoch 399 
Overall Loss: 10.438595
Rec Loss: 10.246318
KL Loss: 0.192276
Y Loss: 0.283304
T Loss: 10.104666
Epoch 449 
Overall Loss: 10.400793
Rec Loss: 10.226392
KL Loss: 0.174401
Y Loss: 0.223764
T Loss: 10.114510
Epoch 499 
Overall Loss: 10.373689
Rec Loss: 10.213818
KL Loss: 0.159871
Y Loss: 0.178041
T Loss: 10.124798
Epoch 549 
Overall Loss: 10.343640
Rec Loss: 10.194936
KL Loss: 0.148704
Y Loss: 0.140015
T Loss: 10.124929
Epoch 599 
Overall Loss: 10.333379
Rec Loss: 10.195302
KL Loss: 0.138077
Y Loss: 0.112640
T Loss: 10.138983
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 0.124399
Epoch 99
Rec Loss: 0.117980
Epoch 149
Rec Loss: 0.119365
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.155452
Epoch 99
Rec Loss: 10.135056
Epoch 149
Rec Loss: 10.125142
Epoch 199
Rec Loss: 10.107654
Epoch 249
Rec Loss: 10.095025
Epoch 299
Rec Loss: 10.090202
Epoch 349
Rec Loss: 10.087251
Epoch 399
Rec Loss: 10.085524
Epoch 449
Rec Loss: 10.069811
Epoch 499
Rec Loss: 10.086349
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.270391
Insample Error: 0.505960
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 15.953841
Rec Loss: 13.974767
KL Loss: 1.979074
Y Loss: 1.397287
T Loss: 13.814278
X Loss: -0.538155
Epoch 99 
Overall Loss: -2.528726
Rec Loss: -11.390860
KL Loss: 8.862134
Y Loss: 1.152609
T Loss: 13.558040
X Loss: -25.525205
Epoch 149 
Overall Loss: -7.029564
Rec Loss: -16.932824
KL Loss: 9.903260
Y Loss: 1.087336
T Loss: 13.203534
X Loss: -30.680026
Epoch 199 
Overall Loss: -9.300181
Rec Loss: -19.886838
KL Loss: 10.586657
Y Loss: 1.037764
T Loss: 12.996653
X Loss: -33.402374
Epoch 249 
Overall Loss: -10.652828
Rec Loss: -21.707167
KL Loss: 11.054339
Y Loss: 0.980643
T Loss: 12.880613
X Loss: -35.078102
Epoch 299 
Overall Loss: -12.030525
Rec Loss: -23.440616
KL Loss: 11.410091
Y Loss: 0.911587
T Loss: 12.773154
X Loss: -36.669564
Epoch 349 
Overall Loss: -12.954801
Rec Loss: -24.661166
KL Loss: 11.706366
Y Loss: 0.850188
T Loss: 12.680459
X Loss: -37.766720
Epoch 399 
Overall Loss: -13.525325
Rec Loss: -25.501794
KL Loss: 11.976469
Y Loss: 0.802718
T Loss: 12.559662
X Loss: -38.462815
Epoch 449 
Overall Loss: -14.752252
Rec Loss: -27.003967
KL Loss: 12.251716
Y Loss: 0.756585
T Loss: 12.420595
X Loss: -39.802854
Epoch 499 
Overall Loss: -15.410484
Rec Loss: -27.840863
KL Loss: 12.430378
Y Loss: 0.714628
T Loss: 12.291143
X Loss: -40.489319
Epoch 549 
Overall Loss: -15.973037
Rec Loss: -28.650956
KL Loss: 12.677920
Y Loss: 0.690169
T Loss: 12.176733
X Loss: -41.172775
Epoch 599 
Overall Loss: -16.572937
Rec Loss: -29.448549
KL Loss: 12.875611
Y Loss: 0.675204
T Loss: 12.067824
X Loss: -41.853975
Epoch 649 
Overall Loss: -17.037592
Rec Loss: -30.058958
KL Loss: 13.021366
Y Loss: 0.657315
T Loss: 11.974834
X Loss: -42.362449
Epoch 699 
Overall Loss: -17.119432
Rec Loss: -30.271414
KL Loss: 13.151982
Y Loss: 0.645201
T Loss: 11.882013
X Loss: -42.476026
Epoch 749 
Overall Loss: -17.864166
Rec Loss: -31.135177
KL Loss: 13.271010
Y Loss: 0.635364
T Loss: 11.826936
X Loss: -43.279795
Epoch 799 
Overall Loss: -18.516697
Rec Loss: -31.794713
KL Loss: 13.278018
Y Loss: 0.637347
T Loss: 11.734871
X Loss: -43.848257
Epoch 849 
Overall Loss: -18.818199
Rec Loss: -32.222622
KL Loss: 13.404423
Y Loss: 0.619675
T Loss: 11.648891
X Loss: -44.181351
Epoch 899 
Overall Loss: -19.114008
Rec Loss: -32.593522
KL Loss: 13.479515
Y Loss: 0.630576
T Loss: 11.593047
X Loss: -44.501859
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.619341
Epoch 99
Rec Loss: 2.609903
Epoch 149
Rec Loss: 2.600354
Epoch 199
Rec Loss: 2.598489
Epoch 249
Rec Loss: 2.585364
Epoch 299
Rec Loss: 2.586633
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.012832
Epoch 99
Rec Loss: 0.008546
Epoch 149
Rec Loss: 0.006975
Epoch 199
Rec Loss: 0.009557
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.719967
Insample Error 1.480395
Ours, Train RMSE
0.3593, 
0.2765, 
0.2844, 
0.2751, 
0.2573, 
0.2783, 
0.2851, 
0.4691, 
0.2698, 
0.2704, 
CEVAE, Train RMSE
0.6955, 
0.3858, 
0.5668, 
0.8421, 
0.6253, 
0.7864, 
0.6817, 
0.7949, 
0.6868, 
0.7200, 
Ours, Insample RMSE
0.6572, 
0.5228, 
0.5248, 
0.5645, 
0.4890, 
0.5370, 
0.5669, 
0.7853, 
0.5669, 
0.5060, 
CEVAE, Insample RMSE
1.2758, 
2.7619, 
1.2003, 
1.6336, 
1.2000, 
1.4653, 
1.2739, 
1.4326, 
1.2096, 
1.4804, 
Train, RMSE mean 0.3025 std 0.0614
CEVAE, RMSE mean 0.6785 std 0.1245
Ours, RMSE mean 0.5720 std 0.0836, reconstruct confounder 0.1204 (0.0190) noise 10.0997 (0.0218)
CEVAE, RMSE mean 1.4933 std 0.4451, reconstruct confounder 2.6983 (0.2025) noise 0.0032 (0.0023)
Experiment Start!
Namespace(cevaelr=5e-05, decay=0.0, l=0.001, latdim=4, mask=0, nlayer=50, obsm=4, stop=2000, ycof=0.5, ylayer=50)
Y Mean 1.037543, Std 4.233836 
Test Y Mean 0.042888, Std 4.254001 
Observe confounder 4, Noise 10 dimension
Learning Rate 0.001000
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 12.269420
Rec Loss: 12.020044
KL Loss: 0.249375
Y Loss: 0.651087
T Loss: 11.694501
Epoch 99 
Overall Loss: 11.993545
Rec Loss: 11.872518
KL Loss: 0.121027
Y Loss: 0.260029
T Loss: 11.742504
Epoch 149 
Overall Loss: 11.936956
Rec Loss: 11.843170
KL Loss: 0.093786
Y Loss: 0.182115
T Loss: 11.752113
Epoch 199 
Overall Loss: 11.907429
Rec Loss: 11.826206
KL Loss: 0.081223
Y Loss: 0.142231
T Loss: 11.755091
Epoch 249 
Overall Loss: 11.879698
Rec Loss: 11.809923
KL Loss: 0.069775
Y Loss: 0.120234
T Loss: 11.749806
Epoch 299 
Overall Loss: 11.873861
Rec Loss: 11.807671
KL Loss: 0.066190
Y Loss: 0.102875
T Loss: 11.756233
Epoch 349 
Overall Loss: 11.854228
Rec Loss: 11.797831
KL Loss: 0.056396
Y Loss: 0.088955
T Loss: 11.753354
Epoch 399 
Overall Loss: 11.847065
Rec Loss: 11.794155
KL Loss: 0.052910
Y Loss: 0.081350
T Loss: 11.753480
Epoch 449 
Overall Loss: 11.834364
Rec Loss: 11.779825
KL Loss: 0.054540
Y Loss: 0.071611
T Loss: 11.744020
Epoch 499 
Overall Loss: 11.833206
Rec Loss: 11.783303
KL Loss: 0.049903
Y Loss: 0.066221
T Loss: 11.750192
Epoch 549 
Overall Loss: 11.837528
Rec Loss: 11.785265
KL Loss: 0.052263
Y Loss: 0.067388
T Loss: 11.751571
Epoch 599 
Overall Loss: 11.820634
Rec Loss: 11.772856
KL Loss: 0.047778
Y Loss: 0.059040
T Loss: 11.743336
Epoch 649 
Overall Loss: 11.822454
Rec Loss: 11.771658
KL Loss: 0.050796
Y Loss: 0.065013
T Loss: 11.739151
Epoch 699 
Overall Loss: 11.802930
Rec Loss: 11.761235
KL Loss: 0.041694
Y Loss: 0.051690
T Loss: 11.735390
Epoch 749 
Overall Loss: 11.798227
Rec Loss: 11.753483
KL Loss: 0.044744
Y Loss: 0.052916
T Loss: 11.727026
Epoch 799 
Overall Loss: 11.799382
Rec Loss: 11.761943
KL Loss: 0.037439
Y Loss: 0.050650
T Loss: 11.736618
Epoch 849 
Overall Loss: 11.794513
Rec Loss: 11.755739
KL Loss: 0.038775
Y Loss: 0.046938
T Loss: 11.732270
Epoch 899 
Overall Loss: 11.794747
Rec Loss: 11.753373
KL Loss: 0.041374
Y Loss: 0.043519
T Loss: 11.731614
Epoch 949 
Overall Loss: 11.789829
Rec Loss: 11.748941
KL Loss: 0.040887
Y Loss: 0.042186
T Loss: 11.727848
Epoch 999 
Overall Loss: 11.780635
Rec Loss: 11.745748
KL Loss: 0.034887
Y Loss: 0.043566
T Loss: 11.723965
Epoch 1049 
Overall Loss: 11.776704
Rec Loss: 11.744525
KL Loss: 0.032180
Y Loss: 0.042313
T Loss: 11.723368
Epoch 1099 
Overall Loss: 11.775351
Rec Loss: 11.741400
KL Loss: 0.033952
Y Loss: 0.042532
T Loss: 11.720134
Epoch 1149 
Overall Loss: 11.767789
Rec Loss: 11.736663
KL Loss: 0.031126
Y Loss: 0.036784
T Loss: 11.718271
Epoch 1199 
Overall Loss: 11.765698
Rec Loss: 11.737181
KL Loss: 0.028517
Y Loss: 0.041182
T Loss: 11.716590
Epoch 1249 
Overall Loss: 11.769827
Rec Loss: 11.736873
KL Loss: 0.032955
Y Loss: 0.035639
T Loss: 11.719053
Epoch 1299 
Overall Loss: 11.784155
Rec Loss: 11.731793
KL Loss: 0.052362
Y Loss: 0.033102
T Loss: 11.715242
Epoch 1349 
Overall Loss: 11.753733
Rec Loss: 11.724882
KL Loss: 0.028852
Y Loss: 0.029096
T Loss: 11.710334
Epoch 1399 
Overall Loss: 11.753934
Rec Loss: 11.723872
KL Loss: 0.030062
Y Loss: 0.029684
T Loss: 11.709030
Epoch 1449 
Overall Loss: 11.746870
Rec Loss: 11.721274
KL Loss: 0.025596
Y Loss: 0.031479
T Loss: 11.705535
Epoch 1499 
Overall Loss: 11.740317
Rec Loss: 11.717257
KL Loss: 0.023060
Y Loss: 0.030820
T Loss: 11.701848
Epoch 1549 
Overall Loss: 11.740199
Rec Loss: 11.716864
KL Loss: 0.023335
Y Loss: 0.029275
T Loss: 11.702226
Epoch 1599 
Overall Loss: 11.742151
Rec Loss: 11.715137
KL Loss: 0.027014
Y Loss: 0.033412
T Loss: 11.698431
Epoch 1649 
Overall Loss: 11.756878
Rec Loss: 11.729117
KL Loss: 0.027761
Y Loss: 0.053243
T Loss: 11.702496
Epoch 1699 
Overall Loss: 11.734316
Rec Loss: 11.710144
KL Loss: 0.024172
Y Loss: 0.025545
T Loss: 11.697372
Epoch 1749 
Overall Loss: 11.731340
Rec Loss: 11.707202
KL Loss: 0.024137
Y Loss: 0.034133
T Loss: 11.690136
Epoch 1799 
Overall Loss: 11.743621
Rec Loss: 11.715634
KL Loss: 0.027987
Y Loss: 0.036073
T Loss: 11.697597
Epoch 1849 
Overall Loss: 11.734497
Rec Loss: 11.705554
KL Loss: 0.028944
Y Loss: 0.025860
T Loss: 11.692624
Epoch 1899 
Overall Loss: 11.724088
Rec Loss: 11.704693
KL Loss: 0.019394
Y Loss: 0.025184
T Loss: 11.692101
Epoch 1949 
Overall Loss: 11.724423
Rec Loss: 11.702905
KL Loss: 0.021517
Y Loss: 0.027362
T Loss: 11.689225
Epoch 1999 
Overall Loss: 11.721226
Rec Loss: 11.699645
KL Loss: 0.021581
Y Loss: 0.028029
T Loss: 11.685631
Epoch 2049 
Overall Loss: 11.725354
Rec Loss: 11.699515
KL Loss: 0.025839
Y Loss: 0.023581
T Loss: 11.687724
Epoch 2099 
Overall Loss: 11.721818
Rec Loss: 11.697764
KL Loss: 0.024054
Y Loss: 0.023519
T Loss: 11.686004
Epoch 2149 
Overall Loss: 11.721054
Rec Loss: 11.693364
KL Loss: 0.027691
Y Loss: 0.021551
T Loss: 11.682588
Epoch 2199 
Overall Loss: 11.720243
Rec Loss: 11.696074
KL Loss: 0.024169
Y Loss: 0.026397
T Loss: 11.682875
Epoch 2249 
Overall Loss: 11.762079
Rec Loss: 11.699160
KL Loss: 0.062920
Y Loss: 0.030159
T Loss: 11.684080
Epoch 2299 
Overall Loss: 11.711181
Rec Loss: 11.692036
KL Loss: 0.019145
Y Loss: 0.023335
T Loss: 11.680368
Epoch 2349 
Overall Loss: 11.709605
Rec Loss: 11.689684
KL Loss: 0.019921
Y Loss: 0.023344
T Loss: 11.678012
Epoch 2399 
Overall Loss: 11.707483
Rec Loss: 11.687070
KL Loss: 0.020413
Y Loss: 0.022732
T Loss: 11.675703
Epoch 2449 
Overall Loss: 11.725244
Rec Loss: 11.685095
KL Loss: 0.040149
Y Loss: 0.025314
T Loss: 11.672439
Epoch 2499 
Overall Loss: 11.703213
Rec Loss: 11.684745
KL Loss: 0.018468
Y Loss: 0.022635
T Loss: 11.673427
Epoch 2549 
Overall Loss: 11.712012
Rec Loss: 11.682804
KL Loss: 0.029208
Y Loss: 0.024003
T Loss: 11.670802
Epoch 2599 
Overall Loss: 11.700417
Rec Loss: 11.680685
KL Loss: 0.019732
Y Loss: 0.021231
T Loss: 11.670069
Epoch 2649 
Overall Loss: 11.697483
Rec Loss: 11.679542
KL Loss: 0.017941
Y Loss: 0.024236
T Loss: 11.667424
Epoch 2699 
Overall Loss: 11.696818
Rec Loss: 11.677747
KL Loss: 0.019071
Y Loss: 0.020992
T Loss: 11.667251
Epoch 2749 
Overall Loss: 11.696383
Rec Loss: 11.677485
KL Loss: 0.018898
Y Loss: 0.020821
T Loss: 11.667074
Epoch 2799 
Overall Loss: 11.694946
Rec Loss: 11.674515
KL Loss: 0.020431
Y Loss: 0.020427
T Loss: 11.664302
Epoch 2849 
Overall Loss: 11.702826
Rec Loss: 11.680749
KL Loss: 0.022076
Y Loss: 0.036148
T Loss: 11.662675
Epoch 2899 
Overall Loss: 11.703874
Rec Loss: 11.674133
KL Loss: 0.029741
Y Loss: 0.022116
T Loss: 11.663076
Epoch 2949 
Overall Loss: 11.689452
Rec Loss: 11.673104
KL Loss: 0.016347
Y Loss: 0.025278
T Loss: 11.660466
Epoch 2999 
Overall Loss: 11.685684
Rec Loss: 11.668544
KL Loss: 0.017141
Y Loss: 0.021809
T Loss: 11.657639
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 0.028724
Epoch 99
Rec Loss: 0.023541
Epoch 149
Rec Loss: 0.022204
Epoch 199
Rec Loss: 0.021629
Epoch 249
Rec Loss: 0.021560
Epoch 299
Rec Loss: 0.021417
Epoch 349
Rec Loss: 0.020867
Epoch 399
Rec Loss: 0.021078
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.848582
Epoch 99
Rec Loss: 9.822819
Epoch 149
Rec Loss: 9.818534
Epoch 199
Rec Loss: 9.783294
Epoch 249
Rec Loss: 9.766048
Epoch 299
Rec Loss: 9.765277
Epoch 349
Rec Loss: 9.758721
Epoch 399
Rec Loss: 9.739061
Epoch 449
Rec Loss: 9.735283
Epoch 499
Rec Loss: 9.722627
Epoch 549
Rec Loss: 9.710797
Epoch 599
Rec Loss: 9.716036
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.078991
Insample Error: 0.159651
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 20.294868
Rec Loss: 16.688104
KL Loss: 3.606764
Y Loss: 6.143751
T Loss: 13.399112
X Loss: 0.217116
Epoch 99 
Overall Loss: 2.394461
Rec Loss: -7.944383
KL Loss: 10.338844
Y Loss: 2.199183
T Loss: 13.358694
X Loss: -22.402669
Epoch 149 
Overall Loss: -3.757992
Rec Loss: -15.850676
KL Loss: 12.092685
Y Loss: 1.406742
T Loss: 13.332097
X Loss: -29.886144
Epoch 199 
Overall Loss: -6.984573
Rec Loss: -20.245925
KL Loss: 13.261352
Y Loss: 0.880283
T Loss: 13.305674
X Loss: -33.991742
Epoch 249 
Overall Loss: -8.973331
Rec Loss: -22.903702
KL Loss: 13.930371
Y Loss: 0.613884
T Loss: 13.288160
X Loss: -36.498805
Epoch 299 
Overall Loss: -10.137802
Rec Loss: -24.543894
KL Loss: 14.406091
Y Loss: 0.456666
T Loss: 13.262566
X Loss: -38.034792
Epoch 349 
Overall Loss: -11.242571
Rec Loss: -26.035405
KL Loss: 14.792834
Y Loss: 0.357862
T Loss: 13.228317
X Loss: -39.442652
Epoch 399 
Overall Loss: -11.849916
Rec Loss: -26.885380
KL Loss: 15.035464
Y Loss: 0.309818
T Loss: 13.208075
X Loss: -40.248363
Epoch 449 
Overall Loss: -12.821237
Rec Loss: -28.098475
KL Loss: 15.277239
Y Loss: 0.299884
T Loss: 13.164505
X Loss: -41.412922
Epoch 499 
Overall Loss: -13.396395
Rec Loss: -28.953909
KL Loss: 15.557514
Y Loss: 0.285869
T Loss: 13.116657
X Loss: -42.213502
Epoch 549 
Overall Loss: -13.977250
Rec Loss: -29.676270
KL Loss: 15.699020
Y Loss: 0.275154
T Loss: 13.044993
X Loss: -42.858839
Epoch 599 
Overall Loss: -14.307570
Rec Loss: -30.250997
KL Loss: 15.943427
Y Loss: 0.254050
T Loss: 12.990014
X Loss: -43.368035
Epoch 649 
Overall Loss: -15.082294
Rec Loss: -31.161161
KL Loss: 16.078867
Y Loss: 0.255913
T Loss: 12.889323
X Loss: -44.178442
Epoch 699 
Overall Loss: -15.508190
Rec Loss: -31.818972
KL Loss: 16.310782
Y Loss: 0.239289
T Loss: 12.813871
X Loss: -44.752487
Epoch 749 
Overall Loss: -16.029735
Rec Loss: -32.416548
KL Loss: 16.386812
Y Loss: 0.237094
T Loss: 12.716312
X Loss: -45.251407
Epoch 799 
Overall Loss: -16.379596
Rec Loss: -32.995393
KL Loss: 16.615795
Y Loss: 0.208695
T Loss: 12.642964
X Loss: -45.742704
Epoch 849 
Overall Loss: -16.747004
Rec Loss: -33.498184
KL Loss: 16.751179
Y Loss: 0.205889
T Loss: 12.563699
X Loss: -46.164826
Epoch 899 
Overall Loss: -17.040352
Rec Loss: -33.839599
KL Loss: 16.799247
Y Loss: 0.206362
T Loss: 12.520433
X Loss: -46.463215
Epoch 949 
Overall Loss: -17.327190
Rec Loss: -34.280890
KL Loss: 16.953700
Y Loss: 0.189594
T Loss: 12.465876
X Loss: -46.841561
Epoch 999 
Overall Loss: -17.707460
Rec Loss: -34.662775
KL Loss: 16.955316
Y Loss: 0.187997
T Loss: 12.438728
X Loss: -47.195500
Epoch 1049 
Overall Loss: -18.072926
Rec Loss: -35.166430
KL Loss: 17.093504
Y Loss: 0.186777
T Loss: 12.403511
X Loss: -47.663330
Epoch 1099 
Overall Loss: -18.239931
Rec Loss: -35.447897
KL Loss: 17.207966
Y Loss: 0.188051
T Loss: 12.385090
X Loss: -47.927013
Epoch 1149 
Overall Loss: -18.530237
Rec Loss: -35.800796
KL Loss: 17.270560
Y Loss: 0.173304
T Loss: 12.359869
X Loss: -48.247318
Epoch 1199 
Overall Loss: -18.796454
Rec Loss: -35.993187
KL Loss: 17.196734
Y Loss: 0.188995
T Loss: 12.344565
X Loss: -48.432252
Epoch 1249 
Overall Loss: -19.076528
Rec Loss: -36.526359
KL Loss: 17.449831
Y Loss: 0.172404
T Loss: 12.312946
X Loss: -48.925505
Epoch 1299 
Overall Loss: -19.072170
Rec Loss: -36.403977
KL Loss: 17.331805
Y Loss: 0.198824
T Loss: 12.302761
X Loss: -48.806149
Epoch 1349 
Overall Loss: -19.378306
Rec Loss: -36.861952
KL Loss: 17.483646
Y Loss: 0.188315
T Loss: 12.276995
X Loss: -49.233105
Epoch 1399 
Overall Loss: -19.582696
Rec Loss: -37.241431
KL Loss: 17.658735
Y Loss: 0.186097
T Loss: 12.257184
X Loss: -49.591664
Epoch 1449 
Overall Loss: -19.709200
Rec Loss: -37.445548
KL Loss: 17.736349
Y Loss: 0.192453
T Loss: 12.242301
X Loss: -49.784077
Epoch 1499 
Overall Loss: -19.971139
Rec Loss: -37.586812
KL Loss: 17.615674
Y Loss: 0.199562
T Loss: 12.238623
X Loss: -49.925216
Epoch 1549 
Overall Loss: -19.620521
Rec Loss: -37.429751
KL Loss: 17.809231
Y Loss: 0.187710
T Loss: 12.215955
X Loss: -49.739562
Epoch 1599 
Overall Loss: -20.296249
Rec Loss: -38.178994
KL Loss: 17.882744
Y Loss: 0.192506
T Loss: 12.203008
X Loss: -50.478254
Epoch 1649 
Overall Loss: -20.619498
Rec Loss: -38.467731
KL Loss: 17.848234
Y Loss: 0.203613
T Loss: 12.197526
X Loss: -50.767065
Epoch 1699 
Overall Loss: -20.589365
Rec Loss: -38.579984
KL Loss: 17.990618
Y Loss: 0.193175
T Loss: 12.178175
X Loss: -50.854747
Epoch 1749 
Overall Loss: -20.702554
Rec Loss: -38.651947
KL Loss: 17.949393
Y Loss: 0.190055
T Loss: 12.179408
X Loss: -50.926381
Epoch 1799 
Overall Loss: -20.742027
Rec Loss: -38.773195
KL Loss: 18.031169
Y Loss: 0.207535
T Loss: 12.160860
X Loss: -51.037825
Epoch 1849 
Overall Loss: -21.183136
Rec Loss: -39.280088
KL Loss: 18.096952
Y Loss: 0.204688
T Loss: 12.161999
X Loss: -51.544432
Epoch 1899 
Overall Loss: -21.177109
Rec Loss: -39.358622
KL Loss: 18.181514
Y Loss: 0.207511
T Loss: 12.153097
X Loss: -51.615475
Epoch 1949 
Overall Loss: -21.159617
Rec Loss: -39.391609
KL Loss: 18.231993
Y Loss: 0.207760
T Loss: 12.153292
X Loss: -51.648782
Epoch 1999 
Overall Loss: -21.580357
Rec Loss: -39.840758
KL Loss: 18.260401
Y Loss: 0.212868
T Loss: 12.124241
X Loss: -52.071434
Epoch 2049 
Overall Loss: -21.580598
Rec Loss: -39.778411
KL Loss: 18.197814
Y Loss: 0.221107
T Loss: 12.137472
X Loss: -52.026437
Epoch 2099 
Overall Loss: -21.662460
Rec Loss: -39.896630
KL Loss: 18.234170
Y Loss: 0.221919
T Loss: 12.125540
X Loss: -52.133130
Epoch 2149 
Overall Loss: -21.277942
Rec Loss: -39.563163
KL Loss: 18.285222
Y Loss: 0.227553
T Loss: 12.115889
X Loss: -51.792829
Epoch 2199 
Overall Loss: -21.778258
Rec Loss: -40.106709
KL Loss: 18.328450
Y Loss: 0.233562
T Loss: 12.116153
X Loss: -52.339643
Epoch 2249 
Overall Loss: -21.957623
Rec Loss: -40.238064
KL Loss: 18.280442
Y Loss: 0.215685
T Loss: 12.104087
X Loss: -52.449994
Epoch 2299 
Overall Loss: -22.152040
Rec Loss: -40.608023
KL Loss: 18.455983
Y Loss: 0.228166
T Loss: 12.098733
X Loss: -52.820839
Epoch 2349 
Overall Loss: -21.453850
Rec Loss: -40.004914
KL Loss: 18.551062
Y Loss: 0.225979
T Loss: 12.086988
X Loss: -52.204891
Epoch 2399 
Overall Loss: -22.417191
Rec Loss: -40.852517
KL Loss: 18.435327
Y Loss: 0.234552
T Loss: 12.088130
X Loss: -53.057923
Epoch 2449 
Overall Loss: -22.018948
Rec Loss: -40.482589
KL Loss: 18.463643
Y Loss: 0.225783
T Loss: 12.103921
X Loss: -52.699402
Epoch 2499 
Overall Loss: -22.764021
Rec Loss: -41.340356
KL Loss: 18.576334
Y Loss: 0.246319
T Loss: 12.083358
X Loss: -53.546872
Epoch 2549 
Overall Loss: -22.930023
Rec Loss: -41.521453
KL Loss: 18.591431
Y Loss: 0.242554
T Loss: 12.076992
X Loss: -53.719722
Epoch 2599 
Overall Loss: -22.948629
Rec Loss: -41.500920
KL Loss: 18.552291
Y Loss: 0.239718
T Loss: 12.085069
X Loss: -53.705849
Epoch 2649 
Overall Loss: -23.089553
Rec Loss: -41.786015
KL Loss: 18.696463
Y Loss: 0.238839
T Loss: 12.074839
X Loss: -53.980274
Epoch 2699 
Overall Loss: -22.635295
Rec Loss: -41.382937
KL Loss: 18.747643
Y Loss: 0.244791
T Loss: 12.073387
X Loss: -53.578719
Epoch 2749 
Overall Loss: -23.030040
Rec Loss: -41.515508
KL Loss: 18.485467
Y Loss: 0.270552
T Loss: 12.085215
X Loss: -53.735997
Epoch 2799 
Overall Loss: -23.463996
Rec Loss: -42.058467
KL Loss: 18.594471
Y Loss: 0.274494
T Loss: 12.075019
X Loss: -54.270733
Epoch 2849 
Overall Loss: -23.285852
Rec Loss: -42.142668
KL Loss: 18.856816
Y Loss: 0.253438
T Loss: 12.054891
X Loss: -54.324279
Epoch 2899 
Overall Loss: -22.880759
Rec Loss: -41.619211
KL Loss: 18.738453
Y Loss: 0.252215
T Loss: 12.057228
X Loss: -53.802546
Epoch 2949 
Overall Loss: -23.083205
Rec Loss: -41.681212
KL Loss: 18.598007
Y Loss: 0.269887
T Loss: 12.071637
X Loss: -53.887793
Epoch 2999 
Overall Loss: -23.314760
Rec Loss: -42.157060
KL Loss: 18.842301
Y Loss: 0.260562
T Loss: 12.050912
X Loss: -54.338253
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.381761
Epoch 99
Rec Loss: 2.364340
Epoch 149
Rec Loss: 2.344435
Epoch 199
Rec Loss: 2.342527
Epoch 249
Rec Loss: 2.333558
Epoch 299
Rec Loss: 2.329239
Epoch 349
Rec Loss: 2.325064
Epoch 399
Rec Loss: 2.324151
Epoch 449
Rec Loss: 2.323700
Epoch 499
Rec Loss: 2.322131
Epoch 549
Rec Loss: 2.325120
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.002784
Epoch 99
Rec Loss: 0.001929
Epoch 149
Rec Loss: 0.001329
Epoch 199
Rec Loss: 0.001014
Epoch 249
Rec Loss: 0.000772
Epoch 299
Rec Loss: 0.001000
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.256906
Insample Error 2.864001
[34m== Direct Regression: Training all ==[0m
Epoch 49 
Prediction Loss: 0.496873
Epoch 99 
Prediction Loss: 0.136722
Epoch 149 
Prediction Loss: 0.067142
Epoch 199 
Prediction Loss: 0.045319
Epoch 249 
Prediction Loss: 0.034602
Epoch 299 
Prediction Loss: 0.025414
Epoch 349 
Prediction Loss: 0.021593
Epoch 399 
Prediction Loss: 0.017852
Epoch 449 
Prediction Loss: 0.016233
Epoch 499 
Prediction Loss: 0.016104
Epoch 549 
Prediction Loss: 0.013118
Epoch 599 
Prediction Loss: 0.013223
Epoch 649 
Prediction Loss: 0.015288
Epoch 699 
Prediction Loss: 0.011883
Epoch 749 
Prediction Loss: 0.010800
Epoch 799 
Prediction Loss: 0.009834
Epoch 849 
Prediction Loss: 0.008766
Epoch 899 
Prediction Loss: 0.008933
Epoch 949 
Prediction Loss: 0.008866
Epoch 999 
Prediction Loss: 0.008455
Epoch 1049 
Prediction Loss: 0.008809
Epoch 1099 
Prediction Loss: 0.007084
Epoch 1149 
Prediction Loss: 0.007366
Epoch 1199 
Prediction Loss: 0.006761
Epoch 1249 
Prediction Loss: 0.007421
Epoch 1299 
Prediction Loss: 0.008675
Epoch 1349 
Prediction Loss: 0.006791
Epoch 1399 
Prediction Loss: 0.007501
Epoch 1449 
Prediction Loss: 0.006401
Epoch 1499 
Prediction Loss: 0.005038
Epoch 1549 
Prediction Loss: 0.005288
Epoch 1599 
Prediction Loss: 0.006402
Epoch 1649 
Prediction Loss: 0.005259
Epoch 1699 
Prediction Loss: 0.005633
Epoch 1749 
Prediction Loss: 0.004882
Epoch 1799 
Prediction Loss: 0.007479
Epoch 1849 
Prediction Loss: 0.004775
Epoch 1899 
Prediction Loss: 0.004824
Epoch 1949 
Prediction Loss: 0.004191
Epoch 1999 
Prediction Loss: 0.004953
Epoch 2049 
Prediction Loss: 0.005048
Epoch 2099 
Prediction Loss: 0.003980
Epoch 2149 
Prediction Loss: 0.004341
Epoch 2199 
Prediction Loss: 0.006982
Epoch 2249 
Prediction Loss: 0.005463
Epoch 2299 
Prediction Loss: 0.004406
Epoch 2349 
Prediction Loss: 0.004445
Epoch 2399 
Prediction Loss: 0.003804
Epoch 2449 
Prediction Loss: 0.004512
Epoch 2499 
Prediction Loss: 0.004008
Epoch 2549 
Prediction Loss: 0.004068
Epoch 2599 
Prediction Loss: 0.003514
Epoch 2649 
Prediction Loss: 0.004453
Epoch 2699 
Prediction Loss: 0.006582
Epoch 2749 
Prediction Loss: 0.004024
Epoch 2799 
Prediction Loss: 0.003003
Epoch 2849 
Prediction Loss: 0.007240
Epoch 2899 
Prediction Loss: 0.003561
Epoch 2949 
Prediction Loss: 0.005099
Epoch 2999 
Prediction Loss: 0.002815
Epoch 3049 
Prediction Loss: 0.002328
Epoch 3099 
Prediction Loss: 0.003435
Epoch 3149 
Prediction Loss: 0.003311
Epoch 3199 
Prediction Loss: 0.002914
Epoch 3249 
Prediction Loss: 0.003079
Epoch 3299 
Prediction Loss: 0.002755
Epoch 3349 
Prediction Loss: 0.002982
Epoch 3399 
Prediction Loss: 0.003210
Epoch 3449 
Prediction Loss: 0.003524
Epoch 3499 
Prediction Loss: 0.002615
Epoch 3549 
Prediction Loss: 0.004003
Epoch 3599 
Prediction Loss: 0.002930
Epoch 3649 
Prediction Loss: 0.003534
Epoch 3699 
Prediction Loss: 0.008433
Epoch 3749 
Prediction Loss: 0.004667
Epoch 3799 
Prediction Loss: 0.009996
Epoch 3849 
Prediction Loss: 0.002941
Epoch 3899 
Prediction Loss: 0.003427
Epoch 3949 
Prediction Loss: 0.002618
Epoch 3999 
Prediction Loss: 0.002729
Epoch 4049 
Prediction Loss: 0.002187
Epoch 4099 
Prediction Loss: 0.002647
Epoch 4149 
Prediction Loss: 0.004794
Epoch 4199 
Prediction Loss: 0.006006
Epoch 4249 
Prediction Loss: 0.002927
Epoch 4299 
Prediction Loss: 0.002523
Epoch 4349 
Prediction Loss: 0.008136
Epoch 4399 
Prediction Loss: 0.003484
Epoch 4449 
Prediction Loss: 0.002330
Epoch 4499 
Prediction Loss: 0.002350
Epoch 4549 
Prediction Loss: 0.002279
Epoch 4599 
Prediction Loss: 0.002411
Epoch 4649 
Prediction Loss: 0.003105
Epoch 4699 
Prediction Loss: 0.001877
Epoch 4749 
Prediction Loss: 0.004216
Epoch 4799 
Prediction Loss: 0.003025
Epoch 4849 
Prediction Loss: 0.002920
Epoch 4899 
Prediction Loss: 0.003434
Epoch 4949 
Prediction Loss: 0.003526
Epoch 4999 
Prediction Loss: 0.002973
Epoch 5049 
Prediction Loss: 0.006784
Epoch 5099 
Prediction Loss: 0.006042
Epoch 5149 
Prediction Loss: 0.002117
Epoch 5199 
Prediction Loss: 0.004070
Epoch 5249 
Prediction Loss: 0.002791
Epoch 5299 
Prediction Loss: 0.005454
Epoch 5349 
Prediction Loss: 0.002076
Epoch 5399 
Prediction Loss: 0.002953
Epoch 5449 
Prediction Loss: 0.005000
Epoch 5499 
Prediction Loss: 0.002090
Epoch 5549 
Prediction Loss: 0.002261
Epoch 5599 
Prediction Loss: 0.002166
Epoch 5649 
Prediction Loss: 0.001977
Epoch 5699 
Prediction Loss: 0.002818
Epoch 5749 
Prediction Loss: 0.002440
Epoch 5799 
Prediction Loss: 0.003004
Epoch 5849 
Prediction Loss: 0.001944
Epoch 5899 
Prediction Loss: 0.002863
Epoch 5949 
Prediction Loss: 0.001649
Epoch 5999 
Prediction Loss: 0.004663
[34m== Direct Regression: Testing in sample performance ==[0m
Train Error 0.049009
Insample Error 0.112422
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 12.258539
Rec Loss: 12.015217
KL Loss: 0.243321
Y Loss: 0.637781
T Loss: 11.696327
Epoch 99 
Overall Loss: 11.978942
Rec Loss: 11.864604
KL Loss: 0.114338
Y Loss: 0.244695
T Loss: 11.742257
Epoch 149 
Overall Loss: 11.913924
Rec Loss: 11.823834
KL Loss: 0.090090
Y Loss: 0.150824
T Loss: 11.748423
Epoch 199 
Overall Loss: 11.883821
Rec Loss: 11.804226
KL Loss: 0.079596
Y Loss: 0.117134
T Loss: 11.745658
Epoch 249 
Overall Loss: 11.867496
Rec Loss: 11.796400
KL Loss: 0.071097
Y Loss: 0.099658
T Loss: 11.746571
Epoch 299 
Overall Loss: 11.862645
Rec Loss: 11.795618
KL Loss: 0.067028
Y Loss: 0.086740
T Loss: 11.752248
Epoch 349 
Overall Loss: 11.837570
Rec Loss: 11.780837
KL Loss: 0.056733
Y Loss: 0.076503
T Loss: 11.742585
Epoch 399 
Overall Loss: 11.832996
Rec Loss: 11.780080
KL Loss: 0.052916
Y Loss: 0.069404
T Loss: 11.745378
Epoch 449 
Overall Loss: 11.828529
Rec Loss: 11.779087
KL Loss: 0.049442
Y Loss: 0.066567
T Loss: 11.745803
Epoch 499 
Overall Loss: 11.820652
Rec Loss: 11.776818
KL Loss: 0.043834
Y Loss: 0.060814
T Loss: 11.746411
Epoch 549 
Overall Loss: 11.816980
Rec Loss: 11.767175
KL Loss: 0.049805
Y Loss: 0.060357
T Loss: 11.736996
Epoch 599 
Overall Loss: 11.812620
Rec Loss: 11.770706
KL Loss: 0.041914
Y Loss: 0.057350
T Loss: 11.742031
Epoch 649 
Overall Loss: 11.803364
Rec Loss: 11.762574
KL Loss: 0.040791
Y Loss: 0.052962
T Loss: 11.736092
Epoch 699 
Overall Loss: 11.792348
Rec Loss: 11.756551
KL Loss: 0.035797
Y Loss: 0.048045
T Loss: 11.732529
Epoch 749 
Overall Loss: 11.793843
Rec Loss: 11.755819
KL Loss: 0.038023
Y Loss: 0.050405
T Loss: 11.730617
Epoch 799 
Overall Loss: 11.789479
Rec Loss: 11.751589
KL Loss: 0.037890
Y Loss: 0.047331
T Loss: 11.727924
Epoch 849 
Overall Loss: 11.784958
Rec Loss: 11.748850
KL Loss: 0.036108
Y Loss: 0.048156
T Loss: 11.724772
Epoch 899 
Overall Loss: 11.780978
Rec Loss: 11.748108
KL Loss: 0.032870
Y Loss: 0.049467
T Loss: 11.723375
Epoch 949 
Overall Loss: 11.775247
Rec Loss: 11.743528
KL Loss: 0.031719
Y Loss: 0.043101
T Loss: 11.721977
Epoch 999 
Overall Loss: 11.776947
Rec Loss: 11.741013
KL Loss: 0.035934
Y Loss: 0.039691
T Loss: 11.721168
Epoch 1049 
Overall Loss: 11.767769
Rec Loss: 11.737295
KL Loss: 0.030474
Y Loss: 0.040521
T Loss: 11.717034
Epoch 1099 
Overall Loss: 11.764501
Rec Loss: 11.735718
KL Loss: 0.028783
Y Loss: 0.039005
T Loss: 11.716215
Epoch 1149 
Overall Loss: 11.766062
Rec Loss: 11.732240
KL Loss: 0.033821
Y Loss: 0.037647
T Loss: 11.713417
Epoch 1199 
Overall Loss: 11.754941
Rec Loss: 11.729938
KL Loss: 0.025003
Y Loss: 0.034500
T Loss: 11.712688
Epoch 1249 
Overall Loss: 11.752162
Rec Loss: 11.725148
KL Loss: 0.027014
Y Loss: 0.039081
T Loss: 11.705607
Epoch 1299 
Overall Loss: 11.747096
Rec Loss: 11.719281
KL Loss: 0.027816
Y Loss: 0.041450
T Loss: 11.698556
Epoch 1349 
Overall Loss: 11.776488
Rec Loss: 11.723378
KL Loss: 0.053109
Y Loss: 0.040313
T Loss: 11.703221
Epoch 1399 
Overall Loss: 11.741950
Rec Loss: 11.718057
KL Loss: 0.023893
Y Loss: 0.036231
T Loss: 11.699942
Epoch 1449 
Overall Loss: 11.740730
Rec Loss: 11.713679
KL Loss: 0.027050
Y Loss: 0.030167
T Loss: 11.698595
Epoch 1499 
Overall Loss: 11.741531
Rec Loss: 11.714528
KL Loss: 0.027003
Y Loss: 0.038404
T Loss: 11.695326
Epoch 1549 
Overall Loss: 11.743212
Rec Loss: 11.714741
KL Loss: 0.028471
Y Loss: 0.038934
T Loss: 11.695274
Epoch 1599 
Overall Loss: 11.732565
Rec Loss: 11.709637
KL Loss: 0.022928
Y Loss: 0.034235
T Loss: 11.692519
Epoch 1649 
Overall Loss: 11.734939
Rec Loss: 11.706492
KL Loss: 0.028448
Y Loss: 0.033014
T Loss: 11.689985
Epoch 1699 
Overall Loss: 11.758610
Rec Loss: 11.709479
KL Loss: 0.049131
Y Loss: 0.033917
T Loss: 11.692521
Epoch 1749 
Overall Loss: 11.728376
Rec Loss: 11.701156
KL Loss: 0.027220
Y Loss: 0.030991
T Loss: 11.685661
Epoch 1799 
Overall Loss: 11.723159
Rec Loss: 11.699874
KL Loss: 0.023286
Y Loss: 0.037520
T Loss: 11.681114
Epoch 1849 
Overall Loss: 11.730906
Rec Loss: 11.698959
KL Loss: 0.031946
Y Loss: 0.031589
T Loss: 11.683165
Epoch 1899 
Overall Loss: 11.724645
Rec Loss: 11.696202
KL Loss: 0.028444
Y Loss: 0.029299
T Loss: 11.681552
Epoch 1949 
Overall Loss: 11.710584
Rec Loss: 11.690219
KL Loss: 0.020365
Y Loss: 0.029626
T Loss: 11.675406
Epoch 1999 
Overall Loss: 11.782100
Rec Loss: 11.705518
KL Loss: 0.076582
Y Loss: 0.048841
T Loss: 11.681097
Epoch 2049 
Overall Loss: 11.708980
Rec Loss: 11.689281
KL Loss: 0.019698
Y Loss: 0.026952
T Loss: 11.675805
Epoch 2099 
Overall Loss: 11.716723
Rec Loss: 11.692570
KL Loss: 0.024154
Y Loss: 0.037066
T Loss: 11.674037
Epoch 2149 
Overall Loss: 11.707261
Rec Loss: 11.687804
KL Loss: 0.019456
Y Loss: 0.030149
T Loss: 11.672730
Epoch 2199 
Overall Loss: 11.707046
Rec Loss: 11.687866
KL Loss: 0.019180
Y Loss: 0.029491
T Loss: 11.673120
Epoch 2249 
Overall Loss: 11.705951
Rec Loss: 11.682374
KL Loss: 0.023576
Y Loss: 0.027241
T Loss: 11.668754
Epoch 2299 
Overall Loss: 11.696747
Rec Loss: 11.680088
KL Loss: 0.016660
Y Loss: 0.027215
T Loss: 11.666480
Epoch 2349 
Overall Loss: 11.711671
Rec Loss: 11.683989
KL Loss: 0.027682
Y Loss: 0.031230
T Loss: 11.668374
Epoch 2399 
Overall Loss: 11.705016
Rec Loss: 11.683399
KL Loss: 0.021617
Y Loss: 0.034068
T Loss: 11.666365
Epoch 2449 
Overall Loss: 11.700699
Rec Loss: 11.677031
KL Loss: 0.023668
Y Loss: 0.028446
T Loss: 11.662808
Epoch 2499 
Overall Loss: 11.693932
Rec Loss: 11.676126
KL Loss: 0.017805
Y Loss: 0.028405
T Loss: 11.661924
Epoch 2549 
Overall Loss: 11.693148
Rec Loss: 11.676206
KL Loss: 0.016941
Y Loss: 0.027115
T Loss: 11.662649
Epoch 2599 
Overall Loss: 11.694347
Rec Loss: 11.670551
KL Loss: 0.023796
Y Loss: 0.026488
T Loss: 11.657307
Epoch 2649 
Overall Loss: 11.689275
Rec Loss: 11.671679
KL Loss: 0.017596
Y Loss: 0.028756
T Loss: 11.657301
Epoch 2699 
Overall Loss: 11.688536
Rec Loss: 11.671046
KL Loss: 0.017490
Y Loss: 0.029327
T Loss: 11.656382
Epoch 2749 
Overall Loss: 11.683944
Rec Loss: 11.666953
KL Loss: 0.016991
Y Loss: 0.027481
T Loss: 11.653213
Epoch 2799 
Overall Loss: 11.690343
Rec Loss: 11.666596
KL Loss: 0.023747
Y Loss: 0.028239
T Loss: 11.652476
Epoch 2849 
Overall Loss: 11.680338
Rec Loss: 11.666027
KL Loss: 0.014310
Y Loss: 0.025208
T Loss: 11.653424
Epoch 2899 
Overall Loss: 11.689211
Rec Loss: 11.670298
KL Loss: 0.018913
Y Loss: 0.039167
T Loss: 11.650714
Epoch 2949 
Overall Loss: 11.679190
Rec Loss: 11.660965
KL Loss: 0.018225
Y Loss: 0.026645
T Loss: 11.647642
Epoch 2999 
Overall Loss: 11.675801
Rec Loss: 11.660778
KL Loss: 0.015023
Y Loss: 0.024227
T Loss: 11.648664
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 0.026449
Epoch 99
Rec Loss: 0.021129
Epoch 149
Rec Loss: 0.020419
Epoch 199
Rec Loss: 0.019918
Epoch 249
Rec Loss: 0.019539
Epoch 299
Rec Loss: 0.019359
Epoch 349
Rec Loss: 0.018974
Epoch 399
Rec Loss: 0.018447
Epoch 449
Rec Loss: 0.018729
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.815797
Epoch 99
Rec Loss: 9.773242
Epoch 149
Rec Loss: 9.762692
Epoch 199
Rec Loss: 9.756839
Epoch 249
Rec Loss: 9.753775
Epoch 299
Rec Loss: 9.735482
Epoch 349
Rec Loss: 9.721600
Epoch 399
Rec Loss: 9.730696
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.097672
Insample Error: 0.231957
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 19.215790
Rec Loss: 15.582510
KL Loss: 3.633281
Y Loss: 6.479503
T Loss: 13.382057
X Loss: -1.039299
Epoch 99 
Overall Loss: 2.018782
Rec Loss: -6.488438
KL Loss: 8.507220
Y Loss: 2.959971
T Loss: 13.316140
X Loss: -21.284563
Epoch 149 
Overall Loss: -4.045905
Rec Loss: -13.951095
KL Loss: 9.905190
Y Loss: 2.147233
T Loss: 13.285802
X Loss: -28.310513
Epoch 199 
Overall Loss: -7.737095
Rec Loss: -18.897567
KL Loss: 11.160472
Y Loss: 1.448394
T Loss: 13.217227
X Loss: -32.838991
Epoch 249 
Overall Loss: -9.803138
Rec Loss: -21.817277
KL Loss: 12.014138
Y Loss: 1.029852
T Loss: 13.111436
X Loss: -35.443639
Epoch 299 
Overall Loss: -11.422825
Rec Loss: -23.975910
KL Loss: 12.553085
Y Loss: 0.886429
T Loss: 13.011883
X Loss: -37.431007
Epoch 349 
Overall Loss: -12.788207
Rec Loss: -25.767875
KL Loss: 12.979668
Y Loss: 0.798570
T Loss: 12.922086
X Loss: -39.089246
Epoch 399 
Overall Loss: -13.577736
Rec Loss: -26.833544
KL Loss: 13.255808
Y Loss: 0.767050
T Loss: 12.854786
X Loss: -40.071854
Epoch 449 
Overall Loss: -14.468518
Rec Loss: -27.912813
KL Loss: 13.444296
Y Loss: 0.760645
T Loss: 12.793187
X Loss: -41.086323
Epoch 499 
Overall Loss: -15.131057
Rec Loss: -28.724176
KL Loss: 13.593119
Y Loss: 0.716626
T Loss: 12.757960
X Loss: -41.840449
Epoch 549 
Overall Loss: -15.749478
Rec Loss: -29.508387
KL Loss: 13.758909
Y Loss: 0.707907
T Loss: 12.720349
X Loss: -42.582689
Epoch 599 
Overall Loss: -16.358949
Rec Loss: -30.175047
KL Loss: 13.816098
Y Loss: 0.691905
T Loss: 12.696323
X Loss: -43.217323
Epoch 649 
Overall Loss: -16.632964
Rec Loss: -30.613306
KL Loss: 13.980341
Y Loss: 0.669646
T Loss: 12.676349
X Loss: -43.624479
Epoch 699 
Overall Loss: -17.297723
Rec Loss: -31.272296
KL Loss: 13.974573
Y Loss: 0.676122
T Loss: 12.661651
X Loss: -44.272009
Epoch 749 
Overall Loss: -17.729683
Rec Loss: -31.865193
KL Loss: 14.135511
Y Loss: 0.660719
T Loss: 12.614835
X Loss: -44.810389
Epoch 799 
Overall Loss: -17.719529
Rec Loss: -31.937046
KL Loss: 14.217516
Y Loss: 0.657720
T Loss: 12.595892
X Loss: -44.861798
Epoch 849 
Overall Loss: -18.358212
Rec Loss: -32.678275
KL Loss: 14.320063
Y Loss: 0.647744
T Loss: 12.553779
X Loss: -45.555927
Epoch 899 
Overall Loss: -18.895226
Rec Loss: -33.321264
KL Loss: 14.426038
Y Loss: 0.643126
T Loss: 12.529363
X Loss: -46.172190
Epoch 949 
Overall Loss: -19.017363
Rec Loss: -33.457173
KL Loss: 14.439810
Y Loss: 0.644459
T Loss: 12.489841
X Loss: -46.269245
Epoch 999 
Overall Loss: -19.497507
Rec Loss: -34.033707
KL Loss: 14.536200
Y Loss: 0.642164
T Loss: 12.452065
X Loss: -46.806854
Epoch 1049 
Overall Loss: -19.777271
Rec Loss: -34.387559
KL Loss: 14.610287
Y Loss: 0.599122
T Loss: 12.414574
X Loss: -47.101695
Epoch 1099 
Overall Loss: -19.890282
Rec Loss: -34.469825
KL Loss: 14.579544
Y Loss: 0.633833
T Loss: 12.384848
X Loss: -47.171591
Epoch 1149 
Overall Loss: -20.419984
Rec Loss: -35.160862
KL Loss: 14.740878
Y Loss: 0.618910
T Loss: 12.345226
X Loss: -47.815543
Epoch 1199 
Overall Loss: -20.638761
Rec Loss: -35.516892
KL Loss: 14.878130
Y Loss: 0.591841
T Loss: 12.314383
X Loss: -48.127194
Epoch 1249 
Overall Loss: -20.539749
Rec Loss: -35.421728
KL Loss: 14.881980
Y Loss: 0.581001
T Loss: 12.275624
X Loss: -47.987853
Epoch 1299 
Overall Loss: -21.145300
Rec Loss: -36.119647
KL Loss: 14.974348
Y Loss: 0.590987
T Loss: 12.250001
X Loss: -48.665143
Epoch 1349 
Overall Loss: -21.252813
Rec Loss: -36.282434
KL Loss: 15.029621
Y Loss: 0.593012
T Loss: 12.221681
X Loss: -48.800622
Epoch 1399 
Overall Loss: -21.427791
Rec Loss: -36.469125
KL Loss: 15.041333
Y Loss: 0.598692
T Loss: 12.209049
X Loss: -48.977520
Epoch 1449 
Overall Loss: -21.884861
Rec Loss: -37.006964
KL Loss: 15.122102
Y Loss: 0.574428
T Loss: 12.174541
X Loss: -49.468719
Epoch 1499 
Overall Loss: -22.055391
Rec Loss: -37.277476
KL Loss: 15.222086
Y Loss: 0.583639
T Loss: 12.152403
X Loss: -49.721700
Epoch 1549 
Overall Loss: -22.233285
Rec Loss: -37.480668
KL Loss: 15.247384
Y Loss: 0.584072
T Loss: 12.147540
X Loss: -49.920245
Epoch 1599 
Overall Loss: -22.332854
Rec Loss: -37.677109
KL Loss: 15.344254
Y Loss: 0.562516
T Loss: 12.115185
X Loss: -50.073551
Epoch 1649 
Overall Loss: -22.560673
Rec Loss: -37.683004
KL Loss: 15.122331
Y Loss: 0.597277
T Loss: 12.126570
X Loss: -50.108212
Epoch 1699 
Overall Loss: -22.933111
Rec Loss: -38.289091
KL Loss: 15.355981
Y Loss: 0.567577
T Loss: 12.103283
X Loss: -50.676163
Epoch 1749 
Overall Loss: -23.045708
Rec Loss: -38.401600
KL Loss: 15.355892
Y Loss: 0.566341
T Loss: 12.083906
X Loss: -50.768676
Epoch 1799 
Overall Loss: -23.046804
Rec Loss: -38.450894
KL Loss: 15.404090
Y Loss: 0.563163
T Loss: 12.086036
X Loss: -50.818512
Epoch 1849 
Overall Loss: -23.157463
Rec Loss: -38.520258
KL Loss: 15.362794
Y Loss: 0.563831
T Loss: 12.078380
X Loss: -50.880553
Epoch 1899 
Overall Loss: -23.322928
Rec Loss: -38.850322
KL Loss: 15.527393
Y Loss: 0.567000
T Loss: 12.067307
X Loss: -51.201129
Epoch 1949 
Overall Loss: -23.473371
Rec Loss: -39.043308
KL Loss: 15.569936
Y Loss: 0.567628
T Loss: 12.064192
X Loss: -51.391314
Epoch 1999 
Overall Loss: -23.589454
Rec Loss: -39.198170
KL Loss: 15.608717
Y Loss: 0.561320
T Loss: 12.048911
X Loss: -51.527740
Epoch 2049 
Overall Loss: -23.615298
Rec Loss: -39.156880
KL Loss: 15.541582
Y Loss: 0.582325
T Loss: 12.063478
X Loss: -51.511521
Epoch 2099 
Overall Loss: -23.879608
Rec Loss: -39.623693
KL Loss: 15.744085
Y Loss: 0.567451
T Loss: 12.045888
X Loss: -51.953307
Epoch 2149 
Overall Loss: -23.404255
Rec Loss: -39.074213
KL Loss: 15.669958
Y Loss: 0.582947
T Loss: 12.043289
X Loss: -51.408976
Epoch 2199 
Overall Loss: -23.953269
Rec Loss: -39.606468
KL Loss: 15.653199
Y Loss: 0.582774
T Loss: 12.047087
X Loss: -51.944944
Epoch 2249 
Overall Loss: -24.278485
Rec Loss: -39.974868
KL Loss: 15.696384
Y Loss: 0.546582
T Loss: 12.043354
X Loss: -52.291515
Epoch 2299 
Overall Loss: -24.182728
Rec Loss: -39.921177
KL Loss: 15.738449
Y Loss: 0.573418
T Loss: 12.044588
X Loss: -52.252475
Epoch 2349 
Overall Loss: -24.278534
Rec Loss: -40.162487
KL Loss: 15.883954
Y Loss: 0.565502
T Loss: 12.021155
X Loss: -52.466392
Epoch 2399 
Overall Loss: -24.762071
Rec Loss: -40.686016
KL Loss: 15.923944
Y Loss: 0.549039
T Loss: 12.021039
X Loss: -52.981573
Epoch 2449 
Overall Loss: -24.433074
Rec Loss: -40.339687
KL Loss: 15.906614
Y Loss: 0.548244
T Loss: 12.025576
X Loss: -52.639386
Epoch 2499 
Overall Loss: -24.978368
Rec Loss: -40.924673
KL Loss: 15.946305
Y Loss: 0.547766
T Loss: 12.015907
X Loss: -53.214462
Epoch 2549 
Overall Loss: -24.921977
Rec Loss: -40.743017
KL Loss: 15.821041
Y Loss: 0.574198
T Loss: 12.030864
X Loss: -53.060980
Epoch 2599 
Overall Loss: -25.189611
Rec Loss: -41.094295
KL Loss: 15.904684
Y Loss: 0.562204
T Loss: 12.012171
X Loss: -53.387568
Epoch 2649 
Overall Loss: -25.049768
Rec Loss: -40.829913
KL Loss: 15.780145
Y Loss: 0.604346
T Loss: 12.021162
X Loss: -53.153248
Epoch 2699 
Overall Loss: -25.101420
Rec Loss: -40.970173
KL Loss: 15.868753
Y Loss: 0.583950
T Loss: 12.027299
X Loss: -53.289447
Epoch 2749 
Overall Loss: -25.357943
Rec Loss: -41.403320
KL Loss: 16.045376
Y Loss: 0.554169
T Loss: 11.999777
X Loss: -53.680181
Epoch 2799 
Overall Loss: -25.593147
Rec Loss: -41.750522
KL Loss: 16.157374
Y Loss: 0.561037
T Loss: 12.007332
X Loss: -54.038372
Epoch 2849 
Overall Loss: -24.986768
Rec Loss: -41.087760
KL Loss: 16.100991
Y Loss: 0.553068
T Loss: 11.999276
X Loss: -53.363568
Epoch 2899 
Overall Loss: -25.701867
Rec Loss: -41.556054
KL Loss: 15.854186
Y Loss: 0.599610
T Loss: 12.020755
X Loss: -53.876613
Epoch 2949 
Overall Loss: -25.543278
Rec Loss: -41.690947
KL Loss: 16.147668
Y Loss: 0.570185
T Loss: 12.004022
X Loss: -53.980061
Epoch 2999 
Overall Loss: -25.599475
Rec Loss: -41.765083
KL Loss: 16.165608
Y Loss: 0.550404
T Loss: 12.001241
X Loss: -54.041524
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.383503
Epoch 99
Rec Loss: 2.350637
Epoch 149
Rec Loss: 2.341829
Epoch 199
Rec Loss: 2.332881
Epoch 249
Rec Loss: 2.330473
Epoch 299
Rec Loss: 2.329794
Epoch 349
Rec Loss: 2.329828
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.003559
Epoch 99
Rec Loss: 0.001931
Epoch 149
Rec Loss: 0.001172
Epoch 199
Rec Loss: 0.001107
Epoch 249
Rec Loss: 0.001959
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.290314
Insample Error 1.872190
[34m== Direct Regression: Training all ==[0m
Epoch 49 
Prediction Loss: 0.730573
Epoch 99 
Prediction Loss: 0.160938
Epoch 149 
Prediction Loss: 0.060307
Epoch 199 
Prediction Loss: 0.044076
Epoch 249 
Prediction Loss: 0.034297
Epoch 299 
Prediction Loss: 0.026071
Epoch 349 
Prediction Loss: 0.018666
Epoch 399 
Prediction Loss: 0.014087
Epoch 449 
Prediction Loss: 0.011255
Epoch 499 
Prediction Loss: 0.010632
Epoch 549 
Prediction Loss: 0.008491
Epoch 599 
Prediction Loss: 0.006807
Epoch 649 
Prediction Loss: 0.006444
Epoch 699 
Prediction Loss: 0.005075
Epoch 749 
Prediction Loss: 0.006417
Epoch 799 
Prediction Loss: 0.004503
Epoch 849 
Prediction Loss: 0.004323
Epoch 899 
Prediction Loss: 0.004241
Epoch 949 
Prediction Loss: 0.003773
Epoch 999 
Prediction Loss: 0.005084
Epoch 1049 
Prediction Loss: 0.003450
Epoch 1099 
Prediction Loss: 0.003092
Epoch 1149 
Prediction Loss: 0.004637
Epoch 1199 
Prediction Loss: 0.003082
Epoch 1249 
Prediction Loss: 0.003057
Epoch 1299 
Prediction Loss: 0.003924
Epoch 1349 
Prediction Loss: 0.003808
Epoch 1399 
Prediction Loss: 0.003140
Epoch 1449 
Prediction Loss: 0.003109
Epoch 1499 
Prediction Loss: 0.002457
Epoch 1549 
Prediction Loss: 0.003664
Epoch 1599 
Prediction Loss: 0.002309
Epoch 1649 
Prediction Loss: 0.002520
Epoch 1699 
Prediction Loss: 0.002365
Epoch 1749 
Prediction Loss: 0.002964
Epoch 1799 
Prediction Loss: 0.002816
Epoch 1849 
Prediction Loss: 0.002365
Epoch 1899 
Prediction Loss: 0.002524
Epoch 1949 
Prediction Loss: 0.002412
Epoch 1999 
Prediction Loss: 0.002681
Epoch 2049 
Prediction Loss: 0.003085
Epoch 2099 
Prediction Loss: 0.002184
Epoch 2149 
Prediction Loss: 0.001761
Epoch 2199 
Prediction Loss: 0.002720
Epoch 2249 
Prediction Loss: 0.001797
Epoch 2299 
Prediction Loss: 0.002896
Epoch 2349 
Prediction Loss: 0.002314
Epoch 2399 
Prediction Loss: 0.001732
Epoch 2449 
Prediction Loss: 0.001802
Epoch 2499 
Prediction Loss: 0.002405
Epoch 2549 
Prediction Loss: 0.002361
Epoch 2599 
Prediction Loss: 0.004202
Epoch 2649 
Prediction Loss: 0.002607
Epoch 2699 
Prediction Loss: 0.001944
Epoch 2749 
Prediction Loss: 0.002414
Epoch 2799 
Prediction Loss: 0.001558
Epoch 2849 
Prediction Loss: 0.002556
Epoch 2899 
Prediction Loss: 0.002523
Epoch 2949 
Prediction Loss: 0.001608
Epoch 2999 
Prediction Loss: 0.001325
Epoch 3049 
Prediction Loss: 0.002518
Epoch 3099 
Prediction Loss: 0.001782
Epoch 3149 
Prediction Loss: 0.001706
Epoch 3199 
Prediction Loss: 0.001404
Epoch 3249 
Prediction Loss: 0.001145
Epoch 3299 
Prediction Loss: 0.002355
Epoch 3349 
Prediction Loss: 0.001709
Epoch 3399 
Prediction Loss: 0.001335
Epoch 3449 
Prediction Loss: 0.001340
Epoch 3499 
Prediction Loss: 0.001348
Epoch 3549 
Prediction Loss: 0.000964
Epoch 3599 
Prediction Loss: 0.001057
Epoch 3649 
Prediction Loss: 0.001183
Epoch 3699 
Prediction Loss: 0.003297
Epoch 3749 
Prediction Loss: 0.001841
Epoch 3799 
Prediction Loss: 0.001684
Epoch 3849 
Prediction Loss: 0.001026
Epoch 3899 
Prediction Loss: 0.001288
Epoch 3949 
Prediction Loss: 0.003300
Epoch 3999 
Prediction Loss: 0.002017
Epoch 4049 
Prediction Loss: 0.001387
Epoch 4099 
Prediction Loss: 0.001090
Epoch 4149 
Prediction Loss: 0.001306
Epoch 4199 
Prediction Loss: 0.001819
Epoch 4249 
Prediction Loss: 0.001023
Epoch 4299 
Prediction Loss: 0.001274
Epoch 4349 
Prediction Loss: 0.003050
Epoch 4399 
Prediction Loss: 0.000994
Epoch 4449 
Prediction Loss: 0.001172
Epoch 4499 
Prediction Loss: 0.001237
Epoch 4549 
Prediction Loss: 0.001004
Epoch 4599 
Prediction Loss: 0.002178
Epoch 4649 
Prediction Loss: 0.001449
Epoch 4699 
Prediction Loss: 0.001483
Epoch 4749 
Prediction Loss: 0.001315
Epoch 4799 
Prediction Loss: 0.001833
Epoch 4849 
Prediction Loss: 0.001280
Epoch 4899 
Prediction Loss: 0.001372
Epoch 4949 
Prediction Loss: 0.001252
Epoch 4999 
Prediction Loss: 0.001354
Epoch 5049 
Prediction Loss: 0.000938
Epoch 5099 
Prediction Loss: 0.001437
Epoch 5149 
Prediction Loss: 0.000929
Epoch 5199 
Prediction Loss: 0.001338
Epoch 5249 
Prediction Loss: 0.001576
Experiment Start!
Namespace(cevaelr=5e-05, decay=0.0, l=5e-05, latdim=4, mask=0, nlayer=50, obsm=4, stop=20, ycof=0.5, ylayer=50)
Y Mean 1.037543, Std 4.233836 
Test Y Mean 0.042888, Std 4.254001 
Observe confounder 4, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
