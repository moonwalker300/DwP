Y Mean 1.192369, Std 4.040208 
Observe confounder 4, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 19.595092
Rec Loss: 18.289171
KL Loss: 1.305921
Y Loss: 2.543808
T Loss: 13.201555
Epoch 99 
Overall Loss: 16.341588
Rec Loss: 15.317630
KL Loss: 1.023959
Y Loss: 1.051819
T Loss: 13.213990
Epoch 149 
Overall Loss: 15.318841
Rec Loss: 14.667659
KL Loss: 0.651183
Y Loss: 0.740150
T Loss: 13.187359
Epoch 199 
Overall Loss: 14.823783
Rec Loss: 14.255332
KL Loss: 0.568451
Y Loss: 0.554788
T Loss: 13.145756
Epoch 249 
Overall Loss: 14.606090
Rec Loss: 14.029856
KL Loss: 0.576234
Y Loss: 0.456137
T Loss: 13.117581
Epoch 299 
Overall Loss: 14.455054
Rec Loss: 13.867585
KL Loss: 0.587469
Y Loss: 0.389815
T Loss: 13.087954
Epoch 349 
Overall Loss: 14.324484
Rec Loss: 13.712796
KL Loss: 0.611689
Y Loss: 0.329194
T Loss: 13.054408
Epoch 399 
Overall Loss: 14.203733
Rec Loss: 13.569388
KL Loss: 0.634345
Y Loss: 0.278429
T Loss: 13.012529
Epoch 449 
Overall Loss: 14.123706
Rec Loss: 13.468340
KL Loss: 0.655365
Y Loss: 0.250204
T Loss: 12.967932
Epoch 499 
Overall Loss: 14.079916
Rec Loss: 13.418008
KL Loss: 0.661908
Y Loss: 0.238001
T Loss: 12.942005
Epoch 549 
Overall Loss: 14.055566
Rec Loss: 13.401111
KL Loss: 0.654456
Y Loss: 0.236952
T Loss: 12.927206
Epoch 599 
Overall Loss: 14.023749
Rec Loss: 13.384721
KL Loss: 0.639028
Y Loss: 0.231504
T Loss: 12.921713
Epoch 649 
Overall Loss: 13.983136
Rec Loss: 13.360380
KL Loss: 0.622756
Y Loss: 0.223712
T Loss: 12.912957
Epoch 699 
Overall Loss: 13.952052
Rec Loss: 13.342335
KL Loss: 0.609716
Y Loss: 0.218192
T Loss: 12.905951
Epoch 749 
Overall Loss: 13.920428
Rec Loss: 13.323548
KL Loss: 0.596880
Y Loss: 0.211709
T Loss: 12.900129
Epoch 799 
Overall Loss: 13.909871
Rec Loss: 13.326124
KL Loss: 0.583747
Y Loss: 0.210914
T Loss: 12.904295
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.548654
Epoch 99
Rec Loss: 1.543981
Epoch 149
Rec Loss: 1.542828
Epoch 199
Rec Loss: 1.538883
Epoch 249
Rec Loss: 1.542231
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.080374
Epoch 99
Rec Loss: 10.078530
Epoch 149
Rec Loss: 10.075325
Epoch 199
Rec Loss: 10.077696
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.245552
Insample Error: 1.910384
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 31.366014
Rec Loss: 26.231642
KL Loss: 5.134372
Y Loss: 3.639604
T Loss: 13.224682
Epoch 99 
Overall Loss: 24.638879
Rec Loss: 21.145956
KL Loss: 3.492924
Y Loss: 1.139811
T Loss: 13.278008
Epoch 149 
Overall Loss: 23.102243
Rec Loss: 19.554542
KL Loss: 3.547701
Y Loss: 0.781632
T Loss: 13.234744
Epoch 199 
Overall Loss: 22.129846
Rec Loss: 18.248765
KL Loss: 3.881081
Y Loss: 0.626225
T Loss: 13.170721
Epoch 249 
Overall Loss: 21.599508
Rec Loss: 17.562438
KL Loss: 4.037071
Y Loss: 0.523829
T Loss: 13.134075
Epoch 299 
Overall Loss: 21.287500
Rec Loss: 17.070113
KL Loss: 4.217387
Y Loss: 0.453413
T Loss: 13.114259
Epoch 349 
Overall Loss: 21.005054
Rec Loss: 16.541049
KL Loss: 4.464006
Y Loss: 0.391329
T Loss: 13.091984
Epoch 399 
Overall Loss: 20.833468
Rec Loss: 16.205464
KL Loss: 4.628003
Y Loss: 0.350252
T Loss: 13.086777
Epoch 449 
Overall Loss: 20.722166
Rec Loss: 15.981433
KL Loss: 4.740733
Y Loss: 0.325396
T Loss: 13.087215
Epoch 499 
Overall Loss: 20.579404
Rec Loss: 15.730493
KL Loss: 4.848912
Y Loss: 0.308019
T Loss: 13.081785
Epoch 549 
Overall Loss: 20.549298
Rec Loss: 15.570037
KL Loss: 4.979262
Y Loss: 0.303440
T Loss: 13.087073
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.753757
Epoch 99
Rec Loss: 1.747530
Epoch 149
Rec Loss: 1.747622
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.304249
Epoch 99
Rec Loss: 6.296950
Epoch 149
Rec Loss: 6.281257
Epoch 199
Rec Loss: 6.306317
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.246981
Insample Error 2.033641
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 19.653393
Rec Loss: 18.181003
KL Loss: 1.472391
Y Loss: 2.489559
T Loss: 13.201884
Epoch 99 
Overall Loss: 16.107382
Rec Loss: 15.295604
KL Loss: 0.811778
Y Loss: 1.042465
T Loss: 13.210674
Epoch 149 
Overall Loss: 15.345647
Rec Loss: 14.776162
KL Loss: 0.569485
Y Loss: 0.791839
T Loss: 13.192482
Epoch 199 
Overall Loss: 14.960922
Rec Loss: 14.463330
KL Loss: 0.497592
Y Loss: 0.651066
T Loss: 13.161198
Epoch 249 
Overall Loss: 14.765903
Rec Loss: 14.280384
KL Loss: 0.485519
Y Loss: 0.571798
T Loss: 13.136789
Epoch 299 
Overall Loss: 14.588250
Rec Loss: 14.101864
KL Loss: 0.486386
Y Loss: 0.495177
T Loss: 13.111510
Epoch 349 
Overall Loss: 14.482952
Rec Loss: 13.990624
KL Loss: 0.492328
Y Loss: 0.446959
T Loss: 13.096705
Epoch 399 
Overall Loss: 14.406789
Rec Loss: 13.902370
KL Loss: 0.504418
Y Loss: 0.410073
T Loss: 13.082223
Epoch 449 
Overall Loss: 14.320491
Rec Loss: 13.816807
KL Loss: 0.503684
Y Loss: 0.372838
T Loss: 13.071132
Epoch 499 
Overall Loss: 14.251367
Rec Loss: 13.746523
KL Loss: 0.504843
Y Loss: 0.346721
T Loss: 13.053082
Epoch 549 
Overall Loss: 14.139537
Rec Loss: 13.645461
KL Loss: 0.494076
Y Loss: 0.309900
T Loss: 13.025661
Epoch 599 
Overall Loss: 14.073110
Rec Loss: 13.580881
KL Loss: 0.492229
Y Loss: 0.288462
T Loss: 13.003957
Epoch 649 
Overall Loss: 13.984313
Rec Loss: 13.518879
KL Loss: 0.465434
Y Loss: 0.266975
T Loss: 12.984929
Epoch 699 
Overall Loss: 13.911339
Rec Loss: 13.472488
KL Loss: 0.438851
Y Loss: 0.249883
T Loss: 12.972722
Epoch 749 
Overall Loss: 13.860353
Rec Loss: 13.451801
KL Loss: 0.408551
Y Loss: 0.239635
T Loss: 12.972532
Epoch 799 
Overall Loss: 13.805290
Rec Loss: 13.427253
KL Loss: 0.378037
Y Loss: 0.226737
T Loss: 12.973778
Epoch 849 
Overall Loss: 13.750077
Rec Loss: 13.410024
KL Loss: 0.340053
Y Loss: 0.220651
T Loss: 12.968723
Epoch 899 
Overall Loss: 13.720471
Rec Loss: 13.402524
KL Loss: 0.317947
Y Loss: 0.212125
T Loss: 12.978275
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.514549
Epoch 99
Rec Loss: 1.506104
Epoch 149
Rec Loss: 1.512296
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.028907
Epoch 99
Rec Loss: 10.023376
Epoch 149
Rec Loss: 10.019038
Epoch 199
Rec Loss: 10.029377
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.343333
Insample Error: 1.221680
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 32.413504
Rec Loss: 27.285744
KL Loss: 5.127760
Y Loss: 4.173377
T Loss: 13.233723
Epoch 99 
Overall Loss: 24.876975
Rec Loss: 21.191404
KL Loss: 3.685570
Y Loss: 1.199335
T Loss: 13.268887
Epoch 149 
Overall Loss: 23.116502
Rec Loss: 19.244277
KL Loss: 3.872225
Y Loss: 0.844377
T Loss: 13.232629
Epoch 199 
Overall Loss: 22.075481
Rec Loss: 17.877963
KL Loss: 4.197517
Y Loss: 0.659336
T Loss: 13.217394
Epoch 249 
Overall Loss: 21.465350
Rec Loss: 16.823210
KL Loss: 4.642140
Y Loss: 0.549253
T Loss: 13.204476
Epoch 299 
Overall Loss: 21.121936
Rec Loss: 16.315461
KL Loss: 4.806475
Y Loss: 0.464936
T Loss: 13.194286
Epoch 349 
Overall Loss: 20.933200
Rec Loss: 15.995369
KL Loss: 4.937832
Y Loss: 0.434048
T Loss: 13.182033
Epoch 399 
Overall Loss: 20.769256
Rec Loss: 15.639770
KL Loss: 5.129486
Y Loss: 0.392740
T Loss: 13.165628
Epoch 449 
Overall Loss: 20.629702
Rec Loss: 15.255547
KL Loss: 5.374154
Y Loss: 0.357686
T Loss: 13.148779
Epoch 499 
Overall Loss: 20.505937
Rec Loss: 14.960460
KL Loss: 5.545477
Y Loss: 0.329448
T Loss: 13.130780
Epoch 549 
Overall Loss: 20.452993
Rec Loss: 14.835118
KL Loss: 5.617875
Y Loss: 0.318655
T Loss: 13.113685
Epoch 599 
Overall Loss: 20.395531
Rec Loss: 14.743165
KL Loss: 5.652366
Y Loss: 0.303428
T Loss: 13.096750
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.742921
Epoch 99
Rec Loss: 1.739083
Epoch 149
Rec Loss: 1.743605
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.801547
Epoch 99
Rec Loss: 5.799997
Epoch 149
Rec Loss: 5.782552
Epoch 199
Rec Loss: 5.803283
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.241169
Insample Error 1.992382
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 20.080537
Rec Loss: 19.043655
KL Loss: 1.036882
Y Loss: 2.927268
T Loss: 13.189119
Epoch 99 
Overall Loss: 16.094011
Rec Loss: 15.235621
KL Loss: 0.858390
Y Loss: 1.011027
T Loss: 13.213568
Epoch 149 
Overall Loss: 15.213543
Rec Loss: 14.584661
KL Loss: 0.628882
Y Loss: 0.691712
T Loss: 13.201237
Epoch 199 
Overall Loss: 14.807823
Rec Loss: 14.234120
KL Loss: 0.573704
Y Loss: 0.536353
T Loss: 13.161414
Epoch 249 
Overall Loss: 14.623252
Rec Loss: 14.058865
KL Loss: 0.564387
Y Loss: 0.464226
T Loss: 13.130412
Epoch 299 
Overall Loss: 14.473721
Rec Loss: 13.912855
KL Loss: 0.560866
Y Loss: 0.402755
T Loss: 13.107344
Epoch 349 
Overall Loss: 14.369021
Rec Loss: 13.795379
KL Loss: 0.573642
Y Loss: 0.352899
T Loss: 13.089582
Epoch 399 
Overall Loss: 14.243097
Rec Loss: 13.666191
KL Loss: 0.576907
Y Loss: 0.296135
T Loss: 13.073922
Epoch 449 
Overall Loss: 14.194419
Rec Loss: 13.601173
KL Loss: 0.593246
Y Loss: 0.271577
T Loss: 13.058019
Epoch 499 
Overall Loss: 14.157873
Rec Loss: 13.553456
KL Loss: 0.604417
Y Loss: 0.260263
T Loss: 13.032929
Epoch 549 
Overall Loss: 14.111350
Rec Loss: 13.496207
KL Loss: 0.615143
Y Loss: 0.244041
T Loss: 13.008124
Epoch 599 
Overall Loss: 14.070252
Rec Loss: 13.461088
KL Loss: 0.609164
Y Loss: 0.236770
T Loss: 12.987548
Epoch 649 
Overall Loss: 14.048120
Rec Loss: 13.441707
KL Loss: 0.606412
Y Loss: 0.233251
T Loss: 12.975205
Epoch 699 
Overall Loss: 14.026131
Rec Loss: 13.438327
KL Loss: 0.587804
Y Loss: 0.238575
T Loss: 12.961178
Epoch 749 
Overall Loss: 13.981998
Rec Loss: 13.406117
KL Loss: 0.575882
Y Loss: 0.226741
T Loss: 12.952634
Epoch 799 
Overall Loss: 13.934989
Rec Loss: 13.385773
KL Loss: 0.549216
Y Loss: 0.221735
T Loss: 12.942302
Epoch 849 
Overall Loss: 13.910021
Rec Loss: 13.381095
KL Loss: 0.528926
Y Loss: 0.217125
T Loss: 12.946846
Epoch 899 
Overall Loss: 13.894696
Rec Loss: 13.396928
KL Loss: 0.497768
Y Loss: 0.222665
T Loss: 12.951598
Epoch 949 
Overall Loss: 13.840463
Rec Loss: 13.376152
KL Loss: 0.464311
Y Loss: 0.212879
T Loss: 12.950394
Epoch 999 
Overall Loss: 13.785196
Rec Loss: 13.356560
KL Loss: 0.428636
Y Loss: 0.201957
T Loss: 12.952646
Epoch 1049 
Overall Loss: 13.761881
Rec Loss: 13.367034
KL Loss: 0.394847
Y Loss: 0.201422
T Loss: 12.964190
Epoch 1099 
Overall Loss: 13.703397
Rec Loss: 13.345820
KL Loss: 0.357576
Y Loss: 0.191995
T Loss: 12.961829
Epoch 1149 
Overall Loss: 13.650111
Rec Loss: 13.333349
KL Loss: 0.316762
Y Loss: 0.182884
T Loss: 12.967581
Epoch 1199 
Overall Loss: 13.611555
Rec Loss: 13.330901
KL Loss: 0.280653
Y Loss: 0.176772
T Loss: 12.977358
Epoch 1249 
Overall Loss: 13.583717
Rec Loss: 13.332423
KL Loss: 0.251294
Y Loss: 0.173992
T Loss: 12.984439
Epoch 1299 
Overall Loss: 13.562692
Rec Loss: 13.331423
KL Loss: 0.231269
Y Loss: 0.167734
T Loss: 12.995955
Epoch 1349 
Overall Loss: 13.526144
Rec Loss: 13.316863
KL Loss: 0.209282
Y Loss: 0.160175
T Loss: 12.996512
Epoch 1399 
Overall Loss: 13.507802
Rec Loss: 13.311038
KL Loss: 0.196764
Y Loss: 0.156584
T Loss: 12.997870
Epoch 1449 
Overall Loss: 13.487756
Rec Loss: 13.306674
KL Loss: 0.181082
Y Loss: 0.153691
T Loss: 12.999292
Epoch 1499 
Overall Loss: 13.478237
Rec Loss: 13.307698
KL Loss: 0.170538
Y Loss: 0.152662
T Loss: 13.002373
Epoch 1549 
Overall Loss: 13.465433
Rec Loss: 13.304234
KL Loss: 0.161199
Y Loss: 0.148850
T Loss: 13.006533
Epoch 1599 
Overall Loss: 13.444553
Rec Loss: 13.291292
KL Loss: 0.153260
Y Loss: 0.146753
T Loss: 12.997786
Epoch 1649 
Overall Loss: 13.440490
Rec Loss: 13.296007
KL Loss: 0.144483
Y Loss: 0.144973
T Loss: 13.006060
Epoch 1699 
Overall Loss: 13.428641
Rec Loss: 13.289207
KL Loss: 0.139435
Y Loss: 0.142250
T Loss: 13.004707
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.340424
Epoch 99
Rec Loss: 1.335809
Epoch 149
Rec Loss: 1.340820
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.012149
Epoch 99
Rec Loss: 10.016698
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.322383
Insample Error: 0.730271
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 31.303161
Rec Loss: 25.944776
KL Loss: 5.358384
Y Loss: 3.452173
T Loss: 13.248421
Epoch 99 
Overall Loss: 24.697064
Rec Loss: 21.045802
KL Loss: 3.651262
Y Loss: 1.163423
T Loss: 13.270356
Epoch 149 
Overall Loss: 22.842328
Rec Loss: 18.748854
KL Loss: 4.093474
Y Loss: 0.818222
T Loss: 13.215359
Epoch 199 
Overall Loss: 21.955407
Rec Loss: 17.483419
KL Loss: 4.471988
Y Loss: 0.649074
T Loss: 13.192886
Epoch 249 
Overall Loss: 21.575822
Rec Loss: 16.940796
KL Loss: 4.635027
Y Loss: 0.572094
T Loss: 13.203386
Epoch 299 
Overall Loss: 21.299154
Rec Loss: 16.574589
KL Loss: 4.724565
Y Loss: 0.522423
T Loss: 13.200238
Epoch 349 
Overall Loss: 21.045925
Rec Loss: 16.155301
KL Loss: 4.890624
Y Loss: 0.467300
T Loss: 13.182132
Epoch 399 
Overall Loss: 20.868543
Rec Loss: 15.676941
KL Loss: 5.191602
Y Loss: 0.425845
T Loss: 13.171412
Epoch 449 
Overall Loss: 20.689058
Rec Loss: 15.208324
KL Loss: 5.480734
Y Loss: 0.382288
T Loss: 13.156830
Epoch 499 
Overall Loss: 20.584230
Rec Loss: 14.860951
KL Loss: 5.723280
Y Loss: 0.364735
T Loss: 13.140453
Epoch 549 
Overall Loss: 20.524518
Rec Loss: 14.659528
KL Loss: 5.864991
Y Loss: 0.358657
T Loss: 13.126455
Epoch 599 
Overall Loss: 20.447039
Rec Loss: 14.455248
KL Loss: 5.991791
Y Loss: 0.340181
T Loss: 13.110193
Epoch 649 
Overall Loss: 20.413236
Rec Loss: 14.326886
KL Loss: 6.086349
Y Loss: 0.334685
T Loss: 13.100698
Epoch 699 
Overall Loss: 20.380301
Rec Loss: 14.217668
KL Loss: 6.162633
Y Loss: 0.330352
T Loss: 13.085116
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.738081
Epoch 99
Rec Loss: 1.736478
Epoch 149
Rec Loss: 1.734054
Epoch 199
Rec Loss: 1.736520
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.785957
Epoch 99
Rec Loss: 5.781769
Epoch 149
Rec Loss: 5.779272
Epoch 199
Rec Loss: 5.762582
Epoch 249
Rec Loss: 5.765690
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.264096
Insample Error 2.023055
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 20.988701
Rec Loss: 19.596653
KL Loss: 1.392047
Y Loss: 3.203868
T Loss: 13.188918
Epoch 99 
Overall Loss: 16.038373
Rec Loss: 15.039627
KL Loss: 0.998747
Y Loss: 0.906131
T Loss: 13.227365
Epoch 149 
Overall Loss: 15.196964
Rec Loss: 14.497059
KL Loss: 0.699905
Y Loss: 0.645901
T Loss: 13.205256
Epoch 199 
Overall Loss: 14.733486
Rec Loss: 14.144243
KL Loss: 0.589242
Y Loss: 0.485002
T Loss: 13.174239
Epoch 249 
Overall Loss: 14.507436
Rec Loss: 13.920617
KL Loss: 0.586819
Y Loss: 0.387505
T Loss: 13.145606
Epoch 299 
Overall Loss: 14.394689
Rec Loss: 13.798686
KL Loss: 0.596003
Y Loss: 0.335632
T Loss: 13.127423
Epoch 349 
Overall Loss: 14.312694
Rec Loss: 13.714989
KL Loss: 0.597705
Y Loss: 0.305187
T Loss: 13.104615
Epoch 399 
Overall Loss: 14.220974
Rec Loss: 13.614977
KL Loss: 0.605997
Y Loss: 0.266004
T Loss: 13.082970
Epoch 449 
Overall Loss: 14.192291
Rec Loss: 13.589734
KL Loss: 0.602557
Y Loss: 0.259296
T Loss: 13.071141
Epoch 499 
Overall Loss: 14.151247
Rec Loss: 13.550259
KL Loss: 0.600988
Y Loss: 0.250757
T Loss: 13.048745
Epoch 549 
Overall Loss: 14.124191
Rec Loss: 13.532230
KL Loss: 0.591960
Y Loss: 0.249076
T Loss: 13.034079
Epoch 599 
Overall Loss: 14.062213
Rec Loss: 13.479980
KL Loss: 0.582233
Y Loss: 0.233620
T Loss: 13.012740
Epoch 649 
Overall Loss: 14.023094
Rec Loss: 13.462269
KL Loss: 0.560825
Y Loss: 0.233012
T Loss: 12.996244
Epoch 699 
Overall Loss: 13.976225
Rec Loss: 13.432695
KL Loss: 0.543530
Y Loss: 0.225244
T Loss: 12.982207
Epoch 749 
Overall Loss: 13.918154
Rec Loss: 13.407221
KL Loss: 0.510933
Y Loss: 0.221659
T Loss: 12.963903
Epoch 799 
Overall Loss: 13.881617
Rec Loss: 13.407461
KL Loss: 0.474156
Y Loss: 0.221002
T Loss: 12.965457
Epoch 849 
Overall Loss: 13.822906
Rec Loss: 13.386105
KL Loss: 0.436801
Y Loss: 0.212671
T Loss: 12.960763
Epoch 899 
Overall Loss: 13.772558
Rec Loss: 13.378856
KL Loss: 0.393702
Y Loss: 0.206075
T Loss: 12.966706
Epoch 949 
Overall Loss: 13.713989
Rec Loss: 13.359498
KL Loss: 0.354492
Y Loss: 0.192763
T Loss: 12.973971
Epoch 999 
Overall Loss: 13.676896
Rec Loss: 13.362693
KL Loss: 0.314203
Y Loss: 0.192530
T Loss: 12.977633
Epoch 1049 
Overall Loss: 13.637594
Rec Loss: 13.353243
KL Loss: 0.284351
Y Loss: 0.184423
T Loss: 12.984398
Epoch 1099 
Overall Loss: 13.595567
Rec Loss: 13.338666
KL Loss: 0.256902
Y Loss: 0.176859
T Loss: 12.984947
Epoch 1149 
Overall Loss: 13.566968
Rec Loss: 13.338185
KL Loss: 0.228783
Y Loss: 0.172368
T Loss: 12.993449
Epoch 1199 
Overall Loss: 13.528128
Rec Loss: 13.315761
KL Loss: 0.212367
Y Loss: 0.161905
T Loss: 12.991952
Epoch 1249 
Overall Loss: 13.517220
Rec Loss: 13.317714
KL Loss: 0.199506
Y Loss: 0.159240
T Loss: 12.999235
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.512223
Epoch 99
Rec Loss: 1.511873
Epoch 149
Rec Loss: 1.510294
Epoch 199
Rec Loss: 1.509371
Epoch 249
Rec Loss: 1.504477
Epoch 299
Rec Loss: 1.504158
Epoch 349
Rec Loss: 1.514101
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.060297
Epoch 99
Rec Loss: 10.058797
Epoch 149
Rec Loss: 10.052579
Epoch 199
Rec Loss: 10.050514
Epoch 249
Rec Loss: 10.047524
Epoch 299
Rec Loss: 10.055995
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.324111
Insample Error: 0.923455
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 29.890558
Rec Loss: 25.501981
KL Loss: 4.388577
Y Loss: 3.271948
T Loss: 13.229066
Epoch 99 
Overall Loss: 24.694496
Rec Loss: 21.287847
KL Loss: 3.406649
Y Loss: 1.253873
T Loss: 13.264896
Epoch 149 
Overall Loss: 23.179529
Rec Loss: 19.598425
KL Loss: 3.581104
Y Loss: 0.876389
T Loss: 13.209238
Epoch 199 
Overall Loss: 22.098147
Rec Loss: 18.309014
KL Loss: 3.789133
Y Loss: 0.635810
T Loss: 13.176815
Epoch 249 
Overall Loss: 21.636154
Rec Loss: 17.758440
KL Loss: 3.877714
Y Loss: 0.528307
T Loss: 13.161527
Epoch 299 
Overall Loss: 21.279817
Rec Loss: 17.297361
KL Loss: 3.982456
Y Loss: 0.446405
T Loss: 13.133212
Epoch 349 
Overall Loss: 20.982856
Rec Loss: 16.963874
KL Loss: 4.018982
Y Loss: 0.365188
T Loss: 13.127551
Epoch 399 
Overall Loss: 20.785243
Rec Loss: 16.800997
KL Loss: 3.984245
Y Loss: 0.311847
T Loss: 13.118586
Epoch 449 
Overall Loss: 20.648227
Rec Loss: 16.682732
KL Loss: 3.965494
Y Loss: 0.284469
T Loss: 13.109466
Epoch 499 
Overall Loss: 20.565091
Rec Loss: 16.554068
KL Loss: 4.011022
Y Loss: 0.277439
T Loss: 13.098964
Epoch 549 
Overall Loss: 20.496709
Rec Loss: 16.401693
KL Loss: 4.095016
Y Loss: 0.270918
T Loss: 13.088894
Epoch 599 
Overall Loss: 20.425404
Rec Loss: 16.275858
KL Loss: 4.149547
Y Loss: 0.267405
T Loss: 13.071950
Epoch 649 
Overall Loss: 20.392341
Rec Loss: 16.207862
KL Loss: 4.184479
Y Loss: 0.266703
T Loss: 13.062321
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.721924
Epoch 99
Rec Loss: 1.724824
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.325632
Epoch 99
Rec Loss: 6.290953
Epoch 149
Rec Loss: 6.306422
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.221698
Insample Error 2.027548
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 20.039638
Rec Loss: 18.733980
KL Loss: 1.305658
Y Loss: 2.764888
T Loss: 13.204204
Epoch 99 
Overall Loss: 16.001234
Rec Loss: 15.144118
KL Loss: 0.857116
Y Loss: 0.969284
T Loss: 13.205549
Epoch 149 
Overall Loss: 15.245738
Rec Loss: 14.674166
KL Loss: 0.571572
Y Loss: 0.743686
T Loss: 13.186794
Epoch 199 
Overall Loss: 14.847001
Rec Loss: 14.341324
KL Loss: 0.505676
Y Loss: 0.593543
T Loss: 13.154239
Epoch 249 
Overall Loss: 14.628412
Rec Loss: 14.113137
KL Loss: 0.515274
Y Loss: 0.492615
T Loss: 13.127907
Epoch 299 
Overall Loss: 14.491989
Rec Loss: 13.970014
KL Loss: 0.521975
Y Loss: 0.430787
T Loss: 13.108440
Epoch 349 
Overall Loss: 14.378416
Rec Loss: 13.841708
KL Loss: 0.536708
Y Loss: 0.375243
T Loss: 13.091222
Epoch 399 
Overall Loss: 14.278035
Rec Loss: 13.727828
KL Loss: 0.550208
Y Loss: 0.322700
T Loss: 13.082427
Epoch 449 
Overall Loss: 14.199601
Rec Loss: 13.631747
KL Loss: 0.567853
Y Loss: 0.284106
T Loss: 13.063536
Epoch 499 
Overall Loss: 14.149316
Rec Loss: 13.583931
KL Loss: 0.565385
Y Loss: 0.261090
T Loss: 13.061751
Epoch 549 
Overall Loss: 14.098637
Rec Loss: 13.538046
KL Loss: 0.560591
Y Loss: 0.245769
T Loss: 13.046508
Epoch 599 
Overall Loss: 14.042860
Rec Loss: 13.502671
KL Loss: 0.540188
Y Loss: 0.234419
T Loss: 13.033833
Epoch 649 
Overall Loss: 14.002468
Rec Loss: 13.481758
KL Loss: 0.520710
Y Loss: 0.228603
T Loss: 13.024552
Epoch 699 
Overall Loss: 13.960801
Rec Loss: 13.471138
KL Loss: 0.489663
Y Loss: 0.225977
T Loss: 13.019185
Epoch 749 
Overall Loss: 13.902439
Rec Loss: 13.447981
KL Loss: 0.454458
Y Loss: 0.217646
T Loss: 13.012688
Epoch 799 
Overall Loss: 13.857182
Rec Loss: 13.433163
KL Loss: 0.424019
Y Loss: 0.213641
T Loss: 13.005882
Epoch 849 
Overall Loss: 13.826912
Rec Loss: 13.432141
KL Loss: 0.394771
Y Loss: 0.209470
T Loss: 13.013201
Epoch 899 
Overall Loss: 13.763782
Rec Loss: 13.403417
KL Loss: 0.360365
Y Loss: 0.198796
T Loss: 13.005826
Epoch 949 
Overall Loss: 13.729965
Rec Loss: 13.398119
KL Loss: 0.331847
Y Loss: 0.197385
T Loss: 13.003348
Epoch 999 
Overall Loss: 13.684558
Rec Loss: 13.388007
KL Loss: 0.296552
Y Loss: 0.193252
T Loss: 13.001503
Epoch 1049 
Overall Loss: 13.668975
Rec Loss: 13.395567
KL Loss: 0.273409
Y Loss: 0.193394
T Loss: 13.008779
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.528540
Epoch 99
Rec Loss: 1.531596
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.048438
Epoch 99
Rec Loss: 10.050899
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.329483
Insample Error: 1.225850
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 30.275486
Rec Loss: 25.383392
KL Loss: 4.892093
Y Loss: 3.196287
T Loss: 13.218918
Epoch 99 
Overall Loss: 24.623025
Rec Loss: 21.213821
KL Loss: 3.409204
Y Loss: 1.182049
T Loss: 13.271165
Epoch 149 
Overall Loss: 22.962058
Rec Loss: 19.501522
KL Loss: 3.460536
Y Loss: 0.809995
T Loss: 13.239814
Epoch 199 
Overall Loss: 22.022954
Rec Loss: 18.584828
KL Loss: 3.438126
Y Loss: 0.583621
T Loss: 13.214816
Epoch 249 
Overall Loss: 21.357724
Rec Loss: 17.996198
KL Loss: 3.361526
Y Loss: 0.412761
T Loss: 13.189885
Epoch 299 
Overall Loss: 21.023151
Rec Loss: 17.657086
KL Loss: 3.366065
Y Loss: 0.331951
T Loss: 13.162070
Epoch 349 
Overall Loss: 20.800863
Rec Loss: 17.250120
KL Loss: 3.550744
Y Loss: 0.297687
T Loss: 13.137053
Epoch 399 
Overall Loss: 20.630602
Rec Loss: 16.867373
KL Loss: 3.763229
Y Loss: 0.276971
T Loss: 13.115593
Epoch 449 
Overall Loss: 20.494917
Rec Loss: 16.550505
KL Loss: 3.944413
Y Loss: 0.279875
T Loss: 13.095684
Epoch 499 
Overall Loss: 20.459201
Rec Loss: 16.386729
KL Loss: 4.072472
Y Loss: 0.275289
T Loss: 13.084366
Epoch 549 
Overall Loss: 20.410532
Rec Loss: 16.249705
KL Loss: 4.160826
Y Loss: 0.273561
T Loss: 13.068190
Epoch 599 
Overall Loss: 20.372475
Rec Loss: 16.151305
KL Loss: 4.221170
Y Loss: 0.267876
T Loss: 13.058541
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.732013
Epoch 99
Rec Loss: 1.733298
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.207551
Epoch 99
Rec Loss: 6.185444
Epoch 149
Rec Loss: 6.183331
Epoch 199
Rec Loss: 6.193015
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.221082
Insample Error 2.066541
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 19.428076
Rec Loss: 17.926704
KL Loss: 1.501372
Y Loss: 2.368888
T Loss: 13.188929
Epoch 99 
Overall Loss: 16.079759
Rec Loss: 15.203812
KL Loss: 0.875948
Y Loss: 1.002364
T Loss: 13.199084
Epoch 149 
Overall Loss: 15.309771
Rec Loss: 14.731912
KL Loss: 0.577858
Y Loss: 0.780180
T Loss: 13.171553
Epoch 199 
Overall Loss: 14.924226
Rec Loss: 14.397955
KL Loss: 0.526271
Y Loss: 0.631955
T Loss: 13.134044
Epoch 249 
Overall Loss: 14.741675
Rec Loss: 14.213691
KL Loss: 0.527984
Y Loss: 0.551558
T Loss: 13.110575
Epoch 299 
Overall Loss: 14.617554
Rec Loss: 14.091445
KL Loss: 0.526108
Y Loss: 0.497400
T Loss: 13.096644
Epoch 349 
Overall Loss: 14.501999
Rec Loss: 13.975322
KL Loss: 0.526677
Y Loss: 0.447136
T Loss: 13.081050
Epoch 399 
Overall Loss: 14.386124
Rec Loss: 13.861721
KL Loss: 0.524402
Y Loss: 0.397140
T Loss: 13.067441
Epoch 449 
Overall Loss: 14.293257
Rec Loss: 13.772339
KL Loss: 0.520918
Y Loss: 0.360142
T Loss: 13.052054
Epoch 499 
Overall Loss: 14.190095
Rec Loss: 13.673641
KL Loss: 0.516454
Y Loss: 0.321526
T Loss: 13.030589
Epoch 549 
Overall Loss: 14.091705
Rec Loss: 13.583133
KL Loss: 0.508573
Y Loss: 0.289970
T Loss: 13.003192
Epoch 599 
Overall Loss: 13.998299
Rec Loss: 13.500403
KL Loss: 0.497896
Y Loss: 0.260662
T Loss: 12.979078
Epoch 649 
Overall Loss: 13.938368
Rec Loss: 13.451118
KL Loss: 0.487249
Y Loss: 0.240646
T Loss: 12.969826
Epoch 699 
Overall Loss: 13.868484
Rec Loss: 13.409775
KL Loss: 0.458709
Y Loss: 0.227432
T Loss: 12.954912
Epoch 749 
Overall Loss: 13.818347
Rec Loss: 13.389565
KL Loss: 0.428782
Y Loss: 0.213333
T Loss: 12.962900
Epoch 799 
Overall Loss: 13.780370
Rec Loss: 13.384213
KL Loss: 0.396157
Y Loss: 0.207149
T Loss: 12.969915
Epoch 849 
Overall Loss: 13.738663
Rec Loss: 13.374143
KL Loss: 0.364520
Y Loss: 0.199431
T Loss: 12.975281
Epoch 899 
Overall Loss: 13.686048
Rec Loss: 13.353013
KL Loss: 0.333036
Y Loss: 0.188208
T Loss: 12.976597
Epoch 949 
Overall Loss: 13.655564
Rec Loss: 13.355485
KL Loss: 0.300078
Y Loss: 0.185373
T Loss: 12.984740
Epoch 999 
Overall Loss: 13.622212
Rec Loss: 13.355567
KL Loss: 0.266645
Y Loss: 0.183689
T Loss: 12.988189
Epoch 1049 
Overall Loss: 13.585276
Rec Loss: 13.341707
KL Loss: 0.243568
Y Loss: 0.172033
T Loss: 12.997642
Epoch 1099 
Overall Loss: 13.562774
Rec Loss: 13.346063
KL Loss: 0.216710
Y Loss: 0.169500
T Loss: 13.007063
Epoch 1149 
Overall Loss: 13.538625
Rec Loss: 13.343237
KL Loss: 0.195388
Y Loss: 0.169244
T Loss: 13.004750
Epoch 1199 
Overall Loss: 13.521278
Rec Loss: 13.344461
KL Loss: 0.176818
Y Loss: 0.163659
T Loss: 13.017143
Epoch 1249 
Overall Loss: 13.509779
Rec Loss: 13.344291
KL Loss: 0.165488
Y Loss: 0.160954
T Loss: 13.022383
Epoch 1299 
Overall Loss: 13.482558
Rec Loss: 13.329272
KL Loss: 0.153286
Y Loss: 0.154680
T Loss: 13.019911
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.474316
Epoch 99
Rec Loss: 1.473129
Epoch 149
Rec Loss: 1.476182
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.016413
Epoch 99
Rec Loss: 10.007767
Epoch 149
Rec Loss: 10.011111
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.330379
Insample Error: 0.841948
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 28.611295
Rec Loss: 23.684516
KL Loss: 4.926779
Y Loss: 2.351677
T Loss: 13.236353
Epoch 99 
Overall Loss: 24.567582
Rec Loss: 21.110853
KL Loss: 3.456729
Y Loss: 1.128078
T Loss: 13.268686
Epoch 149 
Overall Loss: 23.449093
Rec Loss: 19.798368
KL Loss: 3.650725
Y Loss: 0.907923
T Loss: 13.241412
Epoch 199 
Overall Loss: 22.566830
Rec Loss: 18.512238
KL Loss: 4.054593
Y Loss: 0.772368
T Loss: 13.221559
Epoch 249 
Overall Loss: 21.808712
Rec Loss: 17.264146
KL Loss: 4.544566
Y Loss: 0.645836
T Loss: 13.191944
Epoch 299 
Overall Loss: 21.319037
Rec Loss: 16.432077
KL Loss: 4.886959
Y Loss: 0.548110
T Loss: 13.189597
Epoch 349 
Overall Loss: 21.042683
Rec Loss: 15.962903
KL Loss: 5.079780
Y Loss: 0.474631
T Loss: 13.175770
Epoch 399 
Overall Loss: 20.777089
Rec Loss: 15.618445
KL Loss: 5.158644
Y Loss: 0.410574
T Loss: 13.158471
Epoch 449 
Overall Loss: 20.632315
Rec Loss: 15.377598
KL Loss: 5.254717
Y Loss: 0.355836
T Loss: 13.147244
Epoch 499 
Overall Loss: 20.519675
Rec Loss: 15.201205
KL Loss: 5.318470
Y Loss: 0.332042
T Loss: 13.130344
Epoch 549 
Overall Loss: 20.423553
Rec Loss: 15.057298
KL Loss: 5.366255
Y Loss: 0.315740
T Loss: 13.112089
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.759143
Epoch 99
Rec Loss: 1.757150
Epoch 149
Rec Loss: 1.754100
Epoch 199
Rec Loss: 1.758296
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.889834
Epoch 99
Rec Loss: 5.877585
Epoch 149
Rec Loss: 5.881356
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.265220
Insample Error 2.011284
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 18.664430
Rec Loss: 17.281428
KL Loss: 1.383002
Y Loss: 2.047265
T Loss: 13.186898
Epoch 99 
Overall Loss: 15.974299
Rec Loss: 15.143181
KL Loss: 0.831119
Y Loss: 0.978293
T Loss: 13.186594
Epoch 149 
Overall Loss: 15.257370
Rec Loss: 14.697105
KL Loss: 0.560265
Y Loss: 0.768235
T Loss: 13.160635
Epoch 199 
Overall Loss: 14.887509
Rec Loss: 14.362067
KL Loss: 0.525442
Y Loss: 0.614001
T Loss: 13.134064
Epoch 249 
Overall Loss: 14.689179
Rec Loss: 14.152646
KL Loss: 0.536533
Y Loss: 0.521094
T Loss: 13.110459
Epoch 299 
Overall Loss: 14.589234
Rec Loss: 14.044440
KL Loss: 0.544794
Y Loss: 0.473531
T Loss: 13.097377
Epoch 349 
Overall Loss: 14.476152
Rec Loss: 13.931143
KL Loss: 0.545009
Y Loss: 0.426380
T Loss: 13.078382
Epoch 399 
Overall Loss: 14.405002
Rec Loss: 13.846482
KL Loss: 0.558520
Y Loss: 0.390336
T Loss: 13.065810
Epoch 449 
Overall Loss: 14.329066
Rec Loss: 13.763528
KL Loss: 0.565537
Y Loss: 0.359541
T Loss: 13.044446
Epoch 499 
Overall Loss: 14.267703
Rec Loss: 13.679512
KL Loss: 0.588192
Y Loss: 0.324327
T Loss: 13.030858
Epoch 549 
Overall Loss: 14.174233
Rec Loss: 13.575034
KL Loss: 0.599200
Y Loss: 0.289199
T Loss: 12.996636
Epoch 599 
Overall Loss: 14.100751
Rec Loss: 13.494360
KL Loss: 0.606391
Y Loss: 0.258859
T Loss: 12.976643
Epoch 649 
Overall Loss: 14.042219
Rec Loss: 13.443560
KL Loss: 0.598659
Y Loss: 0.243866
T Loss: 12.955829
Epoch 699 
Overall Loss: 13.991390
Rec Loss: 13.412869
KL Loss: 0.578521
Y Loss: 0.237300
T Loss: 12.938270
Epoch 749 
Overall Loss: 13.943776
Rec Loss: 13.390771
KL Loss: 0.553004
Y Loss: 0.226561
T Loss: 12.937649
Epoch 799 
Overall Loss: 13.920479
Rec Loss: 13.387104
KL Loss: 0.533375
Y Loss: 0.226469
T Loss: 12.934167
Epoch 849 
Overall Loss: 13.849732
Rec Loss: 13.348246
KL Loss: 0.501486
Y Loss: 0.211667
T Loss: 12.924913
Epoch 899 
Overall Loss: 13.819098
Rec Loss: 13.343087
KL Loss: 0.476011
Y Loss: 0.208217
T Loss: 12.926651
Epoch 949 
Overall Loss: 13.777412
Rec Loss: 13.333338
KL Loss: 0.444074
Y Loss: 0.203176
T Loss: 12.926987
Epoch 999 
Overall Loss: 13.725717
Rec Loss: 13.318844
KL Loss: 0.406873
Y Loss: 0.198289
T Loss: 12.922267
Epoch 1049 
Overall Loss: 13.664698
Rec Loss: 13.288256
KL Loss: 0.376442
Y Loss: 0.184568
T Loss: 12.919120
Epoch 1099 
Overall Loss: 13.635504
Rec Loss: 13.282998
KL Loss: 0.352506
Y Loss: 0.179052
T Loss: 12.924894
Epoch 1149 
Overall Loss: 13.605851
Rec Loss: 13.283149
KL Loss: 0.322702
Y Loss: 0.175264
T Loss: 12.932620
Epoch 1199 
Overall Loss: 13.584613
Rec Loss: 13.282712
KL Loss: 0.301900
Y Loss: 0.174300
T Loss: 12.934113
Epoch 1249 
Overall Loss: 13.546697
Rec Loss: 13.263149
KL Loss: 0.283548
Y Loss: 0.165611
T Loss: 12.931926
Epoch 1299 
Overall Loss: 13.529471
Rec Loss: 13.265412
KL Loss: 0.264059
Y Loss: 0.162576
T Loss: 12.940260
Epoch 1349 
Overall Loss: 13.517025
Rec Loss: 13.268258
KL Loss: 0.248767
Y Loss: 0.162163
T Loss: 12.943932
Epoch 1399 
Overall Loss: 13.497019
Rec Loss: 13.262425
KL Loss: 0.234595
Y Loss: 0.158750
T Loss: 12.944925
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.398634
Epoch 99
Rec Loss: 1.392233
Epoch 149
Rec Loss: 1.394542
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.014778
Epoch 99
Rec Loss: 10.023231
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.315620
Insample Error: 0.942006
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 30.162621
Rec Loss: 25.214748
KL Loss: 4.947873
Y Loss: 3.126029
T Loss: 13.214315
Epoch 99 
Overall Loss: 24.709350
Rec Loss: 21.210291
KL Loss: 3.499060
Y Loss: 1.180965
T Loss: 13.271692
Epoch 149 
Overall Loss: 22.791791
Rec Loss: 18.980874
KL Loss: 3.810916
Y Loss: 0.754797
T Loss: 13.241987
Epoch 199 
Overall Loss: 22.066153
Rec Loss: 18.171404
KL Loss: 3.894748
Y Loss: 0.624421
T Loss: 13.229689
Epoch 249 
Overall Loss: 21.700668
Rec Loss: 17.637327
KL Loss: 4.063342
Y Loss: 0.571769
T Loss: 13.209873
Epoch 299 
Overall Loss: 21.282965
Rec Loss: 16.873148
KL Loss: 4.409817
Y Loss: 0.461419
T Loss: 13.192178
Epoch 349 
Overall Loss: 21.003836
Rec Loss: 16.153512
KL Loss: 4.850325
Y Loss: 0.400248
T Loss: 13.165927
Epoch 399 
Overall Loss: 20.828254
Rec Loss: 15.602642
KL Loss: 5.225612
Y Loss: 0.379632
T Loss: 13.150643
Epoch 449 
Overall Loss: 20.697397
Rec Loss: 15.136827
KL Loss: 5.560570
Y Loss: 0.367747
T Loss: 13.134602
Epoch 499 
Overall Loss: 20.611914
Rec Loss: 14.876554
KL Loss: 5.735360
Y Loss: 0.354136
T Loss: 13.121335
Epoch 549 
Overall Loss: 20.467016
Rec Loss: 14.527484
KL Loss: 5.939532
Y Loss: 0.340656
T Loss: 13.109928
Epoch 599 
Overall Loss: 20.409667
Rec Loss: 14.230275
KL Loss: 6.179392
Y Loss: 0.341908
T Loss: 13.094381
Epoch 649 
Overall Loss: 20.326458
Rec Loss: 14.005355
KL Loss: 6.321103
Y Loss: 0.331173
T Loss: 13.083023
Epoch 699 
Overall Loss: 20.281796
Rec Loss: 13.804225
KL Loss: 6.477571
Y Loss: 0.320294
T Loss: 13.070984
Epoch 749 
Overall Loss: 20.230076
Rec Loss: 13.678602
KL Loss: 6.551473
Y Loss: 0.318137
T Loss: 13.061158
Epoch 799 
Overall Loss: 20.147162
Rec Loss: 13.494316
KL Loss: 6.652846
Y Loss: 0.306697
T Loss: 13.047718
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.681066
Epoch 99
Rec Loss: 1.684833
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.692226
Epoch 99
Rec Loss: 5.682053
Epoch 149
Rec Loss: 5.684500
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.241564
Insample Error 1.897411
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 19.525737
Rec Loss: 17.980479
KL Loss: 1.545259
Y Loss: 2.381008
T Loss: 13.218462
Epoch 99 
Overall Loss: 16.234092
Rec Loss: 15.299881
KL Loss: 0.934210
Y Loss: 1.027906
T Loss: 13.244069
Epoch 149 
Overall Loss: 15.380607
Rec Loss: 14.771942
KL Loss: 0.608665
Y Loss: 0.778160
T Loss: 13.215621
Epoch 199 
Overall Loss: 14.947078
Rec Loss: 14.432177
KL Loss: 0.514901
Y Loss: 0.626729
T Loss: 13.178719
Epoch 249 
Overall Loss: 14.714064
Rec Loss: 14.213383
KL Loss: 0.500681
Y Loss: 0.533682
T Loss: 13.146019
Epoch 299 
Overall Loss: 14.595547
Rec Loss: 14.098882
KL Loss: 0.496665
Y Loss: 0.489430
T Loss: 13.120021
Epoch 349 
Overall Loss: 14.482330
Rec Loss: 13.988289
KL Loss: 0.494041
Y Loss: 0.440212
T Loss: 13.107866
Epoch 399 
Overall Loss: 14.433775
Rec Loss: 13.936393
KL Loss: 0.497383
Y Loss: 0.426226
T Loss: 13.083940
Epoch 449 
Overall Loss: 14.323784
Rec Loss: 13.829838
KL Loss: 0.493947
Y Loss: 0.376328
T Loss: 13.077181
Epoch 499 
Overall Loss: 14.232324
Rec Loss: 13.745954
KL Loss: 0.486370
Y Loss: 0.344862
T Loss: 13.056230
Epoch 549 
Overall Loss: 14.131051
Rec Loss: 13.662174
KL Loss: 0.468877
Y Loss: 0.312714
T Loss: 13.036746
Epoch 599 
Overall Loss: 14.036974
Rec Loss: 13.590316
KL Loss: 0.446659
Y Loss: 0.286067
T Loss: 13.018181
Epoch 649 
Overall Loss: 13.922433
Rec Loss: 13.501752
KL Loss: 0.420681
Y Loss: 0.250687
T Loss: 13.000379
Epoch 699 
Overall Loss: 13.862587
Rec Loss: 13.469562
KL Loss: 0.393026
Y Loss: 0.239766
T Loss: 12.990028
Epoch 749 
Overall Loss: 13.806103
Rec Loss: 13.439586
KL Loss: 0.366517
Y Loss: 0.227295
T Loss: 12.984995
Epoch 799 
Overall Loss: 13.744960
Rec Loss: 13.408510
KL Loss: 0.336450
Y Loss: 0.211075
T Loss: 12.986360
Epoch 849 
Overall Loss: 13.702866
Rec Loss: 13.390246
KL Loss: 0.312621
Y Loss: 0.204564
T Loss: 12.981118
Epoch 899 
Overall Loss: 13.660347
Rec Loss: 13.366321
KL Loss: 0.294025
Y Loss: 0.192081
T Loss: 12.982160
Epoch 949 
Overall Loss: 13.625998
Rec Loss: 13.352418
KL Loss: 0.273580
Y Loss: 0.186125
T Loss: 12.980167
Epoch 999 
Overall Loss: 13.590791
Rec Loss: 13.337457
KL Loss: 0.253335
Y Loss: 0.180314
T Loss: 12.976830
Epoch 1049 
Overall Loss: 13.571951
Rec Loss: 13.335384
KL Loss: 0.236567
Y Loss: 0.175817
T Loss: 12.983751
Epoch 1099 
Overall Loss: 13.542943
Rec Loss: 13.323247
KL Loss: 0.219695
Y Loss: 0.172587
T Loss: 12.978072
Epoch 1149 
Overall Loss: 13.524547
Rec Loss: 13.315374
KL Loss: 0.209173
Y Loss: 0.166885
T Loss: 12.981605
Epoch 1199 
Overall Loss: 13.504606
Rec Loss: 13.309826
KL Loss: 0.194780
Y Loss: 0.166503
T Loss: 12.976820
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.433824
Epoch 99
Rec Loss: 1.428524
Epoch 149
Rec Loss: 1.430780
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.057657
Epoch 99
Rec Loss: 10.061757
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.330623
Insample Error: 0.886155
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 29.352105
Rec Loss: 24.295150
KL Loss: 5.056955
Y Loss: 2.677094
T Loss: 13.213780
Epoch 99 
Overall Loss: 24.526774
Rec Loss: 21.049492
KL Loss: 3.477282
Y Loss: 1.102403
T Loss: 13.246524
Epoch 149 
Overall Loss: 22.940296
Rec Loss: 19.627429
KL Loss: 3.312868
Y Loss: 0.771682
T Loss: 13.231840
Epoch 199 
Overall Loss: 22.205421
Rec Loss: 19.019114
KL Loss: 3.186307
Y Loss: 0.584324
T Loss: 13.214846
Epoch 249 
Overall Loss: 21.696754
Rec Loss: 18.280864
KL Loss: 3.415889
Y Loss: 0.485118
T Loss: 13.186064
Epoch 299 
Overall Loss: 21.413688
Rec Loss: 17.696947
KL Loss: 3.716741
Y Loss: 0.453098
T Loss: 13.178079
Epoch 349 
Overall Loss: 21.279632
Rec Loss: 17.455388
KL Loss: 3.824245
Y Loss: 0.416307
T Loss: 13.163501
Epoch 399 
Overall Loss: 21.190669
Rec Loss: 17.283650
KL Loss: 3.907019
Y Loss: 0.415537
T Loss: 13.149458
Epoch 449 
Overall Loss: 20.938801
Rec Loss: 16.778430
KL Loss: 4.160371
Y Loss: 0.373471
T Loss: 13.128358
Epoch 499 
Overall Loss: 20.665872
Rec Loss: 16.013660
KL Loss: 4.652212
Y Loss: 0.343816
T Loss: 13.110112
Epoch 549 
Overall Loss: 20.521991
Rec Loss: 15.571369
KL Loss: 4.950622
Y Loss: 0.321214
T Loss: 13.099423
Epoch 599 
Overall Loss: 20.487607
Rec Loss: 15.416759
KL Loss: 5.070849
Y Loss: 0.322487
T Loss: 13.086556
Epoch 649 
Overall Loss: 20.349458
Rec Loss: 15.217718
KL Loss: 5.131740
Y Loss: 0.305509
T Loss: 13.072332
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.716828
Epoch 99
Rec Loss: 1.715809
Epoch 149
Rec Loss: 1.711995
Epoch 199
Rec Loss: 1.710377
Epoch 249
Rec Loss: 1.711814
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.100837
Epoch 99
Rec Loss: 6.106263
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.250505
Insample Error 1.946156
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 18.702528
Rec Loss: 17.057606
KL Loss: 1.644923
Y Loss: 1.930586
T Loss: 13.196434
Epoch 99 
Overall Loss: 16.111888
Rec Loss: 15.031492
KL Loss: 1.080396
Y Loss: 0.907929
T Loss: 13.215634
Epoch 149 
Overall Loss: 15.322044
Rec Loss: 14.582059
KL Loss: 0.739985
Y Loss: 0.692671
T Loss: 13.196717
Epoch 199 
Overall Loss: 14.811083
Rec Loss: 14.242487
KL Loss: 0.568596
Y Loss: 0.540578
T Loss: 13.161331
Epoch 249 
Overall Loss: 14.600271
Rec Loss: 14.036007
KL Loss: 0.564264
Y Loss: 0.449986
T Loss: 13.136036
Epoch 299 
Overall Loss: 14.479266
Rec Loss: 13.902938
KL Loss: 0.576328
Y Loss: 0.390229
T Loss: 13.122481
Epoch 349 
Overall Loss: 14.354890
Rec Loss: 13.770178
KL Loss: 0.584713
Y Loss: 0.334502
T Loss: 13.101174
Epoch 399 
Overall Loss: 14.282343
Rec Loss: 13.688312
KL Loss: 0.594031
Y Loss: 0.301174
T Loss: 13.085964
Epoch 449 
Overall Loss: 14.214660
Rec Loss: 13.618335
KL Loss: 0.596325
Y Loss: 0.275517
T Loss: 13.067301
Epoch 499 
Overall Loss: 14.150939
Rec Loss: 13.554584
KL Loss: 0.596355
Y Loss: 0.252106
T Loss: 13.050372
Epoch 549 
Overall Loss: 14.103559
Rec Loss: 13.519998
KL Loss: 0.583561
Y Loss: 0.243119
T Loss: 13.033761
Epoch 599 
Overall Loss: 14.036709
Rec Loss: 13.464027
KL Loss: 0.572682
Y Loss: 0.230120
T Loss: 13.003786
Epoch 649 
Overall Loss: 13.999548
Rec Loss: 13.450058
KL Loss: 0.549490
Y Loss: 0.230811
T Loss: 12.988436
Epoch 699 
Overall Loss: 13.941877
Rec Loss: 13.413424
KL Loss: 0.528453
Y Loss: 0.220500
T Loss: 12.972424
Epoch 749 
Overall Loss: 13.902254
Rec Loss: 13.406528
KL Loss: 0.495726
Y Loss: 0.219480
T Loss: 12.967568
Epoch 799 
Overall Loss: 13.865595
Rec Loss: 13.402817
KL Loss: 0.462778
Y Loss: 0.217888
T Loss: 12.967041
Epoch 849 
Overall Loss: 13.817930
Rec Loss: 13.390355
KL Loss: 0.427575
Y Loss: 0.211399
T Loss: 12.967557
Epoch 899 
Overall Loss: 13.783805
Rec Loss: 13.391053
KL Loss: 0.392753
Y Loss: 0.208249
T Loss: 12.974555
Epoch 949 
Overall Loss: 13.744542
Rec Loss: 13.385556
KL Loss: 0.358987
Y Loss: 0.201950
T Loss: 12.981656
Epoch 999 
Overall Loss: 13.712516
Rec Loss: 13.382380
KL Loss: 0.330136
Y Loss: 0.198552
T Loss: 12.985276
Epoch 1049 
Overall Loss: 13.668554
Rec Loss: 13.370482
KL Loss: 0.298072
Y Loss: 0.190818
T Loss: 12.988845
Epoch 1099 
Overall Loss: 13.635743
Rec Loss: 13.363454
KL Loss: 0.272290
Y Loss: 0.184786
T Loss: 12.993882
Epoch 1149 
Overall Loss: 13.611440
Rec Loss: 13.361093
KL Loss: 0.250347
Y Loss: 0.180582
T Loss: 12.999930
Epoch 1199 
Overall Loss: 13.588237
Rec Loss: 13.357844
KL Loss: 0.230393
Y Loss: 0.177304
T Loss: 13.003235
Epoch 1249 
Overall Loss: 13.562347
Rec Loss: 13.348945
KL Loss: 0.213401
Y Loss: 0.170855
T Loss: 13.007235
Epoch 1299 
Overall Loss: 13.534612
Rec Loss: 13.339792
KL Loss: 0.194821
Y Loss: 0.166092
T Loss: 13.007607
Epoch 1349 
Overall Loss: 13.510969
Rec Loss: 13.329684
KL Loss: 0.181285
Y Loss: 0.161156
T Loss: 13.007371
Epoch 1399 
Overall Loss: 13.503218
Rec Loss: 13.331809
KL Loss: 0.171409
Y Loss: 0.158227
T Loss: 13.015355
Epoch 1449 
Overall Loss: 13.487633
Rec Loss: 13.329105
KL Loss: 0.158528
Y Loss: 0.155588
T Loss: 13.017929
Epoch 1499 
Overall Loss: 13.479078
Rec Loss: 13.326481
KL Loss: 0.152597
Y Loss: 0.157852
T Loss: 13.010778
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.427608
Epoch 99
Rec Loss: 1.417605
Epoch 149
Rec Loss: 1.412772
Epoch 199
Rec Loss: 1.414632
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.065420
Epoch 99
Rec Loss: 10.067320
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.325439
Insample Error: 0.847170
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 31.378541
Rec Loss: 26.386518
KL Loss: 4.992024
Y Loss: 3.714435
T Loss: 13.218536
Epoch 99 
Overall Loss: 24.648011
Rec Loss: 20.971079
KL Loss: 3.676932
Y Loss: 1.236465
T Loss: 13.261890
Epoch 149 
Overall Loss: 23.228053
Rec Loss: 19.650310
KL Loss: 3.577744
Y Loss: 0.861972
T Loss: 13.235476
Epoch 199 
Overall Loss: 22.105224
Rec Loss: 18.148349
KL Loss: 3.956875
Y Loss: 0.621566
T Loss: 13.172701
Epoch 249 
Overall Loss: 21.542614
Rec Loss: 17.515399
KL Loss: 4.027215
Y Loss: 0.509326
T Loss: 13.151312
Epoch 299 
Overall Loss: 21.100179
Rec Loss: 17.114303
KL Loss: 3.985876
Y Loss: 0.382261
T Loss: 13.149021
Epoch 349 
Overall Loss: 20.787242
Rec Loss: 16.752315
KL Loss: 4.034928
Y Loss: 0.327867
T Loss: 13.150016
Epoch 399 
Overall Loss: 20.575732
Rec Loss: 16.450998
KL Loss: 4.124734
Y Loss: 0.296334
T Loss: 13.141172
Epoch 449 
Overall Loss: 20.476214
Rec Loss: 16.228343
KL Loss: 4.247871
Y Loss: 0.276604
T Loss: 13.120026
Epoch 499 
Overall Loss: 20.412943
Rec Loss: 16.048159
KL Loss: 4.364784
Y Loss: 0.276394
T Loss: 13.101725
Epoch 549 
Overall Loss: 20.332045
Rec Loss: 15.837134
KL Loss: 4.494910
Y Loss: 0.262935
T Loss: 13.084078
Epoch 599 
Overall Loss: 20.315763
Rec Loss: 15.698884
KL Loss: 4.616880
Y Loss: 0.263037
T Loss: 13.070309
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.731583
Epoch 99
Rec Loss: 1.725384
Epoch 149
Rec Loss: 1.729636
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.074588
Epoch 99
Rec Loss: 6.091144
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.222444
Insample Error 2.018669
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 19.040763
Rec Loss: 17.608893
KL Loss: 1.431871
Y Loss: 2.201294
T Loss: 13.206304
Epoch 99 
Overall Loss: 16.149888
Rec Loss: 15.163209
KL Loss: 0.986679
Y Loss: 0.969905
T Loss: 13.223399
Epoch 149 
Overall Loss: 15.193209
Rec Loss: 14.562426
KL Loss: 0.630783
Y Loss: 0.687551
T Loss: 13.187324
Epoch 199 
Overall Loss: 14.770603
Rec Loss: 14.219931
KL Loss: 0.550672
Y Loss: 0.533074
T Loss: 13.153784
Epoch 249 
Overall Loss: 14.632825
Rec Loss: 14.087251
KL Loss: 0.545574
Y Loss: 0.479542
T Loss: 13.128167
Epoch 299 
Overall Loss: 14.506029
Rec Loss: 13.959806
KL Loss: 0.546223
Y Loss: 0.428765
T Loss: 13.102277
Epoch 349 
Overall Loss: 14.409462
Rec Loss: 13.851249
KL Loss: 0.558213
Y Loss: 0.383339
T Loss: 13.084571
Epoch 399 
Overall Loss: 14.323246
Rec Loss: 13.758528
KL Loss: 0.564719
Y Loss: 0.347804
T Loss: 13.062920
Epoch 449 
Overall Loss: 14.239020
Rec Loss: 13.658318
KL Loss: 0.580702
Y Loss: 0.310461
T Loss: 13.037396
Epoch 499 
Overall Loss: 14.147612
Rec Loss: 13.561802
KL Loss: 0.585810
Y Loss: 0.275787
T Loss: 13.010228
Epoch 549 
Overall Loss: 14.072422
Rec Loss: 13.476871
KL Loss: 0.595551
Y Loss: 0.252381
T Loss: 12.972109
Epoch 599 
Overall Loss: 14.012849
Rec Loss: 13.438881
KL Loss: 0.573967
Y Loss: 0.241195
T Loss: 12.956492
Epoch 649 
Overall Loss: 13.956111
Rec Loss: 13.405986
KL Loss: 0.550125
Y Loss: 0.231906
T Loss: 12.942173
Epoch 699 
Overall Loss: 13.915252
Rec Loss: 13.396242
KL Loss: 0.519009
Y Loss: 0.225919
T Loss: 12.944405
Epoch 749 
Overall Loss: 13.857018
Rec Loss: 13.376284
KL Loss: 0.480734
Y Loss: 0.215348
T Loss: 12.945588
Epoch 799 
Overall Loss: 13.814759
Rec Loss: 13.362847
KL Loss: 0.451912
Y Loss: 0.208542
T Loss: 12.945764
Epoch 849 
Overall Loss: 13.781068
Rec Loss: 13.367981
KL Loss: 0.413088
Y Loss: 0.206326
T Loss: 12.955329
Epoch 899 
Overall Loss: 13.744355
Rec Loss: 13.365153
KL Loss: 0.379203
Y Loss: 0.201811
T Loss: 12.961530
Epoch 949 
Overall Loss: 13.673900
Rec Loss: 13.338118
KL Loss: 0.335782
Y Loss: 0.192025
T Loss: 12.954069
Epoch 999 
Overall Loss: 13.637488
Rec Loss: 13.335277
KL Loss: 0.302211
Y Loss: 0.185926
T Loss: 12.963425
Epoch 1049 
Overall Loss: 13.603630
Rec Loss: 13.332037
KL Loss: 0.271593
Y Loss: 0.181335
T Loss: 12.969367
Epoch 1099 
Overall Loss: 13.567665
Rec Loss: 13.321115
KL Loss: 0.246550
Y Loss: 0.173054
T Loss: 12.975006
Epoch 1149 
Overall Loss: 13.536667
Rec Loss: 13.314377
KL Loss: 0.222289
Y Loss: 0.166051
T Loss: 12.982276
Epoch 1199 
Overall Loss: 13.514597
Rec Loss: 13.304631
KL Loss: 0.209966
Y Loss: 0.160687
T Loss: 12.983256
Epoch 1249 
Overall Loss: 13.496257
Rec Loss: 13.299957
KL Loss: 0.196300
Y Loss: 0.159024
T Loss: 12.981909
Epoch 1299 
Overall Loss: 13.470637
Rec Loss: 13.284984
KL Loss: 0.185654
Y Loss: 0.153199
T Loss: 12.978587
Epoch 1349 
Overall Loss: 13.464518
Rec Loss: 13.290374
KL Loss: 0.174143
Y Loss: 0.154997
T Loss: 12.980380
Epoch 1399 
Overall Loss: 13.447663
Rec Loss: 13.280689
KL Loss: 0.166974
Y Loss: 0.149765
T Loss: 12.981160
Epoch 1449 
Overall Loss: 13.440636
Rec Loss: 13.279139
KL Loss: 0.161497
Y Loss: 0.149082
T Loss: 12.980975
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.342434
Epoch 99
Rec Loss: 1.353093
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.974078
Epoch 99
Rec Loss: 9.989704
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.328484
Insample Error: 0.756735
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 30.349422
Rec Loss: 25.326775
KL Loss: 5.022647
Y Loss: 3.168114
T Loss: 13.219008
Epoch 99 
Overall Loss: 24.441978
Rec Loss: 20.906040
KL Loss: 3.535938
Y Loss: 1.111635
T Loss: 13.248239
Epoch 149 
Overall Loss: 22.864585
Rec Loss: 19.494448
KL Loss: 3.370138
Y Loss: 0.774607
T Loss: 13.211364
Epoch 199 
Overall Loss: 21.970901
Rec Loss: 18.637971
KL Loss: 3.332931
Y Loss: 0.565498
T Loss: 13.178255
Epoch 249 
Overall Loss: 21.370100
Rec Loss: 17.865672
KL Loss: 3.504427
Y Loss: 0.441790
T Loss: 13.173610
Epoch 299 
Overall Loss: 21.053848
Rec Loss: 17.517014
KL Loss: 3.536835
Y Loss: 0.354533
T Loss: 13.163796
Epoch 349 
Overall Loss: 20.889567
Rec Loss: 17.321885
KL Loss: 3.567682
Y Loss: 0.315806
T Loss: 13.145740
Epoch 399 
Overall Loss: 20.762766
Rec Loss: 17.182650
KL Loss: 3.580117
Y Loss: 0.289084
T Loss: 13.126581
Epoch 449 
Overall Loss: 20.552417
Rec Loss: 16.689480
KL Loss: 3.862937
Y Loss: 0.271098
T Loss: 13.098180
Epoch 499 
Overall Loss: 20.426735
Rec Loss: 16.245979
KL Loss: 4.180756
Y Loss: 0.266696
T Loss: 13.087053
Epoch 549 
Overall Loss: 20.386652
Rec Loss: 16.114787
KL Loss: 4.271864
Y Loss: 0.263101
T Loss: 13.075952
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.732294
Epoch 99
Rec Loss: 1.736775
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.226247
Epoch 99
Rec Loss: 6.222816
Epoch 149
Rec Loss: 6.220143
Epoch 199
Rec Loss: 6.207957
Epoch 249
Rec Loss: 6.208065
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.220173
Insample Error 2.053679
Ours, Train RMSE
0.2456, 
0.3433, 
0.3224, 
0.3241, 
0.3295, 
0.3304, 
0.3156, 
0.3306, 
0.3254, 
0.3285, 
1.9104, 
1.2217, 
0.7303, 
0.9235, 
1.2259, 
0.8419, 
0.9420, 
0.8862, 
0.8472, 
0.7567, 
2.0336, 
1.9924, 
2.0231, 
2.0275, 
2.0665, 
2.0113, 
1.8974, 
1.9462, 
2.0187, 
2.0537, 
Train, RMSE mean 0.3195 std 0.0256
Ours, RMSE mean 1.0286 std 0.3351, reconstruct confounder 1.4463 (0.0709) noise 10.0322 (0.0299)
CEVAE, RMSE mean 2.0070 std 0.0482, reconstruct confounder 1.7278 (0.0195) noise 6.0244 (0.2168)
Experiment Start!
Namespace(decay=0.0, l=5e-05, latdim=4, mask=0, nlayer=50, obsm=4, ycof=1.0, ylayer=50)
Y Mean 1.192369, Std 4.040208 
Observe confounder 4, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.183448
Rec Loss: 16.243095
KL Loss: 0.940352
Y Loss: 3.030919
T Loss: 13.212176
Epoch 99 
Overall Loss: 15.156478
Rec Loss: 14.501149
KL Loss: 0.655329
Y Loss: 1.297346
T Loss: 13.203803
Epoch 149 
Overall Loss: 14.437819
Rec Loss: 14.059647
KL Loss: 0.378172
Y Loss: 0.899806
T Loss: 13.159841
Epoch 199 
Overall Loss: 14.170494
Rec Loss: 13.819169
KL Loss: 0.351325
Y Loss: 0.702785
T Loss: 13.116384
Epoch 249 
Overall Loss: 14.055128
Rec Loss: 13.709736
KL Loss: 0.345392
Y Loss: 0.618118
T Loss: 13.091619
Epoch 299 
Overall Loss: 13.972362
Rec Loss: 13.637679
KL Loss: 0.334683
Y Loss: 0.567812
T Loss: 13.069868
Epoch 349 
Overall Loss: 13.903761
Rec Loss: 13.573644
KL Loss: 0.330118
Y Loss: 0.520602
T Loss: 13.053041
Epoch 399 
Overall Loss: 13.837023
Rec Loss: 13.511309
KL Loss: 0.325715
Y Loss: 0.476376
T Loss: 13.034933
Epoch 449 
Overall Loss: 13.777766
Rec Loss: 13.453497
KL Loss: 0.324270
Y Loss: 0.440531
T Loss: 13.012966
Epoch 499 
Overall Loss: 13.739493
Rec Loss: 13.412694
KL Loss: 0.326799
Y Loss: 0.420036
T Loss: 12.992657
Epoch 549 
Overall Loss: 13.714920
Rec Loss: 13.393533
KL Loss: 0.321386
Y Loss: 0.410275
T Loss: 12.983258
Epoch 599 
Overall Loss: 13.674525
Rec Loss: 13.369052
KL Loss: 0.305473
Y Loss: 0.388355
T Loss: 12.980697
Epoch 649 
Overall Loss: 13.631346
Rec Loss: 13.344241
KL Loss: 0.287105
Y Loss: 0.370572
T Loss: 12.973669
Epoch 699 
Overall Loss: 13.591844
Rec Loss: 13.323690
KL Loss: 0.268154
Y Loss: 0.351989
T Loss: 12.971700
Epoch 749 
Overall Loss: 13.552078
Rec Loss: 13.304881
KL Loss: 0.247197
Y Loss: 0.329618
T Loss: 12.975263
Epoch 799 
Overall Loss: 13.524771
Rec Loss: 13.296721
KL Loss: 0.228050
Y Loss: 0.316140
T Loss: 12.980581
Epoch 849 
Overall Loss: 13.496743
Rec Loss: 13.288649
KL Loss: 0.208094
Y Loss: 0.299856
T Loss: 12.988793
Epoch 899 
Overall Loss: 13.461265
Rec Loss: 13.270564
KL Loss: 0.190701
Y Loss: 0.281634
T Loss: 12.988930
Epoch 949 
Overall Loss: 13.434488
Rec Loss: 13.256902
KL Loss: 0.177586
Y Loss: 0.263122
T Loss: 12.993780
Epoch 999 
Overall Loss: 13.420289
Rec Loss: 13.259324
KL Loss: 0.160965
Y Loss: 0.257909
T Loss: 13.001415
Epoch 1049 
Overall Loss: 13.390100
Rec Loss: 13.243183
KL Loss: 0.146917
Y Loss: 0.243666
T Loss: 12.999517
Epoch 1099 
Overall Loss: 13.375325
Rec Loss: 13.240828
KL Loss: 0.134497
Y Loss: 0.236700
T Loss: 13.004127
Epoch 1149 
Overall Loss: 13.358182
Rec Loss: 13.232117
KL Loss: 0.126064
Y Loss: 0.227633
T Loss: 13.004484
Epoch 1199 
Overall Loss: 13.339983
Rec Loss: 13.222730
KL Loss: 0.117253
Y Loss: 0.217378
T Loss: 13.005352
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.421740
Epoch 99
Rec Loss: 1.417151
Epoch 149
Rec Loss: 1.426422
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.068832
Epoch 99
Rec Loss: 10.075701
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.386762
Insample Error: 0.989735
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 26.314775
Rec Loss: 23.181011
KL Loss: 3.133765
Y Loss: 4.057160
T Loss: 13.258643
Epoch 99 
Overall Loss: 23.011461
Rec Loss: 20.552484
KL Loss: 2.458977
Y Loss: 1.594923
T Loss: 13.262893
Epoch 149 
Overall Loss: 21.912353
Rec Loss: 19.262477
KL Loss: 2.649876
Y Loss: 1.177004
T Loss: 13.216753
Epoch 199 
Overall Loss: 21.205535
Rec Loss: 18.392752
KL Loss: 2.812783
Y Loss: 0.898410
T Loss: 13.178913
Epoch 249 
Overall Loss: 20.786163
Rec Loss: 17.631763
KL Loss: 3.154401
Y Loss: 0.749918
T Loss: 13.152639
Epoch 299 
Overall Loss: 20.593653
Rec Loss: 17.193488
KL Loss: 3.400165
Y Loss: 0.687826
T Loss: 13.143197
Epoch 349 
Overall Loss: 20.466403
Rec Loss: 16.885612
KL Loss: 3.580790
Y Loss: 0.633795
T Loss: 13.115677
Epoch 399 
Overall Loss: 20.388929
Rec Loss: 16.680162
KL Loss: 3.708766
Y Loss: 0.603907
T Loss: 13.099113
Epoch 449 
Overall Loss: 20.343493
Rec Loss: 16.547844
KL Loss: 3.795649
Y Loss: 0.604527
T Loss: 13.079179
Epoch 499 
Overall Loss: 20.259077
Rec Loss: 16.390823
KL Loss: 3.868254
Y Loss: 0.571675
T Loss: 13.071941
Epoch 549 
Overall Loss: 20.234175
Rec Loss: 16.262706
KL Loss: 3.971470
Y Loss: 0.575396
T Loss: 13.058075
Epoch 599 
Overall Loss: 20.034885
Rec Loss: 15.778745
KL Loss: 4.256139
Y Loss: 0.548212
T Loss: 13.046685
Epoch 649 
Overall Loss: 19.953239
Rec Loss: 15.423389
KL Loss: 4.529850
Y Loss: 0.562600
T Loss: 13.032027
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.692257
Epoch 99
Rec Loss: 1.691033
Epoch 149
Rec Loss: 1.687438
Epoch 199
Rec Loss: 1.689386
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.151053
Epoch 99
Rec Loss: 6.160555
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.401758
Insample Error 1.929379
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.077043
Rec Loss: 16.049163
KL Loss: 1.027881
Y Loss: 2.835352
T Loss: 13.213811
Epoch 99 
Overall Loss: 14.971995
Rec Loss: 14.433477
KL Loss: 0.538518
Y Loss: 1.238862
T Loss: 13.194615
Epoch 149 
Overall Loss: 14.429536
Rec Loss: 14.093251
KL Loss: 0.336286
Y Loss: 0.935019
T Loss: 13.158231
Epoch 199 
Overall Loss: 14.203186
Rec Loss: 13.911190
KL Loss: 0.291996
Y Loss: 0.788796
T Loss: 13.122394
Epoch 249 
Overall Loss: 14.097419
Rec Loss: 13.820892
KL Loss: 0.276526
Y Loss: 0.726143
T Loss: 13.094749
Epoch 299 
Overall Loss: 13.999047
Rec Loss: 13.734585
KL Loss: 0.264462
Y Loss: 0.662086
T Loss: 13.072500
Epoch 349 
Overall Loss: 13.942968
Rec Loss: 13.689049
KL Loss: 0.253919
Y Loss: 0.625577
T Loss: 13.063472
Epoch 399 
Overall Loss: 13.884988
Rec Loss: 13.637973
KL Loss: 0.247015
Y Loss: 0.584717
T Loss: 13.053255
Epoch 449 
Overall Loss: 13.812594
Rec Loss: 13.579257
KL Loss: 0.233337
Y Loss: 0.533616
T Loss: 13.045641
Epoch 499 
Overall Loss: 13.753955
Rec Loss: 13.527303
KL Loss: 0.226651
Y Loss: 0.492896
T Loss: 13.034407
Epoch 549 
Overall Loss: 13.673403
Rec Loss: 13.455762
KL Loss: 0.217642
Y Loss: 0.437145
T Loss: 13.018617
Epoch 599 
Overall Loss: 13.626674
Rec Loss: 13.412098
KL Loss: 0.214575
Y Loss: 0.403353
T Loss: 13.008746
Epoch 649 
Overall Loss: 13.570449
Rec Loss: 13.370088
KL Loss: 0.200361
Y Loss: 0.370598
T Loss: 12.999491
Epoch 699 
Overall Loss: 13.524610
Rec Loss: 13.336234
KL Loss: 0.188376
Y Loss: 0.340170
T Loss: 12.996064
Epoch 749 
Overall Loss: 13.491632
Rec Loss: 13.316112
KL Loss: 0.175520
Y Loss: 0.318000
T Loss: 12.998112
Epoch 799 
Overall Loss: 13.456522
Rec Loss: 13.291344
KL Loss: 0.165178
Y Loss: 0.291600
T Loss: 12.999744
Epoch 849 
Overall Loss: 13.416084
Rec Loss: 13.266808
KL Loss: 0.149276
Y Loss: 0.273891
T Loss: 12.992917
Epoch 899 
Overall Loss: 13.400360
Rec Loss: 13.259016
KL Loss: 0.141344
Y Loss: 0.257960
T Loss: 13.001056
Epoch 949 
Overall Loss: 13.368929
Rec Loss: 13.241073
KL Loss: 0.127856
Y Loss: 0.239875
T Loss: 13.001198
Epoch 999 
Overall Loss: 13.347454
Rec Loss: 13.226486
KL Loss: 0.120968
Y Loss: 0.226243
T Loss: 13.000242
Epoch 1049 
Overall Loss: 13.333182
Rec Loss: 13.220348
KL Loss: 0.112835
Y Loss: 0.216852
T Loss: 13.003495
Epoch 1099 
Overall Loss: 13.318012
Rec Loss: 13.213408
KL Loss: 0.104604
Y Loss: 0.207743
T Loss: 13.005665
Epoch 1149 
Overall Loss: 13.302596
Rec Loss: 13.202649
KL Loss: 0.099947
Y Loss: 0.203028
T Loss: 12.999621
Epoch 1199 
Overall Loss: 13.290890
Rec Loss: 13.195770
KL Loss: 0.095119
Y Loss: 0.194774
T Loss: 13.000996
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.397092
Epoch 99
Rec Loss: 1.386835
Epoch 149
Rec Loss: 1.385473
Epoch 199
Rec Loss: 1.393675
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.953556
Epoch 99
Rec Loss: 9.940866
Epoch 149
Rec Loss: 9.954220
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.385254
Insample Error: 0.820138
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 28.209864
Rec Loss: 25.318531
KL Loss: 2.891333
Y Loss: 6.253133
T Loss: 13.276369
Epoch 99 
Overall Loss: 22.727058
Rec Loss: 19.791488
KL Loss: 2.935570
Y Loss: 1.649988
T Loss: 13.239323
Epoch 149 
Overall Loss: 21.480802
Rec Loss: 18.218958
KL Loss: 3.261844
Y Loss: 1.105699
T Loss: 13.213600
Epoch 199 
Overall Loss: 21.107451
Rec Loss: 17.713932
KL Loss: 3.393518
Y Loss: 0.953625
T Loss: 13.188835
Epoch 249 
Overall Loss: 20.814119
Rec Loss: 17.306958
KL Loss: 3.507161
Y Loss: 0.831700
T Loss: 13.167862
Epoch 299 
Overall Loss: 20.570532
Rec Loss: 16.694795
KL Loss: 3.875737
Y Loss: 0.779147
T Loss: 13.140668
Epoch 349 
Overall Loss: 20.348222
Rec Loss: 16.050652
KL Loss: 4.297570
Y Loss: 0.706045
T Loss: 13.128968
Epoch 399 
Overall Loss: 20.196803
Rec Loss: 15.661156
KL Loss: 4.535647
Y Loss: 0.635884
T Loss: 13.114966
Epoch 449 
Overall Loss: 20.118823
Rec Loss: 15.371804
KL Loss: 4.747020
Y Loss: 0.621899
T Loss: 13.098500
Epoch 499 
Overall Loss: 20.006995
Rec Loss: 15.055963
KL Loss: 4.951032
Y Loss: 0.580287
T Loss: 13.089169
Epoch 549 
Overall Loss: 19.931915
Rec Loss: 14.811679
KL Loss: 5.120236
Y Loss: 0.573741
T Loss: 13.068962
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.701372
Epoch 99
Rec Loss: 1.705615
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.897034
Epoch 99
Rec Loss: 5.870704
Epoch 149
Rec Loss: 5.885801
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.399842
Insample Error 1.922190
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.411296
Rec Loss: 16.646509
KL Loss: 0.764788
Y Loss: 3.449004
T Loss: 13.197505
Epoch 99 
Overall Loss: 15.026194
Rec Loss: 14.467166
KL Loss: 0.559028
Y Loss: 1.270440
T Loss: 13.196726
Epoch 149 
Overall Loss: 14.408250
Rec Loss: 14.035659
KL Loss: 0.372591
Y Loss: 0.866640
T Loss: 13.169018
Epoch 199 
Overall Loss: 14.163886
Rec Loss: 13.823984
KL Loss: 0.339902
Y Loss: 0.701985
T Loss: 13.121999
Epoch 249 
Overall Loss: 14.052462
Rec Loss: 13.731474
KL Loss: 0.320988
Y Loss: 0.637255
T Loss: 13.094220
Epoch 299 
Overall Loss: 13.971299
Rec Loss: 13.668332
KL Loss: 0.302968
Y Loss: 0.593582
T Loss: 13.074749
Epoch 349 
Overall Loss: 13.900770
Rec Loss: 13.609957
KL Loss: 0.290812
Y Loss: 0.545733
T Loss: 13.064224
Epoch 399 
Overall Loss: 13.830418
Rec Loss: 13.555983
KL Loss: 0.274435
Y Loss: 0.499129
T Loss: 13.056854
Epoch 449 
Overall Loss: 13.774832
Rec Loss: 13.506477
KL Loss: 0.268355
Y Loss: 0.462016
T Loss: 13.044461
Epoch 499 
Overall Loss: 13.731069
Rec Loss: 13.469584
KL Loss: 0.261485
Y Loss: 0.439471
T Loss: 13.030112
Epoch 549 
Overall Loss: 13.678324
Rec Loss: 13.420247
KL Loss: 0.258077
Y Loss: 0.405018
T Loss: 13.015228
Epoch 599 
Overall Loss: 13.631656
Rec Loss: 13.387807
KL Loss: 0.243850
Y Loss: 0.380250
T Loss: 13.007556
Epoch 649 
Overall Loss: 13.590840
Rec Loss: 13.354567
KL Loss: 0.236274
Y Loss: 0.356189
T Loss: 12.998378
Epoch 699 
Overall Loss: 13.556738
Rec Loss: 13.334586
KL Loss: 0.222153
Y Loss: 0.339276
T Loss: 12.995309
Epoch 749 
Overall Loss: 13.517218
Rec Loss: 13.310461
KL Loss: 0.206757
Y Loss: 0.310278
T Loss: 13.000183
Epoch 799 
Overall Loss: 13.477230
Rec Loss: 13.289341
KL Loss: 0.187889
Y Loss: 0.292495
T Loss: 12.996847
Epoch 849 
Overall Loss: 13.449102
Rec Loss: 13.276166
KL Loss: 0.172936
Y Loss: 0.275075
T Loss: 13.001091
Epoch 899 
Overall Loss: 13.424210
Rec Loss: 13.267209
KL Loss: 0.157001
Y Loss: 0.261740
T Loss: 13.005469
Epoch 949 
Overall Loss: 13.397047
Rec Loss: 13.252347
KL Loss: 0.144700
Y Loss: 0.247253
T Loss: 13.005094
Epoch 999 
Overall Loss: 13.364957
Rec Loss: 13.232849
KL Loss: 0.132108
Y Loss: 0.227774
T Loss: 13.005075
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.465549
Epoch 99
Rec Loss: 1.462156
Epoch 149
Rec Loss: 1.456005
Epoch 199
Rec Loss: 1.460697
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.030456
Epoch 99
Rec Loss: 10.028367
Epoch 149
Rec Loss: 10.031089
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.393952
Insample Error: 1.024226
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 26.650646
Rec Loss: 23.647780
KL Loss: 3.002866
Y Loss: 4.525793
T Loss: 13.271081
Epoch 99 
Overall Loss: 22.995163
Rec Loss: 20.280939
KL Loss: 2.714224
Y Loss: 1.757955
T Loss: 13.260079
Epoch 149 
Overall Loss: 21.724649
Rec Loss: 18.381838
KL Loss: 3.342810
Y Loss: 1.248439
T Loss: 13.195780
Epoch 199 
Overall Loss: 21.186594
Rec Loss: 17.664261
KL Loss: 3.522334
Y Loss: 1.028106
T Loss: 13.115173
Epoch 249 
Overall Loss: 20.859845
Rec Loss: 17.127616
KL Loss: 3.732229
Y Loss: 0.868521
T Loss: 13.099640
Epoch 299 
Overall Loss: 20.650138
Rec Loss: 16.682342
KL Loss: 3.967796
Y Loss: 0.812671
T Loss: 13.124807
Epoch 349 
Overall Loss: 20.403423
Rec Loss: 16.102397
KL Loss: 4.301026
Y Loss: 0.750799
T Loss: 13.139818
Epoch 399 
Overall Loss: 20.247913
Rec Loss: 15.729245
KL Loss: 4.518668
Y Loss: 0.707730
T Loss: 13.124522
Epoch 449 
Overall Loss: 20.146568
Rec Loss: 15.435398
KL Loss: 4.711170
Y Loss: 0.647110
T Loss: 13.104235
Epoch 499 
Overall Loss: 20.034203
Rec Loss: 15.209989
KL Loss: 4.824214
Y Loss: 0.619850
T Loss: 13.081592
Epoch 549 
Overall Loss: 19.952230
Rec Loss: 15.019327
KL Loss: 4.932903
Y Loss: 0.585082
T Loss: 13.066189
Epoch 599 
Overall Loss: 19.905084
Rec Loss: 14.881588
KL Loss: 5.023497
Y Loss: 0.554248
T Loss: 13.050243
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.686426
Epoch 99
Rec Loss: 1.680822
Epoch 149
Rec Loss: 1.686981
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.925362
Epoch 99
Rec Loss: 5.922548
Epoch 149
Rec Loss: 5.917750
Epoch 199
Rec Loss: 5.922097
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.395326
Insample Error 1.785180
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 18.275449
Rec Loss: 17.331629
KL Loss: 0.943820
Y Loss: 4.131450
T Loss: 13.200179
Epoch 99 
Overall Loss: 15.003713
Rec Loss: 14.367865
KL Loss: 0.635848
Y Loss: 1.154886
T Loss: 13.212979
Epoch 149 
Overall Loss: 14.413165
Rec Loss: 14.005877
KL Loss: 0.407288
Y Loss: 0.838954
T Loss: 13.166923
Epoch 199 
Overall Loss: 14.140973
Rec Loss: 13.793086
KL Loss: 0.347886
Y Loss: 0.666889
T Loss: 13.126197
Epoch 249 
Overall Loss: 14.016687
Rec Loss: 13.685751
KL Loss: 0.330937
Y Loss: 0.588012
T Loss: 13.097739
Epoch 299 
Overall Loss: 13.934987
Rec Loss: 13.617974
KL Loss: 0.317013
Y Loss: 0.538470
T Loss: 13.079503
Epoch 349 
Overall Loss: 13.873600
Rec Loss: 13.573846
KL Loss: 0.299753
Y Loss: 0.510539
T Loss: 13.063307
Epoch 399 
Overall Loss: 13.807571
Rec Loss: 13.513885
KL Loss: 0.293685
Y Loss: 0.465592
T Loss: 13.048293
Epoch 449 
Overall Loss: 13.753661
Rec Loss: 13.470309
KL Loss: 0.283352
Y Loss: 0.436543
T Loss: 13.033766
Epoch 499 
Overall Loss: 13.704996
Rec Loss: 13.432271
KL Loss: 0.272725
Y Loss: 0.412057
T Loss: 13.020214
Epoch 549 
Overall Loss: 13.656955
Rec Loss: 13.397544
KL Loss: 0.259411
Y Loss: 0.385774
T Loss: 13.011769
Epoch 599 
Overall Loss: 13.585906
Rec Loss: 13.343642
KL Loss: 0.242264
Y Loss: 0.342036
T Loss: 13.001606
Epoch 649 
Overall Loss: 13.550307
Rec Loss: 13.330588
KL Loss: 0.219718
Y Loss: 0.328947
T Loss: 13.001641
Epoch 699 
Overall Loss: 13.506495
Rec Loss: 13.305782
KL Loss: 0.200713
Y Loss: 0.300043
T Loss: 13.005738
Epoch 749 
Overall Loss: 13.467160
Rec Loss: 13.284245
KL Loss: 0.182915
Y Loss: 0.284734
T Loss: 12.999511
Epoch 799 
Overall Loss: 13.444935
Rec Loss: 13.278456
KL Loss: 0.166479
Y Loss: 0.270879
T Loss: 13.007576
Epoch 849 
Overall Loss: 13.413433
Rec Loss: 13.257870
KL Loss: 0.155563
Y Loss: 0.254946
T Loss: 13.002924
Epoch 899 
Overall Loss: 13.386233
Rec Loss: 13.243438
KL Loss: 0.142794
Y Loss: 0.239406
T Loss: 13.004032
Epoch 949 
Overall Loss: 13.356723
Rec Loss: 13.223664
KL Loss: 0.133059
Y Loss: 0.220875
T Loss: 13.002788
Epoch 999 
Overall Loss: 13.352066
Rec Loss: 13.227584
KL Loss: 0.124482
Y Loss: 0.219907
T Loss: 13.007677
Epoch 1049 
Overall Loss: 13.333911
Rec Loss: 13.216998
KL Loss: 0.116913
Y Loss: 0.208504
T Loss: 13.008493
Epoch 1099 
Overall Loss: 13.319359
Rec Loss: 13.207976
KL Loss: 0.111382
Y Loss: 0.201093
T Loss: 13.006884
Epoch 1149 
Overall Loss: 13.308113
Rec Loss: 13.204422
KL Loss: 0.103692
Y Loss: 0.194390
T Loss: 13.010032
Epoch 1199 
Overall Loss: 13.292874
Rec Loss: 13.192132
KL Loss: 0.100742
Y Loss: 0.185018
T Loss: 13.007114
Epoch 1249 
Overall Loss: 13.289849
Rec Loss: 13.192704
KL Loss: 0.097146
Y Loss: 0.183074
T Loss: 13.009630
Epoch 1299 
Overall Loss: 13.281015
Rec Loss: 13.188061
KL Loss: 0.092954
Y Loss: 0.176967
T Loss: 13.011093
Epoch 1349 
Overall Loss: 13.270991
Rec Loss: 13.181573
KL Loss: 0.089419
Y Loss: 0.175983
T Loss: 13.005590
Epoch 1399 
Overall Loss: 13.268050
Rec Loss: 13.181451
KL Loss: 0.086599
Y Loss: 0.171874
T Loss: 13.009577
Epoch 1449 
Overall Loss: 13.257140
Rec Loss: 13.173057
KL Loss: 0.084083
Y Loss: 0.170684
T Loss: 13.002373
Epoch 1499 
Overall Loss: 13.257140
Rec Loss: 13.175300
KL Loss: 0.081841
Y Loss: 0.164092
T Loss: 13.011208
Epoch 1549 
Overall Loss: 13.251082
Rec Loss: 13.170923
KL Loss: 0.080159
Y Loss: 0.161903
T Loss: 13.009020
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.321334
Epoch 99
Rec Loss: 1.321557
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.046187
Epoch 99
Rec Loss: 10.040489
Epoch 149
Rec Loss: 10.037490
Epoch 199
Rec Loss: 10.035219
Epoch 249
Rec Loss: 10.035341
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.353558
Insample Error: 0.661427
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 26.180255
Rec Loss: 23.091231
KL Loss: 3.089024
Y Loss: 4.019941
T Loss: 13.261379
Epoch 99 
Overall Loss: 22.901891
Rec Loss: 20.243223
KL Loss: 2.658669
Y Loss: 1.646641
T Loss: 13.268764
Epoch 149 
Overall Loss: 21.574707
Rec Loss: 18.122143
KL Loss: 3.452564
Y Loss: 1.185808
T Loss: 13.182655
Epoch 199 
Overall Loss: 20.980416
Rec Loss: 17.064409
KL Loss: 3.916007
Y Loss: 0.998108
T Loss: 13.181431
Epoch 249 
Overall Loss: 20.687809
Rec Loss: 16.664928
KL Loss: 4.022880
Y Loss: 0.903078
T Loss: 13.167239
Epoch 299 
Overall Loss: 20.542184
Rec Loss: 16.450637
KL Loss: 4.091547
Y Loss: 0.851226
T Loss: 13.155649
Epoch 349 
Overall Loss: 20.384910
Rec Loss: 16.179487
KL Loss: 4.205424
Y Loss: 0.774108
T Loss: 13.133800
Epoch 399 
Overall Loss: 20.226619
Rec Loss: 15.920735
KL Loss: 4.305884
Y Loss: 0.678049
T Loss: 13.121100
Epoch 449 
Overall Loss: 20.104848
Rec Loss: 15.691227
KL Loss: 4.413621
Y Loss: 0.621585
T Loss: 13.104366
Epoch 499 
Overall Loss: 19.970010
Rec Loss: 15.500804
KL Loss: 4.469206
Y Loss: 0.558075
T Loss: 13.083167
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.711737
Epoch 99
Rec Loss: 1.707382
Epoch 149
Rec Loss: 1.702882
Epoch 199
Rec Loss: 1.707276
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.019231
Epoch 99
Rec Loss: 5.997700
Epoch 149
Rec Loss: 6.008000
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.400495
Insample Error 1.861386
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.475429
Rec Loss: 16.591841
KL Loss: 0.883588
Y Loss: 3.390897
T Loss: 13.200945
Epoch 99 
Overall Loss: 14.870718
Rec Loss: 14.299261
KL Loss: 0.571458
Y Loss: 1.114498
T Loss: 13.184763
Epoch 149 
Overall Loss: 14.356378
Rec Loss: 14.011101
KL Loss: 0.345277
Y Loss: 0.862400
T Loss: 13.148701
Epoch 199 
Overall Loss: 14.134607
Rec Loss: 13.824496
KL Loss: 0.310111
Y Loss: 0.714435
T Loss: 13.110062
Epoch 249 
Overall Loss: 14.023754
Rec Loss: 13.719241
KL Loss: 0.304512
Y Loss: 0.634985
T Loss: 13.084257
Epoch 299 
Overall Loss: 13.947002
Rec Loss: 13.654644
KL Loss: 0.292357
Y Loss: 0.588308
T Loss: 13.066336
Epoch 349 
Overall Loss: 13.880687
Rec Loss: 13.598582
KL Loss: 0.282105
Y Loss: 0.543326
T Loss: 13.055256
Epoch 399 
Overall Loss: 13.824693
Rec Loss: 13.556390
KL Loss: 0.268303
Y Loss: 0.502748
T Loss: 13.053642
Epoch 449 
Overall Loss: 13.762803
Rec Loss: 13.501972
KL Loss: 0.260831
Y Loss: 0.461776
T Loss: 13.040196
Epoch 499 
Overall Loss: 13.721326
Rec Loss: 13.476450
KL Loss: 0.244875
Y Loss: 0.432087
T Loss: 13.044363
Epoch 549 
Overall Loss: 13.664294
Rec Loss: 13.434774
KL Loss: 0.229521
Y Loss: 0.395982
T Loss: 13.038792
Epoch 599 
Overall Loss: 13.613895
Rec Loss: 13.400311
KL Loss: 0.213585
Y Loss: 0.365115
T Loss: 13.035195
Epoch 649 
Overall Loss: 13.577972
Rec Loss: 13.380913
KL Loss: 0.197059
Y Loss: 0.344037
T Loss: 13.036876
Epoch 699 
Overall Loss: 13.541387
Rec Loss: 13.361679
KL Loss: 0.179708
Y Loss: 0.323889
T Loss: 13.037790
Epoch 749 
Overall Loss: 13.491306
Rec Loss: 13.330433
KL Loss: 0.160873
Y Loss: 0.295297
T Loss: 13.035136
Epoch 799 
Overall Loss: 13.466444
Rec Loss: 13.317788
KL Loss: 0.148656
Y Loss: 0.281165
T Loss: 13.036623
Epoch 849 
Overall Loss: 13.441268
Rec Loss: 13.305575
KL Loss: 0.135693
Y Loss: 0.267392
T Loss: 13.038183
Epoch 899 
Overall Loss: 13.411166
Rec Loss: 13.287054
KL Loss: 0.124112
Y Loss: 0.250220
T Loss: 13.036834
Epoch 949 
Overall Loss: 13.391743
Rec Loss: 13.277643
KL Loss: 0.114101
Y Loss: 0.240708
T Loss: 13.036935
Epoch 999 
Overall Loss: 13.369303
Rec Loss: 13.265650
KL Loss: 0.103652
Y Loss: 0.231501
T Loss: 13.034149
Epoch 1049 
Overall Loss: 13.358010
Rec Loss: 13.257736
KL Loss: 0.100274
Y Loss: 0.225236
T Loss: 13.032500
Epoch 1099 
Overall Loss: 13.338128
Rec Loss: 13.243453
KL Loss: 0.094675
Y Loss: 0.209094
T Loss: 13.034360
Epoch 1149 
Overall Loss: 13.333186
Rec Loss: 13.244177
KL Loss: 0.089008
Y Loss: 0.208515
T Loss: 13.035663
Epoch 1199 
Overall Loss: 13.310712
Rec Loss: 13.222683
KL Loss: 0.088029
Y Loss: 0.195394
T Loss: 13.027290
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.494398
Epoch 99
Rec Loss: 1.488161
Epoch 149
Rec Loss: 1.489963
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.058236
Epoch 99
Rec Loss: 10.046834
Epoch 149
Rec Loss: 10.053286
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.380264
Insample Error: 0.853518
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 26.432746
Rec Loss: 23.375563
KL Loss: 3.057183
Y Loss: 4.224560
T Loss: 13.269961
Epoch 99 
Overall Loss: 22.876553
Rec Loss: 20.161204
KL Loss: 2.715349
Y Loss: 1.661664
T Loss: 13.276878
Epoch 149 
Overall Loss: 21.716376
Rec Loss: 18.318201
KL Loss: 3.398176
Y Loss: 1.257561
T Loss: 13.243967
Epoch 199 
Overall Loss: 20.837900
Rec Loss: 16.571347
KL Loss: 4.266553
Y Loss: 1.006887
T Loss: 13.208711
Epoch 249 
Overall Loss: 20.503820
Rec Loss: 15.832279
KL Loss: 4.671541
Y Loss: 0.855620
T Loss: 13.185394
Epoch 299 
Overall Loss: 20.320382
Rec Loss: 15.297290
KL Loss: 5.023092
Y Loss: 0.776763
T Loss: 13.164027
Epoch 349 
Overall Loss: 20.195199
Rec Loss: 14.871109
KL Loss: 5.324090
Y Loss: 0.715374
T Loss: 13.147238
Epoch 399 
Overall Loss: 20.084245
Rec Loss: 14.551494
KL Loss: 5.532752
Y Loss: 0.680665
T Loss: 13.123279
Epoch 449 
Overall Loss: 20.070846
Rec Loss: 14.328609
KL Loss: 5.742237
Y Loss: 0.670976
T Loss: 13.106612
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.758646
Epoch 99
Rec Loss: 1.761463
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.747807
Epoch 99
Rec Loss: 5.742612
Epoch 149
Rec Loss: 5.741998
Epoch 199
Rec Loss: 5.734299
Epoch 249
Rec Loss: 5.738456
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.451187
Insample Error 1.913786
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.129421
Rec Loss: 16.119079
KL Loss: 1.010342
Y Loss: 2.918489
T Loss: 13.200590
Epoch 99 
Overall Loss: 14.922092
Rec Loss: 14.383326
KL Loss: 0.538766
Y Loss: 1.199730
T Loss: 13.183596
Epoch 149 
Overall Loss: 14.393467
Rec Loss: 14.058402
KL Loss: 0.335065
Y Loss: 0.918880
T Loss: 13.139522
Epoch 199 
Overall Loss: 14.187814
Rec Loss: 13.878305
KL Loss: 0.309509
Y Loss: 0.778930
T Loss: 13.099375
Epoch 249 
Overall Loss: 14.087045
Rec Loss: 13.790461
KL Loss: 0.296584
Y Loss: 0.713860
T Loss: 13.076601
Epoch 299 
Overall Loss: 14.011922
Rec Loss: 13.731472
KL Loss: 0.280450
Y Loss: 0.667900
T Loss: 13.063572
Epoch 349 
Overall Loss: 13.935234
Rec Loss: 13.670943
KL Loss: 0.264291
Y Loss: 0.617451
T Loss: 13.053492
Epoch 399 
Overall Loss: 13.856425
Rec Loss: 13.605300
KL Loss: 0.251124
Y Loss: 0.560088
T Loss: 13.045213
Epoch 449 
Overall Loss: 13.785898
Rec Loss: 13.548957
KL Loss: 0.236940
Y Loss: 0.509799
T Loss: 13.039158
Epoch 499 
Overall Loss: 13.718849
Rec Loss: 13.492903
KL Loss: 0.225945
Y Loss: 0.463783
T Loss: 13.029120
Epoch 549 
Overall Loss: 13.654124
Rec Loss: 13.441896
KL Loss: 0.212228
Y Loss: 0.417067
T Loss: 13.024828
Epoch 599 
Overall Loss: 13.591414
Rec Loss: 13.395408
KL Loss: 0.196006
Y Loss: 0.377277
T Loss: 13.018132
Epoch 649 
Overall Loss: 13.547162
Rec Loss: 13.363874
KL Loss: 0.183288
Y Loss: 0.342690
T Loss: 13.021184
Epoch 699 
Overall Loss: 13.496092
Rec Loss: 13.330763
KL Loss: 0.165329
Y Loss: 0.315358
T Loss: 13.015406
Epoch 749 
Overall Loss: 13.458406
Rec Loss: 13.305320
KL Loss: 0.153086
Y Loss: 0.287126
T Loss: 13.018194
Epoch 799 
Overall Loss: 13.436363
Rec Loss: 13.295862
KL Loss: 0.140501
Y Loss: 0.270326
T Loss: 13.025535
Epoch 849 
Overall Loss: 13.408413
Rec Loss: 13.279678
KL Loss: 0.128735
Y Loss: 0.255212
T Loss: 13.024466
Epoch 899 
Overall Loss: 13.379039
Rec Loss: 13.261372
KL Loss: 0.117667
Y Loss: 0.237993
T Loss: 13.023380
Epoch 949 
Overall Loss: 13.359875
Rec Loss: 13.252341
KL Loss: 0.107534
Y Loss: 0.228205
T Loss: 13.024136
Epoch 999 
Overall Loss: 13.344419
Rec Loss: 13.245510
KL Loss: 0.098909
Y Loss: 0.222088
T Loss: 13.023422
Epoch 1049 
Overall Loss: 13.326876
Rec Loss: 13.233987
KL Loss: 0.092890
Y Loss: 0.207735
T Loss: 13.026252
Epoch 1099 
Overall Loss: 13.320342
Rec Loss: 13.234128
KL Loss: 0.086214
Y Loss: 0.204148
T Loss: 13.029980
Epoch 1149 
Overall Loss: 13.306963
Rec Loss: 13.224841
KL Loss: 0.082121
Y Loss: 0.202142
T Loss: 13.022699
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.423884
Epoch 99
Rec Loss: 1.409500
Epoch 149
Rec Loss: 1.422247
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.033136
Epoch 99
Rec Loss: 10.033463
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.383211
Insample Error: 0.810983
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 26.114650
Rec Loss: 23.092425
KL Loss: 3.022224
Y Loss: 4.103472
T Loss: 13.232817
Epoch 99 
Overall Loss: 22.635477
Rec Loss: 20.106410
KL Loss: 2.529067
Y Loss: 1.519449
T Loss: 13.232566
Epoch 149 
Overall Loss: 21.329264
Rec Loss: 18.262444
KL Loss: 3.066820
Y Loss: 1.007774
T Loss: 13.153977
Epoch 199 
Overall Loss: 20.769345
Rec Loss: 17.204599
KL Loss: 3.564745
Y Loss: 0.844482
T Loss: 13.159669
Epoch 249 
Overall Loss: 20.461542
Rec Loss: 16.681290
KL Loss: 3.780252
Y Loss: 0.732656
T Loss: 13.154746
Epoch 299 
Overall Loss: 20.315575
Rec Loss: 16.377238
KL Loss: 3.938337
Y Loss: 0.675827
T Loss: 13.133280
Epoch 349 
Overall Loss: 20.221954
Rec Loss: 16.128129
KL Loss: 4.093824
Y Loss: 0.629378
T Loss: 13.111499
Epoch 399 
Overall Loss: 20.115964
Rec Loss: 15.920141
KL Loss: 4.195823
Y Loss: 0.583693
T Loss: 13.098310
Epoch 449 
Overall Loss: 20.033238
Rec Loss: 15.736240
KL Loss: 4.296998
Y Loss: 0.557351
T Loss: 13.080772
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.724933
Epoch 99
Rec Loss: 1.729219
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.072123
Epoch 99
Rec Loss: 6.061244
Epoch 149
Rec Loss: 6.055440
Epoch 199
Rec Loss: 6.054784
Epoch 249
Rec Loss: 6.079911
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.396218
Insample Error 1.955349
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.641928
Rec Loss: 15.657657
KL Loss: 0.984271
Y Loss: 2.462887
T Loss: 13.194770
Epoch 99 
Overall Loss: 14.871936
Rec Loss: 14.347519
KL Loss: 0.524418
Y Loss: 1.174251
T Loss: 13.173268
Epoch 149 
Overall Loss: 14.375944
Rec Loss: 14.040982
KL Loss: 0.334962
Y Loss: 0.907240
T Loss: 13.133742
Epoch 199 
Overall Loss: 14.175661
Rec Loss: 13.858306
KL Loss: 0.317355
Y Loss: 0.753022
T Loss: 13.105284
Epoch 249 
Overall Loss: 14.068312
Rec Loss: 13.756217
KL Loss: 0.312095
Y Loss: 0.676501
T Loss: 13.079716
Epoch 299 
Overall Loss: 14.016904
Rec Loss: 13.714175
KL Loss: 0.302729
Y Loss: 0.643603
T Loss: 13.070572
Epoch 349 
Overall Loss: 13.939879
Rec Loss: 13.649867
KL Loss: 0.290012
Y Loss: 0.596629
T Loss: 13.053238
Epoch 399 
Overall Loss: 13.895719
Rec Loss: 13.608021
KL Loss: 0.287698
Y Loss: 0.567081
T Loss: 13.040940
Epoch 449 
Overall Loss: 13.841689
Rec Loss: 13.554016
KL Loss: 0.287673
Y Loss: 0.537175
T Loss: 13.016841
Epoch 499 
Overall Loss: 13.801171
Rec Loss: 13.501599
KL Loss: 0.299572
Y Loss: 0.498506
T Loss: 13.003093
Epoch 549 
Overall Loss: 13.735499
Rec Loss: 13.435713
KL Loss: 0.299786
Y Loss: 0.454976
T Loss: 12.980737
Epoch 599 
Overall Loss: 13.677822
Rec Loss: 13.381912
KL Loss: 0.295911
Y Loss: 0.414548
T Loss: 12.967363
Epoch 649 
Overall Loss: 13.628572
Rec Loss: 13.348305
KL Loss: 0.280267
Y Loss: 0.389878
T Loss: 12.958426
Epoch 699 
Overall Loss: 13.581123
Rec Loss: 13.316292
KL Loss: 0.264830
Y Loss: 0.362821
T Loss: 12.953471
Epoch 749 
Overall Loss: 13.533837
Rec Loss: 13.290275
KL Loss: 0.243562
Y Loss: 0.330068
T Loss: 12.960207
Epoch 799 
Overall Loss: 13.509845
Rec Loss: 13.284977
KL Loss: 0.224868
Y Loss: 0.318878
T Loss: 12.966098
Epoch 849 
Overall Loss: 13.455211
Rec Loss: 13.250608
KL Loss: 0.204603
Y Loss: 0.284619
T Loss: 12.965989
Epoch 899 
Overall Loss: 13.430155
Rec Loss: 13.244048
KL Loss: 0.186107
Y Loss: 0.267477
T Loss: 12.976571
Epoch 949 
Overall Loss: 13.402086
Rec Loss: 13.234326
KL Loss: 0.167760
Y Loss: 0.252911
T Loss: 12.981416
Epoch 999 
Overall Loss: 13.371945
Rec Loss: 13.219240
KL Loss: 0.152705
Y Loss: 0.238501
T Loss: 12.980739
Epoch 1049 
Overall Loss: 13.338161
Rec Loss: 13.197753
KL Loss: 0.140408
Y Loss: 0.219551
T Loss: 12.978203
Epoch 1099 
Overall Loss: 13.319983
Rec Loss: 13.188782
KL Loss: 0.131201
Y Loss: 0.209327
T Loss: 12.979455
Epoch 1149 
Overall Loss: 13.311248
Rec Loss: 13.188121
KL Loss: 0.123127
Y Loss: 0.200174
T Loss: 12.987946
Epoch 1199 
Overall Loss: 13.295928
Rec Loss: 13.178433
KL Loss: 0.117494
Y Loss: 0.196893
T Loss: 12.981540
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.373913
Epoch 99
Rec Loss: 1.381343
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.000643
Epoch 99
Rec Loss: 9.990248
Epoch 149
Rec Loss: 9.984572
Epoch 199
Rec Loss: 9.984299
Epoch 249
Rec Loss: 9.991551
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.375445
Insample Error: 0.868034
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 26.848857
Rec Loss: 23.847860
KL Loss: 3.000997
Y Loss: 4.853424
T Loss: 13.244184
Epoch 99 
Overall Loss: 22.756111
Rec Loss: 20.205501
KL Loss: 2.550610
Y Loss: 1.552695
T Loss: 13.221821
Epoch 149 
Overall Loss: 21.703769
Rec Loss: 18.912681
KL Loss: 2.791087
Y Loss: 1.149082
T Loss: 13.117618
Epoch 199 
Overall Loss: 21.113869
Rec Loss: 18.066809
KL Loss: 3.047060
Y Loss: 0.884918
T Loss: 13.066387
Epoch 249 
Overall Loss: 20.802875
Rec Loss: 17.524506
KL Loss: 3.278369
Y Loss: 0.760545
T Loss: 13.055124
Epoch 299 
Overall Loss: 20.581819
Rec Loss: 17.094275
KL Loss: 3.487544
Y Loss: 0.711883
T Loss: 13.082725
Epoch 349 
Overall Loss: 20.377297
Rec Loss: 16.678160
KL Loss: 3.699136
Y Loss: 0.670534
T Loss: 13.115737
Epoch 399 
Overall Loss: 20.214862
Rec Loss: 16.371368
KL Loss: 3.843494
Y Loss: 0.613119
T Loss: 13.113622
Epoch 449 
Overall Loss: 20.133178
Rec Loss: 16.196941
KL Loss: 3.936237
Y Loss: 0.576827
T Loss: 13.095092
Epoch 499 
Overall Loss: 20.039868
Rec Loss: 16.033919
KL Loss: 4.005948
Y Loss: 0.548272
T Loss: 13.080168
Epoch 549 
Overall Loss: 19.969443
Rec Loss: 15.898416
KL Loss: 4.071027
Y Loss: 0.530741
T Loss: 13.065638
Epoch 599 
Overall Loss: 19.935426
Rec Loss: 15.792211
KL Loss: 4.143215
Y Loss: 0.526489
T Loss: 13.054060
Epoch 649 
Overall Loss: 19.916514
Rec Loss: 15.715193
KL Loss: 4.201321
Y Loss: 0.523421
T Loss: 13.037977
Epoch 699 
Overall Loss: 19.852799
Rec Loss: 15.602093
KL Loss: 4.250706
Y Loss: 0.504575
T Loss: 13.028130
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.683870
Epoch 99
Rec Loss: 1.678805
Epoch 149
Rec Loss: 1.673165
Epoch 199
Rec Loss: 1.677504
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.127903
Epoch 99
Rec Loss: 6.122550
Epoch 149
Rec Loss: 6.118429
Epoch 199
Rec Loss: 6.125457
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.369643
Insample Error 1.906526
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.035565
Rec Loss: 16.015829
KL Loss: 1.019735
Y Loss: 2.785919
T Loss: 13.229910
Epoch 99 
Overall Loss: 15.077095
Rec Loss: 14.482368
KL Loss: 0.594727
Y Loss: 1.257293
T Loss: 13.225075
Epoch 149 
Overall Loss: 14.442176
Rec Loss: 14.104297
KL Loss: 0.337880
Y Loss: 0.931553
T Loss: 13.172744
Epoch 199 
Overall Loss: 14.190146
Rec Loss: 13.896027
KL Loss: 0.294119
Y Loss: 0.768642
T Loss: 13.127385
Epoch 249 
Overall Loss: 14.066080
Rec Loss: 13.783451
KL Loss: 0.282629
Y Loss: 0.689483
T Loss: 13.093968
Epoch 299 
Overall Loss: 14.002335
Rec Loss: 13.734731
KL Loss: 0.267604
Y Loss: 0.658467
T Loss: 13.076263
Epoch 349 
Overall Loss: 13.934872
Rec Loss: 13.684802
KL Loss: 0.250070
Y Loss: 0.612820
T Loss: 13.071982
Epoch 399 
Overall Loss: 13.885659
Rec Loss: 13.650535
KL Loss: 0.235124
Y Loss: 0.596542
T Loss: 13.053993
Epoch 449 
Overall Loss: 13.801372
Rec Loss: 13.580790
KL Loss: 0.220582
Y Loss: 0.528424
T Loss: 13.052366
Epoch 499 
Overall Loss: 13.731814
Rec Loss: 13.522083
KL Loss: 0.209730
Y Loss: 0.478024
T Loss: 13.044059
Epoch 549 
Overall Loss: 13.664872
Rec Loss: 13.469008
KL Loss: 0.195863
Y Loss: 0.431361
T Loss: 13.037648
Epoch 599 
Overall Loss: 13.608308
Rec Loss: 13.424153
KL Loss: 0.184154
Y Loss: 0.389615
T Loss: 13.034538
Epoch 649 
Overall Loss: 13.544335
Rec Loss: 13.372101
KL Loss: 0.172233
Y Loss: 0.343344
T Loss: 13.028757
Epoch 699 
Overall Loss: 13.507013
Rec Loss: 13.344017
KL Loss: 0.162997
Y Loss: 0.319077
T Loss: 13.024939
Epoch 749 
Overall Loss: 13.470088
Rec Loss: 13.315716
KL Loss: 0.154372
Y Loss: 0.295275
T Loss: 13.020441
Epoch 799 
Overall Loss: 13.435458
Rec Loss: 13.291172
KL Loss: 0.144286
Y Loss: 0.269738
T Loss: 13.021435
Epoch 849 
Overall Loss: 13.411833
Rec Loss: 13.275992
KL Loss: 0.135841
Y Loss: 0.257895
T Loss: 13.018096
Epoch 899 
Overall Loss: 13.385606
Rec Loss: 13.256162
KL Loss: 0.129444
Y Loss: 0.239263
T Loss: 13.016899
Epoch 949 
Overall Loss: 13.367772
Rec Loss: 13.246114
KL Loss: 0.121657
Y Loss: 0.229171
T Loss: 13.016943
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.486794
Epoch 99
Rec Loss: 1.487618
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.029012
Epoch 99
Rec Loss: 10.022036
Epoch 149
Rec Loss: 10.023356
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.395776
Insample Error: 0.989881
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 27.564504
Rec Loss: 24.736610
KL Loss: 2.827894
Y Loss: 5.675874
T Loss: 13.252886
Epoch 99 
Overall Loss: 23.049497
Rec Loss: 20.451583
KL Loss: 2.597915
Y Loss: 1.790405
T Loss: 13.275464
Epoch 149 
Overall Loss: 21.623904
Rec Loss: 18.658585
KL Loss: 2.965318
Y Loss: 1.130168
T Loss: 13.231407
Epoch 199 
Overall Loss: 20.978699
Rec Loss: 17.693435
KL Loss: 3.285264
Y Loss: 0.861991
T Loss: 13.181985
Epoch 249 
Overall Loss: 20.606873
Rec Loss: 16.844579
KL Loss: 3.762293
Y Loss: 0.779430
T Loss: 13.172595
Epoch 299 
Overall Loss: 20.399221
Rec Loss: 16.403904
KL Loss: 3.995317
Y Loss: 0.716551
T Loss: 13.150021
Epoch 349 
Overall Loss: 20.304059
Rec Loss: 16.115492
KL Loss: 4.188567
Y Loss: 0.674205
T Loss: 13.132932
Epoch 399 
Overall Loss: 20.183834
Rec Loss: 15.881041
KL Loss: 4.302793
Y Loss: 0.640251
T Loss: 13.110444
Epoch 449 
Overall Loss: 20.124017
Rec Loss: 15.713168
KL Loss: 4.410849
Y Loss: 0.625255
T Loss: 13.098996
Epoch 499 
Overall Loss: 20.060419
Rec Loss: 15.614316
KL Loss: 4.446103
Y Loss: 0.608751
T Loss: 13.086238
Epoch 549 
Overall Loss: 20.000806
Rec Loss: 15.491399
KL Loss: 4.509408
Y Loss: 0.596322
T Loss: 13.073592
Epoch 599 
Overall Loss: 19.950775
Rec Loss: 15.404469
KL Loss: 4.546307
Y Loss: 0.577315
T Loss: 13.053432
Epoch 649 
Overall Loss: 19.925790
Rec Loss: 15.326904
KL Loss: 4.598887
Y Loss: 0.550891
T Loss: 13.037847
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.682925
Epoch 99
Rec Loss: 1.683991
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.189848
Epoch 99
Rec Loss: 6.191734
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.384095
Insample Error 1.868443
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.945205
Rec Loss: 15.829413
KL Loss: 1.115792
Y Loss: 2.624263
T Loss: 13.205150
Epoch 99 
Overall Loss: 15.024220
Rec Loss: 14.296152
KL Loss: 0.728068
Y Loss: 1.087762
T Loss: 13.208390
Epoch 149 
Overall Loss: 14.452350
Rec Loss: 13.995705
KL Loss: 0.456646
Y Loss: 0.830984
T Loss: 13.164721
Epoch 199 
Overall Loss: 14.146068
Rec Loss: 13.793898
KL Loss: 0.352170
Y Loss: 0.679180
T Loss: 13.114718
Epoch 249 
Overall Loss: 14.029455
Rec Loss: 13.692231
KL Loss: 0.337224
Y Loss: 0.605540
T Loss: 13.086692
Epoch 299 
Overall Loss: 13.954555
Rec Loss: 13.622633
KL Loss: 0.331922
Y Loss: 0.557812
T Loss: 13.064821
Epoch 349 
Overall Loss: 13.881198
Rec Loss: 13.552267
KL Loss: 0.328930
Y Loss: 0.514852
T Loss: 13.037416
Epoch 399 
Overall Loss: 13.820774
Rec Loss: 13.488301
KL Loss: 0.332472
Y Loss: 0.477220
T Loss: 13.011081
Epoch 449 
Overall Loss: 13.760122
Rec Loss: 13.432823
KL Loss: 0.327299
Y Loss: 0.441243
T Loss: 12.991581
Epoch 499 
Overall Loss: 13.710952
Rec Loss: 13.392339
KL Loss: 0.318613
Y Loss: 0.405426
T Loss: 12.986914
Epoch 549 
Overall Loss: 13.665532
Rec Loss: 13.369420
KL Loss: 0.296112
Y Loss: 0.385461
T Loss: 12.983959
Epoch 599 
Overall Loss: 13.625937
Rec Loss: 13.347602
KL Loss: 0.278335
Y Loss: 0.361134
T Loss: 12.986468
Epoch 649 
Overall Loss: 13.585283
Rec Loss: 13.331668
KL Loss: 0.253615
Y Loss: 0.345862
T Loss: 12.985806
Epoch 699 
Overall Loss: 13.545668
Rec Loss: 13.310873
KL Loss: 0.234795
Y Loss: 0.321171
T Loss: 12.989701
Epoch 749 
Overall Loss: 13.509171
Rec Loss: 13.297683
KL Loss: 0.211488
Y Loss: 0.308568
T Loss: 12.989116
Epoch 799 
Overall Loss: 13.481213
Rec Loss: 13.288165
KL Loss: 0.193049
Y Loss: 0.292322
T Loss: 12.995843
Epoch 849 
Overall Loss: 13.450668
Rec Loss: 13.275221
KL Loss: 0.175448
Y Loss: 0.278024
T Loss: 12.997197
Epoch 899 
Overall Loss: 13.424326
Rec Loss: 13.264674
KL Loss: 0.159652
Y Loss: 0.266058
T Loss: 12.998615
Epoch 949 
Overall Loss: 13.399537
Rec Loss: 13.252152
KL Loss: 0.147385
Y Loss: 0.248925
T Loss: 13.003227
Epoch 999 
Overall Loss: 13.379117
Rec Loss: 13.241786
KL Loss: 0.137331
Y Loss: 0.238896
T Loss: 13.002889
Epoch 1049 
Overall Loss: 13.351569
Rec Loss: 13.226751
KL Loss: 0.124818
Y Loss: 0.225051
T Loss: 13.001700
Epoch 1099 
Overall Loss: 13.341421
Rec Loss: 13.225219
KL Loss: 0.116202
Y Loss: 0.215393
T Loss: 13.009826
Epoch 1149 
Overall Loss: 13.328005
Rec Loss: 13.219411
KL Loss: 0.108594
Y Loss: 0.206800
T Loss: 13.012611
Epoch 1199 
Overall Loss: 13.314449
Rec Loss: 13.212960
KL Loss: 0.101489
Y Loss: 0.201964
T Loss: 13.010996
Epoch 1249 
Overall Loss: 13.300144
Rec Loss: 13.203640
KL Loss: 0.096504
Y Loss: 0.193282
T Loss: 13.010358
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.380936
Epoch 99
Rec Loss: 1.381800
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.029860
Epoch 99
Rec Loss: 10.022900
Epoch 149
Rec Loss: 10.030441
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.372980
Insample Error: 0.837801
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 27.794618
Rec Loss: 24.981690
KL Loss: 2.812928
Y Loss: 5.942506
T Loss: 13.248977
Epoch 99 
Overall Loss: 23.040451
Rec Loss: 20.083685
KL Loss: 2.956767
Y Loss: 1.909331
T Loss: 13.259272
Epoch 149 
Overall Loss: 21.598817
Rec Loss: 17.973044
KL Loss: 3.625773
Y Loss: 1.231931
T Loss: 13.177796
Epoch 199 
Overall Loss: 21.021387
Rec Loss: 17.085366
KL Loss: 3.936020
Y Loss: 1.035815
T Loss: 13.192412
Epoch 249 
Overall Loss: 20.657615
Rec Loss: 16.453571
KL Loss: 4.204043
Y Loss: 0.873803
T Loss: 13.184077
Epoch 299 
Overall Loss: 20.426762
Rec Loss: 15.894658
KL Loss: 4.532103
Y Loss: 0.770363
T Loss: 13.161856
Epoch 349 
Overall Loss: 20.276165
Rec Loss: 15.470613
KL Loss: 4.805552
Y Loss: 0.711780
T Loss: 13.143158
Epoch 399 
Overall Loss: 20.133153
Rec Loss: 15.116878
KL Loss: 5.016274
Y Loss: 0.670335
T Loss: 13.123019
Epoch 449 
Overall Loss: 20.080067
Rec Loss: 14.930189
KL Loss: 5.149878
Y Loss: 0.646964
T Loss: 13.105071
Epoch 499 
Overall Loss: 20.015167
Rec Loss: 14.730904
KL Loss: 5.284263
Y Loss: 0.634472
T Loss: 13.082117
Epoch 549 
Overall Loss: 19.958159
Rec Loss: 14.560403
KL Loss: 5.397757
Y Loss: 0.612762
T Loss: 13.069661
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.695039
Epoch 99
Rec Loss: 1.700770
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.815015
Epoch 99
Rec Loss: 5.810525
Epoch 149
Rec Loss: 5.805040
Epoch 199
Rec Loss: 5.797765
Epoch 249
Rec Loss: 5.800838
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.417919
Insample Error 1.863891
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.827562
Rec Loss: 15.899258
KL Loss: 0.928305
Y Loss: 2.691290
T Loss: 13.207968
Epoch 99 
Overall Loss: 15.017008
Rec Loss: 14.376363
KL Loss: 0.640644
Y Loss: 1.171161
T Loss: 13.205203
Epoch 149 
Overall Loss: 14.369868
Rec Loss: 13.987611
KL Loss: 0.382257
Y Loss: 0.833233
T Loss: 13.154378
Epoch 199 
Overall Loss: 14.116607
Rec Loss: 13.783436
KL Loss: 0.333171
Y Loss: 0.668769
T Loss: 13.114667
Epoch 249 
Overall Loss: 14.027776
Rec Loss: 13.711744
KL Loss: 0.316033
Y Loss: 0.626418
T Loss: 13.085326
Epoch 299 
Overall Loss: 13.954882
Rec Loss: 13.653551
KL Loss: 0.301331
Y Loss: 0.590689
T Loss: 13.062862
Epoch 349 
Overall Loss: 13.893454
Rec Loss: 13.602374
KL Loss: 0.291080
Y Loss: 0.551968
T Loss: 13.050406
Epoch 399 
Overall Loss: 13.835311
Rec Loss: 13.557204
KL Loss: 0.278107
Y Loss: 0.527954
T Loss: 13.029250
Epoch 449 
Overall Loss: 13.783117
Rec Loss: 13.506866
KL Loss: 0.276251
Y Loss: 0.485089
T Loss: 13.021777
Epoch 499 
Overall Loss: 13.722923
Rec Loss: 13.455106
KL Loss: 0.267817
Y Loss: 0.451338
T Loss: 13.003767
Epoch 549 
Overall Loss: 13.678212
Rec Loss: 13.411163
KL Loss: 0.267049
Y Loss: 0.422095
T Loss: 12.989068
Epoch 599 
Overall Loss: 13.625698
Rec Loss: 13.373048
KL Loss: 0.252650
Y Loss: 0.398331
T Loss: 12.974717
Epoch 649 
Overall Loss: 13.586195
Rec Loss: 13.349191
KL Loss: 0.237004
Y Loss: 0.370986
T Loss: 12.978205
Epoch 699 
Overall Loss: 13.547862
Rec Loss: 13.324343
KL Loss: 0.223519
Y Loss: 0.347980
T Loss: 12.976363
Epoch 749 
Overall Loss: 13.502962
Rec Loss: 13.296476
KL Loss: 0.206486
Y Loss: 0.319253
T Loss: 12.977223
Epoch 799 
Overall Loss: 13.475723
Rec Loss: 13.286012
KL Loss: 0.189711
Y Loss: 0.302020
T Loss: 12.983991
Epoch 849 
Overall Loss: 13.449182
Rec Loss: 13.275361
KL Loss: 0.173821
Y Loss: 0.287538
T Loss: 12.987823
Epoch 899 
Overall Loss: 13.425185
Rec Loss: 13.264124
KL Loss: 0.161060
Y Loss: 0.271117
T Loss: 12.993008
Epoch 949 
Overall Loss: 13.390079
Rec Loss: 13.245298
KL Loss: 0.144781
Y Loss: 0.251076
T Loss: 12.994222
Epoch 999 
Overall Loss: 13.361810
Rec Loss: 13.228424
KL Loss: 0.133386
Y Loss: 0.236641
T Loss: 12.991783
Epoch 1049 
Overall Loss: 13.338979
Rec Loss: 13.214917
KL Loss: 0.124062
Y Loss: 0.224257
T Loss: 12.990660
Epoch 1099 
Overall Loss: 13.323256
Rec Loss: 13.205783
KL Loss: 0.117472
Y Loss: 0.212407
T Loss: 12.993376
Epoch 1149 
Overall Loss: 13.306466
Rec Loss: 13.196647
KL Loss: 0.109819
Y Loss: 0.202307
T Loss: 12.994340
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.398517
Epoch 99
Rec Loss: 1.397261
Epoch 149
Rec Loss: 1.391683
Epoch 199
Rec Loss: 1.397901
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.014477
Epoch 99
Rec Loss: 10.010537
Epoch 149
Rec Loss: 9.999280
Epoch 199
Rec Loss: 10.004552
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.386387
Insample Error: 0.906787
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 26.893708
Rec Loss: 23.982451
KL Loss: 2.911257
Y Loss: 4.974265
T Loss: 13.245184
Epoch 99 
Overall Loss: 22.826857
Rec Loss: 20.219398
KL Loss: 2.607459
Y Loss: 1.697565
T Loss: 13.236545
Epoch 149 
Overall Loss: 21.616146
Rec Loss: 18.697778
KL Loss: 2.918369
Y Loss: 1.103132
T Loss: 13.208073
Epoch 199 
Overall Loss: 21.065292
Rec Loss: 17.903668
KL Loss: 3.161624
Y Loss: 0.884977
T Loss: 13.182332
Epoch 249 
Overall Loss: 20.637005
Rec Loss: 17.121893
KL Loss: 3.515113
Y Loss: 0.730722
T Loss: 13.162513
Epoch 299 
Overall Loss: 20.407787
Rec Loss: 16.795427
KL Loss: 3.612360
Y Loss: 0.637811
T Loss: 13.138900
Epoch 349 
Overall Loss: 20.203373
Rec Loss: 16.480619
KL Loss: 3.722754
Y Loss: 0.565195
T Loss: 13.110245
Epoch 399 
Overall Loss: 20.114407
Rec Loss: 16.247174
KL Loss: 3.867233
Y Loss: 0.542869
T Loss: 13.096960
Epoch 449 
Overall Loss: 20.047094
Rec Loss: 16.027359
KL Loss: 4.019734
Y Loss: 0.526512
T Loss: 13.072967
Epoch 499 
Overall Loss: 20.014027
Rec Loss: 15.859076
KL Loss: 4.154953
Y Loss: 0.504826
T Loss: 13.061670
Epoch 549 
Overall Loss: 19.967291
Rec Loss: 15.723749
KL Loss: 4.243542
Y Loss: 0.510560
T Loss: 13.045705
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.714243
Epoch 99
Rec Loss: 1.712532
Epoch 149
Rec Loss: 1.710909
Epoch 199
Rec Loss: 1.713245
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.129201
Epoch 99
Rec Loss: 6.125943
Epoch 149
Rec Loss: 6.136096
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.361636
Insample Error 1.963357
Ours, Train RMSE
0.3868, 
0.3853, 
0.3940, 
0.3536, 
0.3803, 
0.3832, 
0.3754, 
0.3958, 
0.3730, 
0.3864, 
Ours, Insample RMSE
0.9897, 
0.8201, 
1.0242, 
0.6614, 
0.8535, 
0.8110, 
0.8680, 
0.9899, 
0.8378, 
0.9068, 
CEVAE, Insample RMSE
1.9294, 
1.9222, 
1.7852, 
1.8614, 
1.9138, 
1.9553, 
1.9065, 
1.8684, 
1.8639, 
1.9634, 
Train, RMSE mean 0.3814 std 0.0115
Ours, RMSE mean 0.8763 std 0.1021, reconstruct confounder 1.4111 (0.0501) noise 10.0182 (0.0339)
CEVAE, RMSE mean 1.8969 std 0.0505, reconstruct confounder 1.7018 (0.0239) noise 5.9958 (0.1505)
Experiment Start!
Namespace(decay=0.0, l=5e-05, latdim=4, mask=0, nlayer=50, obsm=4, ycof=0.5, ylayer=50)
Y Mean 1.192369, Std 4.040208 
Observe confounder 4, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.854899
Rec Loss: 15.236787
KL Loss: 0.618111
Y Loss: 4.022935
T Loss: 13.225320
Epoch 99 
Overall Loss: 14.352337
Rec Loss: 14.001160
KL Loss: 0.351178
Y Loss: 1.643084
T Loss: 13.179618
Epoch 149 
Overall Loss: 13.866991
Rec Loss: 13.654474
KL Loss: 0.212517
Y Loss: 1.068183
T Loss: 13.120382
Epoch 199 
Overall Loss: 13.733312
Rec Loss: 13.526353
KL Loss: 0.206959
Y Loss: 0.892053
T Loss: 13.080326
Epoch 249 
Overall Loss: 13.665704
Rec Loss: 13.475233
KL Loss: 0.190471
Y Loss: 0.822339
T Loss: 13.064063
Epoch 299 
Overall Loss: 13.613005
Rec Loss: 13.444190
KL Loss: 0.168815
Y Loss: 0.777766
T Loss: 13.055308
Epoch 349 
Overall Loss: 13.568756
Rec Loss: 13.417100
KL Loss: 0.151657
Y Loss: 0.726617
T Loss: 13.053791
Epoch 399 
Overall Loss: 13.528638
Rec Loss: 13.392431
KL Loss: 0.136206
Y Loss: 0.678952
T Loss: 13.052955
Epoch 449 
Overall Loss: 13.485646
Rec Loss: 13.359529
KL Loss: 0.126116
Y Loss: 0.620720
T Loss: 13.049169
Epoch 499 
Overall Loss: 13.453716
Rec Loss: 13.333042
KL Loss: 0.120674
Y Loss: 0.582890
T Loss: 13.041597
Epoch 549 
Overall Loss: 13.429523
Rec Loss: 13.311155
KL Loss: 0.118368
Y Loss: 0.549417
T Loss: 13.036447
Epoch 599 
Overall Loss: 13.394691
Rec Loss: 13.280735
KL Loss: 0.113957
Y Loss: 0.497509
T Loss: 13.031981
Epoch 649 
Overall Loss: 13.361157
Rec Loss: 13.249307
KL Loss: 0.111850
Y Loss: 0.456558
T Loss: 13.021028
Epoch 699 
Overall Loss: 13.333794
Rec Loss: 13.225090
KL Loss: 0.108704
Y Loss: 0.418218
T Loss: 13.015981
Epoch 749 
Overall Loss: 13.307010
Rec Loss: 13.203292
KL Loss: 0.103718
Y Loss: 0.376059
T Loss: 13.015263
Epoch 799 
Overall Loss: 13.290330
Rec Loss: 13.191220
KL Loss: 0.099110
Y Loss: 0.350754
T Loss: 13.015843
Epoch 849 
Overall Loss: 13.273117
Rec Loss: 13.180852
KL Loss: 0.092264
Y Loss: 0.323512
T Loss: 13.019096
Epoch 899 
Overall Loss: 13.254612
Rec Loss: 13.168323
KL Loss: 0.086289
Y Loss: 0.302805
T Loss: 13.016920
Epoch 949 
Overall Loss: 13.238374
Rec Loss: 13.156668
KL Loss: 0.081706
Y Loss: 0.279833
T Loss: 13.016752
Epoch 999 
Overall Loss: 13.233905
Rec Loss: 13.156958
KL Loss: 0.076947
Y Loss: 0.271054
T Loss: 13.021431
Epoch 1049 
Overall Loss: 13.214281
Rec Loss: 13.141765
KL Loss: 0.072516
Y Loss: 0.251019
T Loss: 13.016255
Epoch 1099 
Overall Loss: 13.206548
Rec Loss: 13.138469
KL Loss: 0.068079
Y Loss: 0.244382
T Loss: 13.016278
Epoch 1149 
Overall Loss: 13.198155
Rec Loss: 13.132145
KL Loss: 0.066010
Y Loss: 0.234343
T Loss: 13.014974
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.370678
Epoch 99
Rec Loss: 1.368413
Epoch 149
Rec Loss: 1.367549
Epoch 199
Rec Loss: 1.373151
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.054374
Epoch 99
Rec Loss: 10.055559
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.411560
Insample Error: 0.896382
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 24.791486
Rec Loss: 23.224601
KL Loss: 1.566886
Y Loss: 8.001353
T Loss: 13.279035
Epoch 99 
Overall Loss: 21.809808
Rec Loss: 19.756469
KL Loss: 2.053338
Y Loss: 2.661707
T Loss: 13.231356
Epoch 149 
Overall Loss: 20.860014
Rec Loss: 18.320830
KL Loss: 2.539184
Y Loss: 1.814349
T Loss: 13.135027
Epoch 199 
Overall Loss: 20.393200
Rec Loss: 17.483576
KL Loss: 2.909623
Y Loss: 1.445037
T Loss: 13.113658
Epoch 249 
Overall Loss: 20.060287
Rec Loss: 16.710032
KL Loss: 3.350254
Y Loss: 1.278296
T Loss: 13.105575
Epoch 299 
Overall Loss: 19.830745
Rec Loss: 16.108275
KL Loss: 3.722470
Y Loss: 1.144417
T Loss: 13.103926
Epoch 349 
Overall Loss: 19.761703
Rec Loss: 15.859042
KL Loss: 3.902661
Y Loss: 1.101146
T Loss: 13.077315
Epoch 399 
Overall Loss: 19.662427
Rec Loss: 15.603640
KL Loss: 4.058787
Y Loss: 1.047837
T Loss: 13.063849
Epoch 449 
Overall Loss: 19.595230
Rec Loss: 15.428676
KL Loss: 4.166554
Y Loss: 0.982726
T Loss: 13.050446
Epoch 499 
Overall Loss: 19.566294
Rec Loss: 15.254152
KL Loss: 4.312142
Y Loss: 0.970031
T Loss: 13.037559
Epoch 549 
Overall Loss: 19.504978
Rec Loss: 15.079152
KL Loss: 4.425826
Y Loss: 0.930024
T Loss: 13.022252
Epoch 599 
Overall Loss: 19.492538
Rec Loss: 14.984699
KL Loss: 4.507839
Y Loss: 0.929962
T Loss: 13.012247
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.705400
Epoch 99
Rec Loss: 1.697649
Epoch 149
Rec Loss: 1.700069
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.968969
Epoch 99
Rec Loss: 5.966257
Epoch 149
Rec Loss: 5.964311
Epoch 199
Rec Loss: 5.964612
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.531722
Insample Error 1.809754
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.625184
Rec Loss: 14.989865
KL Loss: 0.635319
Y Loss: 3.529796
T Loss: 13.224967
Epoch 99 
Overall Loss: 14.224769
Rec Loss: 13.930476
KL Loss: 0.294293
Y Loss: 1.545883
T Loss: 13.157535
Epoch 149 
Overall Loss: 13.832904
Rec Loss: 13.651754
KL Loss: 0.181149
Y Loss: 1.098179
T Loss: 13.102665
Epoch 199 
Overall Loss: 13.719713
Rec Loss: 13.552305
KL Loss: 0.167408
Y Loss: 0.958549
T Loss: 13.073030
Epoch 249 
Overall Loss: 13.664250
Rec Loss: 13.512839
KL Loss: 0.151411
Y Loss: 0.905274
T Loss: 13.060202
Epoch 299 
Overall Loss: 13.607904
Rec Loss: 13.471058
KL Loss: 0.136846
Y Loss: 0.835094
T Loss: 13.053511
Epoch 349 
Overall Loss: 13.573282
Rec Loss: 13.447834
KL Loss: 0.125448
Y Loss: 0.788358
T Loss: 13.053655
Epoch 399 
Overall Loss: 13.531816
Rec Loss: 13.414087
KL Loss: 0.117730
Y Loss: 0.729706
T Loss: 13.049234
Epoch 449 
Overall Loss: 13.486424
Rec Loss: 13.378490
KL Loss: 0.107934
Y Loss: 0.659016
T Loss: 13.048982
Epoch 499 
Overall Loss: 13.450851
Rec Loss: 13.349160
KL Loss: 0.101691
Y Loss: 0.606847
T Loss: 13.045736
Epoch 549 
Overall Loss: 13.401755
Rec Loss: 13.303690
KL Loss: 0.098065
Y Loss: 0.533866
T Loss: 13.036757
Epoch 599 
Overall Loss: 13.372405
Rec Loss: 13.275998
KL Loss: 0.096407
Y Loss: 0.485557
T Loss: 13.033219
Epoch 649 
Overall Loss: 13.337516
Rec Loss: 13.244996
KL Loss: 0.092520
Y Loss: 0.437954
T Loss: 13.026020
Epoch 699 
Overall Loss: 13.306648
Rec Loss: 13.216292
KL Loss: 0.090356
Y Loss: 0.390620
T Loss: 13.020982
Epoch 749 
Overall Loss: 13.286499
Rec Loss: 13.199024
KL Loss: 0.087475
Y Loss: 0.357830
T Loss: 13.020109
Epoch 799 
Overall Loss: 13.261743
Rec Loss: 13.175952
KL Loss: 0.085791
Y Loss: 0.321436
T Loss: 13.015234
Epoch 849 
Overall Loss: 13.235977
Rec Loss: 13.154685
KL Loss: 0.081292
Y Loss: 0.296607
T Loss: 13.006381
Epoch 899 
Overall Loss: 13.226896
Rec Loss: 13.147063
KL Loss: 0.079832
Y Loss: 0.275299
T Loss: 13.009414
Epoch 949 
Overall Loss: 13.210279
Rec Loss: 13.133902
KL Loss: 0.076377
Y Loss: 0.255572
T Loss: 13.006116
Epoch 999 
Overall Loss: 13.197791
Rec Loss: 13.122251
KL Loss: 0.075540
Y Loss: 0.241616
T Loss: 13.001443
Epoch 1049 
Overall Loss: 13.192583
Rec Loss: 13.119179
KL Loss: 0.073404
Y Loss: 0.233784
T Loss: 13.002287
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.355628
Epoch 99
Rec Loss: 1.341338
Epoch 149
Rec Loss: 1.346199
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.957181
Epoch 99
Rec Loss: 9.959973
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.413141
Insample Error: 0.835502
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 24.352167
Rec Loss: 22.630867
KL Loss: 1.721300
Y Loss: 6.995218
T Loss: 13.273397
Epoch 99 
Overall Loss: 21.640691
Rec Loss: 19.421858
KL Loss: 2.218832
Y Loss: 2.382432
T Loss: 13.205973
Epoch 149 
Overall Loss: 20.650787
Rec Loss: 17.572879
KL Loss: 3.077908
Y Loss: 1.735637
T Loss: 13.137391
Epoch 199 
Overall Loss: 20.282125
Rec Loss: 16.868560
KL Loss: 3.413565
Y Loss: 1.479768
T Loss: 13.142790
Epoch 249 
Overall Loss: 20.118675
Rec Loss: 16.509607
KL Loss: 3.609068
Y Loss: 1.377332
T Loss: 13.136933
Epoch 299 
Overall Loss: 19.921891
Rec Loss: 16.168827
KL Loss: 3.753064
Y Loss: 1.222533
T Loss: 13.120282
Epoch 349 
Overall Loss: 19.784551
Rec Loss: 15.851807
KL Loss: 3.932744
Y Loss: 1.141239
T Loss: 13.088962
Epoch 399 
Overall Loss: 19.737785
Rec Loss: 15.615375
KL Loss: 4.122410
Y Loss: 1.074525
T Loss: 13.071219
Epoch 449 
Overall Loss: 19.626819
Rec Loss: 15.364085
KL Loss: 4.262734
Y Loss: 0.996663
T Loss: 13.054999
Epoch 499 
Overall Loss: 19.603601
Rec Loss: 15.244762
KL Loss: 4.358839
Y Loss: 0.980389
T Loss: 13.047305
Epoch 549 
Overall Loss: 19.577346
Rec Loss: 15.109259
KL Loss: 4.468087
Y Loss: 0.962514
T Loss: 13.031565
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.712201
Epoch 99
Rec Loss: 1.708216
Epoch 149
Rec Loss: 1.708944
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.965436
Epoch 99
Rec Loss: 5.954655
Epoch 149
Rec Loss: 5.935376
Epoch 199
Rec Loss: 5.958034
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.583055
Insample Error 1.868988
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.761305
Rec Loss: 15.261298
KL Loss: 0.500008
Y Loss: 4.116606
T Loss: 13.202995
Epoch 99 
Overall Loss: 14.256517
Rec Loss: 13.961458
KL Loss: 0.295059
Y Loss: 1.602408
T Loss: 13.160254
Epoch 149 
Overall Loss: 13.854129
Rec Loss: 13.651821
KL Loss: 0.202309
Y Loss: 1.067140
T Loss: 13.118250
Epoch 199 
Overall Loss: 13.717409
Rec Loss: 13.532670
KL Loss: 0.184739
Y Loss: 0.913334
T Loss: 13.076003
Epoch 249 
Overall Loss: 13.645762
Rec Loss: 13.484223
KL Loss: 0.161539
Y Loss: 0.846777
T Loss: 13.060835
Epoch 299 
Overall Loss: 13.595986
Rec Loss: 13.456172
KL Loss: 0.139813
Y Loss: 0.799058
T Loss: 13.056643
Epoch 349 
Overall Loss: 13.551623
Rec Loss: 13.426821
KL Loss: 0.124802
Y Loss: 0.740176
T Loss: 13.056733
Epoch 399 
Overall Loss: 13.511615
Rec Loss: 13.400126
KL Loss: 0.111489
Y Loss: 0.684895
T Loss: 13.057679
Epoch 449 
Overall Loss: 13.474844
Rec Loss: 13.371382
KL Loss: 0.103462
Y Loss: 0.633722
T Loss: 13.054521
Epoch 499 
Overall Loss: 13.441598
Rec Loss: 13.343816
KL Loss: 0.097782
Y Loss: 0.586447
T Loss: 13.050593
Epoch 549 
Overall Loss: 13.404835
Rec Loss: 13.310671
KL Loss: 0.094164
Y Loss: 0.528486
T Loss: 13.046428
Epoch 599 
Overall Loss: 13.368821
Rec Loss: 13.279895
KL Loss: 0.088925
Y Loss: 0.469565
T Loss: 13.045113
Epoch 649 
Overall Loss: 13.335642
Rec Loss: 13.248051
KL Loss: 0.087591
Y Loss: 0.418857
T Loss: 13.038623
Epoch 699 
Overall Loss: 13.310498
Rec Loss: 13.224979
KL Loss: 0.085519
Y Loss: 0.381472
T Loss: 13.034243
Epoch 749 
Overall Loss: 13.287184
Rec Loss: 13.204084
KL Loss: 0.083099
Y Loss: 0.338775
T Loss: 13.034697
Epoch 799 
Overall Loss: 13.264048
Rec Loss: 13.184048
KL Loss: 0.079999
Y Loss: 0.313281
T Loss: 13.027408
Epoch 849 
Overall Loss: 13.251308
Rec Loss: 13.173350
KL Loss: 0.077957
Y Loss: 0.294680
T Loss: 13.026010
Epoch 899 
Overall Loss: 13.237738
Rec Loss: 13.162799
KL Loss: 0.074940
Y Loss: 0.276517
T Loss: 13.024540
Epoch 949 
Overall Loss: 13.226271
Rec Loss: 13.153058
KL Loss: 0.073212
Y Loss: 0.260986
T Loss: 13.022565
Epoch 999 
Overall Loss: 13.209600
Rec Loss: 13.139128
KL Loss: 0.070472
Y Loss: 0.241344
T Loss: 13.018456
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.404470
Epoch 99
Rec Loss: 1.404127
Epoch 149
Rec Loss: 1.395031
Epoch 199
Rec Loss: 1.400341
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.007576
Epoch 99
Rec Loss: 10.007054
Epoch 149
Rec Loss: 10.011206
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.416559
Insample Error: 0.939098
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 24.550340
Rec Loss: 22.894103
KL Loss: 1.656237
Y Loss: 7.338195
T Loss: 13.306501
Epoch 99 
Overall Loss: 21.585108
Rec Loss: 19.370765
KL Loss: 2.214342
Y Loss: 2.408284
T Loss: 13.220068
Epoch 149 
Overall Loss: 20.711873
Rec Loss: 17.966903
KL Loss: 2.744971
Y Loss: 1.693756
T Loss: 13.167288
Epoch 199 
Overall Loss: 20.428341
Rec Loss: 17.494024
KL Loss: 2.934317
Y Loss: 1.442072
T Loss: 13.145769
Epoch 249 
Overall Loss: 20.205058
Rec Loss: 17.086019
KL Loss: 3.119039
Y Loss: 1.247066
T Loss: 13.121963
Epoch 299 
Overall Loss: 20.063157
Rec Loss: 16.722082
KL Loss: 3.341074
Y Loss: 1.172274
T Loss: 13.092303
Epoch 349 
Overall Loss: 19.840232
Rec Loss: 16.027507
KL Loss: 3.812725
Y Loss: 1.084096
T Loss: 13.072510
Epoch 399 
Overall Loss: 19.667379
Rec Loss: 15.450946
KL Loss: 4.216434
Y Loss: 1.038509
T Loss: 13.058400
Epoch 449 
Overall Loss: 19.598296
Rec Loss: 15.164639
KL Loss: 4.433658
Y Loss: 0.984264
T Loss: 13.050534
Epoch 499 
Overall Loss: 19.528267
Rec Loss: 14.960166
KL Loss: 4.568101
Y Loss: 0.944374
T Loss: 13.032142
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.709309
Epoch 99
Rec Loss: 1.707897
Epoch 149
Rec Loss: 1.702455
Epoch 199
Rec Loss: 1.705198
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.974398
Epoch 99
Rec Loss: 5.966492
Epoch 149
Rec Loss: 5.964124
Epoch 199
Rec Loss: 5.977305
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.560927
Insample Error 1.817140
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.574633
Rec Loss: 16.052945
KL Loss: 0.521688
Y Loss: 5.679479
T Loss: 13.213205
Epoch 99 
Overall Loss: 14.258925
Rec Loss: 13.952868
KL Loss: 0.306057
Y Loss: 1.565578
T Loss: 13.170079
Epoch 149 
Overall Loss: 13.827706
Rec Loss: 13.631451
KL Loss: 0.196254
Y Loss: 1.047825
T Loss: 13.107539
Epoch 199 
Overall Loss: 13.703898
Rec Loss: 13.520565
KL Loss: 0.183333
Y Loss: 0.887390
T Loss: 13.076870
Epoch 249 
Overall Loss: 13.634867
Rec Loss: 13.473412
KL Loss: 0.161456
Y Loss: 0.814137
T Loss: 13.066343
Epoch 299 
Overall Loss: 13.584260
Rec Loss: 13.442272
KL Loss: 0.141988
Y Loss: 0.754772
T Loss: 13.064886
Epoch 349 
Overall Loss: 13.539537
Rec Loss: 13.417957
KL Loss: 0.121580
Y Loss: 0.713340
T Loss: 13.061287
Epoch 399 
Overall Loss: 13.493214
Rec Loss: 13.382637
KL Loss: 0.110576
Y Loss: 0.646641
T Loss: 13.059317
Epoch 449 
Overall Loss: 13.454762
Rec Loss: 13.354655
KL Loss: 0.100107
Y Loss: 0.589157
T Loss: 13.060076
Epoch 499 
Overall Loss: 13.418536
Rec Loss: 13.326863
KL Loss: 0.091672
Y Loss: 0.539767
T Loss: 13.056979
Epoch 549 
Overall Loss: 13.385931
Rec Loss: 13.302486
KL Loss: 0.083445
Y Loss: 0.490520
T Loss: 13.057226
Epoch 599 
Overall Loss: 13.339520
Rec Loss: 13.263739
KL Loss: 0.075781
Y Loss: 0.416280
T Loss: 13.055599
Epoch 649 
Overall Loss: 13.311708
Rec Loss: 13.243749
KL Loss: 0.067958
Y Loss: 0.375233
T Loss: 13.056133
Epoch 699 
Overall Loss: 13.281265
Rec Loss: 13.219949
KL Loss: 0.061317
Y Loss: 0.325897
T Loss: 13.057000
Epoch 749 
Overall Loss: 13.260737
Rec Loss: 13.204376
KL Loss: 0.056360
Y Loss: 0.298218
T Loss: 13.055268
Epoch 799 
Overall Loss: 13.242988
Rec Loss: 13.191577
KL Loss: 0.051411
Y Loss: 0.271131
T Loss: 13.056011
Epoch 849 
Overall Loss: 13.230684
Rec Loss: 13.183175
KL Loss: 0.047509
Y Loss: 0.251829
T Loss: 13.057260
Epoch 899 
Overall Loss: 13.218650
Rec Loss: 13.173927
KL Loss: 0.044723
Y Loss: 0.235231
T Loss: 13.056312
Epoch 949 
Overall Loss: 13.204732
Rec Loss: 13.163046
KL Loss: 0.041686
Y Loss: 0.216956
T Loss: 13.054568
Epoch 999 
Overall Loss: 13.203920
Rec Loss: 13.165238
KL Loss: 0.038681
Y Loss: 0.218035
T Loss: 13.056221
Epoch 1049 
Overall Loss: 13.199814
Rec Loss: 13.163602
KL Loss: 0.036212
Y Loss: 0.211691
T Loss: 13.057756
Epoch 1099 
Overall Loss: 13.192248
Rec Loss: 13.158168
KL Loss: 0.034080
Y Loss: 0.204007
T Loss: 13.056164
Epoch 1149 
Overall Loss: 13.185026
Rec Loss: 13.153423
KL Loss: 0.031603
Y Loss: 0.199599
T Loss: 13.053624
Epoch 1199 
Overall Loss: 13.181657
Rec Loss: 13.151228
KL Loss: 0.030429
Y Loss: 0.192902
T Loss: 13.054777
Epoch 1249 
Overall Loss: 13.183825
Rec Loss: 13.154598
KL Loss: 0.029227
Y Loss: 0.193789
T Loss: 13.057703
Epoch 1299 
Overall Loss: 13.174571
Rec Loss: 13.146510
KL Loss: 0.028061
Y Loss: 0.187956
T Loss: 13.052532
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.504418
Epoch 99
Rec Loss: 1.504736
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.952848
Epoch 99
Rec Loss: 9.944107
Epoch 149
Rec Loss: 9.947998
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.384838
Insample Error: 0.699608
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 23.903058
Rec Loss: 22.115478
KL Loss: 1.787580
Y Loss: 6.158472
T Loss: 13.238171
Epoch 99 
Overall Loss: 21.546753
Rec Loss: 19.322652
KL Loss: 2.224101
Y Loss: 2.491937
T Loss: 13.202419
Epoch 149 
Overall Loss: 20.505684
Rec Loss: 17.283811
KL Loss: 3.221874
Y Loss: 1.705624
T Loss: 13.170114
Epoch 199 
Overall Loss: 20.177012
Rec Loss: 16.649956
KL Loss: 3.527056
Y Loss: 1.420537
T Loss: 13.149059
Epoch 249 
Overall Loss: 19.984985
Rec Loss: 16.320679
KL Loss: 3.664306
Y Loss: 1.261141
T Loss: 13.114926
Epoch 299 
Overall Loss: 19.837451
Rec Loss: 15.947461
KL Loss: 3.889990
Y Loss: 1.142577
T Loss: 13.091284
Epoch 349 
Overall Loss: 19.758172
Rec Loss: 15.678621
KL Loss: 4.079551
Y Loss: 1.085741
T Loss: 13.077220
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.740074
Epoch 99
Rec Loss: 1.738088
Epoch 149
Rec Loss: 1.740476
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.980315
Epoch 99
Rec Loss: 5.960459
Epoch 149
Rec Loss: 5.987340
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.625860
Insample Error 1.798562
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.057872
Rec Loss: 15.527561
KL Loss: 0.530312
Y Loss: 4.666761
T Loss: 13.194180
Epoch 99 
Overall Loss: 14.143435
Rec Loss: 13.843932
KL Loss: 0.299503
Y Loss: 1.390866
T Loss: 13.148499
Epoch 149 
Overall Loss: 13.795119
Rec Loss: 13.607642
KL Loss: 0.187477
Y Loss: 1.016762
T Loss: 13.099261
Epoch 199 
Overall Loss: 13.692340
Rec Loss: 13.511030
KL Loss: 0.181310
Y Loss: 0.883422
T Loss: 13.069319
Epoch 249 
Overall Loss: 13.627510
Rec Loss: 13.460606
KL Loss: 0.166905
Y Loss: 0.809440
T Loss: 13.055885
Epoch 299 
Overall Loss: 13.580137
Rec Loss: 13.429262
KL Loss: 0.150875
Y Loss: 0.760276
T Loss: 13.049124
Epoch 349 
Overall Loss: 13.537896
Rec Loss: 13.400373
KL Loss: 0.137522
Y Loss: 0.710364
T Loss: 13.045191
Epoch 399 
Overall Loss: 13.503806
Rec Loss: 13.376509
KL Loss: 0.127297
Y Loss: 0.662387
T Loss: 13.045316
Epoch 449 
Overall Loss: 13.462668
Rec Loss: 13.340698
KL Loss: 0.121970
Y Loss: 0.612782
T Loss: 13.034307
Epoch 499 
Overall Loss: 13.433274
Rec Loss: 13.316419
KL Loss: 0.116856
Y Loss: 0.563528
T Loss: 13.034654
Epoch 549 
Overall Loss: 13.391936
Rec Loss: 13.279842
KL Loss: 0.112093
Y Loss: 0.510632
T Loss: 13.024527
Epoch 599 
Overall Loss: 13.356438
Rec Loss: 13.248465
KL Loss: 0.107973
Y Loss: 0.461780
T Loss: 13.017575
Epoch 649 
Overall Loss: 13.336035
Rec Loss: 13.232299
KL Loss: 0.103737
Y Loss: 0.424471
T Loss: 13.020063
Epoch 699 
Overall Loss: 13.308595
Rec Loss: 13.209908
KL Loss: 0.098687
Y Loss: 0.387388
T Loss: 13.016215
Epoch 749 
Overall Loss: 13.278360
Rec Loss: 13.185000
KL Loss: 0.093360
Y Loss: 0.345083
T Loss: 13.012459
Epoch 799 
Overall Loss: 13.259520
Rec Loss: 13.169363
KL Loss: 0.090157
Y Loss: 0.321825
T Loss: 13.008450
Epoch 849 
Overall Loss: 13.239908
Rec Loss: 13.152764
KL Loss: 0.087143
Y Loss: 0.296041
T Loss: 13.004744
Epoch 899 
Overall Loss: 13.222759
Rec Loss: 13.137987
KL Loss: 0.084772
Y Loss: 0.271502
T Loss: 13.002236
Epoch 949 
Overall Loss: 13.211851
Rec Loss: 13.129144
KL Loss: 0.082706
Y Loss: 0.252362
T Loss: 13.002964
Epoch 999 
Overall Loss: 13.200013
Rec Loss: 13.118059
KL Loss: 0.081954
Y Loss: 0.243467
T Loss: 12.996325
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.343382
Epoch 99
Rec Loss: 1.338787
Epoch 149
Rec Loss: 1.341307
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.029631
Epoch 99
Rec Loss: 10.022966
Epoch 149
Rec Loss: 10.019863
Epoch 199
Rec Loss: 10.015872
Epoch 249
Rec Loss: 10.017884
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.412165
Insample Error: 0.900431
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 24.769510
Rec Loss: 23.169822
KL Loss: 1.599688
Y Loss: 8.182077
T Loss: 13.253287
Epoch 99 
Overall Loss: 21.809461
Rec Loss: 19.606703
KL Loss: 2.202758
Y Loss: 2.816783
T Loss: 13.220964
Epoch 149 
Overall Loss: 20.766000
Rec Loss: 17.747739
KL Loss: 3.018261
Y Loss: 1.842756
T Loss: 13.132686
Epoch 199 
Overall Loss: 20.276416
Rec Loss: 16.787915
KL Loss: 3.488501
Y Loss: 1.530425
T Loss: 13.131046
Epoch 249 
Overall Loss: 19.996043
Rec Loss: 16.178693
KL Loss: 3.817350
Y Loss: 1.325171
T Loss: 13.122764
Epoch 299 
Overall Loss: 19.826820
Rec Loss: 15.742497
KL Loss: 4.084324
Y Loss: 1.215629
T Loss: 13.111918
Epoch 349 
Overall Loss: 19.704342
Rec Loss: 15.338503
KL Loss: 4.365840
Y Loss: 1.114383
T Loss: 13.090119
Epoch 399 
Overall Loss: 19.612112
Rec Loss: 15.052125
KL Loss: 4.559986
Y Loss: 1.065574
T Loss: 13.065168
Epoch 449 
Overall Loss: 19.583128
Rec Loss: 14.882284
KL Loss: 4.700843
Y Loss: 1.039931
T Loss: 13.054113
Epoch 499 
Overall Loss: 19.540999
Rec Loss: 14.748158
KL Loss: 4.792840
Y Loss: 0.995914
T Loss: 13.042954
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.714599
Epoch 99
Rec Loss: 1.710529
Epoch 149
Rec Loss: 1.709622
Epoch 199
Rec Loss: 1.712342
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.839129
Epoch 99
Rec Loss: 5.833931
Epoch 149
Rec Loss: 5.816799
Epoch 199
Rec Loss: 5.827356
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.569272
Insample Error 1.783643
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.918628
Rec Loss: 15.329598
KL Loss: 0.589030
Y Loss: 4.236157
T Loss: 13.211519
Epoch 99 
Overall Loss: 14.157245
Rec Loss: 13.894500
KL Loss: 0.262746
Y Loss: 1.485193
T Loss: 13.151903
Epoch 149 
Overall Loss: 13.818431
Rec Loss: 13.633395
KL Loss: 0.185037
Y Loss: 1.066117
T Loss: 13.100336
Epoch 199 
Overall Loss: 13.717951
Rec Loss: 13.542332
KL Loss: 0.175619
Y Loss: 0.948404
T Loss: 13.068130
Epoch 249 
Overall Loss: 13.653626
Rec Loss: 13.497086
KL Loss: 0.156540
Y Loss: 0.884851
T Loss: 13.054660
Epoch 299 
Overall Loss: 13.605003
Rec Loss: 13.465958
KL Loss: 0.139044
Y Loss: 0.831022
T Loss: 13.050447
Epoch 349 
Overall Loss: 13.555805
Rec Loss: 13.431080
KL Loss: 0.124726
Y Loss: 0.765163
T Loss: 13.048498
Epoch 399 
Overall Loss: 13.504634
Rec Loss: 13.391902
KL Loss: 0.112732
Y Loss: 0.688483
T Loss: 13.047660
Epoch 449 
Overall Loss: 13.458281
Rec Loss: 13.356628
KL Loss: 0.101653
Y Loss: 0.614684
T Loss: 13.049286
Epoch 499 
Overall Loss: 13.420762
Rec Loss: 13.327713
KL Loss: 0.093049
Y Loss: 0.562348
T Loss: 13.046539
Epoch 549 
Overall Loss: 13.382732
Rec Loss: 13.298307
KL Loss: 0.084424
Y Loss: 0.499542
T Loss: 13.048536
Epoch 599 
Overall Loss: 13.344610
Rec Loss: 13.267280
KL Loss: 0.077330
Y Loss: 0.446339
T Loss: 13.044110
Epoch 649 
Overall Loss: 13.318184
Rec Loss: 13.245964
KL Loss: 0.072220
Y Loss: 0.397989
T Loss: 13.046970
Epoch 699 
Overall Loss: 13.286898
Rec Loss: 13.221058
KL Loss: 0.065840
Y Loss: 0.354925
T Loss: 13.043596
Epoch 749 
Overall Loss: 13.264181
Rec Loss: 13.202722
KL Loss: 0.061459
Y Loss: 0.319458
T Loss: 13.042993
Epoch 799 
Overall Loss: 13.252334
Rec Loss: 13.195167
KL Loss: 0.057167
Y Loss: 0.294536
T Loss: 13.047899
Epoch 849 
Overall Loss: 13.236640
Rec Loss: 13.183421
KL Loss: 0.053218
Y Loss: 0.275157
T Loss: 13.045843
Epoch 899 
Overall Loss: 13.221301
Rec Loss: 13.171276
KL Loss: 0.050025
Y Loss: 0.253994
T Loss: 13.044279
Epoch 949 
Overall Loss: 13.211779
Rec Loss: 13.164419
KL Loss: 0.047361
Y Loss: 0.244052
T Loss: 13.042392
Epoch 999 
Overall Loss: 13.204252
Rec Loss: 13.158265
KL Loss: 0.045988
Y Loss: 0.237011
T Loss: 13.039759
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.475775
Epoch 99
Rec Loss: 1.465651
Epoch 149
Rec Loss: 1.468875
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.024384
Epoch 99
Rec Loss: 10.014558
Epoch 149
Rec Loss: 10.022283
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.417714
Insample Error: 0.841952
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 24.833210
Rec Loss: 23.212204
KL Loss: 1.621006
Y Loss: 7.948737
T Loss: 13.294880
Epoch 99 
Overall Loss: 21.852470
Rec Loss: 19.880901
KL Loss: 1.971570
Y Loss: 2.531691
T Loss: 13.225639
Epoch 149 
Overall Loss: 20.658505
Rec Loss: 17.721134
KL Loss: 2.937371
Y Loss: 1.711023
T Loss: 13.172749
Epoch 199 
Overall Loss: 20.175096
Rec Loss: 16.693775
KL Loss: 3.481321
Y Loss: 1.456411
T Loss: 13.143484
Epoch 249 
Overall Loss: 20.023889
Rec Loss: 16.296081
KL Loss: 3.727808
Y Loss: 1.330860
T Loss: 13.126175
Epoch 299 
Overall Loss: 19.890317
Rec Loss: 15.929578
KL Loss: 3.960739
Y Loss: 1.219595
T Loss: 13.104600
Epoch 349 
Overall Loss: 19.815729
Rec Loss: 15.667184
KL Loss: 4.148545
Y Loss: 1.179421
T Loss: 13.086656
Epoch 399 
Overall Loss: 19.706219
Rec Loss: 15.382948
KL Loss: 4.323271
Y Loss: 1.103309
T Loss: 13.076743
Epoch 449 
Overall Loss: 19.675790
Rec Loss: 15.208754
KL Loss: 4.467036
Y Loss: 1.094114
T Loss: 13.064373
Epoch 499 
Overall Loss: 19.593048
Rec Loss: 14.958912
KL Loss: 4.634137
Y Loss: 1.040031
T Loss: 13.051070
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.734057
Epoch 99
Rec Loss: 1.722501
Epoch 149
Rec Loss: 1.729227
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.876213
Epoch 99
Rec Loss: 5.863155
Epoch 149
Rec Loss: 5.852506
Epoch 199
Rec Loss: 5.871303
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.594958
Insample Error 1.839521
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.574763
Rec Loss: 14.966478
KL Loss: 0.608285
Y Loss: 3.538026
T Loss: 13.197465
Epoch 99 
Overall Loss: 14.130782
Rec Loss: 13.866286
KL Loss: 0.264496
Y Loss: 1.454532
T Loss: 13.139020
Epoch 149 
Overall Loss: 13.820972
Rec Loss: 13.629840
KL Loss: 0.191132
Y Loss: 1.070206
T Loss: 13.094737
Epoch 199 
Overall Loss: 13.712483
Rec Loss: 13.532124
KL Loss: 0.180359
Y Loss: 0.922132
T Loss: 13.071059
Epoch 249 
Overall Loss: 13.648865
Rec Loss: 13.482137
KL Loss: 0.166728
Y Loss: 0.855274
T Loss: 13.054500
Epoch 299 
Overall Loss: 13.620793
Rec Loss: 13.467816
KL Loss: 0.152978
Y Loss: 0.822498
T Loss: 13.056567
Epoch 349 
Overall Loss: 13.567815
Rec Loss: 13.428267
KL Loss: 0.139548
Y Loss: 0.763462
T Loss: 13.046536
Epoch 399 
Overall Loss: 13.539664
Rec Loss: 13.405968
KL Loss: 0.133696
Y Loss: 0.728070
T Loss: 13.041933
Epoch 449 
Overall Loss: 13.504248
Rec Loss: 13.375278
KL Loss: 0.128970
Y Loss: 0.690803
T Loss: 13.029877
Epoch 499 
Overall Loss: 13.481763
Rec Loss: 13.349810
KL Loss: 0.131952
Y Loss: 0.649738
T Loss: 13.024942
Epoch 549 
Overall Loss: 13.435850
Rec Loss: 13.303242
KL Loss: 0.132608
Y Loss: 0.584822
T Loss: 13.010831
Epoch 599 
Overall Loss: 13.397627
Rec Loss: 13.263235
KL Loss: 0.134392
Y Loss: 0.526066
T Loss: 13.000202
Epoch 649 
Overall Loss: 13.361842
Rec Loss: 13.230084
KL Loss: 0.131757
Y Loss: 0.482016
T Loss: 12.989077
Epoch 699 
Overall Loss: 13.332627
Rec Loss: 13.205145
KL Loss: 0.127482
Y Loss: 0.436952
T Loss: 12.986669
Epoch 749 
Overall Loss: 13.300332
Rec Loss: 13.181695
KL Loss: 0.118638
Y Loss: 0.386215
T Loss: 12.988587
Epoch 799 
Overall Loss: 13.287362
Rec Loss: 13.176642
KL Loss: 0.110719
Y Loss: 0.363351
T Loss: 12.994967
Epoch 849 
Overall Loss: 13.255860
Rec Loss: 13.152511
KL Loss: 0.103349
Y Loss: 0.319428
T Loss: 12.992796
Epoch 899 
Overall Loss: 13.237740
Rec Loss: 13.142169
KL Loss: 0.095572
Y Loss: 0.289577
T Loss: 12.997380
Epoch 949 
Overall Loss: 13.221142
Rec Loss: 13.131313
KL Loss: 0.089829
Y Loss: 0.268023
T Loss: 12.997302
Epoch 999 
Overall Loss: 13.206795
Rec Loss: 13.121005
KL Loss: 0.085791
Y Loss: 0.247434
T Loss: 12.997288
Epoch 1049 
Overall Loss: 13.189997
Rec Loss: 13.107233
KL Loss: 0.082764
Y Loss: 0.232054
T Loss: 12.991206
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.371860
Epoch 99
Rec Loss: 1.368410
Epoch 149
Rec Loss: 1.362796
Epoch 199
Rec Loss: 1.366752
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.001019
Epoch 99
Rec Loss: 9.984530
Epoch 149
Rec Loss: 9.994898
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.412398
Insample Error: 0.892703
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 23.691324
Rec Loss: 21.844057
KL Loss: 1.847268
Y Loss: 5.347566
T Loss: 13.272193
Epoch 99 
Overall Loss: 21.593101
Rec Loss: 19.709785
KL Loss: 1.883316
Y Loss: 2.331082
T Loss: 13.194055
Epoch 149 
Overall Loss: 20.777122
Rec Loss: 18.428121
KL Loss: 2.349001
Y Loss: 1.627123
T Loss: 13.120433
Epoch 199 
Overall Loss: 20.352098
Rec Loss: 17.633864
KL Loss: 2.718235
Y Loss: 1.325856
T Loss: 13.081799
Epoch 249 
Overall Loss: 20.006709
Rec Loss: 16.833761
KL Loss: 3.172949
Y Loss: 1.170769
T Loss: 13.091796
Epoch 299 
Overall Loss: 19.849549
Rec Loss: 16.527691
KL Loss: 3.321858
Y Loss: 1.069742
T Loss: 13.092059
Epoch 349 
Overall Loss: 19.750965
Rec Loss: 16.324719
KL Loss: 3.426245
Y Loss: 0.969700
T Loss: 13.070517
Epoch 399 
Overall Loss: 19.718522
Rec Loss: 16.217194
KL Loss: 3.501328
Y Loss: 0.940845
T Loss: 13.059298
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.720364
Epoch 99
Rec Loss: 1.718012
Epoch 149
Rec Loss: 1.722068
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.273574
Epoch 99
Rec Loss: 6.272716
Epoch 149
Rec Loss: 6.278111
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.598262
Insample Error 1.878088
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.592260
Rec Loss: 14.982164
KL Loss: 0.610096
Y Loss: 3.494258
T Loss: 13.235036
Epoch 99 
Overall Loss: 14.273208
Rec Loss: 13.967471
KL Loss: 0.305737
Y Loss: 1.583291
T Loss: 13.175826
Epoch 149 
Overall Loss: 13.830947
Rec Loss: 13.653946
KL Loss: 0.177001
Y Loss: 1.096228
T Loss: 13.105832
Epoch 199 
Overall Loss: 13.721097
Rec Loss: 13.550099
KL Loss: 0.170999
Y Loss: 0.954671
T Loss: 13.072763
Epoch 249 
Overall Loss: 13.648980
Rec Loss: 13.494418
KL Loss: 0.154561
Y Loss: 0.871350
T Loss: 13.058743
Epoch 299 
Overall Loss: 13.607374
Rec Loss: 13.468792
KL Loss: 0.138581
Y Loss: 0.825848
T Loss: 13.055868
Epoch 349 
Overall Loss: 13.565741
Rec Loss: 13.440590
KL Loss: 0.125151
Y Loss: 0.764143
T Loss: 13.058519
Epoch 399 
Overall Loss: 13.529192
Rec Loss: 13.414247
KL Loss: 0.114945
Y Loss: 0.730945
T Loss: 13.048775
Epoch 449 
Overall Loss: 13.480768
Rec Loss: 13.373592
KL Loss: 0.107176
Y Loss: 0.644497
T Loss: 13.051344
Epoch 499 
Overall Loss: 13.441182
Rec Loss: 13.339529
KL Loss: 0.101653
Y Loss: 0.584366
T Loss: 13.047345
Epoch 549 
Overall Loss: 13.402085
Rec Loss: 13.306635
KL Loss: 0.095450
Y Loss: 0.526178
T Loss: 13.043546
Epoch 599 
Overall Loss: 13.370864
Rec Loss: 13.279869
KL Loss: 0.090995
Y Loss: 0.476262
T Loss: 13.041738
Epoch 649 
Overall Loss: 13.335548
Rec Loss: 13.249089
KL Loss: 0.086460
Y Loss: 0.423119
T Loss: 13.037530
Epoch 699 
Overall Loss: 13.310819
Rec Loss: 13.227290
KL Loss: 0.083529
Y Loss: 0.389244
T Loss: 13.032668
Epoch 749 
Overall Loss: 13.287422
Rec Loss: 13.206745
KL Loss: 0.080677
Y Loss: 0.355187
T Loss: 13.029152
Epoch 799 
Overall Loss: 13.269377
Rec Loss: 13.192070
KL Loss: 0.077307
Y Loss: 0.323265
T Loss: 13.030438
Epoch 849 
Overall Loss: 13.252979
Rec Loss: 13.178580
KL Loss: 0.074398
Y Loss: 0.304635
T Loss: 13.026263
Epoch 899 
Overall Loss: 13.237384
Rec Loss: 13.165308
KL Loss: 0.072076
Y Loss: 0.280802
T Loss: 13.024907
Epoch 949 
Overall Loss: 13.225208
Rec Loss: 13.155632
KL Loss: 0.069576
Y Loss: 0.265863
T Loss: 13.022700
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.385440
Epoch 99
Rec Loss: 1.388555
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.967316
Epoch 99
Rec Loss: 9.947641
Epoch 149
Rec Loss: 9.944659
Epoch 199
Rec Loss: 9.942278
Epoch 249
Rec Loss: 9.944912
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.434292
Insample Error: 0.926201
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 24.516259
Rec Loss: 22.896041
KL Loss: 1.620218
Y Loss: 7.526529
T Loss: 13.273099
Epoch 99 
Overall Loss: 21.664725
Rec Loss: 19.675995
KL Loss: 1.988730
Y Loss: 2.563065
T Loss: 13.204395
Epoch 149 
Overall Loss: 20.693669
Rec Loss: 18.126309
KL Loss: 2.567360
Y Loss: 1.573598
T Loss: 13.169309
Epoch 199 
Overall Loss: 20.318017
Rec Loss: 17.630562
KL Loss: 2.687455
Y Loss: 1.307385
T Loss: 13.133546
Epoch 249 
Overall Loss: 20.100316
Rec Loss: 17.264088
KL Loss: 2.836228
Y Loss: 1.134100
T Loss: 13.103358
Epoch 299 
Overall Loss: 19.863952
Rec Loss: 16.603956
KL Loss: 3.259996
Y Loss: 1.002292
T Loss: 13.082051
Epoch 349 
Overall Loss: 19.781361
Rec Loss: 16.430312
KL Loss: 3.351049
Y Loss: 0.961796
T Loss: 13.063565
Epoch 399 
Overall Loss: 19.701951
Rec Loss: 16.263751
KL Loss: 3.438200
Y Loss: 0.884889
T Loss: 13.053354
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.713763
Epoch 99
Rec Loss: 1.708573
Epoch 149
Rec Loss: 1.710548
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.334303
Epoch 99
Rec Loss: 6.318583
Epoch 149
Rec Loss: 6.317994
Epoch 199
Rec Loss: 6.320285
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.572418
Insample Error 1.787656
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.661119
Rec Loss: 14.984065
KL Loss: 0.677054
Y Loss: 3.544039
T Loss: 13.212046
Epoch 99 
Overall Loss: 14.264612
Rec Loss: 13.922687
KL Loss: 0.341925
Y Loss: 1.510887
T Loss: 13.167243
Epoch 149 
Overall Loss: 13.817287
Rec Loss: 13.622672
KL Loss: 0.194616
Y Loss: 1.049603
T Loss: 13.097870
Epoch 199 
Overall Loss: 13.705072
Rec Loss: 13.529260
KL Loss: 0.175812
Y Loss: 0.924756
T Loss: 13.066882
Epoch 249 
Overall Loss: 13.643634
Rec Loss: 13.486698
KL Loss: 0.156936
Y Loss: 0.857846
T Loss: 13.057775
Epoch 299 
Overall Loss: 13.601553
Rec Loss: 13.459439
KL Loss: 0.142114
Y Loss: 0.804373
T Loss: 13.057253
Epoch 349 
Overall Loss: 13.564868
Rec Loss: 13.434312
KL Loss: 0.130556
Y Loss: 0.764480
T Loss: 13.052072
Epoch 399 
Overall Loss: 13.523552
Rec Loss: 13.397986
KL Loss: 0.125566
Y Loss: 0.710372
T Loss: 13.042800
Epoch 449 
Overall Loss: 13.486420
Rec Loss: 13.366422
KL Loss: 0.119998
Y Loss: 0.661299
T Loss: 13.035772
Epoch 499 
Overall Loss: 13.449685
Rec Loss: 13.330842
KL Loss: 0.118842
Y Loss: 0.595879
T Loss: 13.032903
Epoch 549 
Overall Loss: 13.406303
Rec Loss: 13.292613
KL Loss: 0.113690
Y Loss: 0.537722
T Loss: 13.023752
Epoch 599 
Overall Loss: 13.373899
Rec Loss: 13.263057
KL Loss: 0.110843
Y Loss: 0.473246
T Loss: 13.026433
Epoch 649 
Overall Loss: 13.337585
Rec Loss: 13.233646
KL Loss: 0.103938
Y Loss: 0.419898
T Loss: 13.023698
Epoch 699 
Overall Loss: 13.301313
Rec Loss: 13.204099
KL Loss: 0.097213
Y Loss: 0.365111
T Loss: 13.021544
Epoch 749 
Overall Loss: 13.273035
Rec Loss: 13.184238
KL Loss: 0.088797
Y Loss: 0.334502
T Loss: 13.016987
Epoch 799 
Overall Loss: 13.253237
Rec Loss: 13.171108
KL Loss: 0.082129
Y Loss: 0.298905
T Loss: 13.021656
Epoch 849 
Overall Loss: 13.233313
Rec Loss: 13.156988
KL Loss: 0.076326
Y Loss: 0.275507
T Loss: 13.019234
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.450327
Epoch 99
Rec Loss: 1.446778
Epoch 149
Rec Loss: 1.448447
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.063458
Epoch 99
Rec Loss: 10.059511
Epoch 149
Rec Loss: 10.062343
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.433640
Insample Error: 0.991060
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 24.197059
Rec Loss: 22.461165
KL Loss: 1.735894
Y Loss: 6.725400
T Loss: 13.283405
Epoch 99 
Overall Loss: 21.674996
Rec Loss: 19.574202
KL Loss: 2.100794
Y Loss: 2.450077
T Loss: 13.230847
Epoch 149 
Overall Loss: 20.831460
Rec Loss: 18.286296
KL Loss: 2.545164
Y Loss: 1.756117
T Loss: 13.162659
Epoch 199 
Overall Loss: 20.434459
Rec Loss: 17.635018
KL Loss: 2.799441
Y Loss: 1.398535
T Loss: 13.124602
Epoch 249 
Overall Loss: 20.086188
Rec Loss: 16.743434
KL Loss: 3.342754
Y Loss: 1.264426
T Loss: 13.108686
Epoch 299 
Overall Loss: 19.908043
Rec Loss: 16.259403
KL Loss: 3.648640
Y Loss: 1.163740
T Loss: 13.102472
Epoch 349 
Overall Loss: 19.794734
Rec Loss: 15.910438
KL Loss: 3.884296
Y Loss: 1.089250
T Loss: 13.076601
Epoch 399 
Overall Loss: 19.720560
Rec Loss: 15.646235
KL Loss: 4.074326
Y Loss: 1.034201
T Loss: 13.064336
Epoch 449 
Overall Loss: 19.627234
Rec Loss: 15.422579
KL Loss: 4.204654
Y Loss: 0.990758
T Loss: 13.049635
Epoch 499 
Overall Loss: 19.558836
Rec Loss: 15.197155
KL Loss: 4.361681
Y Loss: 0.942911
T Loss: 13.038878
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.710335
Epoch 99
Rec Loss: 1.711957
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.956659
Epoch 99
Rec Loss: 5.952508
Epoch 149
Rec Loss: 5.953886
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.574808
Insample Error 1.824289
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.486536
Rec Loss: 14.912919
KL Loss: 0.573617
Y Loss: 3.383802
T Loss: 13.221018
Epoch 99 
Overall Loss: 14.272419
Rec Loss: 13.930822
KL Loss: 0.341597
Y Loss: 1.521863
T Loss: 13.169890
Epoch 149 
Overall Loss: 13.816686
Rec Loss: 13.612469
KL Loss: 0.204217
Y Loss: 1.025681
T Loss: 13.099629
Epoch 199 
Overall Loss: 13.692828
Rec Loss: 13.504256
KL Loss: 0.188572
Y Loss: 0.866574
T Loss: 13.070970
Epoch 249 
Overall Loss: 13.634847
Rec Loss: 13.466096
KL Loss: 0.168752
Y Loss: 0.820509
T Loss: 13.055842
Epoch 299 
Overall Loss: 13.583377
Rec Loss: 13.432198
KL Loss: 0.151180
Y Loss: 0.769993
T Loss: 13.047201
Epoch 349 
Overall Loss: 13.541857
Rec Loss: 13.400461
KL Loss: 0.141396
Y Loss: 0.716068
T Loss: 13.042428
Epoch 399 
Overall Loss: 13.499819
Rec Loss: 13.366762
KL Loss: 0.133057
Y Loss: 0.676509
T Loss: 13.028508
Epoch 449 
Overall Loss: 13.469804
Rec Loss: 13.338246
KL Loss: 0.131558
Y Loss: 0.617064
T Loss: 13.029714
Epoch 499 
Overall Loss: 13.427236
Rec Loss: 13.298779
KL Loss: 0.128457
Y Loss: 0.563559
T Loss: 13.017000
Epoch 549 
Overall Loss: 13.397711
Rec Loss: 13.270524
KL Loss: 0.127187
Y Loss: 0.520596
T Loss: 13.010226
Epoch 599 
Overall Loss: 13.360476
Rec Loss: 13.240187
KL Loss: 0.120289
Y Loss: 0.480603
T Loss: 12.999885
Epoch 649 
Overall Loss: 13.333688
Rec Loss: 13.220560
KL Loss: 0.113128
Y Loss: 0.433337
T Loss: 13.003891
Epoch 699 
Overall Loss: 13.305802
Rec Loss: 13.197346
KL Loss: 0.108455
Y Loss: 0.391212
T Loss: 13.001741
Epoch 749 
Overall Loss: 13.272868
Rec Loss: 13.171332
KL Loss: 0.101536
Y Loss: 0.343348
T Loss: 12.999658
Epoch 799 
Overall Loss: 13.255473
Rec Loss: 13.160933
KL Loss: 0.094540
Y Loss: 0.312326
T Loss: 13.004770
Epoch 849 
Overall Loss: 13.239106
Rec Loss: 13.149803
KL Loss: 0.089303
Y Loss: 0.286752
T Loss: 13.006427
Epoch 899 
Overall Loss: 13.222651
Rec Loss: 13.137782
KL Loss: 0.084870
Y Loss: 0.264287
T Loss: 13.005638
Epoch 949 
Overall Loss: 13.206119
Rec Loss: 13.126003
KL Loss: 0.080116
Y Loss: 0.244076
T Loss: 13.003965
Epoch 999 
Overall Loss: 13.192158
Rec Loss: 13.114859
KL Loss: 0.077298
Y Loss: 0.231488
T Loss: 12.999115
Epoch 1049 
Overall Loss: 13.181906
Rec Loss: 13.107176
KL Loss: 0.074731
Y Loss: 0.223335
T Loss: 12.995508
Epoch 1099 
Overall Loss: 13.176233
Rec Loss: 13.102367
KL Loss: 0.073866
Y Loss: 0.215199
T Loss: 12.994768
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.291345
Epoch 99
Rec Loss: 1.284125
Epoch 149
Rec Loss: 1.283471
Epoch 199
Rec Loss: 1.288637
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.003232
Epoch 99
Rec Loss: 10.011548
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.399191
Insample Error: 0.792203
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 24.392836
Rec Loss: 22.677141
KL Loss: 1.715695
Y Loss: 6.952594
T Loss: 13.312497
Epoch 99 
Overall Loss: 21.647505
Rec Loss: 19.420238
KL Loss: 2.227267
Y Loss: 2.488816
T Loss: 13.227429
Epoch 149 
Overall Loss: 20.721101
Rec Loss: 17.806325
KL Loss: 2.914776
Y Loss: 1.767601
T Loss: 13.135510
Epoch 199 
Overall Loss: 20.277585
Rec Loss: 16.918928
KL Loss: 3.358657
Y Loss: 1.484864
T Loss: 13.131149
Epoch 249 
Overall Loss: 20.032663
Rec Loss: 16.450830
KL Loss: 3.581833
Y Loss: 1.299571
T Loss: 13.121372
Epoch 299 
Overall Loss: 19.853433
Rec Loss: 16.093842
KL Loss: 3.759592
Y Loss: 1.120276
T Loss: 13.100513
Epoch 349 
Overall Loss: 19.754876
Rec Loss: 15.918787
KL Loss: 3.836089
Y Loss: 1.048806
T Loss: 13.082909
Epoch 399 
Overall Loss: 19.693242
Rec Loss: 15.720936
KL Loss: 3.972306
Y Loss: 0.991522
T Loss: 13.060595
Epoch 449 
Overall Loss: 19.654981
Rec Loss: 15.578835
KL Loss: 4.076146
Y Loss: 0.980194
T Loss: 13.045891
Epoch 499 
Overall Loss: 19.616136
Rec Loss: 15.443430
KL Loss: 4.172706
Y Loss: 0.948139
T Loss: 13.029522
Epoch 549 
Overall Loss: 19.552445
Rec Loss: 15.293079
KL Loss: 4.259366
Y Loss: 0.893319
T Loss: 13.023726
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.697574
Epoch 99
Rec Loss: 1.695468
Epoch 149
Rec Loss: 1.693039
Epoch 199
Rec Loss: 1.697594
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.004549
Epoch 99
Rec Loss: 5.997633
Epoch 149
Rec Loss: 5.984445
Epoch 199
Rec Loss: 5.985610
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.545358
Insample Error 1.898291
Ours, Train RMSE
0.4116, 
0.4131, 
0.4166, 
0.3848, 
0.4122, 
0.4177, 
0.4124, 
0.4343, 
0.4336, 
0.3992, 
Ours, Insample RMSE
0.8964, 
0.8355, 
0.9391, 
0.6996, 
0.9004, 
0.8420, 
0.8927, 
0.9262, 
0.9911, 
0.7922, 
CEVAE, Insample RMSE
1.8098, 
1.8690, 
1.8171, 
1.7986, 
1.7836, 
1.8395, 
1.8781, 
1.7877, 
1.8243, 
1.8983, 
Train, RMSE mean 0.4135 std 0.0138
Ours, RMSE mean 0.8715 std 0.0786, reconstruct confounder 1.3891 (0.0630) noise 9.9983 (0.0394)
CEVAE, RMSE mean 1.8306 std 0.0376, reconstruct confounder 1.7108 (0.0123) noise 6.0021 (0.1554)
Experiment Start!
Namespace(decay=0.0, l=5e-05, latdim=4, mask=0, nlayer=50, obsm=4, ycof=4.0, ylayer=50)
Y Mean 1.192369, Std 4.040208 
Observe confounder 4, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 24.194536
Rec Loss: 22.451259
KL Loss: 1.743276
Y Loss: 2.314828
T Loss: 13.191949
Epoch 99 
Overall Loss: 18.228270
Rec Loss: 16.747026
KL Loss: 1.481244
Y Loss: 0.882886
T Loss: 13.215481
Epoch 149 
Overall Loss: 16.672781
Rec Loss: 15.659366
KL Loss: 1.013414
Y Loss: 0.615069
T Loss: 13.199092
Epoch 199 
Overall Loss: 15.832311
Rec Loss: 14.944355
KL Loss: 0.887956
Y Loss: 0.446659
T Loss: 13.157718
Epoch 249 
Overall Loss: 15.390063
Rec Loss: 14.478212
KL Loss: 0.911851
Y Loss: 0.339539
T Loss: 13.120056
Epoch 299 
Overall Loss: 15.074491
Rec Loss: 14.125163
KL Loss: 0.949327
Y Loss: 0.263137
T Loss: 13.072615
Epoch 349 
Overall Loss: 14.805950
Rec Loss: 13.808948
KL Loss: 0.997002
Y Loss: 0.200399
T Loss: 13.007352
Epoch 399 
Overall Loss: 14.598295
Rec Loss: 13.578647
KL Loss: 1.019648
Y Loss: 0.159290
T Loss: 12.941486
Epoch 449 
Overall Loss: 14.494119
Rec Loss: 13.464612
KL Loss: 1.029507
Y Loss: 0.141151
T Loss: 12.900010
Epoch 499 
Overall Loss: 14.437286
Rec Loss: 13.420463
KL Loss: 1.016823
Y Loss: 0.132825
T Loss: 12.889161
Epoch 549 
Overall Loss: 14.397965
Rec Loss: 13.399691
KL Loss: 0.998273
Y Loss: 0.130438
T Loss: 12.877940
Epoch 599 
Overall Loss: 14.364961
Rec Loss: 13.387548
KL Loss: 0.977413
Y Loss: 0.127684
T Loss: 12.876811
Epoch 649 
Overall Loss: 14.317740
Rec Loss: 13.362336
KL Loss: 0.955405
Y Loss: 0.122896
T Loss: 12.870751
Epoch 699 
Overall Loss: 14.289249
Rec Loss: 13.350428
KL Loss: 0.938821
Y Loss: 0.121301
T Loss: 12.865225
Epoch 749 
Overall Loss: 14.260688
Rec Loss: 13.333422
KL Loss: 0.927265
Y Loss: 0.118265
T Loss: 12.860364
Epoch 799 
Overall Loss: 14.257219
Rec Loss: 13.339697
KL Loss: 0.917523
Y Loss: 0.118845
T Loss: 12.864315
Epoch 849 
Overall Loss: 14.232677
Rec Loss: 13.336999
KL Loss: 0.895678
Y Loss: 0.117980
T Loss: 12.865078
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.555890
Epoch 99
Rec Loss: 1.552017
Epoch 149
Rec Loss: 1.550474
Epoch 199
Rec Loss: 1.550618
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.077527
Epoch 99
Rec Loss: 10.076387
Epoch 149
Rec Loss: 10.078276
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.145369
Insample Error: 2.089076
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 36.593509
Rec Loss: 28.991371
KL Loss: 7.602139
Y Loss: 2.514507
T Loss: 13.215418
Epoch 99 
Overall Loss: 27.075950
Rec Loss: 22.231823
KL Loss: 4.844127
Y Loss: 0.839555
T Loss: 13.276736
Epoch 149 
Overall Loss: 25.195127
Rec Loss: 20.701382
KL Loss: 4.493745
Y Loss: 0.620433
T Loss: 13.258103
Epoch 199 
Overall Loss: 24.193736
Rec Loss: 19.711688
KL Loss: 4.482048
Y Loss: 0.506020
T Loss: 13.206190
Epoch 249 
Overall Loss: 23.100225
Rec Loss: 18.488891
KL Loss: 4.611334
Y Loss: 0.395021
T Loss: 13.170653
Epoch 299 
Overall Loss: 22.388701
Rec Loss: 17.368418
KL Loss: 5.020284
Y Loss: 0.322349
T Loss: 13.169882
Epoch 349 
Overall Loss: 22.068127
Rec Loss: 16.759788
KL Loss: 5.308338
Y Loss: 0.288120
T Loss: 13.184226
Epoch 399 
Overall Loss: 21.763842
Rec Loss: 16.278737
KL Loss: 5.485105
Y Loss: 0.265405
T Loss: 13.184304
Epoch 449 
Overall Loss: 21.630170
Rec Loss: 15.936226
KL Loss: 5.693944
Y Loss: 0.256638
T Loss: 13.182215
Epoch 499 
Overall Loss: 21.439633
Rec Loss: 15.562017
KL Loss: 5.877617
Y Loss: 0.231846
T Loss: 13.178145
Epoch 549 
Overall Loss: 21.229805
Rec Loss: 15.145101
KL Loss: 6.084704
Y Loss: 0.203479
T Loss: 13.167378
Epoch 599 
Overall Loss: 21.072869
Rec Loss: 14.790657
KL Loss: 6.282212
Y Loss: 0.188148
T Loss: 13.159790
Epoch 649 
Overall Loss: 20.967503
Rec Loss: 14.551058
KL Loss: 6.416445
Y Loss: 0.179671
T Loss: 13.144263
Epoch 699 
Overall Loss: 20.918414
Rec Loss: 14.368111
KL Loss: 6.550303
Y Loss: 0.178199
T Loss: 13.126833
Epoch 749 
Overall Loss: 20.851956
Rec Loss: 14.210145
KL Loss: 6.641811
Y Loss: 0.174827
T Loss: 13.117880
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.779053
Epoch 99
Rec Loss: 1.772150
Epoch 149
Rec Loss: 1.775207
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.840476
Epoch 99
Rec Loss: 5.826189
Epoch 149
Rec Loss: 5.849975
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.160480
Insample Error 2.065278
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 24.193318
Rec Loss: 22.221955
KL Loss: 1.971363
Y Loss: 2.258082
T Loss: 13.189626
Epoch 99 
Overall Loss: 17.990065
Rec Loss: 16.784471
KL Loss: 1.205594
Y Loss: 0.892512
T Loss: 13.214422
Epoch 149 
Overall Loss: 16.767485
Rec Loss: 15.845964
KL Loss: 0.921521
Y Loss: 0.659549
T Loss: 13.207766
Epoch 199 
Overall Loss: 16.097466
Rec Loss: 15.274231
KL Loss: 0.823235
Y Loss: 0.523201
T Loss: 13.181427
Epoch 249 
Overall Loss: 15.728063
Rec Loss: 14.901171
KL Loss: 0.826892
Y Loss: 0.434897
T Loss: 13.161582
Epoch 299 
Overall Loss: 15.389980
Rec Loss: 14.535852
KL Loss: 0.854128
Y Loss: 0.350037
T Loss: 13.135704
Epoch 349 
Overall Loss: 15.166049
Rec Loss: 14.278567
KL Loss: 0.887482
Y Loss: 0.290270
T Loss: 13.117487
Epoch 399 
Overall Loss: 15.023902
Rec Loss: 14.098492
KL Loss: 0.925411
Y Loss: 0.250625
T Loss: 13.095993
Epoch 449 
Overall Loss: 14.885280
Rec Loss: 13.942288
KL Loss: 0.942992
Y Loss: 0.217003
T Loss: 13.074276
Epoch 499 
Overall Loss: 14.775583
Rec Loss: 13.811229
KL Loss: 0.964354
Y Loss: 0.193411
T Loss: 13.037586
Epoch 549 
Overall Loss: 14.605225
Rec Loss: 13.626623
KL Loss: 0.978601
Y Loss: 0.162698
T Loss: 12.975830
Epoch 599 
Overall Loss: 14.506934
Rec Loss: 13.511450
KL Loss: 0.995484
Y Loss: 0.145530
T Loss: 12.929331
Epoch 649 
Overall Loss: 14.413950
Rec Loss: 13.440503
KL Loss: 0.973447
Y Loss: 0.134041
T Loss: 12.904338
Epoch 699 
Overall Loss: 14.353704
Rec Loss: 13.408171
KL Loss: 0.945533
Y Loss: 0.128145
T Loss: 12.895590
Epoch 749 
Overall Loss: 14.314269
Rec Loss: 13.389408
KL Loss: 0.924861
Y Loss: 0.126263
T Loss: 12.884355
Epoch 799 
Overall Loss: 14.262163
Rec Loss: 13.363663
KL Loss: 0.898500
Y Loss: 0.121383
T Loss: 12.878133
Epoch 849 
Overall Loss: 14.239869
Rec Loss: 13.368595
KL Loss: 0.871274
Y Loss: 0.125414
T Loss: 12.866939
Epoch 899 
Overall Loss: 14.205210
Rec Loss: 13.357824
KL Loss: 0.847386
Y Loss: 0.121703
T Loss: 12.871011
Epoch 949 
Overall Loss: 14.156128
Rec Loss: 13.346330
KL Loss: 0.809798
Y Loss: 0.118497
T Loss: 12.872343
Epoch 999 
Overall Loss: 14.120212
Rec Loss: 13.341621
KL Loss: 0.778591
Y Loss: 0.117144
T Loss: 12.873046
Epoch 1049 
Overall Loss: 14.095342
Rec Loss: 13.344765
KL Loss: 0.750577
Y Loss: 0.116646
T Loss: 12.878183
Epoch 1099 
Overall Loss: 14.071405
Rec Loss: 13.357789
KL Loss: 0.713616
Y Loss: 0.118966
T Loss: 12.881924
Epoch 1149 
Overall Loss: 14.029386
Rec Loss: 13.347840
KL Loss: 0.681546
Y Loss: 0.116087
T Loss: 12.883493
Epoch 1199 
Overall Loss: 14.005440
Rec Loss: 13.357160
KL Loss: 0.648279
Y Loss: 0.117475
T Loss: 12.887262
Epoch 1249 
Overall Loss: 13.982623
Rec Loss: 13.365330
KL Loss: 0.617293
Y Loss: 0.118368
T Loss: 12.891860
Epoch 1299 
Overall Loss: 13.958223
Rec Loss: 13.373906
KL Loss: 0.584316
Y Loss: 0.119043
T Loss: 12.897736
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.522366
Epoch 99
Rec Loss: 1.516917
Epoch 149
Rec Loss: 1.519827
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.036369
Epoch 99
Rec Loss: 10.027905
Epoch 149
Rec Loss: 10.030572
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.218998
Insample Error: 1.378356
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 34.530150
Rec Loss: 27.481229
KL Loss: 7.048920
Y Loss: 2.135081
T Loss: 13.225424
Epoch 99 
Overall Loss: 26.673306
Rec Loss: 21.973137
KL Loss: 4.700169
Y Loss: 0.763260
T Loss: 13.276776
Epoch 149 
Overall Loss: 24.433505
Rec Loss: 20.318196
KL Loss: 4.115309
Y Loss: 0.514406
T Loss: 13.266359
Epoch 199 
Overall Loss: 23.075673
Rec Loss: 19.201864
KL Loss: 3.873809
Y Loss: 0.356640
T Loss: 13.255853
Epoch 249 
Overall Loss: 22.248961
Rec Loss: 18.348186
KL Loss: 3.900775
Y Loss: 0.257116
T Loss: 13.235282
Epoch 299 
Overall Loss: 21.867380
Rec Loss: 17.678771
KL Loss: 4.188609
Y Loss: 0.226303
T Loss: 13.216851
Epoch 349 
Overall Loss: 21.542243
Rec Loss: 16.959489
KL Loss: 4.582754
Y Loss: 0.202725
T Loss: 13.197879
Epoch 399 
Overall Loss: 21.321953
Rec Loss: 16.414607
KL Loss: 4.907346
Y Loss: 0.193140
T Loss: 13.179448
Epoch 449 
Overall Loss: 21.184703
Rec Loss: 16.119724
KL Loss: 5.064980
Y Loss: 0.177733
T Loss: 13.166912
Epoch 499 
Overall Loss: 21.102445
Rec Loss: 15.925743
KL Loss: 5.176702
Y Loss: 0.166926
T Loss: 13.153948
Epoch 549 
Overall Loss: 21.029185
Rec Loss: 15.789424
KL Loss: 5.239761
Y Loss: 0.167338
T Loss: 13.137491
Epoch 599 
Overall Loss: 20.989966
Rec Loss: 15.666604
KL Loss: 5.323361
Y Loss: 0.167368
T Loss: 13.124461
Epoch 649 
Overall Loss: 20.929885
Rec Loss: 15.524240
KL Loss: 5.405644
Y Loss: 0.162522
T Loss: 13.113738
Epoch 699 
Overall Loss: 20.851726
Rec Loss: 15.315571
KL Loss: 5.536154
Y Loss: 0.152666
T Loss: 13.105524
Epoch 749 
Overall Loss: 20.796683
Rec Loss: 15.120113
KL Loss: 5.676570
Y Loss: 0.156785
T Loss: 13.093034
Epoch 799 
Overall Loss: 20.712828
Rec Loss: 14.924521
KL Loss: 5.788308
Y Loss: 0.155774
T Loss: 13.084881
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.756779
Epoch 99
Rec Loss: 1.753122
Epoch 149
Rec Loss: 1.750660
Epoch 199
Rec Loss: 1.748961
Epoch 249
Rec Loss: 1.753785
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.034823
Epoch 99
Rec Loss: 6.059670
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.151027
Insample Error 2.076282
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 25.431934
Rec Loss: 24.060338
KL Loss: 1.371595
Y Loss: 2.719475
T Loss: 13.182440
Epoch 99 
Overall Loss: 17.937553
Rec Loss: 16.671165
KL Loss: 1.266388
Y Loss: 0.861846
T Loss: 13.223779
Epoch 149 
Overall Loss: 16.490783
Rec Loss: 15.501038
KL Loss: 0.989745
Y Loss: 0.568974
T Loss: 13.225140
Epoch 199 
Overall Loss: 15.776912
Rec Loss: 14.860100
KL Loss: 0.916811
Y Loss: 0.416961
T Loss: 13.192255
Epoch 249 
Overall Loss: 15.396763
Rec Loss: 14.481854
KL Loss: 0.914909
Y Loss: 0.330082
T Loss: 13.161528
Epoch 299 
Overall Loss: 15.088753
Rec Loss: 14.169100
KL Loss: 0.919653
Y Loss: 0.257634
T Loss: 13.138565
Epoch 349 
Overall Loss: 14.886003
Rec Loss: 13.947940
KL Loss: 0.938063
Y Loss: 0.208228
T Loss: 13.115028
Epoch 399 
Overall Loss: 14.677358
Rec Loss: 13.743550
KL Loss: 0.933808
Y Loss: 0.162584
T Loss: 13.093213
Epoch 449 
Overall Loss: 14.601808
Rec Loss: 13.658479
KL Loss: 0.943329
Y Loss: 0.146527
T Loss: 13.072373
Epoch 499 
Overall Loss: 14.548220
Rec Loss: 13.598678
KL Loss: 0.949541
Y Loss: 0.138940
T Loss: 13.042919
Epoch 549 
Overall Loss: 14.488786
Rec Loss: 13.530178
KL Loss: 0.958609
Y Loss: 0.129568
T Loss: 13.011907
Epoch 599 
Overall Loss: 14.443172
Rec Loss: 13.490046
KL Loss: 0.953126
Y Loss: 0.126699
T Loss: 12.983251
Epoch 649 
Overall Loss: 14.416199
Rec Loss: 13.460418
KL Loss: 0.955780
Y Loss: 0.124501
T Loss: 12.962416
Epoch 699 
Overall Loss: 14.386773
Rec Loss: 13.443102
KL Loss: 0.943671
Y Loss: 0.126533
T Loss: 12.936969
Epoch 749 
Overall Loss: 14.341584
Rec Loss: 13.399911
KL Loss: 0.941673
Y Loss: 0.120971
T Loss: 12.916027
Epoch 799 
Overall Loss: 14.293024
Rec Loss: 13.374529
KL Loss: 0.918496
Y Loss: 0.118626
T Loss: 12.900023
Epoch 849 
Overall Loss: 14.270343
Rec Loss: 13.359713
KL Loss: 0.910630
Y Loss: 0.116100
T Loss: 12.895312
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.554640
Epoch 99
Rec Loss: 1.548638
Epoch 149
Rec Loss: 1.551268
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.073723
Epoch 99
Rec Loss: 10.063428
Epoch 149
Rec Loss: 10.067318
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.142706
Insample Error: 2.039985
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 36.717050
Rec Loss: 29.438658
KL Loss: 7.278392
Y Loss: 2.637831
T Loss: 13.198012
Epoch 99 
Overall Loss: 27.267228
Rec Loss: 22.567630
KL Loss: 4.699597
Y Loss: 0.914453
T Loss: 13.272412
Epoch 149 
Overall Loss: 24.762184
Rec Loss: 20.644321
KL Loss: 4.117863
Y Loss: 0.570810
T Loss: 13.268641
Epoch 199 
Overall Loss: 23.335119
Rec Loss: 19.392668
KL Loss: 3.942451
Y Loss: 0.403369
T Loss: 13.254769
Epoch 249 
Overall Loss: 22.510746
Rec Loss: 18.644613
KL Loss: 3.866134
Y Loss: 0.299774
T Loss: 13.239625
Epoch 299 
Overall Loss: 22.063807
Rec Loss: 17.921719
KL Loss: 4.142089
Y Loss: 0.250863
T Loss: 13.222111
Epoch 349 
Overall Loss: 21.634911
Rec Loss: 17.084240
KL Loss: 4.550670
Y Loss: 0.212535
T Loss: 13.195299
Epoch 399 
Overall Loss: 21.381711
Rec Loss: 16.528278
KL Loss: 4.853432
Y Loss: 0.193754
T Loss: 13.172493
Epoch 449 
Overall Loss: 21.193762
Rec Loss: 15.959317
KL Loss: 5.234445
Y Loss: 0.180587
T Loss: 13.151312
Epoch 499 
Overall Loss: 21.082232
Rec Loss: 15.625930
KL Loss: 5.456301
Y Loss: 0.178906
T Loss: 13.136710
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.807026
Epoch 99
Rec Loss: 1.806545
Epoch 149
Rec Loss: 1.808268
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.232661
Epoch 99
Rec Loss: 6.228456
Epoch 149
Rec Loss: 6.220459
Epoch 199
Rec Loss: 6.227122
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.172527
Insample Error 2.108168
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 26.208404
Rec Loss: 24.251528
KL Loss: 1.956876
Y Loss: 2.766774
T Loss: 13.184434
Epoch 99 
Overall Loss: 17.774401
Rec Loss: 16.367372
KL Loss: 1.407029
Y Loss: 0.781906
T Loss: 13.239749
Epoch 149 
Overall Loss: 16.491942
Rec Loss: 15.419239
KL Loss: 1.072703
Y Loss: 0.546437
T Loss: 13.233493
Epoch 199 
Overall Loss: 15.687606
Rec Loss: 14.776917
KL Loss: 0.910690
Y Loss: 0.392424
T Loss: 13.207222
Epoch 249 
Overall Loss: 15.195695
Rec Loss: 14.282696
KL Loss: 0.912999
Y Loss: 0.274544
T Loss: 13.184519
Epoch 299 
Overall Loss: 14.944971
Rec Loss: 14.008519
KL Loss: 0.936452
Y Loss: 0.210665
T Loss: 13.165861
Epoch 349 
Overall Loss: 14.786379
Rec Loss: 13.844410
KL Loss: 0.941969
Y Loss: 0.174866
T Loss: 13.144947
Epoch 399 
Overall Loss: 14.646750
Rec Loss: 13.704057
KL Loss: 0.942694
Y Loss: 0.145028
T Loss: 13.123945
Epoch 449 
Overall Loss: 14.609477
Rec Loss: 13.674537
KL Loss: 0.934940
Y Loss: 0.141143
T Loss: 13.109966
Epoch 499 
Overall Loss: 14.558446
Rec Loss: 13.627375
KL Loss: 0.931071
Y Loss: 0.134683
T Loss: 13.088643
Epoch 549 
Overall Loss: 14.528705
Rec Loss: 13.608032
KL Loss: 0.920673
Y Loss: 0.133819
T Loss: 13.072755
Epoch 599 
Overall Loss: 14.485485
Rec Loss: 13.571561
KL Loss: 0.913924
Y Loss: 0.127484
T Loss: 13.061625
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.722849
Epoch 99
Rec Loss: 1.718495
Epoch 149
Rec Loss: 1.719867
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.054097
Epoch 99
Rec Loss: 10.055264
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.151261
Insample Error: 2.104678
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 33.437740
Rec Loss: 26.332079
KL Loss: 7.105662
Y Loss: 1.843872
T Loss: 13.223679
Epoch 99 
Overall Loss: 27.014316
Rec Loss: 22.268517
KL Loss: 4.745800
Y Loss: 0.831129
T Loss: 13.284716
Epoch 149 
Overall Loss: 25.285804
Rec Loss: 20.700352
KL Loss: 4.585452
Y Loss: 0.637088
T Loss: 13.258987
Epoch 199 
Overall Loss: 23.897253
Rec Loss: 18.917699
KL Loss: 4.979555
Y Loss: 0.509480
T Loss: 13.230480
Epoch 249 
Overall Loss: 22.846875
Rec Loss: 17.496315
KL Loss: 5.350560
Y Loss: 0.412508
T Loss: 13.228158
Epoch 299 
Overall Loss: 22.378486
Rec Loss: 16.878685
KL Loss: 5.499800
Y Loss: 0.349108
T Loss: 13.229720
Epoch 349 
Overall Loss: 22.040859
Rec Loss: 16.495139
KL Loss: 5.545719
Y Loss: 0.312244
T Loss: 13.219229
Epoch 399 
Overall Loss: 21.656053
Rec Loss: 16.033662
KL Loss: 5.622392
Y Loss: 0.255069
T Loss: 13.212684
Epoch 449 
Overall Loss: 21.386507
Rec Loss: 15.656550
KL Loss: 5.729958
Y Loss: 0.226392
T Loss: 13.196580
Epoch 499 
Overall Loss: 21.167878
Rec Loss: 15.300091
KL Loss: 5.867787
Y Loss: 0.201679
T Loss: 13.181892
Epoch 549 
Overall Loss: 21.008820
Rec Loss: 15.038564
KL Loss: 5.970257
Y Loss: 0.179950
T Loss: 13.164958
Epoch 599 
Overall Loss: 20.940591
Rec Loss: 14.921974
KL Loss: 6.018617
Y Loss: 0.178486
T Loss: 13.148077
Epoch 649 
Overall Loss: 20.886199
Rec Loss: 14.747458
KL Loss: 6.138741
Y Loss: 0.169106
T Loss: 13.132041
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.788129
Epoch 99
Rec Loss: 1.782915
Epoch 149
Rec Loss: 1.784996
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.871210
Epoch 99
Rec Loss: 5.856380
Epoch 149
Rec Loss: 5.857457
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.166792
Insample Error 2.071947
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 25.040051
Rec Loss: 23.244661
KL Loss: 1.795390
Y Loss: 2.511352
T Loss: 13.199252
Epoch 99 
Overall Loss: 17.934153
Rec Loss: 16.685456
KL Loss: 1.248697
Y Loss: 0.868505
T Loss: 13.211435
Epoch 149 
Overall Loss: 16.689469
Rec Loss: 15.796469
KL Loss: 0.893001
Y Loss: 0.648007
T Loss: 13.204441
Epoch 199 
Overall Loss: 15.947442
Rec Loss: 15.149634
KL Loss: 0.797808
Y Loss: 0.493241
T Loss: 13.176671
Epoch 249 
Overall Loss: 15.511867
Rec Loss: 14.682645
KL Loss: 0.829221
Y Loss: 0.382452
T Loss: 13.152838
Epoch 299 
Overall Loss: 15.222838
Rec Loss: 14.362075
KL Loss: 0.860763
Y Loss: 0.306895
T Loss: 13.134495
Epoch 349 
Overall Loss: 14.979523
Rec Loss: 14.082226
KL Loss: 0.897297
Y Loss: 0.242033
T Loss: 13.114093
Epoch 399 
Overall Loss: 14.759507
Rec Loss: 13.836325
KL Loss: 0.923182
Y Loss: 0.184078
T Loss: 13.100015
Epoch 449 
Overall Loss: 14.628143
Rec Loss: 13.686774
KL Loss: 0.941369
Y Loss: 0.152108
T Loss: 13.078344
Epoch 499 
Overall Loss: 14.562955
Rec Loss: 13.628928
KL Loss: 0.934027
Y Loss: 0.139511
T Loss: 13.070883
Epoch 549 
Overall Loss: 14.508949
Rec Loss: 13.576337
KL Loss: 0.932611
Y Loss: 0.132074
T Loss: 13.048042
Epoch 599 
Overall Loss: 14.451442
Rec Loss: 13.532817
KL Loss: 0.918625
Y Loss: 0.127751
T Loss: 13.021811
Epoch 649 
Overall Loss: 14.416484
Rec Loss: 13.497642
KL Loss: 0.918842
Y Loss: 0.125617
T Loss: 12.995174
Epoch 699 
Overall Loss: 14.390942
Rec Loss: 13.484080
KL Loss: 0.906862
Y Loss: 0.126114
T Loss: 12.979626
Epoch 749 
Overall Loss: 14.352793
Rec Loss: 13.461853
KL Loss: 0.890939
Y Loss: 0.123010
T Loss: 12.969815
Epoch 799 
Overall Loss: 14.324681
Rec Loss: 13.451649
KL Loss: 0.873031
Y Loss: 0.122559
T Loss: 12.961415
Epoch 849 
Overall Loss: 14.308293
Rec Loss: 13.450234
KL Loss: 0.858059
Y Loss: 0.121095
T Loss: 12.965853
Epoch 899 
Overall Loss: 14.260881
Rec Loss: 13.433037
KL Loss: 0.827844
Y Loss: 0.118870
T Loss: 12.957558
Epoch 949 
Overall Loss: 14.231164
Rec Loss: 13.422431
KL Loss: 0.808733
Y Loss: 0.117835
T Loss: 12.951092
Epoch 999 
Overall Loss: 14.188075
Rec Loss: 13.414356
KL Loss: 0.773719
Y Loss: 0.118922
T Loss: 12.938667
Epoch 1049 
Overall Loss: 14.166471
Rec Loss: 13.423099
KL Loss: 0.743372
Y Loss: 0.121549
T Loss: 12.936902
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.568756
Epoch 99
Rec Loss: 1.569927
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.052818
Epoch 99
Rec Loss: 10.048443
Epoch 149
Rec Loss: 10.052002
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.181860
Insample Error: 1.793675
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 35.620785
Rec Loss: 29.038250
KL Loss: 6.582534
Y Loss: 2.534658
T Loss: 13.215289
Epoch 99 
Overall Loss: 26.941149
Rec Loss: 22.188475
KL Loss: 4.752674
Y Loss: 0.838755
T Loss: 13.267123
Epoch 149 
Overall Loss: 24.665458
Rec Loss: 20.328004
KL Loss: 4.337454
Y Loss: 0.560532
T Loss: 13.255383
Epoch 199 
Overall Loss: 23.474410
Rec Loss: 19.034145
KL Loss: 4.440265
Y Loss: 0.428094
T Loss: 13.247348
Epoch 249 
Overall Loss: 22.898733
Rec Loss: 18.493852
KL Loss: 4.404881
Y Loss: 0.355944
T Loss: 13.238789
Epoch 299 
Overall Loss: 22.390619
Rec Loss: 17.974376
KL Loss: 4.416243
Y Loss: 0.296754
T Loss: 13.222922
Epoch 349 
Overall Loss: 22.024106
Rec Loss: 17.559576
KL Loss: 4.464530
Y Loss: 0.255812
T Loss: 13.207298
Epoch 399 
Overall Loss: 21.750340
Rec Loss: 17.137242
KL Loss: 4.613098
Y Loss: 0.227299
T Loss: 13.195644
Epoch 449 
Overall Loss: 21.498425
Rec Loss: 16.672246
KL Loss: 4.826179
Y Loss: 0.196890
T Loss: 13.176499
Epoch 499 
Overall Loss: 21.349813
Rec Loss: 16.413345
KL Loss: 4.936467
Y Loss: 0.187439
T Loss: 13.160244
Epoch 549 
Overall Loss: 21.248417
Rec Loss: 16.209133
KL Loss: 5.039284
Y Loss: 0.177156
T Loss: 13.137267
Epoch 599 
Overall Loss: 21.144194
Rec Loss: 15.975954
KL Loss: 5.168240
Y Loss: 0.170550
T Loss: 13.119798
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.777626
Epoch 99
Rec Loss: 1.771971
Epoch 149
Rec Loss: 1.764569
Epoch 199
Rec Loss: 1.765798
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.847428
Epoch 99
Rec Loss: 6.850860
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.153794
Insample Error 2.096769
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 23.517588
Rec Loss: 21.522364
KL Loss: 1.995223
Y Loss: 2.086246
T Loss: 13.177378
Epoch 99 
Overall Loss: 17.975834
Rec Loss: 16.676685
KL Loss: 1.299148
Y Loss: 0.869427
T Loss: 13.198979
Epoch 149 
Overall Loss: 16.783234
Rec Loss: 15.880003
KL Loss: 0.903231
Y Loss: 0.674584
T Loss: 13.181666
Epoch 199 
Overall Loss: 16.059260
Rec Loss: 15.240341
KL Loss: 0.818919
Y Loss: 0.522910
T Loss: 13.148702
Epoch 249 
Overall Loss: 15.696906
Rec Loss: 14.843639
KL Loss: 0.853268
Y Loss: 0.429312
T Loss: 13.126389
Epoch 299 
Overall Loss: 15.441591
Rec Loss: 14.560780
KL Loss: 0.880810
Y Loss: 0.361636
T Loss: 13.114236
Epoch 349 
Overall Loss: 15.239897
Rec Loss: 14.324986
KL Loss: 0.914910
Y Loss: 0.307454
T Loss: 13.095169
Epoch 399 
Overall Loss: 15.043364
Rec Loss: 14.110755
KL Loss: 0.932608
Y Loss: 0.258972
T Loss: 13.074867
Epoch 449 
Overall Loss: 14.877205
Rec Loss: 13.928811
KL Loss: 0.948395
Y Loss: 0.221125
T Loss: 13.044310
Epoch 499 
Overall Loss: 14.691140
Rec Loss: 13.731140
KL Loss: 0.960000
Y Loss: 0.181650
T Loss: 13.004541
Epoch 549 
Overall Loss: 14.537027
Rec Loss: 13.581792
KL Loss: 0.955235
Y Loss: 0.157527
T Loss: 12.951683
Epoch 599 
Overall Loss: 14.426208
Rec Loss: 13.479998
KL Loss: 0.946210
Y Loss: 0.140389
T Loss: 12.918441
Epoch 649 
Overall Loss: 14.370544
Rec Loss: 13.439124
KL Loss: 0.931420
Y Loss: 0.133226
T Loss: 12.906219
Epoch 699 
Overall Loss: 14.300415
Rec Loss: 13.398321
KL Loss: 0.902094
Y Loss: 0.127450
T Loss: 12.888521
Epoch 749 
Overall Loss: 14.256789
Rec Loss: 13.387501
KL Loss: 0.869288
Y Loss: 0.124205
T Loss: 12.890680
Epoch 799 
Overall Loss: 14.225570
Rec Loss: 13.382832
KL Loss: 0.842737
Y Loss: 0.123830
T Loss: 12.887513
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.556566
Epoch 99
Rec Loss: 1.553761
Epoch 149
Rec Loss: 1.551087
Epoch 199
Rec Loss: 1.549274
Epoch 249
Rec Loss: 1.553210
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.070042
Epoch 99
Rec Loss: 10.055589
Epoch 149
Rec Loss: 10.058883
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.168083
Insample Error: 1.880935
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 33.220011
Rec Loss: 25.382939
KL Loss: 7.837074
Y Loss: 1.607550
T Loss: 13.227015
Epoch 99 
Overall Loss: 26.723556
Rec Loss: 21.920068
KL Loss: 4.803488
Y Loss: 0.749932
T Loss: 13.260483
Epoch 149 
Overall Loss: 24.933176
Rec Loss: 20.803855
KL Loss: 4.129321
Y Loss: 0.585745
T Loss: 13.223763
Epoch 199 
Overall Loss: 23.446982
Rec Loss: 19.546335
KL Loss: 3.900646
Y Loss: 0.422454
T Loss: 13.216933
Epoch 249 
Overall Loss: 22.531485
Rec Loss: 18.757531
KL Loss: 3.773954
Y Loss: 0.294884
T Loss: 13.220641
Epoch 299 
Overall Loss: 22.065697
Rec Loss: 18.205808
KL Loss: 3.859889
Y Loss: 0.235194
T Loss: 13.210859
Epoch 349 
Overall Loss: 21.766315
Rec Loss: 17.677655
KL Loss: 4.088661
Y Loss: 0.199534
T Loss: 13.179298
Epoch 399 
Overall Loss: 21.593313
Rec Loss: 17.316854
KL Loss: 4.276460
Y Loss: 0.187282
T Loss: 13.145393
Epoch 449 
Overall Loss: 21.444419
Rec Loss: 16.964362
KL Loss: 4.480057
Y Loss: 0.177404
T Loss: 13.128707
Epoch 499 
Overall Loss: 21.327889
Rec Loss: 16.635889
KL Loss: 4.692000
Y Loss: 0.175445
T Loss: 13.113423
Epoch 549 
Overall Loss: 21.215668
Rec Loss: 16.397639
KL Loss: 4.818029
Y Loss: 0.172173
T Loss: 13.096906
Epoch 599 
Overall Loss: 21.154790
Rec Loss: 16.187832
KL Loss: 4.966958
Y Loss: 0.164705
T Loss: 13.078677
Epoch 649 
Overall Loss: 21.024650
Rec Loss: 15.886636
KL Loss: 5.138015
Y Loss: 0.157793
T Loss: 13.059592
Epoch 699 
Overall Loss: 20.979582
Rec Loss: 15.634428
KL Loss: 5.345153
Y Loss: 0.159907
T Loss: 13.060852
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.740623
Epoch 99
Rec Loss: 1.741852
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.512370
Epoch 99
Rec Loss: 6.491253
Epoch 149
Rec Loss: 6.472053
Epoch 199
Rec Loss: 6.481873
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.157601
Insample Error 2.086821
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 22.350898
Rec Loss: 20.516512
KL Loss: 1.834386
Y Loss: 1.834265
T Loss: 13.179452
Epoch 99 
Overall Loss: 17.777368
Rec Loss: 16.539720
KL Loss: 1.237648
Y Loss: 0.837635
T Loss: 13.189181
Epoch 149 
Overall Loss: 16.665909
Rec Loss: 15.775725
KL Loss: 0.890184
Y Loss: 0.650912
T Loss: 13.172078
Epoch 199 
Overall Loss: 15.995042
Rec Loss: 15.161378
KL Loss: 0.833664
Y Loss: 0.503356
T Loss: 13.147954
Epoch 249 
Overall Loss: 15.590465
Rec Loss: 14.720059
KL Loss: 0.870406
Y Loss: 0.398518
T Loss: 13.125989
Epoch 299 
Overall Loss: 15.357305
Rec Loss: 14.446142
KL Loss: 0.911163
Y Loss: 0.334188
T Loss: 13.109388
Epoch 349 
Overall Loss: 15.154186
Rec Loss: 14.218703
KL Loss: 0.935482
Y Loss: 0.282945
T Loss: 13.086924
Epoch 399 
Overall Loss: 15.012132
Rec Loss: 14.034710
KL Loss: 0.977422
Y Loss: 0.241886
T Loss: 13.067167
Epoch 449 
Overall Loss: 14.890412
Rec Loss: 13.901395
KL Loss: 0.989016
Y Loss: 0.215516
T Loss: 13.039331
Epoch 499 
Overall Loss: 14.792391
Rec Loss: 13.779974
KL Loss: 1.012418
Y Loss: 0.191776
T Loss: 13.012871
Epoch 549 
Overall Loss: 14.650765
Rec Loss: 13.645397
KL Loss: 1.005368
Y Loss: 0.169025
T Loss: 12.969299
Epoch 599 
Overall Loss: 14.559012
Rec Loss: 13.566340
KL Loss: 0.992672
Y Loss: 0.148238
T Loss: 12.973389
Epoch 649 
Overall Loss: 14.483065
Rec Loss: 13.498280
KL Loss: 0.984785
Y Loss: 0.134279
T Loss: 12.961163
Epoch 699 
Overall Loss: 14.434677
Rec Loss: 13.465032
KL Loss: 0.969645
Y Loss: 0.130080
T Loss: 12.944712
Epoch 749 
Overall Loss: 14.402700
Rec Loss: 13.444181
KL Loss: 0.958518
Y Loss: 0.125644
T Loss: 12.941607
Epoch 799 
Overall Loss: 14.398785
Rec Loss: 13.435387
KL Loss: 0.963397
Y Loss: 0.126792
T Loss: 12.928219
Epoch 849 
Overall Loss: 14.343012
Rec Loss: 13.392320
KL Loss: 0.950693
Y Loss: 0.120250
T Loss: 12.911319
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.593287
Epoch 99
Rec Loss: 1.592092
Epoch 149
Rec Loss: 1.596864
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.036517
Epoch 99
Rec Loss: 10.029241
Epoch 149
Rec Loss: 10.030904
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.150648
Insample Error: 2.075133
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 34.317811
Rec Loss: 27.103021
KL Loss: 7.214790
Y Loss: 2.049564
T Loss: 13.198791
Epoch 99 
Overall Loss: 27.003673
Rec Loss: 22.201136
KL Loss: 4.802537
Y Loss: 0.813784
T Loss: 13.272137
Epoch 149 
Overall Loss: 25.286265
Rec Loss: 21.009068
KL Loss: 4.277197
Y Loss: 0.601261
T Loss: 13.264451
Epoch 199 
Overall Loss: 24.032677
Rec Loss: 19.689503
KL Loss: 4.343174
Y Loss: 0.480142
T Loss: 13.243774
Epoch 249 
Overall Loss: 22.940385
Rec Loss: 18.273179
KL Loss: 4.667206
Y Loss: 0.380724
T Loss: 13.239415
Epoch 299 
Overall Loss: 22.400501
Rec Loss: 17.532824
KL Loss: 4.867677
Y Loss: 0.324348
T Loss: 13.228092
Epoch 349 
Overall Loss: 21.904786
Rec Loss: 16.649297
KL Loss: 5.255489
Y Loss: 0.272321
T Loss: 13.216216
Epoch 399 
Overall Loss: 21.602085
Rec Loss: 15.944093
KL Loss: 5.657992
Y Loss: 0.237343
T Loss: 13.196506
Epoch 449 
Overall Loss: 21.296313
Rec Loss: 15.225096
KL Loss: 6.071217
Y Loss: 0.212198
T Loss: 13.170817
Epoch 499 
Overall Loss: 21.132328
Rec Loss: 14.646248
KL Loss: 6.486081
Y Loss: 0.208815
T Loss: 13.155805
Epoch 549 
Overall Loss: 20.980972
Rec Loss: 14.324916
KL Loss: 6.656057
Y Loss: 0.193330
T Loss: 13.145166
Epoch 599 
Overall Loss: 20.933395
Rec Loss: 14.133168
KL Loss: 6.800227
Y Loss: 0.191000
T Loss: 13.133478
Epoch 649 
Overall Loss: 20.887528
Rec Loss: 13.936806
KL Loss: 6.950722
Y Loss: 0.183582
T Loss: 13.122205
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.784891
Epoch 99
Rec Loss: 1.786721
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.792093
Epoch 99
Rec Loss: 5.788786
Epoch 149
Rec Loss: 5.787717
Epoch 199
Rec Loss: 5.790368
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.171278
Insample Error 2.090817
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 23.948002
Rec Loss: 21.811687
KL Loss: 2.136314
Y Loss: 2.150784
T Loss: 13.208552
Epoch 99 
Overall Loss: 18.098257
Rec Loss: 16.722036
KL Loss: 1.376221
Y Loss: 0.867982
T Loss: 13.250107
Epoch 149 
Overall Loss: 16.811003
Rec Loss: 15.821323
KL Loss: 0.989679
Y Loss: 0.645364
T Loss: 13.239866
Epoch 199 
Overall Loss: 16.101440
Rec Loss: 15.243176
KL Loss: 0.858264
Y Loss: 0.507952
T Loss: 13.211369
Epoch 249 
Overall Loss: 15.675072
Rec Loss: 14.827500
KL Loss: 0.847572
Y Loss: 0.410764
T Loss: 13.184445
Epoch 299 
Overall Loss: 15.419269
Rec Loss: 14.562540
KL Loss: 0.856729
Y Loss: 0.351153
T Loss: 13.157928
Epoch 349 
Overall Loss: 15.195037
Rec Loss: 14.319425
KL Loss: 0.875611
Y Loss: 0.294856
T Loss: 13.140001
Epoch 399 
Overall Loss: 15.093524
Rec Loss: 14.189159
KL Loss: 0.904365
Y Loss: 0.269648
T Loss: 13.110566
Epoch 449 
Overall Loss: 14.931915
Rec Loss: 14.012725
KL Loss: 0.919191
Y Loss: 0.229481
T Loss: 13.094800
Epoch 499 
Overall Loss: 14.789875
Rec Loss: 13.856977
KL Loss: 0.932898
Y Loss: 0.199014
T Loss: 13.060922
Epoch 549 
Overall Loss: 14.623725
Rec Loss: 13.677877
KL Loss: 0.945848
Y Loss: 0.164589
T Loss: 13.019519
Epoch 599 
Overall Loss: 14.497023
Rec Loss: 13.544774
KL Loss: 0.952249
Y Loss: 0.142968
T Loss: 12.972902
Epoch 649 
Overall Loss: 14.388477
Rec Loss: 13.451662
KL Loss: 0.936815
Y Loss: 0.130031
T Loss: 12.931538
Epoch 699 
Overall Loss: 14.338593
Rec Loss: 13.423634
KL Loss: 0.914958
Y Loss: 0.129844
T Loss: 12.904257
Epoch 749 
Overall Loss: 14.292919
Rec Loss: 13.402949
KL Loss: 0.889971
Y Loss: 0.127291
T Loss: 12.893785
Epoch 799 
Overall Loss: 14.236073
Rec Loss: 13.382375
KL Loss: 0.853698
Y Loss: 0.122573
T Loss: 12.892084
Epoch 849 
Overall Loss: 14.199220
Rec Loss: 13.374168
KL Loss: 0.825051
Y Loss: 0.121204
T Loss: 12.889354
Epoch 899 
Overall Loss: 14.154094
Rec Loss: 13.351728
KL Loss: 0.802366
Y Loss: 0.116855
T Loss: 12.884306
Epoch 949 
Overall Loss: 14.121809
Rec Loss: 13.349348
KL Loss: 0.772460
Y Loss: 0.117158
T Loss: 12.880715
Epoch 999 
Overall Loss: 14.081607
Rec Loss: 13.337286
KL Loss: 0.744320
Y Loss: 0.115100
T Loss: 12.876886
Epoch 1049 
Overall Loss: 14.047366
Rec Loss: 13.329653
KL Loss: 0.717714
Y Loss: 0.112406
T Loss: 12.880030
Epoch 1099 
Overall Loss: 14.021350
Rec Loss: 13.337341
KL Loss: 0.684009
Y Loss: 0.115209
T Loss: 12.876506
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.526529
Epoch 99
Rec Loss: 1.525056
Epoch 149
Rec Loss: 1.519489
Epoch 199
Rec Loss: 1.518626
Epoch 249
Rec Loss: 1.520116
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.072428
Epoch 99
Rec Loss: 10.069721
Epoch 149
Rec Loss: 10.063974
Epoch 199
Rec Loss: 10.070039
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.188500
Insample Error: 1.556772
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 32.141460
Rec Loss: 25.869307
KL Loss: 6.272154
Y Loss: 1.741833
T Loss: 13.213234
Epoch 99 
Overall Loss: 26.863977
Rec Loss: 22.248206
KL Loss: 4.615771
Y Loss: 0.846738
T Loss: 13.254290
Epoch 149 
Overall Loss: 25.329619
Rec Loss: 20.968273
KL Loss: 4.361346
Y Loss: 0.662259
T Loss: 13.248084
Epoch 199 
Overall Loss: 24.193518
Rec Loss: 19.568917
KL Loss: 4.624602
Y Loss: 0.536052
T Loss: 13.225916
Epoch 249 
Overall Loss: 23.167241
Rec Loss: 18.253702
KL Loss: 4.913539
Y Loss: 0.426605
T Loss: 13.191819
Epoch 299 
Overall Loss: 22.388496
Rec Loss: 17.162894
KL Loss: 5.225603
Y Loss: 0.338136
T Loss: 13.188494
Epoch 349 
Overall Loss: 21.801508
Rec Loss: 16.536139
KL Loss: 5.265368
Y Loss: 0.262629
T Loss: 13.186041
Epoch 399 
Overall Loss: 21.353118
Rec Loss: 16.153930
KL Loss: 5.199187
Y Loss: 0.205877
T Loss: 13.178728
Epoch 449 
Overall Loss: 21.172046
Rec Loss: 15.823595
KL Loss: 5.348451
Y Loss: 0.185272
T Loss: 13.163644
Epoch 499 
Overall Loss: 21.051681
Rec Loss: 15.555200
KL Loss: 5.496481
Y Loss: 0.177704
T Loss: 13.149116
Epoch 549 
Overall Loss: 20.947405
Rec Loss: 15.327424
KL Loss: 5.619981
Y Loss: 0.170362
T Loss: 13.133951
Epoch 599 
Overall Loss: 20.899926
Rec Loss: 15.144650
KL Loss: 5.755276
Y Loss: 0.165147
T Loss: 13.124415
Epoch 649 
Overall Loss: 20.824666
Rec Loss: 14.986368
KL Loss: 5.838298
Y Loss: 0.158334
T Loss: 13.112303
Epoch 699 
Overall Loss: 20.812326
Rec Loss: 14.854733
KL Loss: 5.957593
Y Loss: 0.156828
T Loss: 13.104364
Epoch 749 
Overall Loss: 20.778135
Rec Loss: 14.709982
KL Loss: 6.068153
Y Loss: 0.153553
T Loss: 13.096887
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.760649
Epoch 99
Rec Loss: 1.759199
Epoch 149
Rec Loss: 1.757573
Epoch 199
Rec Loss: 1.759188
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.927262
Epoch 99
Rec Loss: 5.923729
Epoch 149
Rec Loss: 5.911138
Epoch 199
Rec Loss: 5.912282
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.144413
Insample Error 2.112220
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 22.177555
Rec Loss: 20.023678
KL Loss: 2.153878
Y Loss: 1.708834
T Loss: 13.188341
Epoch 99 
Overall Loss: 17.823207
Rec Loss: 16.318198
KL Loss: 1.505009
Y Loss: 0.774858
T Loss: 13.218766
Epoch 149 
Overall Loss: 16.643256
Rec Loss: 15.529113
KL Loss: 1.114143
Y Loss: 0.578691
T Loss: 13.214351
Epoch 199 
Overall Loss: 15.813213
Rec Loss: 14.916422
KL Loss: 0.896791
Y Loss: 0.432198
T Loss: 13.187629
Epoch 249 
Overall Loss: 15.384702
Rec Loss: 14.488188
KL Loss: 0.896514
Y Loss: 0.330730
T Loss: 13.165268
Epoch 299 
Overall Loss: 15.106975
Rec Loss: 14.178216
KL Loss: 0.928759
Y Loss: 0.256537
T Loss: 13.152067
Epoch 349 
Overall Loss: 14.858791
Rec Loss: 13.909149
KL Loss: 0.949643
Y Loss: 0.194314
T Loss: 13.131892
Epoch 399 
Overall Loss: 14.721759
Rec Loss: 13.768348
KL Loss: 0.953411
Y Loss: 0.163077
T Loss: 13.116041
Epoch 449 
Overall Loss: 14.636825
Rec Loss: 13.689768
KL Loss: 0.947057
Y Loss: 0.148122
T Loss: 13.097281
Epoch 499 
Overall Loss: 14.564082
Rec Loss: 13.624712
KL Loss: 0.939369
Y Loss: 0.136009
T Loss: 13.080675
Epoch 549 
Overall Loss: 14.523617
Rec Loss: 13.596906
KL Loss: 0.926710
Y Loss: 0.131672
T Loss: 13.070218
Epoch 599 
Overall Loss: 14.471278
Rec Loss: 13.552256
KL Loss: 0.919021
Y Loss: 0.125150
T Loss: 13.051655
Epoch 649 
Overall Loss: 14.451426
Rec Loss: 13.543123
KL Loss: 0.908303
Y Loss: 0.125998
T Loss: 13.039131
Epoch 699 
Overall Loss: 14.403668
Rec Loss: 13.500018
KL Loss: 0.903650
Y Loss: 0.121226
T Loss: 13.015114
Epoch 749 
Overall Loss: 14.376742
Rec Loss: 13.481410
KL Loss: 0.895331
Y Loss: 0.121434
T Loss: 12.995674
Epoch 799 
Overall Loss: 14.342672
Rec Loss: 13.459190
KL Loss: 0.883482
Y Loss: 0.123502
T Loss: 12.965183
Epoch 849 
Overall Loss: 14.298105
Rec Loss: 13.427871
KL Loss: 0.870234
Y Loss: 0.120987
T Loss: 12.943923
Epoch 899 
Overall Loss: 14.264214
Rec Loss: 13.413921
KL Loss: 0.850293
Y Loss: 0.121443
T Loss: 12.928150
Epoch 949 
Overall Loss: 14.218852
Rec Loss: 13.396209
KL Loss: 0.822643
Y Loss: 0.118880
T Loss: 12.920687
Epoch 999 
Overall Loss: 14.187638
Rec Loss: 13.393956
KL Loss: 0.793682
Y Loss: 0.120291
T Loss: 12.912794
Epoch 1049 
Overall Loss: 14.135677
Rec Loss: 13.370690
KL Loss: 0.764987
Y Loss: 0.115713
T Loss: 12.907838
Epoch 1099 
Overall Loss: 14.095255
Rec Loss: 13.363575
KL Loss: 0.731680
Y Loss: 0.113618
T Loss: 12.909102
Epoch 1149 
Overall Loss: 14.067306
Rec Loss: 13.366287
KL Loss: 0.701019
Y Loss: 0.113643
T Loss: 12.911713
Epoch 1199 
Overall Loss: 14.046047
Rec Loss: 13.375233
KL Loss: 0.670814
Y Loss: 0.115589
T Loss: 12.912879
Epoch 1249 
Overall Loss: 14.009333
Rec Loss: 13.366281
KL Loss: 0.643052
Y Loss: 0.112739
T Loss: 12.915325
Epoch 1299 
Overall Loss: 13.968933
Rec Loss: 13.365997
KL Loss: 0.602936
Y Loss: 0.113341
T Loss: 12.912631
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.534980
Epoch 99
Rec Loss: 1.530827
Epoch 149
Rec Loss: 1.527121
Epoch 199
Rec Loss: 1.524722
Epoch 249
Rec Loss: 1.528688
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.075442
Epoch 99
Rec Loss: 10.072808
Epoch 149
Rec Loss: 10.072244
Epoch 199
Rec Loss: 10.070957
Epoch 249
Rec Loss: 10.070816
Epoch 299
Rec Loss: 10.073248
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.197699
Insample Error: 1.478768
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 38.519985
Rec Loss: 30.806988
KL Loss: 7.712997
Y Loss: 2.993342
T Loss: 13.178879
Epoch 99 
Overall Loss: 27.585469
Rec Loss: 22.620807
KL Loss: 4.964663
Y Loss: 0.928746
T Loss: 13.261949
Epoch 149 
Overall Loss: 25.498434
Rec Loss: 21.013488
KL Loss: 4.484946
Y Loss: 0.636616
T Loss: 13.251652
Epoch 199 
Overall Loss: 24.098142
Rec Loss: 19.466677
KL Loss: 4.631464
Y Loss: 0.495367
T Loss: 13.222806
Epoch 249 
Overall Loss: 22.749433
Rec Loss: 17.536395
KL Loss: 5.213038
Y Loss: 0.375304
T Loss: 13.217723
Epoch 299 
Overall Loss: 22.329175
Rec Loss: 17.092901
KL Loss: 5.236274
Y Loss: 0.330479
T Loss: 13.214288
Epoch 349 
Overall Loss: 21.996142
Rec Loss: 16.796705
KL Loss: 5.199438
Y Loss: 0.292141
T Loss: 13.212362
Epoch 399 
Overall Loss: 21.616685
Rec Loss: 16.398605
KL Loss: 5.218080
Y Loss: 0.246549
T Loss: 13.196040
Epoch 449 
Overall Loss: 21.288313
Rec Loss: 15.951944
KL Loss: 5.336369
Y Loss: 0.203028
T Loss: 13.179495
Epoch 499 
Overall Loss: 21.106719
Rec Loss: 15.658374
KL Loss: 5.448345
Y Loss: 0.183744
T Loss: 13.164946
Epoch 549 
Overall Loss: 20.989157
Rec Loss: 15.448868
KL Loss: 5.540289
Y Loss: 0.178298
T Loss: 13.144935
Epoch 599 
Overall Loss: 20.879098
Rec Loss: 15.229962
KL Loss: 5.649136
Y Loss: 0.166715
T Loss: 13.130011
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.787013
Epoch 99
Rec Loss: 1.788717
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.960217
Epoch 99
Rec Loss: 5.968562
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.164862
Insample Error 2.086825
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 23.089343
Rec Loss: 21.142529
KL Loss: 1.946814
Y Loss: 1.985910
T Loss: 13.198890
Epoch 99 
Overall Loss: 17.899059
Rec Loss: 16.460900
KL Loss: 1.438159
Y Loss: 0.807839
T Loss: 13.229545
Epoch 149 
Overall Loss: 16.482646
Rec Loss: 15.493623
KL Loss: 0.989023
Y Loss: 0.572434
T Loss: 13.203886
Epoch 199 
Overall Loss: 15.775767
Rec Loss: 14.891681
KL Loss: 0.884086
Y Loss: 0.429503
T Loss: 13.173670
Epoch 249 
Overall Loss: 15.481772
Rec Loss: 14.580883
KL Loss: 0.900889
Y Loss: 0.358262
T Loss: 13.147833
Epoch 299 
Overall Loss: 15.226383
Rec Loss: 14.299989
KL Loss: 0.926394
Y Loss: 0.296460
T Loss: 13.114150
Epoch 349 
Overall Loss: 15.019690
Rec Loss: 14.049441
KL Loss: 0.970249
Y Loss: 0.244144
T Loss: 13.072866
Epoch 399 
Overall Loss: 14.849957
Rec Loss: 13.840152
KL Loss: 1.009805
Y Loss: 0.205944
T Loss: 13.016378
Epoch 449 
Overall Loss: 14.698741
Rec Loss: 13.643224
KL Loss: 1.055516
Y Loss: 0.177673
T Loss: 12.932534
Epoch 499 
Overall Loss: 14.574411
Rec Loss: 13.528109
KL Loss: 1.046302
Y Loss: 0.157656
T Loss: 12.897485
Epoch 549 
Overall Loss: 14.482566
Rec Loss: 13.451156
KL Loss: 1.031410
Y Loss: 0.144310
T Loss: 12.873918
Epoch 599 
Overall Loss: 14.409996
Rec Loss: 13.414323
KL Loss: 0.995672
Y Loss: 0.135109
T Loss: 12.873886
Epoch 649 
Overall Loss: 14.343727
Rec Loss: 13.374774
KL Loss: 0.968953
Y Loss: 0.126965
T Loss: 12.866915
Epoch 699 
Overall Loss: 14.300606
Rec Loss: 13.362795
KL Loss: 0.937812
Y Loss: 0.123662
T Loss: 12.868147
Epoch 749 
Overall Loss: 14.255183
Rec Loss: 13.351340
KL Loss: 0.903843
Y Loss: 0.119675
T Loss: 12.872639
Epoch 799 
Overall Loss: 14.219625
Rec Loss: 13.335575
KL Loss: 0.884050
Y Loss: 0.116798
T Loss: 12.868384
Epoch 849 
Overall Loss: 14.198726
Rec Loss: 13.342366
KL Loss: 0.856360
Y Loss: 0.117220
T Loss: 12.873486
Epoch 899 
Overall Loss: 14.170989
Rec Loss: 13.336631
KL Loss: 0.834357
Y Loss: 0.116440
T Loss: 12.870870
Epoch 949 
Overall Loss: 14.119260
Rec Loss: 13.320278
KL Loss: 0.798982
Y Loss: 0.114334
T Loss: 12.862944
Epoch 999 
Overall Loss: 14.092770
Rec Loss: 13.313659
KL Loss: 0.779111
Y Loss: 0.112824
T Loss: 12.862362
Epoch 1049 
Overall Loss: 14.074205
Rec Loss: 13.323421
KL Loss: 0.750784
Y Loss: 0.113959
T Loss: 12.867583
Epoch 1099 
Overall Loss: 14.045890
Rec Loss: 13.316205
KL Loss: 0.729686
Y Loss: 0.111979
T Loss: 12.868287
Epoch 1149 
Overall Loss: 14.007267
Rec Loss: 13.315692
KL Loss: 0.691575
Y Loss: 0.111526
T Loss: 12.869590
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.517505
Epoch 99
Rec Loss: 1.514947
Epoch 149
Rec Loss: 1.510704
Epoch 199
Rec Loss: 1.511392
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.031975
Epoch 99
Rec Loss: 10.026679
Epoch 149
Rec Loss: 10.022920
Epoch 199
Rec Loss: 10.032581
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.172917
Insample Error: 1.645496
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 37.377074
Rec Loss: 31.088222
KL Loss: 6.288851
Y Loss: 3.047286
T Loss: 13.205536
Epoch 99 
Overall Loss: 27.406826
Rec Loss: 22.642800
KL Loss: 4.764026
Y Loss: 0.921270
T Loss: 13.282636
Epoch 149 
Overall Loss: 25.056221
Rec Loss: 21.007313
KL Loss: 4.048907
Y Loss: 0.585143
T Loss: 13.261564
Epoch 199 
Overall Loss: 23.425861
Rec Loss: 19.574405
KL Loss: 3.851456
Y Loss: 0.398171
T Loss: 13.241406
Epoch 249 
Overall Loss: 22.682718
Rec Loss: 18.941895
KL Loss: 3.740822
Y Loss: 0.308568
T Loss: 13.228594
Epoch 299 
Overall Loss: 22.270574
Rec Loss: 18.531762
KL Loss: 3.738812
Y Loss: 0.262701
T Loss: 13.212739
Epoch 349 
Overall Loss: 21.910705
Rec Loss: 18.038401
KL Loss: 3.872304
Y Loss: 0.227053
T Loss: 13.196419
Epoch 399 
Overall Loss: 21.618870
Rec Loss: 17.450080
KL Loss: 4.168791
Y Loss: 0.201387
T Loss: 13.183900
Epoch 449 
Overall Loss: 21.426502
Rec Loss: 17.025094
KL Loss: 4.401407
Y Loss: 0.184138
T Loss: 13.165699
Epoch 499 
Overall Loss: 21.293618
Rec Loss: 16.736715
KL Loss: 4.556903
Y Loss: 0.168866
T Loss: 13.144620
Epoch 549 
Overall Loss: 21.185075
Rec Loss: 16.554509
KL Loss: 4.630565
Y Loss: 0.161763
T Loss: 13.127749
Epoch 599 
Overall Loss: 21.131583
Rec Loss: 16.427500
KL Loss: 4.704083
Y Loss: 0.153957
T Loss: 13.113451
Epoch 649 
Overall Loss: 21.021323
Rec Loss: 16.367374
KL Loss: 4.653949
Y Loss: 0.149392
T Loss: 13.097113
Epoch 699 
Overall Loss: 20.992064
Rec Loss: 16.352508
KL Loss: 4.639556
Y Loss: 0.138420
T Loss: 13.083307
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.743573
Epoch 99
Rec Loss: 1.748917
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 7.334696
Epoch 99
Rec Loss: 7.337825
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.139086
Insample Error 2.082216
Ours, Train RMSE
0.1454, 
0.2190, 
0.1427, 
0.1513, 
0.1819, 
0.1681, 
0.1506, 
0.1885, 
0.1977, 
0.1729, 
Ours, Insample RMSE
2.0891, 
1.3784, 
2.0400, 
2.1047, 
1.7937, 
1.8809, 
2.0751, 
1.5568, 
1.4788, 
1.6455, 
CEVAE, Insample RMSE
2.0653, 
2.0763, 
2.1082, 
2.0719, 
2.0968, 
2.0868, 
2.0908, 
2.1122, 
2.0868, 
2.0822, 
Train, RMSE mean 0.1718 std 0.0239
Ours, RMSE mean 1.8043 std 0.2608, reconstruct confounder 1.5599 (0.0581) noise 10.0513 (0.0179)
CEVAE, RMSE mean 2.0877 std 0.0142, reconstruct confounder 1.7689 (0.0205) noise 6.2251 (0.4869)
Experiment Start!
Namespace(decay=0.0, l=5e-05, latdim=4, mask=0, nlayer=20, obsm=4, ycof=2.0, ylayer=20)
Y Mean 1.192369, Std 4.040208 
Observe confounder 4, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 39.879597
Rec Loss: 39.511613
KL Loss: 0.367986
Y Loss: 12.946371
T Loss: 13.618869
Epoch 99 
Overall Loss: 19.398114
Rec Loss: 18.056744
KL Loss: 1.341371
Y Loss: 2.405053
T Loss: 13.246638
Epoch 149 
Overall Loss: 16.709285
Rec Loss: 15.754786
KL Loss: 0.954500
Y Loss: 1.259266
T Loss: 13.236253
Epoch 199 
Overall Loss: 16.014534
Rec Loss: 15.280758
KL Loss: 0.733777
Y Loss: 1.030717
T Loss: 13.219324
Epoch 249 
Overall Loss: 15.457267
Rec Loss: 14.913359
KL Loss: 0.543908
Y Loss: 0.861341
T Loss: 13.190677
Epoch 299 
Overall Loss: 15.077980
Rec Loss: 14.580685
KL Loss: 0.497295
Y Loss: 0.705114
T Loss: 13.170458
Epoch 349 
Overall Loss: 14.864064
Rec Loss: 14.353305
KL Loss: 0.510759
Y Loss: 0.600487
T Loss: 13.152331
Epoch 399 
Overall Loss: 14.757407
Rec Loss: 14.244261
KL Loss: 0.513146
Y Loss: 0.553526
T Loss: 13.137209
Epoch 449 
Overall Loss: 14.652979
Rec Loss: 14.139342
KL Loss: 0.513637
Y Loss: 0.510685
T Loss: 13.117971
Epoch 499 
Overall Loss: 14.578102
Rec Loss: 14.055362
KL Loss: 0.522741
Y Loss: 0.479383
T Loss: 13.096595
Epoch 549 
Overall Loss: 14.480783
Rec Loss: 13.959823
KL Loss: 0.520960
Y Loss: 0.435677
T Loss: 13.088469
Epoch 599 
Overall Loss: 14.429708
Rec Loss: 13.906204
KL Loss: 0.523504
Y Loss: 0.414614
T Loss: 13.076976
Epoch 649 
Overall Loss: 14.385144
Rec Loss: 13.855501
KL Loss: 0.529643
Y Loss: 0.399300
T Loss: 13.056900
Epoch 699 
Overall Loss: 14.325072
Rec Loss: 13.791310
KL Loss: 0.533762
Y Loss: 0.375672
T Loss: 13.039966
Epoch 749 
Overall Loss: 14.272748
Rec Loss: 13.741323
KL Loss: 0.531426
Y Loss: 0.361754
T Loss: 13.017814
Epoch 799 
Overall Loss: 14.201224
Rec Loss: 13.665138
KL Loss: 0.536086
Y Loss: 0.340911
T Loss: 12.983317
Epoch 849 
Overall Loss: 14.184759
Rec Loss: 13.649413
KL Loss: 0.535345
Y Loss: 0.338129
T Loss: 12.973156
Epoch 899 
Overall Loss: 14.131010
Rec Loss: 13.600157
KL Loss: 0.530853
Y Loss: 0.325073
T Loss: 12.950012
Epoch 949 
Overall Loss: 14.088607
Rec Loss: 13.573504
KL Loss: 0.515103
Y Loss: 0.316297
T Loss: 12.940909
Epoch 999 
Overall Loss: 14.052366
Rec Loss: 13.554921
KL Loss: 0.497444
Y Loss: 0.305796
T Loss: 12.943331
Epoch 1049 
Overall Loss: 13.993438
Rec Loss: 13.514891
KL Loss: 0.478547
Y Loss: 0.289687
T Loss: 12.935516
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.568036
Epoch 99
Rec Loss: 1.563452
Epoch 149
Rec Loss: 1.565185
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.054934
Epoch 99
Rec Loss: 10.066678
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.378996
Insample Error: 1.757637
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 47.079967
Rec Loss: 45.894830
KL Loss: 1.185138
Y Loss: 12.835075
T Loss: 13.644866
Epoch 99 
Overall Loss: 29.669780
Rec Loss: 24.755912
KL Loss: 4.913868
Y Loss: 2.823266
T Loss: 13.254656
Epoch 149 
Overall Loss: 25.717957
Rec Loss: 21.894941
KL Loss: 3.823016
Y Loss: 1.451494
T Loss: 13.263949
Epoch 199 
Overall Loss: 24.570416
Rec Loss: 21.242093
KL Loss: 3.328322
Y Loss: 1.197748
T Loss: 13.256826
Epoch 249 
Overall Loss: 23.912825
Rec Loss: 20.632663
KL Loss: 3.280161
Y Loss: 1.050197
T Loss: 13.240582
Epoch 299 
Overall Loss: 23.317560
Rec Loss: 19.755367
KL Loss: 3.562193
Y Loss: 0.904622
T Loss: 13.220876
Epoch 349 
Overall Loss: 22.791751
Rec Loss: 18.912181
KL Loss: 3.879570
Y Loss: 0.839631
T Loss: 13.213065
Epoch 399 
Overall Loss: 22.541110
Rec Loss: 18.526909
KL Loss: 4.014201
Y Loss: 0.775698
T Loss: 13.201503
Epoch 449 
Overall Loss: 22.328612
Rec Loss: 18.272179
KL Loss: 4.056433
Y Loss: 0.734554
T Loss: 13.188377
Epoch 499 
Overall Loss: 22.109219
Rec Loss: 18.031778
KL Loss: 4.077442
Y Loss: 0.698486
T Loss: 13.187834
Epoch 549 
Overall Loss: 21.666166
Rec Loss: 17.483623
KL Loss: 4.182542
Y Loss: 0.613717
T Loss: 13.170753
Epoch 599 
Overall Loss: 21.308214
Rec Loss: 16.930585
KL Loss: 4.377629
Y Loss: 0.534197
T Loss: 13.173897
Epoch 649 
Overall Loss: 21.120059
Rec Loss: 16.582842
KL Loss: 4.537217
Y Loss: 0.492246
T Loss: 13.164212
Epoch 699 
Overall Loss: 20.955968
Rec Loss: 16.311182
KL Loss: 4.644786
Y Loss: 0.448589
T Loss: 13.158492
Epoch 749 
Overall Loss: 20.810907
Rec Loss: 16.069668
KL Loss: 4.741239
Y Loss: 0.421401
T Loss: 13.140640
Epoch 799 
Overall Loss: 20.676482
Rec Loss: 15.833953
KL Loss: 4.842529
Y Loss: 0.392311
T Loss: 13.127402
Epoch 849 
Overall Loss: 20.586524
Rec Loss: 15.643884
KL Loss: 4.942640
Y Loss: 0.368809
T Loss: 13.118041
Epoch 899 
Overall Loss: 20.529885
Rec Loss: 15.486187
KL Loss: 5.043698
Y Loss: 0.354568
T Loss: 13.106656
Epoch 949 
Overall Loss: 20.456146
Rec Loss: 15.351371
KL Loss: 5.104775
Y Loss: 0.341507
T Loss: 13.095105
Epoch 999 
Overall Loss: 20.449039
Rec Loss: 15.279406
KL Loss: 5.169633
Y Loss: 0.341573
T Loss: 13.081158
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.711917
Epoch 99
Rec Loss: 1.709547
Epoch 149
Rec Loss: 1.710213
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.137340
Epoch 99
Rec Loss: 6.109171
Epoch 149
Rec Loss: 6.107964
Epoch 199
Rec Loss: 6.103305
Epoch 249
Rec Loss: 6.116360
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.274698
Insample Error 1.901702
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 40.074353
Rec Loss: 39.506821
KL Loss: 0.567533
Y Loss: 12.950314
T Loss: 13.606194
Epoch 99 
Overall Loss: 19.285675
Rec Loss: 17.690888
KL Loss: 1.594786
Y Loss: 2.243835
T Loss: 13.203219
Epoch 149 
Overall Loss: 16.760223
Rec Loss: 15.549596
KL Loss: 1.210627
Y Loss: 1.173723
T Loss: 13.202149
Epoch 199 
Overall Loss: 16.123891
Rec Loss: 15.135197
KL Loss: 0.988694
Y Loss: 0.970608
T Loss: 13.193981
Epoch 249 
Overall Loss: 15.520768
Rec Loss: 14.783600
KL Loss: 0.737169
Y Loss: 0.808355
T Loss: 13.166891
Epoch 299 
Overall Loss: 15.055154
Rec Loss: 14.486402
KL Loss: 0.568751
Y Loss: 0.673485
T Loss: 13.139432
Epoch 349 
Overall Loss: 14.796824
Rec Loss: 14.251563
KL Loss: 0.545262
Y Loss: 0.569834
T Loss: 13.111894
Epoch 399 
Overall Loss: 14.657979
Rec Loss: 14.114989
KL Loss: 0.542990
Y Loss: 0.505320
T Loss: 13.104348
Epoch 449 
Overall Loss: 14.574498
Rec Loss: 14.036576
KL Loss: 0.537922
Y Loss: 0.471587
T Loss: 13.093401
Epoch 499 
Overall Loss: 14.505317
Rec Loss: 13.972764
KL Loss: 0.532552
Y Loss: 0.437760
T Loss: 13.097246
Epoch 549 
Overall Loss: 14.465865
Rec Loss: 13.936141
KL Loss: 0.529723
Y Loss: 0.424162
T Loss: 13.087818
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.681905
Epoch 99
Rec Loss: 1.674168
Epoch 149
Rec Loss: 1.678896
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.061631
Epoch 99
Rec Loss: 10.059300
Epoch 149
Rec Loss: 10.059798
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.460179
Insample Error: 1.992479
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 50.285285
Rec Loss: 49.774008
KL Loss: 0.511277
Y Loss: 14.603763
T Loss: 13.737510
Epoch 99 
Overall Loss: 34.491928
Rec Loss: 30.224031
KL Loss: 4.267896
Y Loss: 5.549154
T Loss: 13.262168
Epoch 149 
Overall Loss: 27.646757
Rec Loss: 23.844298
KL Loss: 3.802459
Y Loss: 2.414759
T Loss: 13.289798
Epoch 199 
Overall Loss: 25.277251
Rec Loss: 21.836037
KL Loss: 3.441214
Y Loss: 1.435153
T Loss: 13.310541
Epoch 249 
Overall Loss: 24.116350
Rec Loss: 20.757941
KL Loss: 3.358409
Y Loss: 1.049658
T Loss: 13.293709
Epoch 299 
Overall Loss: 23.243267
Rec Loss: 19.809066
KL Loss: 3.434201
Y Loss: 0.813954
T Loss: 13.259975
Epoch 349 
Overall Loss: 22.558103
Rec Loss: 19.068564
KL Loss: 3.489539
Y Loss: 0.669410
T Loss: 13.240734
Epoch 399 
Overall Loss: 21.984784
Rec Loss: 18.302594
KL Loss: 3.682190
Y Loss: 0.544793
T Loss: 13.231025
Epoch 449 
Overall Loss: 21.670024
Rec Loss: 17.952348
KL Loss: 3.717676
Y Loss: 0.476379
T Loss: 13.215183
Epoch 499 
Overall Loss: 21.480814
Rec Loss: 17.788121
KL Loss: 3.692693
Y Loss: 0.439424
T Loss: 13.207154
Epoch 549 
Overall Loss: 21.317555
Rec Loss: 17.586329
KL Loss: 3.731226
Y Loss: 0.413857
T Loss: 13.187172
Epoch 599 
Overall Loss: 21.175725
Rec Loss: 17.380582
KL Loss: 3.795144
Y Loss: 0.381126
T Loss: 13.177217
Epoch 649 
Overall Loss: 21.043622
Rec Loss: 17.153787
KL Loss: 3.889836
Y Loss: 0.356077
T Loss: 13.158304
Epoch 699 
Overall Loss: 20.944432
Rec Loss: 16.948180
KL Loss: 3.996253
Y Loss: 0.340573
T Loss: 13.148898
Epoch 749 
Overall Loss: 20.875731
Rec Loss: 16.784818
KL Loss: 4.090913
Y Loss: 0.329017
T Loss: 13.133982
Epoch 799 
Overall Loss: 20.800893
Rec Loss: 16.627276
KL Loss: 4.173617
Y Loss: 0.317939
T Loss: 13.122823
Epoch 849 
Overall Loss: 20.791930
Rec Loss: 16.580536
KL Loss: 4.211394
Y Loss: 0.321894
T Loss: 13.106505
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.750253
Epoch 99
Rec Loss: 1.753387
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 7.336885
Epoch 99
Rec Loss: 7.343529
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.244461
Insample Error 1.983706
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 39.828625
Rec Loss: 39.259340
KL Loss: 0.569287
Y Loss: 12.847926
T Loss: 13.563487
Epoch 99 
Overall Loss: 19.183474
Rec Loss: 17.697429
KL Loss: 1.486045
Y Loss: 2.228976
T Loss: 13.239476
Epoch 149 
Overall Loss: 16.937904
Rec Loss: 15.693389
KL Loss: 1.244516
Y Loss: 1.225532
T Loss: 13.242324
Epoch 199 
Overall Loss: 16.168327
Rec Loss: 15.184066
KL Loss: 0.984261
Y Loss: 0.972354
T Loss: 13.239358
Epoch 249 
Overall Loss: 15.573826
Rec Loss: 14.843533
KL Loss: 0.730293
Y Loss: 0.817425
T Loss: 13.208683
Epoch 299 
Overall Loss: 15.121037
Rec Loss: 14.519664
KL Loss: 0.601372
Y Loss: 0.667897
T Loss: 13.183870
Epoch 349 
Overall Loss: 14.925599
Rec Loss: 14.342529
KL Loss: 0.583069
Y Loss: 0.592975
T Loss: 13.156579
Epoch 399 
Overall Loss: 14.797849
Rec Loss: 14.217807
KL Loss: 0.580042
Y Loss: 0.536422
T Loss: 13.144964
Epoch 449 
Overall Loss: 14.717804
Rec Loss: 14.147839
KL Loss: 0.569964
Y Loss: 0.505832
T Loss: 13.136176
Epoch 499 
Overall Loss: 14.624566
Rec Loss: 14.059037
KL Loss: 0.565530
Y Loss: 0.465852
T Loss: 13.127332
Epoch 549 
Overall Loss: 14.563522
Rec Loss: 14.007298
KL Loss: 0.556224
Y Loss: 0.445587
T Loss: 13.116124
Epoch 599 
Overall Loss: 14.456816
Rec Loss: 13.912598
KL Loss: 0.544218
Y Loss: 0.405572
T Loss: 13.101455
Epoch 649 
Overall Loss: 14.384356
Rec Loss: 13.847483
KL Loss: 0.536872
Y Loss: 0.378615
T Loss: 13.090255
Epoch 699 
Overall Loss: 14.320124
Rec Loss: 13.800181
KL Loss: 0.519942
Y Loss: 0.360312
T Loss: 13.079558
Epoch 749 
Overall Loss: 14.262709
Rec Loss: 13.755440
KL Loss: 0.507269
Y Loss: 0.343006
T Loss: 13.069428
Epoch 799 
Overall Loss: 14.184525
Rec Loss: 13.693365
KL Loss: 0.491161
Y Loss: 0.319868
T Loss: 13.053628
Epoch 849 
Overall Loss: 14.120008
Rec Loss: 13.643821
KL Loss: 0.476187
Y Loss: 0.303890
T Loss: 13.036041
Epoch 899 
Overall Loss: 14.065980
Rec Loss: 13.612496
KL Loss: 0.453484
Y Loss: 0.296772
T Loss: 13.018951
Epoch 949 
Overall Loss: 13.974210
Rec Loss: 13.539199
KL Loss: 0.435010
Y Loss: 0.267648
T Loss: 13.003903
Epoch 999 
Overall Loss: 13.920267
Rec Loss: 13.509146
KL Loss: 0.411122
Y Loss: 0.256696
T Loss: 12.995754
Epoch 1049 
Overall Loss: 13.858378
Rec Loss: 13.481951
KL Loss: 0.376427
Y Loss: 0.246446
T Loss: 12.989059
Epoch 1099 
Overall Loss: 13.794154
Rec Loss: 13.445573
KL Loss: 0.348581
Y Loss: 0.230245
T Loss: 12.985083
Epoch 1149 
Overall Loss: 13.742264
Rec Loss: 13.423503
KL Loss: 0.318761
Y Loss: 0.219631
T Loss: 12.984241
Epoch 1199 
Overall Loss: 13.713383
Rec Loss: 13.425092
KL Loss: 0.288291
Y Loss: 0.214256
T Loss: 12.996580
Epoch 1249 
Overall Loss: 13.663645
Rec Loss: 13.408098
KL Loss: 0.255547
Y Loss: 0.203232
T Loss: 13.001635
Epoch 1299 
Overall Loss: 13.639590
Rec Loss: 13.406434
KL Loss: 0.233156
Y Loss: 0.199573
T Loss: 13.007289
Epoch 1349 
Overall Loss: 13.607694
Rec Loss: 13.394399
KL Loss: 0.213295
Y Loss: 0.190631
T Loss: 13.013137
Epoch 1399 
Overall Loss: 13.589367
Rec Loss: 13.395912
KL Loss: 0.193456
Y Loss: 0.187622
T Loss: 13.020668
Epoch 1449 
Overall Loss: 13.554659
Rec Loss: 13.376074
KL Loss: 0.178585
Y Loss: 0.178630
T Loss: 13.018814
Epoch 1499 
Overall Loss: 13.549006
Rec Loss: 13.382311
KL Loss: 0.166696
Y Loss: 0.178997
T Loss: 13.024317
Epoch 1549 
Overall Loss: 13.543599
Rec Loss: 13.387794
KL Loss: 0.155805
Y Loss: 0.178913
T Loss: 13.029967
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.517331
Epoch 99
Rec Loss: 1.506007
Epoch 149
Rec Loss: 1.503967
Epoch 199
Rec Loss: 1.500069
Epoch 249
Rec Loss: 1.501296
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.060625
Epoch 99
Rec Loss: 10.053923
Epoch 149
Rec Loss: 10.055707
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.348898
Insample Error: 0.949610
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 48.628964
Rec Loss: 47.490599
KL Loss: 1.138365
Y Loss: 13.610017
T Loss: 13.668240
Epoch 99 
Overall Loss: 32.600208
Rec Loss: 28.137672
KL Loss: 4.462536
Y Loss: 4.484658
T Loss: 13.279347
Epoch 149 
Overall Loss: 26.847618
Rec Loss: 23.141148
KL Loss: 3.706470
Y Loss: 2.051422
T Loss: 13.296745
Epoch 199 
Overall Loss: 25.008466
Rec Loss: 21.765828
KL Loss: 3.242639
Y Loss: 1.412079
T Loss: 13.294461
Epoch 249 
Overall Loss: 24.061638
Rec Loss: 20.916392
KL Loss: 3.145247
Y Loss: 1.098180
T Loss: 13.268205
Epoch 299 
Overall Loss: 23.415673
Rec Loss: 20.158986
KL Loss: 3.256687
Y Loss: 0.932944
T Loss: 13.229071
Epoch 349 
Overall Loss: 22.931267
Rec Loss: 19.596020
KL Loss: 3.335248
Y Loss: 0.809225
T Loss: 13.180958
Epoch 399 
Overall Loss: 22.494568
Rec Loss: 19.196631
KL Loss: 3.297936
Y Loss: 0.707323
T Loss: 13.152153
Epoch 449 
Overall Loss: 21.967171
Rec Loss: 18.699031
KL Loss: 3.268140
Y Loss: 0.580681
T Loss: 13.133898
Epoch 499 
Overall Loss: 21.553308
Rec Loss: 18.228328
KL Loss: 3.324980
Y Loss: 0.473719
T Loss: 13.143221
Epoch 549 
Overall Loss: 21.280423
Rec Loss: 17.915779
KL Loss: 3.364644
Y Loss: 0.417406
T Loss: 13.155067
Epoch 599 
Overall Loss: 21.052927
Rec Loss: 17.728892
KL Loss: 3.324034
Y Loss: 0.355984
T Loss: 13.151666
Epoch 649 
Overall Loss: 20.920404
Rec Loss: 17.658475
KL Loss: 3.261930
Y Loss: 0.324155
T Loss: 13.143345
Epoch 699 
Overall Loss: 20.821887
Rec Loss: 17.582849
KL Loss: 3.239038
Y Loss: 0.307275
T Loss: 13.128907
Epoch 749 
Overall Loss: 20.757670
Rec Loss: 17.511448
KL Loss: 3.246223
Y Loss: 0.300027
T Loss: 13.108028
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.765665
Epoch 99
Rec Loss: 1.761743
Epoch 149
Rec Loss: 1.763416
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 7.676913
Epoch 99
Rec Loss: 7.656179
Epoch 149
Rec Loss: 7.650984
Epoch 199
Rec Loss: 7.638941
Epoch 249
Rec Loss: 7.642585
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.277746
Insample Error 2.009655
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 39.825511
Rec Loss: 39.265197
KL Loss: 0.560314
Y Loss: 12.796526
T Loss: 13.672146
Epoch 99 
Overall Loss: 20.174915
Rec Loss: 18.745719
KL Loss: 1.429196
Y Loss: 2.763694
T Loss: 13.218331
Epoch 149 
Overall Loss: 17.304872
Rec Loss: 16.032370
KL Loss: 1.272502
Y Loss: 1.399317
T Loss: 13.233736
Epoch 199 
Overall Loss: 16.345731
Rec Loss: 15.297086
KL Loss: 1.048644
Y Loss: 1.038152
T Loss: 13.220782
Epoch 249 
Overall Loss: 15.624137
Rec Loss: 14.843587
KL Loss: 0.780550
Y Loss: 0.827922
T Loss: 13.187742
Epoch 299 
Overall Loss: 15.194195
Rec Loss: 14.577747
KL Loss: 0.616448
Y Loss: 0.708935
T Loss: 13.159877
Epoch 349 
Overall Loss: 14.933730
Rec Loss: 14.337682
KL Loss: 0.596048
Y Loss: 0.601706
T Loss: 13.134270
Epoch 399 
Overall Loss: 14.792914
Rec Loss: 14.194350
KL Loss: 0.598563
Y Loss: 0.539973
T Loss: 13.114404
Epoch 449 
Overall Loss: 14.673331
Rec Loss: 14.086218
KL Loss: 0.587113
Y Loss: 0.493300
T Loss: 13.099619
Epoch 499 
Overall Loss: 14.603891
Rec Loss: 14.027614
KL Loss: 0.576277
Y Loss: 0.466985
T Loss: 13.093644
Epoch 549 
Overall Loss: 14.529764
Rec Loss: 13.958238
KL Loss: 0.571526
Y Loss: 0.436718
T Loss: 13.084803
Epoch 599 
Overall Loss: 14.458213
Rec Loss: 13.893457
KL Loss: 0.564756
Y Loss: 0.410708
T Loss: 13.072042
Epoch 649 
Overall Loss: 14.421411
Rec Loss: 13.853906
KL Loss: 0.567505
Y Loss: 0.399540
T Loss: 13.054825
Epoch 699 
Overall Loss: 14.359763
Rec Loss: 13.799279
KL Loss: 0.560484
Y Loss: 0.378284
T Loss: 13.042712
Epoch 749 
Overall Loss: 14.310474
Rec Loss: 13.745187
KL Loss: 0.565287
Y Loss: 0.358471
T Loss: 13.028246
Epoch 799 
Overall Loss: 14.231719
Rec Loss: 13.659867
KL Loss: 0.571852
Y Loss: 0.330271
T Loss: 12.999325
Epoch 849 
Overall Loss: 14.172653
Rec Loss: 13.598921
KL Loss: 0.573732
Y Loss: 0.312487
T Loss: 12.973948
Epoch 899 
Overall Loss: 14.117768
Rec Loss: 13.542825
KL Loss: 0.574943
Y Loss: 0.294148
T Loss: 12.954529
Epoch 949 
Overall Loss: 14.071403
Rec Loss: 13.500841
KL Loss: 0.570562
Y Loss: 0.278589
T Loss: 12.943662
Epoch 999 
Overall Loss: 14.002470
Rec Loss: 13.444500
KL Loss: 0.557971
Y Loss: 0.257638
T Loss: 12.929224
Epoch 1049 
Overall Loss: 13.978673
Rec Loss: 13.436749
KL Loss: 0.541924
Y Loss: 0.253375
T Loss: 12.929999
Epoch 1099 
Overall Loss: 13.921137
Rec Loss: 13.403138
KL Loss: 0.517999
Y Loss: 0.236743
T Loss: 12.929652
Epoch 1149 
Overall Loss: 13.886735
Rec Loss: 13.393054
KL Loss: 0.493681
Y Loss: 0.232632
T Loss: 12.927789
Epoch 1199 
Overall Loss: 13.866081
Rec Loss: 13.398588
KL Loss: 0.467493
Y Loss: 0.231829
T Loss: 12.934930
Epoch 1249 
Overall Loss: 13.822931
Rec Loss: 13.385636
KL Loss: 0.437295
Y Loss: 0.225188
T Loss: 12.935260
Epoch 1299 
Overall Loss: 13.783534
Rec Loss: 13.374852
KL Loss: 0.408682
Y Loss: 0.218458
T Loss: 12.937936
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.546995
Epoch 99
Rec Loss: 1.545364
Epoch 149
Rec Loss: 1.543664
Epoch 199
Rec Loss: 1.544296
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.079252
Epoch 99
Rec Loss: 10.077247
Epoch 149
Rec Loss: 10.073052
Epoch 199
Rec Loss: 10.076627
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.327747
Insample Error: 1.462603
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 50.130334
Rec Loss: 49.069684
KL Loss: 1.060650
Y Loss: 14.292980
T Loss: 13.666570
Epoch 99 
Overall Loss: 33.321116
Rec Loss: 27.857407
KL Loss: 5.463710
Y Loss: 4.373389
T Loss: 13.230662
Epoch 149 
Overall Loss: 26.573705
Rec Loss: 22.191933
KL Loss: 4.381772
Y Loss: 1.611528
T Loss: 13.255519
Epoch 199 
Overall Loss: 24.767651
Rec Loss: 21.183311
KL Loss: 3.584340
Y Loss: 1.145518
T Loss: 13.251234
Epoch 249 
Overall Loss: 24.069082
Rec Loss: 20.700492
KL Loss: 3.368590
Y Loss: 0.971817
T Loss: 13.230634
Epoch 299 
Overall Loss: 23.628823
Rec Loss: 20.238615
KL Loss: 3.390208
Y Loss: 0.894748
T Loss: 13.186332
Epoch 349 
Overall Loss: 23.164030
Rec Loss: 19.644637
KL Loss: 3.519394
Y Loss: 0.785798
T Loss: 13.180459
Epoch 399 
Overall Loss: 22.777608
Rec Loss: 19.255787
KL Loss: 3.521821
Y Loss: 0.714337
T Loss: 13.175649
Epoch 449 
Overall Loss: 22.387952
Rec Loss: 18.923177
KL Loss: 3.464775
Y Loss: 0.639898
T Loss: 13.172641
Epoch 499 
Overall Loss: 21.944425
Rec Loss: 18.588037
KL Loss: 3.356389
Y Loss: 0.546615
T Loss: 13.172549
Epoch 549 
Overall Loss: 21.595307
Rec Loss: 18.259373
KL Loss: 3.335935
Y Loss: 0.447697
T Loss: 13.180208
Epoch 599 
Overall Loss: 21.365123
Rec Loss: 17.946150
KL Loss: 3.418973
Y Loss: 0.387074
T Loss: 13.178848
Epoch 649 
Overall Loss: 21.226262
Rec Loss: 17.685379
KL Loss: 3.540883
Y Loss: 0.355745
T Loss: 13.168386
Epoch 699 
Overall Loss: 21.143113
Rec Loss: 17.502532
KL Loss: 3.640582
Y Loss: 0.348981
T Loss: 13.156252
Epoch 749 
Overall Loss: 21.044560
Rec Loss: 17.298002
KL Loss: 3.746557
Y Loss: 0.334684
T Loss: 13.138727
Epoch 799 
Overall Loss: 20.979658
Rec Loss: 17.153237
KL Loss: 3.826421
Y Loss: 0.322201
T Loss: 13.129512
Epoch 849 
Overall Loss: 20.927434
Rec Loss: 16.996388
KL Loss: 3.931046
Y Loss: 0.324187
T Loss: 13.112727
Epoch 899 
Overall Loss: 20.836213
Rec Loss: 16.779097
KL Loss: 4.057117
Y Loss: 0.309137
T Loss: 13.101978
Epoch 949 
Overall Loss: 20.775709
Rec Loss: 16.655234
KL Loss: 4.120475
Y Loss: 0.314844
T Loss: 13.090401
Epoch 999 
Overall Loss: 20.705581
Rec Loss: 16.524777
KL Loss: 4.180804
Y Loss: 0.306759
T Loss: 13.083448
Epoch 1049 
Overall Loss: 20.647363
Rec Loss: 16.412326
KL Loss: 4.235038
Y Loss: 0.304675
T Loss: 13.072005
Epoch 1099 
Overall Loss: 20.621174
Rec Loss: 16.340572
KL Loss: 4.280602
Y Loss: 0.303878
T Loss: 13.063388
Epoch 1149 
Overall Loss: 20.556694
Rec Loss: 16.227213
KL Loss: 4.329481
Y Loss: 0.293573
T Loss: 13.057021
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.670241
Epoch 99
Rec Loss: 1.665893
Epoch 149
Rec Loss: 1.666821
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 7.441829
Epoch 99
Rec Loss: 7.413558
Epoch 149
Rec Loss: 7.393348
Epoch 199
Rec Loss: 7.404396
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.236918
Insample Error 1.774127
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 41.666561
Rec Loss: 41.323480
KL Loss: 0.343080
Y Loss: 13.831760
T Loss: 13.659961
Epoch 99 
Overall Loss: 22.690850
Rec Loss: 21.322852
KL Loss: 1.367998
Y Loss: 4.049996
T Loss: 13.222861
Epoch 149 
Overall Loss: 18.025688
Rec Loss: 16.908061
KL Loss: 1.117628
Y Loss: 1.845525
T Loss: 13.217010
Epoch 199 
Overall Loss: 16.576104
Rec Loss: 15.664252
KL Loss: 0.911852
Y Loss: 1.219798
T Loss: 13.224656
Epoch 249 
Overall Loss: 15.773691
Rec Loss: 15.104204
KL Loss: 0.669488
Y Loss: 0.952564
T Loss: 13.199076
Epoch 299 
Overall Loss: 15.245712
Rec Loss: 14.686343
KL Loss: 0.559369
Y Loss: 0.760335
T Loss: 13.165674
Epoch 349 
Overall Loss: 14.984610
Rec Loss: 14.412958
KL Loss: 0.571652
Y Loss: 0.636936
T Loss: 13.139086
Epoch 399 
Overall Loss: 14.813913
Rec Loss: 14.240715
KL Loss: 0.573199
Y Loss: 0.560981
T Loss: 13.118753
Epoch 449 
Overall Loss: 14.707111
Rec Loss: 14.135894
KL Loss: 0.571217
Y Loss: 0.514726
T Loss: 13.106443
Epoch 499 
Overall Loss: 14.602998
Rec Loss: 14.034316
KL Loss: 0.568682
Y Loss: 0.468157
T Loss: 13.098002
Epoch 549 
Overall Loss: 14.534717
Rec Loss: 13.971712
KL Loss: 0.563005
Y Loss: 0.441246
T Loss: 13.089221
Epoch 599 
Overall Loss: 14.459160
Rec Loss: 13.901942
KL Loss: 0.557218
Y Loss: 0.410621
T Loss: 13.080700
Epoch 649 
Overall Loss: 14.396901
Rec Loss: 13.845123
KL Loss: 0.551779
Y Loss: 0.385130
T Loss: 13.074862
Epoch 699 
Overall Loss: 14.340963
Rec Loss: 13.791489
KL Loss: 0.549474
Y Loss: 0.363069
T Loss: 13.065352
Epoch 749 
Overall Loss: 14.272960
Rec Loss: 13.720771
KL Loss: 0.552189
Y Loss: 0.330941
T Loss: 13.058888
Epoch 799 
Overall Loss: 14.257689
Rec Loss: 13.701220
KL Loss: 0.556469
Y Loss: 0.322160
T Loss: 13.056901
Epoch 849 
Overall Loss: 14.191660
Rec Loss: 13.632201
KL Loss: 0.559458
Y Loss: 0.294489
T Loss: 13.043223
Epoch 899 
Overall Loss: 14.140662
Rec Loss: 13.576647
KL Loss: 0.564015
Y Loss: 0.271878
T Loss: 13.032890
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.630708
Epoch 99
Rec Loss: 1.626867
Epoch 149
Rec Loss: 1.632693
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.076985
Epoch 99
Rec Loss: 10.073281
Epoch 149
Rec Loss: 10.072913
Epoch 199
Rec Loss: 10.075787
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.325601
Insample Error: 1.927631
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 50.588653
Rec Loss: 50.077011
KL Loss: 0.511641
Y Loss: 14.724029
T Loss: 13.730970
Epoch 99 
Overall Loss: 33.872717
Rec Loss: 29.339359
KL Loss: 4.533358
Y Loss: 5.126750
T Loss: 13.239325
Epoch 149 
Overall Loss: 27.381538
Rec Loss: 23.434380
KL Loss: 3.947159
Y Loss: 2.236069
T Loss: 13.259423
Epoch 199 
Overall Loss: 25.389207
Rec Loss: 21.846955
KL Loss: 3.542252
Y Loss: 1.441924
T Loss: 13.276953
Epoch 249 
Overall Loss: 24.484487
Rec Loss: 21.163565
KL Loss: 3.320922
Y Loss: 1.132797
T Loss: 13.268826
Epoch 299 
Overall Loss: 23.749732
Rec Loss: 20.424255
KL Loss: 3.325477
Y Loss: 0.913267
T Loss: 13.222869
Epoch 349 
Overall Loss: 22.999627
Rec Loss: 19.517848
KL Loss: 3.481778
Y Loss: 0.770929
T Loss: 13.182721
Epoch 399 
Overall Loss: 22.546970
Rec Loss: 18.988345
KL Loss: 3.558625
Y Loss: 0.664088
T Loss: 13.123886
Epoch 449 
Overall Loss: 22.205423
Rec Loss: 18.563681
KL Loss: 3.641742
Y Loss: 0.587630
T Loss: 13.057796
Epoch 499 
Overall Loss: 21.922892
Rec Loss: 18.237172
KL Loss: 3.685719
Y Loss: 0.547320
T Loss: 13.023056
Epoch 549 
Overall Loss: 21.671104
Rec Loss: 17.965820
KL Loss: 3.705283
Y Loss: 0.496669
T Loss: 13.027809
Epoch 599 
Overall Loss: 21.496587
Rec Loss: 17.792180
KL Loss: 3.704407
Y Loss: 0.478698
T Loss: 13.048365
Epoch 649 
Overall Loss: 21.285458
Rec Loss: 17.580159
KL Loss: 3.705299
Y Loss: 0.427641
T Loss: 13.068290
Epoch 699 
Overall Loss: 21.107469
Rec Loss: 17.422994
KL Loss: 3.684475
Y Loss: 0.380784
T Loss: 13.090064
Epoch 749 
Overall Loss: 20.943358
Rec Loss: 17.234356
KL Loss: 3.709002
Y Loss: 0.338639
T Loss: 13.089243
Epoch 799 
Overall Loss: 20.907570
Rec Loss: 17.179718
KL Loss: 3.727852
Y Loss: 0.332224
T Loss: 13.091425
Epoch 849 
Overall Loss: 20.817632
Rec Loss: 17.047374
KL Loss: 3.770257
Y Loss: 0.310529
T Loss: 13.082235
Epoch 899 
Overall Loss: 20.749899
Rec Loss: 16.984927
KL Loss: 3.764972
Y Loss: 0.302652
T Loss: 13.077150
Epoch 949 
Overall Loss: 20.701782
Rec Loss: 16.945379
KL Loss: 3.756404
Y Loss: 0.287223
T Loss: 13.065249
Epoch 999 
Overall Loss: 20.657116
Rec Loss: 16.922347
KL Loss: 3.734768
Y Loss: 0.281450
T Loss: 13.061631
Epoch 1049 
Overall Loss: 20.618074
Rec Loss: 16.919408
KL Loss: 3.698666
Y Loss: 0.270860
T Loss: 13.060313
Epoch 1099 
Overall Loss: 20.581322
Rec Loss: 16.912404
KL Loss: 3.668918
Y Loss: 0.278588
T Loss: 13.047357
Epoch 1149 
Overall Loss: 20.534157
Rec Loss: 16.869098
KL Loss: 3.665060
Y Loss: 0.265494
T Loss: 13.031631
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.685092
Epoch 99
Rec Loss: 1.683106
Epoch 149
Rec Loss: 1.680775
Epoch 199
Rec Loss: 1.682156
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 7.501329
Epoch 99
Rec Loss: 7.482387
Epoch 149
Rec Loss: 7.488602
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.232372
Insample Error 1.979435
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 42.296550
Rec Loss: 41.878300
KL Loss: 0.418249
Y Loss: 14.021461
T Loss: 13.835379
Epoch 99 
Overall Loss: 22.122965
Rec Loss: 20.529701
KL Loss: 1.593263
Y Loss: 3.631138
T Loss: 13.267426
Epoch 149 
Overall Loss: 17.317893
Rec Loss: 16.381390
KL Loss: 0.936502
Y Loss: 1.565530
T Loss: 13.250331
Epoch 199 
Overall Loss: 16.234265
Rec Loss: 15.478422
KL Loss: 0.755844
Y Loss: 1.118718
T Loss: 13.240985
Epoch 249 
Overall Loss: 15.613951
Rec Loss: 15.014924
KL Loss: 0.599028
Y Loss: 0.897302
T Loss: 13.220320
Epoch 299 
Overall Loss: 15.225860
Rec Loss: 14.679362
KL Loss: 0.546497
Y Loss: 0.740279
T Loss: 13.198806
Epoch 349 
Overall Loss: 14.969874
Rec Loss: 14.421154
KL Loss: 0.548719
Y Loss: 0.623826
T Loss: 13.173501
Epoch 399 
Overall Loss: 14.813867
Rec Loss: 14.266905
KL Loss: 0.546962
Y Loss: 0.555182
T Loss: 13.156541
Epoch 449 
Overall Loss: 14.677870
Rec Loss: 14.133501
KL Loss: 0.544370
Y Loss: 0.493832
T Loss: 13.145836
Epoch 499 
Overall Loss: 14.582698
Rec Loss: 14.048701
KL Loss: 0.533997
Y Loss: 0.459714
T Loss: 13.129272
Epoch 549 
Overall Loss: 14.505444
Rec Loss: 13.972487
KL Loss: 0.532957
Y Loss: 0.425369
T Loss: 13.121748
Epoch 599 
Overall Loss: 14.468895
Rec Loss: 13.939537
KL Loss: 0.529358
Y Loss: 0.414724
T Loss: 13.110089
Epoch 649 
Overall Loss: 14.417258
Rec Loss: 13.890076
KL Loss: 0.527182
Y Loss: 0.394534
T Loss: 13.101008
Epoch 699 
Overall Loss: 14.375665
Rec Loss: 13.850519
KL Loss: 0.525147
Y Loss: 0.378037
T Loss: 13.094446
Epoch 749 
Overall Loss: 14.323934
Rec Loss: 13.796721
KL Loss: 0.527214
Y Loss: 0.355493
T Loss: 13.085735
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.658375
Epoch 99
Rec Loss: 1.653151
Epoch 149
Rec Loss: 1.648813
Epoch 199
Rec Loss: 1.655183
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.050600
Epoch 99
Rec Loss: 10.046540
Epoch 149
Rec Loss: 10.052044
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.395954
Insample Error: 2.004368
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 49.705814
Rec Loss: 49.195366
KL Loss: 0.510448
Y Loss: 14.270658
T Loss: 13.692161
Epoch 99 
Overall Loss: 32.017631
Rec Loss: 27.571216
KL Loss: 4.446415
Y Loss: 4.240750
T Loss: 13.232405
Epoch 149 
Overall Loss: 26.300657
Rec Loss: 22.249444
KL Loss: 4.051213
Y Loss: 1.656046
T Loss: 13.247913
Epoch 199 
Overall Loss: 24.659432
Rec Loss: 21.241103
KL Loss: 3.418327
Y Loss: 1.176951
T Loss: 13.255461
Epoch 249 
Overall Loss: 23.940841
Rec Loss: 20.770987
KL Loss: 3.169853
Y Loss: 0.974375
T Loss: 13.241964
Epoch 299 
Overall Loss: 23.446830
Rec Loss: 20.376159
KL Loss: 3.070670
Y Loss: 0.826788
T Loss: 13.229796
Epoch 349 
Overall Loss: 23.065466
Rec Loss: 20.012908
KL Loss: 3.052557
Y Loss: 0.758960
T Loss: 13.201200
Epoch 399 
Overall Loss: 22.561695
Rec Loss: 19.403327
KL Loss: 3.158370
Y Loss: 0.665752
T Loss: 13.183216
Epoch 449 
Overall Loss: 22.177697
Rec Loss: 18.961287
KL Loss: 3.216409
Y Loss: 0.579900
T Loss: 13.162505
Epoch 499 
Overall Loss: 21.843069
Rec Loss: 18.701113
KL Loss: 3.141957
Y Loss: 0.518230
T Loss: 13.157671
Epoch 549 
Overall Loss: 21.497368
Rec Loss: 18.442614
KL Loss: 3.054754
Y Loss: 0.431968
T Loss: 13.156442
Epoch 599 
Overall Loss: 21.251235
Rec Loss: 18.263925
KL Loss: 2.987310
Y Loss: 0.345381
T Loss: 13.150593
Epoch 649 
Overall Loss: 21.071629
Rec Loss: 18.133291
KL Loss: 2.938338
Y Loss: 0.306437
T Loss: 13.138791
Epoch 699 
Overall Loss: 20.941596
Rec Loss: 17.969143
KL Loss: 2.972453
Y Loss: 0.294019
T Loss: 13.123653
Epoch 749 
Overall Loss: 20.854686
Rec Loss: 17.750271
KL Loss: 3.104415
Y Loss: 0.277402
T Loss: 13.111779
Epoch 799 
Overall Loss: 20.773870
Rec Loss: 17.554745
KL Loss: 3.219126
Y Loss: 0.270720
T Loss: 13.099616
Epoch 849 
Overall Loss: 20.714292
Rec Loss: 17.415074
KL Loss: 3.299219
Y Loss: 0.276542
T Loss: 13.089633
Epoch 899 
Overall Loss: 20.662559
Rec Loss: 17.311496
KL Loss: 3.351063
Y Loss: 0.274281
T Loss: 13.082392
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.722086
Epoch 99
Rec Loss: 1.720208
Epoch 149
Rec Loss: 1.719031
Epoch 199
Rec Loss: 1.716477
Epoch 249
Rec Loss: 1.713790
Epoch 299
Rec Loss: 1.714833
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 7.694427
Epoch 99
Rec Loss: 7.683707
Epoch 149
Rec Loss: 7.673686
Epoch 199
Rec Loss: 7.676379
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.232880
Insample Error 1.973489
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 42.257841
Rec Loss: 42.014310
KL Loss: 0.243532
Y Loss: 14.119730
T Loss: 13.774849
Epoch 99 
Overall Loss: 20.704928
Rec Loss: 19.311182
KL Loss: 1.393746
Y Loss: 3.030591
T Loss: 13.250001
Epoch 149 
Overall Loss: 16.847608
Rec Loss: 15.870817
KL Loss: 0.976791
Y Loss: 1.324663
T Loss: 13.221492
Epoch 199 
Overall Loss: 16.038600
Rec Loss: 15.286434
KL Loss: 0.752166
Y Loss: 1.039954
T Loss: 13.206527
Epoch 249 
Overall Loss: 15.461539
Rec Loss: 14.880441
KL Loss: 0.581098
Y Loss: 0.851435
T Loss: 13.177571
Epoch 299 
Overall Loss: 15.117459
Rec Loss: 14.587445
KL Loss: 0.530014
Y Loss: 0.715125
T Loss: 13.157195
Epoch 349 
Overall Loss: 14.912890
Rec Loss: 14.383631
KL Loss: 0.529259
Y Loss: 0.619429
T Loss: 13.144773
Epoch 399 
Overall Loss: 14.787004
Rec Loss: 14.258046
KL Loss: 0.528958
Y Loss: 0.567801
T Loss: 13.122444
Epoch 449 
Overall Loss: 14.663780
Rec Loss: 14.135777
KL Loss: 0.528002
Y Loss: 0.514984
T Loss: 13.105809
Epoch 499 
Overall Loss: 14.580942
Rec Loss: 14.053574
KL Loss: 0.527368
Y Loss: 0.480090
T Loss: 13.093394
Epoch 549 
Overall Loss: 14.492850
Rec Loss: 13.970841
KL Loss: 0.522009
Y Loss: 0.443964
T Loss: 13.082912
Epoch 599 
Overall Loss: 14.420853
Rec Loss: 13.897906
KL Loss: 0.522947
Y Loss: 0.411575
T Loss: 13.074755
Epoch 649 
Overall Loss: 14.328221
Rec Loss: 13.810780
KL Loss: 0.517441
Y Loss: 0.378098
T Loss: 13.054585
Epoch 699 
Overall Loss: 14.263542
Rec Loss: 13.762489
KL Loss: 0.501053
Y Loss: 0.357202
T Loss: 13.048086
Epoch 749 
Overall Loss: 14.197316
Rec Loss: 13.712201
KL Loss: 0.485115
Y Loss: 0.338440
T Loss: 13.035322
Epoch 799 
Overall Loss: 14.110744
Rec Loss: 13.648731
KL Loss: 0.462013
Y Loss: 0.314497
T Loss: 13.019737
Epoch 849 
Overall Loss: 14.055820
Rec Loss: 13.616032
KL Loss: 0.439789
Y Loss: 0.304320
T Loss: 13.007393
Epoch 899 
Overall Loss: 13.990134
Rec Loss: 13.567883
KL Loss: 0.422250
Y Loss: 0.289978
T Loss: 12.987928
Epoch 949 
Overall Loss: 13.933347
Rec Loss: 13.531096
KL Loss: 0.402251
Y Loss: 0.275929
T Loss: 12.979237
Epoch 999 
Overall Loss: 13.874921
Rec Loss: 13.491466
KL Loss: 0.383455
Y Loss: 0.261397
T Loss: 12.968673
Epoch 1049 
Overall Loss: 13.837233
Rec Loss: 13.470022
KL Loss: 0.367212
Y Loss: 0.254393
T Loss: 12.961236
Epoch 1099 
Overall Loss: 13.801531
Rec Loss: 13.448426
KL Loss: 0.353105
Y Loss: 0.243774
T Loss: 12.960879
Epoch 1149 
Overall Loss: 13.756595
Rec Loss: 13.422306
KL Loss: 0.334289
Y Loss: 0.232802
T Loss: 12.956702
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.525560
Epoch 99
Rec Loss: 1.530008
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.065274
Epoch 99
Rec Loss: 10.062414
Epoch 149
Rec Loss: 10.060532
Epoch 199
Rec Loss: 10.067034
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.359910
Insample Error: 1.294847
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 47.766020
Rec Loss: 47.019117
KL Loss: 0.746903
Y Loss: 13.339016
T Loss: 13.673085
Epoch 99 
Overall Loss: 31.680455
Rec Loss: 27.462566
KL Loss: 4.217889
Y Loss: 4.224769
T Loss: 13.264678
Epoch 149 
Overall Loss: 27.053294
Rec Loss: 23.422131
KL Loss: 3.631163
Y Loss: 2.250400
T Loss: 13.264700
Epoch 199 
Overall Loss: 25.342707
Rec Loss: 22.006647
KL Loss: 3.336060
Y Loss: 1.559544
T Loss: 13.266477
Epoch 249 
Overall Loss: 24.342521
Rec Loss: 21.105910
KL Loss: 3.236610
Y Loss: 1.163523
T Loss: 13.241628
Epoch 299 
Overall Loss: 23.658776
Rec Loss: 20.491305
KL Loss: 3.167470
Y Loss: 0.935268
T Loss: 13.206562
Epoch 349 
Overall Loss: 23.042097
Rec Loss: 19.838510
KL Loss: 3.203588
Y Loss: 0.789573
T Loss: 13.172417
Epoch 399 
Overall Loss: 22.295410
Rec Loss: 18.861877
KL Loss: 3.433533
Y Loss: 0.637992
T Loss: 13.137472
Epoch 449 
Overall Loss: 21.842699
Rec Loss: 18.246688
KL Loss: 3.596012
Y Loss: 0.546699
T Loss: 13.132422
Epoch 499 
Overall Loss: 21.484810
Rec Loss: 17.747979
KL Loss: 3.736832
Y Loss: 0.498424
T Loss: 13.134077
Epoch 549 
Overall Loss: 21.202431
Rec Loss: 17.205725
KL Loss: 3.996706
Y Loss: 0.440593
T Loss: 13.136458
Epoch 599 
Overall Loss: 21.029536
Rec Loss: 16.893487
KL Loss: 4.136049
Y Loss: 0.404219
T Loss: 13.136369
Epoch 649 
Overall Loss: 20.896340
Rec Loss: 16.666837
KL Loss: 4.229504
Y Loss: 0.384159
T Loss: 13.132399
Epoch 699 
Overall Loss: 20.748371
Rec Loss: 16.399818
KL Loss: 4.348554
Y Loss: 0.355902
T Loss: 13.123466
Epoch 749 
Overall Loss: 20.632731
Rec Loss: 16.169628
KL Loss: 4.463102
Y Loss: 0.331723
T Loss: 13.111484
Epoch 799 
Overall Loss: 20.568864
Rec Loss: 16.023587
KL Loss: 4.545277
Y Loss: 0.326982
T Loss: 13.104739
Epoch 849 
Overall Loss: 20.502122
Rec Loss: 15.873208
KL Loss: 4.628914
Y Loss: 0.305446
T Loss: 13.094097
Epoch 899 
Overall Loss: 20.465396
Rec Loss: 15.773550
KL Loss: 4.691847
Y Loss: 0.302206
T Loss: 13.082908
Epoch 949 
Overall Loss: 20.436030
Rec Loss: 15.740319
KL Loss: 4.695712
Y Loss: 0.300079
T Loss: 13.070863
Epoch 999 
Overall Loss: 20.421296
Rec Loss: 15.695732
KL Loss: 4.725564
Y Loss: 0.294482
T Loss: 13.059389
Epoch 1049 
Overall Loss: 20.360110
Rec Loss: 15.611673
KL Loss: 4.748437
Y Loss: 0.285832
T Loss: 13.053787
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.704144
Epoch 99
Rec Loss: 1.703272
Epoch 149
Rec Loss: 1.703051
Epoch 199
Rec Loss: 1.705866
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.108977
Epoch 99
Rec Loss: 6.105963
Epoch 149
Rec Loss: 6.124251
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.233644
Insample Error 1.996524
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 42.365759
Rec Loss: 42.149688
KL Loss: 0.216072
Y Loss: 14.178293
T Loss: 13.793102
Epoch 99 
Overall Loss: 21.914227
Rec Loss: 20.551377
KL Loss: 1.362849
Y Loss: 3.652492
T Loss: 13.246394
Epoch 149 
Overall Loss: 17.213216
Rec Loss: 16.312724
KL Loss: 0.900493
Y Loss: 1.549209
T Loss: 13.214306
Epoch 199 
Overall Loss: 16.146713
Rec Loss: 15.421864
KL Loss: 0.724849
Y Loss: 1.100632
T Loss: 13.220599
Epoch 249 
Overall Loss: 15.528209
Rec Loss: 15.000001
KL Loss: 0.528208
Y Loss: 0.903699
T Loss: 13.192602
Epoch 299 
Overall Loss: 15.078602
Rec Loss: 14.597961
KL Loss: 0.480641
Y Loss: 0.719602
T Loss: 13.158756
Epoch 349 
Overall Loss: 14.863614
Rec Loss: 14.379315
KL Loss: 0.484299
Y Loss: 0.619194
T Loss: 13.140927
Epoch 399 
Overall Loss: 14.718044
Rec Loss: 14.235166
KL Loss: 0.482878
Y Loss: 0.556863
T Loss: 13.121440
Epoch 449 
Overall Loss: 14.630703
Rec Loss: 14.150729
KL Loss: 0.479974
Y Loss: 0.520805
T Loss: 13.109119
Epoch 499 
Overall Loss: 14.543276
Rec Loss: 14.062799
KL Loss: 0.480476
Y Loss: 0.479920
T Loss: 13.102958
Epoch 549 
Overall Loss: 14.457964
Rec Loss: 13.983034
KL Loss: 0.474930
Y Loss: 0.445342
T Loss: 13.092350
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.667926
Epoch 99
Rec Loss: 1.665176
Epoch 149
Rec Loss: 1.663527
Epoch 199
Rec Loss: 1.652876
Epoch 249
Rec Loss: 1.652763
Epoch 299
Rec Loss: 1.648295
Epoch 349
Rec Loss: 1.658300
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.038453
Epoch 99
Rec Loss: 10.040040
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.481695
Insample Error: 1.978113
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 47.532734
Rec Loss: 46.803240
KL Loss: 0.729494
Y Loss: 13.107788
T Loss: 13.715782
Epoch 99 
Overall Loss: 30.725269
Rec Loss: 26.232505
KL Loss: 4.492764
Y Loss: 3.600237
T Loss: 13.266539
Epoch 149 
Overall Loss: 26.115774
Rec Loss: 22.314302
KL Loss: 3.801472
Y Loss: 1.675860
T Loss: 13.273573
Epoch 199 
Overall Loss: 24.631814
Rec Loss: 21.328970
KL Loss: 3.302843
Y Loss: 1.208665
T Loss: 13.270929
Epoch 249 
Overall Loss: 23.870583
Rec Loss: 20.753827
KL Loss: 3.116757
Y Loss: 1.003497
T Loss: 13.239614
Epoch 299 
Overall Loss: 23.187990
Rec Loss: 20.090776
KL Loss: 3.097214
Y Loss: 0.836517
T Loss: 13.185888
Epoch 349 
Overall Loss: 22.719014
Rec Loss: 19.585989
KL Loss: 3.133025
Y Loss: 0.717028
T Loss: 13.148568
Epoch 399 
Overall Loss: 22.350691
Rec Loss: 19.245386
KL Loss: 3.105305
Y Loss: 0.630577
T Loss: 13.106566
Epoch 449 
Overall Loss: 22.015204
Rec Loss: 18.905834
KL Loss: 3.109370
Y Loss: 0.547935
T Loss: 13.060564
Epoch 499 
Overall Loss: 21.711109
Rec Loss: 18.578371
KL Loss: 3.132737
Y Loss: 0.488942
T Loss: 13.018280
Epoch 549 
Overall Loss: 21.455103
Rec Loss: 18.324588
KL Loss: 3.130515
Y Loss: 0.435108
T Loss: 13.018563
Epoch 599 
Overall Loss: 21.264222
Rec Loss: 18.190636
KL Loss: 3.073585
Y Loss: 0.396751
T Loss: 13.035058
Epoch 649 
Overall Loss: 21.032320
Rec Loss: 18.044120
KL Loss: 2.988200
Y Loss: 0.330528
T Loss: 13.066646
Epoch 699 
Overall Loss: 20.931982
Rec Loss: 17.945456
KL Loss: 2.986527
Y Loss: 0.296139
T Loss: 13.086905
Epoch 749 
Overall Loss: 20.868176
Rec Loss: 17.850687
KL Loss: 3.017488
Y Loss: 0.287817
T Loss: 13.078704
Epoch 799 
Overall Loss: 20.815446
Rec Loss: 17.753658
KL Loss: 3.061788
Y Loss: 0.276361
T Loss: 13.074951
Epoch 849 
Overall Loss: 20.771224
Rec Loss: 17.685194
KL Loss: 3.086030
Y Loss: 0.277809
T Loss: 13.072017
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.733079
Epoch 99
Rec Loss: 1.732091
Epoch 149
Rec Loss: 1.730983
Epoch 199
Rec Loss: 1.731046
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 7.830000
Epoch 99
Rec Loss: 7.834585
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.239770
Insample Error 2.044372
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 41.213497
Rec Loss: 40.893832
KL Loss: 0.319665
Y Loss: 13.586552
T Loss: 13.720729
Epoch 99 
Overall Loss: 20.053761
Rec Loss: 18.423460
KL Loss: 1.630301
Y Loss: 2.566818
T Loss: 13.289825
Epoch 149 
Overall Loss: 16.555423
Rec Loss: 15.687657
KL Loss: 0.867766
Y Loss: 1.218319
T Loss: 13.251019
Epoch 199 
Overall Loss: 15.786679
Rec Loss: 15.112630
KL Loss: 0.674048
Y Loss: 0.938358
T Loss: 13.235913
Epoch 249 
Overall Loss: 15.348056
Rec Loss: 14.776749
KL Loss: 0.571307
Y Loss: 0.787112
T Loss: 13.202526
Epoch 299 
Overall Loss: 15.101845
Rec Loss: 14.561597
KL Loss: 0.540247
Y Loss: 0.687242
T Loss: 13.187112
Epoch 349 
Overall Loss: 14.887087
Rec Loss: 14.347920
KL Loss: 0.539166
Y Loss: 0.588842
T Loss: 13.170236
Epoch 399 
Overall Loss: 14.765149
Rec Loss: 14.230895
KL Loss: 0.534255
Y Loss: 0.538469
T Loss: 13.153957
Epoch 449 
Overall Loss: 14.652622
Rec Loss: 14.121520
KL Loss: 0.531102
Y Loss: 0.492475
T Loss: 13.136568
Epoch 499 
Overall Loss: 14.570738
Rec Loss: 14.046997
KL Loss: 0.523741
Y Loss: 0.459134
T Loss: 13.128730
Epoch 549 
Overall Loss: 14.514012
Rec Loss: 13.988901
KL Loss: 0.525110
Y Loss: 0.436953
T Loss: 13.114995
Epoch 599 
Overall Loss: 14.475224
Rec Loss: 13.951597
KL Loss: 0.523626
Y Loss: 0.420160
T Loss: 13.111278
Epoch 649 
Overall Loss: 14.423236
Rec Loss: 13.899079
KL Loss: 0.524157
Y Loss: 0.396729
T Loss: 13.105622
Epoch 699 
Overall Loss: 14.372389
Rec Loss: 13.847457
KL Loss: 0.524932
Y Loss: 0.374322
T Loss: 13.098813
Epoch 749 
Overall Loss: 14.321461
Rec Loss: 13.793931
KL Loss: 0.527531
Y Loss: 0.352952
T Loss: 13.088027
Epoch 799 
Overall Loss: 14.273340
Rec Loss: 13.741135
KL Loss: 0.532206
Y Loss: 0.330052
T Loss: 13.081030
Epoch 849 
Overall Loss: 14.207730
Rec Loss: 13.668878
KL Loss: 0.538852
Y Loss: 0.298878
T Loss: 13.071122
Epoch 899 
Overall Loss: 14.157929
Rec Loss: 13.614840
KL Loss: 0.543089
Y Loss: 0.274969
T Loss: 13.064902
Epoch 949 
Overall Loss: 14.147136
Rec Loss: 13.598297
KL Loss: 0.548839
Y Loss: 0.267140
T Loss: 13.064017
Epoch 999 
Overall Loss: 14.098260
Rec Loss: 13.549310
KL Loss: 0.548950
Y Loss: 0.246427
T Loss: 13.056456
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.656908
Epoch 99
Rec Loss: 1.646905
Epoch 149
Rec Loss: 1.652208
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.076004
Epoch 99
Rec Loss: 10.069640
Epoch 149
Rec Loss: 10.069681
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.317244
Insample Error: 2.023601
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 48.349580
Rec Loss: 46.935615
KL Loss: 1.413966
Y Loss: 13.472667
T Loss: 13.518048
Epoch 99 
Overall Loss: 32.187997
Rec Loss: 26.810400
KL Loss: 5.377597
Y Loss: 3.875977
T Loss: 13.224923
Epoch 149 
Overall Loss: 26.790520
Rec Loss: 22.536995
KL Loss: 4.253525
Y Loss: 1.763484
T Loss: 13.252524
Epoch 199 
Overall Loss: 25.181929
Rec Loss: 21.578126
KL Loss: 3.603802
Y Loss: 1.300762
T Loss: 13.268709
Epoch 249 
Overall Loss: 24.413086
Rec Loss: 21.012369
KL Loss: 3.400718
Y Loss: 1.066561
T Loss: 13.259481
Epoch 299 
Overall Loss: 23.904960
Rec Loss: 20.581780
KL Loss: 3.323180
Y Loss: 0.969012
T Loss: 13.226512
Epoch 349 
Overall Loss: 23.296482
Rec Loss: 19.714461
KL Loss: 3.582022
Y Loss: 0.869875
T Loss: 13.195832
Epoch 399 
Overall Loss: 22.814340
Rec Loss: 18.944283
KL Loss: 3.870056
Y Loss: 0.766025
T Loss: 13.147854
Epoch 449 
Overall Loss: 22.495964
Rec Loss: 18.450931
KL Loss: 4.045033
Y Loss: 0.707767
T Loss: 13.103311
Epoch 499 
Overall Loss: 22.142143
Rec Loss: 17.996736
KL Loss: 4.145406
Y Loss: 0.664399
T Loss: 13.053496
Epoch 549 
Overall Loss: 21.845740
Rec Loss: 17.577070
KL Loss: 4.268671
Y Loss: 0.604360
T Loss: 13.068818
Epoch 599 
Overall Loss: 21.586217
Rec Loss: 17.229040
KL Loss: 4.357177
Y Loss: 0.556526
T Loss: 13.099825
Epoch 649 
Overall Loss: 21.415436
Rec Loss: 16.953542
KL Loss: 4.461894
Y Loss: 0.521517
T Loss: 13.126713
Epoch 699 
Overall Loss: 21.232540
Rec Loss: 16.622194
KL Loss: 4.610346
Y Loss: 0.485145
T Loss: 13.137551
Epoch 749 
Overall Loss: 21.151863
Rec Loss: 16.415532
KL Loss: 4.736331
Y Loss: 0.470571
T Loss: 13.142569
Epoch 799 
Overall Loss: 20.994398
Rec Loss: 16.114498
KL Loss: 4.879900
Y Loss: 0.443335
T Loss: 13.142726
Epoch 849 
Overall Loss: 20.869154
Rec Loss: 15.840266
KL Loss: 5.028888
Y Loss: 0.426501
T Loss: 13.141875
Epoch 899 
Overall Loss: 20.759934
Rec Loss: 15.525233
KL Loss: 5.234701
Y Loss: 0.394860
T Loss: 13.139046
Epoch 949 
Overall Loss: 20.687984
Rec Loss: 15.279364
KL Loss: 5.408620
Y Loss: 0.385243
T Loss: 13.129132
Epoch 999 
Overall Loss: 20.619080
Rec Loss: 15.040623
KL Loss: 5.578458
Y Loss: 0.360988
T Loss: 13.123303
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.761958
Epoch 99
Rec Loss: 1.759240
Epoch 149
Rec Loss: 1.758027
Epoch 199
Rec Loss: 1.755123
Epoch 249
Rec Loss: 1.754959
Epoch 299
Rec Loss: 1.761671
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.932781
Epoch 99
Rec Loss: 5.898292
Epoch 149
Rec Loss: 5.906792
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.298476
Insample Error 2.012781
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 43.783802
Rec Loss: 43.555696
KL Loss: 0.228106
Y Loss: 14.892015
T Loss: 13.771668
Epoch 99 
Overall Loss: 23.882226
Rec Loss: 22.225291
KL Loss: 1.656935
Y Loss: 4.502718
T Loss: 13.219856
Epoch 149 
Overall Loss: 17.729300
Rec Loss: 16.626841
KL Loss: 1.102459
Y Loss: 1.697306
T Loss: 13.232229
Epoch 199 
Overall Loss: 16.501148
Rec Loss: 15.615555
KL Loss: 0.885593
Y Loss: 1.194255
T Loss: 13.227045
Epoch 249 
Overall Loss: 15.698307
Rec Loss: 15.047732
KL Loss: 0.650574
Y Loss: 0.921358
T Loss: 13.205016
Epoch 299 
Overall Loss: 15.191314
Rec Loss: 14.642064
KL Loss: 0.549250
Y Loss: 0.732749
T Loss: 13.176567
Epoch 349 
Overall Loss: 14.918182
Rec Loss: 14.379029
KL Loss: 0.539153
Y Loss: 0.610820
T Loss: 13.157388
Epoch 399 
Overall Loss: 14.808400
Rec Loss: 14.275239
KL Loss: 0.533162
Y Loss: 0.567482
T Loss: 13.140274
Epoch 449 
Overall Loss: 14.685939
Rec Loss: 14.161918
KL Loss: 0.524021
Y Loss: 0.515306
T Loss: 13.131306
Epoch 499 
Overall Loss: 14.610055
Rec Loss: 14.093349
KL Loss: 0.516706
Y Loss: 0.487991
T Loss: 13.117367
Epoch 549 
Overall Loss: 14.527112
Rec Loss: 14.012638
KL Loss: 0.514474
Y Loss: 0.450082
T Loss: 13.112474
Epoch 599 
Overall Loss: 14.453192
Rec Loss: 13.935853
KL Loss: 0.517339
Y Loss: 0.418289
T Loss: 13.099275
Epoch 649 
Overall Loss: 14.417781
Rec Loss: 13.906692
KL Loss: 0.511088
Y Loss: 0.405663
T Loss: 13.095367
Epoch 699 
Overall Loss: 14.369727
Rec Loss: 13.857659
KL Loss: 0.512067
Y Loss: 0.387270
T Loss: 13.083118
Epoch 749 
Overall Loss: 14.318453
Rec Loss: 13.804488
KL Loss: 0.513965
Y Loss: 0.362938
T Loss: 13.078611
Epoch 799 
Overall Loss: 14.289927
Rec Loss: 13.781214
KL Loss: 0.508714
Y Loss: 0.355031
T Loss: 13.071151
Epoch 849 
Overall Loss: 14.208993
Rec Loss: 13.699639
KL Loss: 0.509354
Y Loss: 0.320185
T Loss: 13.059270
Epoch 899 
Overall Loss: 14.172144
Rec Loss: 13.662891
KL Loss: 0.509252
Y Loss: 0.302216
T Loss: 13.058459
Epoch 949 
Overall Loss: 14.108245
Rec Loss: 13.606410
KL Loss: 0.501835
Y Loss: 0.280699
T Loss: 13.045012
Epoch 999 
Overall Loss: 14.064900
Rec Loss: 13.568454
KL Loss: 0.496446
Y Loss: 0.266046
T Loss: 13.036363
Epoch 1049 
Overall Loss: 14.023296
Rec Loss: 13.539363
KL Loss: 0.483934
Y Loss: 0.255838
T Loss: 13.027687
Epoch 1099 
Overall Loss: 13.983503
Rec Loss: 13.515485
KL Loss: 0.468018
Y Loss: 0.245965
T Loss: 13.023556
Epoch 1149 
Overall Loss: 13.939730
Rec Loss: 13.484976
KL Loss: 0.454754
Y Loss: 0.239009
T Loss: 13.006958
Epoch 1199 
Overall Loss: 13.898949
Rec Loss: 13.461698
KL Loss: 0.437250
Y Loss: 0.230794
T Loss: 13.000111
Epoch 1249 
Overall Loss: 13.874354
Rec Loss: 13.460055
KL Loss: 0.414299
Y Loss: 0.229419
T Loss: 13.001218
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.576247
Epoch 99
Rec Loss: 1.574953
Epoch 149
Rec Loss: 1.573554
Epoch 199
Rec Loss: 1.570266
Epoch 249
Rec Loss: 1.571048
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.071789
Epoch 99
Rec Loss: 10.075262
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.322011
Insample Error: 1.582269
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 47.914209
Rec Loss: 47.007999
KL Loss: 0.906211
Y Loss: 13.328164
T Loss: 13.709084
Epoch 99 
Overall Loss: 32.542543
Rec Loss: 27.954544
KL Loss: 4.587999
Y Loss: 4.443951
T Loss: 13.263465
Epoch 149 
Overall Loss: 27.327554
Rec Loss: 23.366891
KL Loss: 3.960664
Y Loss: 2.181539
T Loss: 13.271431
Epoch 199 
Overall Loss: 25.412907
Rec Loss: 21.875071
KL Loss: 3.537836
Y Loss: 1.431171
T Loss: 13.287115
Epoch 249 
Overall Loss: 24.441349
Rec Loss: 21.124663
KL Loss: 3.316686
Y Loss: 1.100699
T Loss: 13.270938
Epoch 299 
Overall Loss: 23.856523
Rec Loss: 20.648747
KL Loss: 3.207776
Y Loss: 0.951730
T Loss: 13.234964
Epoch 349 
Overall Loss: 23.328636
Rec Loss: 20.103623
KL Loss: 3.225013
Y Loss: 0.826420
T Loss: 13.198062
Epoch 399 
Overall Loss: 22.779637
Rec Loss: 19.545570
KL Loss: 3.234068
Y Loss: 0.711008
T Loss: 13.167924
Epoch 449 
Overall Loss: 22.296502
Rec Loss: 19.177032
KL Loss: 3.119471
Y Loss: 0.603502
T Loss: 13.138636
Epoch 499 
Overall Loss: 21.791701
Rec Loss: 18.770365
KL Loss: 3.021336
Y Loss: 0.471541
T Loss: 13.127769
Epoch 549 
Overall Loss: 21.355402
Rec Loss: 18.383515
KL Loss: 2.971886
Y Loss: 0.372250
T Loss: 13.121787
Epoch 599 
Overall Loss: 21.104093
Rec Loss: 18.113139
KL Loss: 2.990954
Y Loss: 0.320821
T Loss: 13.133025
Epoch 649 
Overall Loss: 20.958873
Rec Loss: 17.887559
KL Loss: 3.071313
Y Loss: 0.290886
T Loss: 13.120588
Epoch 699 
Overall Loss: 20.838615
Rec Loss: 17.689016
KL Loss: 3.149598
Y Loss: 0.290315
T Loss: 13.114379
Epoch 749 
Overall Loss: 20.783088
Rec Loss: 17.568749
KL Loss: 3.214339
Y Loss: 0.276352
T Loss: 13.106440
Epoch 799 
Overall Loss: 20.733264
Rec Loss: 17.465966
KL Loss: 3.267298
Y Loss: 0.275813
T Loss: 13.098116
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.746314
Epoch 99
Rec Loss: 1.737834
Epoch 149
Rec Loss: 1.746461
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 7.622617
Epoch 99
Rec Loss: 7.634524
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.229788
Insample Error 1.967201
Ours, Train RMSE
0.3790, 
0.4602, 
0.3489, 
0.3277, 
0.3256, 
0.3960, 
0.3599, 
0.4817, 
0.3172, 
0.3220, 
Ours, Insample RMSE
1.7576, 
1.9925, 
0.9496, 
1.4626, 
1.9276, 
2.0044, 
1.2948, 
1.9781, 
2.0236, 
1.5823, 
CEVAE, Insample RMSE
1.9017, 
1.9837, 
2.0097, 
1.7741, 
1.9794, 
1.9735, 
1.9965, 
2.0444, 
2.0128, 
1.9672, 
Train, RMSE mean 0.3718 std 0.0554
Ours, RMSE mean 1.6973 std 0.3482, reconstruct confounder 1.5948 (0.0581) noise 10.0601 (0.0113)
CEVAE, RMSE mean 1.9643 std 0.0726, reconstruct confounder 1.7209 (0.0304) noise 7.1085 (0.7169)
