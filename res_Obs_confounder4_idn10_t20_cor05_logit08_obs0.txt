Train, RMSE mean 0.2606 std 0.0211
Ours, RMSE mean 2.4386 std 0.0624, reconstruct confounder 1.8424 (0.0297) noise 10.0006 (0.0107)
CEVAE, RMSE mean 2.3901 std 0.0770, reconstruct confounder 1.9164 (0.0604) noise 5.8933 (0.1408)Y Mean 1.514292, Std 3.653528 
Observe confounder 0, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 20.823585
Rec Loss: 17.977123
KL Loss: 2.846462
Y Loss: 2.792306
T Loss: 12.392511
Epoch 99 
Overall Loss: 16.747527
Rec Loss: 14.144558
KL Loss: 2.602968
Y Loss: 0.843265
T Loss: 12.458029
Epoch 149 
Overall Loss: 16.018522
Rec Loss: 13.634742
KL Loss: 2.383780
Y Loss: 0.660584
T Loss: 12.313575
Epoch 199 
Overall Loss: 15.066000
Rec Loss: 12.986222
KL Loss: 2.079778
Y Loss: 0.472463
T Loss: 12.041295
Epoch 249 
Overall Loss: 14.665319
Rec Loss: 12.661358
KL Loss: 2.003961
Y Loss: 0.373630
T Loss: 11.914097
Epoch 299 
Overall Loss: 14.478668
Rec Loss: 12.491912
KL Loss: 1.986756
Y Loss: 0.335769
T Loss: 11.820374
Epoch 349 
Overall Loss: 14.368865
Rec Loss: 12.382339
KL Loss: 1.986526
Y Loss: 0.322520
T Loss: 11.737298
Epoch 399 
Overall Loss: 14.310273
Rec Loss: 12.306729
KL Loss: 2.003545
Y Loss: 0.317720
T Loss: 11.671289
Epoch 449 
Overall Loss: 14.250255
Rec Loss: 12.237299
KL Loss: 2.012956
Y Loss: 0.302926
T Loss: 11.631447
Epoch 499 
Overall Loss: 14.203024
Rec Loss: 12.174467
KL Loss: 2.028557
Y Loss: 0.287229
T Loss: 11.600010
Epoch 549 
Overall Loss: 14.174038
Rec Loss: 12.142126
KL Loss: 2.031912
Y Loss: 0.281954
T Loss: 11.578218
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.877381
Epoch 99
Rec Loss: 1.866992
Epoch 149
Rec Loss: 1.867293
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.015824
Epoch 99
Rec Loss: 10.018419
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.279613
Insample Error: 2.457187
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 25.715399
Rec Loss: 21.944501
KL Loss: 3.770897
Y Loss: 2.245841
T Loss: 12.450453
Epoch 99 
Overall Loss: 22.008222
Rec Loss: 19.045522
KL Loss: 2.962701
Y Loss: 0.897407
T Loss: 12.547199
Epoch 149 
Overall Loss: 20.600545
Rec Loss: 17.160600
KL Loss: 3.439945
Y Loss: 0.637635
T Loss: 12.438793
Epoch 199 
Overall Loss: 20.061454
Rec Loss: 16.584547
KL Loss: 3.476906
Y Loss: 0.542710
T Loss: 12.363968
Epoch 249 
Overall Loss: 19.773275
Rec Loss: 16.205591
KL Loss: 3.567684
Y Loss: 0.499803
T Loss: 12.263799
Epoch 299 
Overall Loss: 19.551137
Rec Loss: 15.854179
KL Loss: 3.696957
Y Loss: 0.460512
T Loss: 12.193895
Epoch 349 
Overall Loss: 19.275052
Rec Loss: 15.167946
KL Loss: 4.107106
Y Loss: 0.418729
T Loss: 12.118554
Epoch 399 
Overall Loss: 19.039802
Rec Loss: 14.386226
KL Loss: 4.653577
Y Loss: 0.380207
T Loss: 12.059387
Epoch 449 
Overall Loss: 18.899031
Rec Loss: 13.980014
KL Loss: 4.919016
Y Loss: 0.358347
T Loss: 12.001233
Epoch 499 
Overall Loss: 18.783964
Rec Loss: 13.557420
KL Loss: 5.226544
Y Loss: 0.341570
T Loss: 11.948424
Epoch 549 
Overall Loss: 18.669026
Rec Loss: 13.238823
KL Loss: 5.430204
Y Loss: 0.341375
T Loss: 11.893937
Epoch 599 
Overall Loss: 18.551420
Rec Loss: 12.915609
KL Loss: 5.635811
Y Loss: 0.322537
T Loss: 11.853908
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.958619
Epoch 99
Rec Loss: 1.964885
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.826698
Epoch 99
Rec Loss: 5.822405
Epoch 149
Rec Loss: 5.821016
Epoch 199
Rec Loss: 5.824109
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.276757
Insample Error 2.462769
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 21.932104
Rec Loss: 19.619489
KL Loss: 2.312615
Y Loss: 3.643794
T Loss: 12.331900
Epoch 99 
Overall Loss: 16.635956
Rec Loss: 14.178191
KL Loss: 2.457764
Y Loss: 0.865890
T Loss: 12.446412
Epoch 149 
Overall Loss: 15.947670
Rec Loss: 13.627949
KL Loss: 2.319720
Y Loss: 0.631693
T Loss: 12.364564
Epoch 199 
Overall Loss: 15.441181
Rec Loss: 13.207118
KL Loss: 2.234064
Y Loss: 0.532359
T Loss: 12.142400
Epoch 249 
Overall Loss: 14.833345
Rec Loss: 12.822877
KL Loss: 2.010468
Y Loss: 0.444500
T Loss: 11.933877
Epoch 299 
Overall Loss: 14.562570
Rec Loss: 12.618388
KL Loss: 1.944181
Y Loss: 0.393168
T Loss: 11.832052
Epoch 349 
Overall Loss: 14.431023
Rec Loss: 12.495475
KL Loss: 1.935548
Y Loss: 0.359243
T Loss: 11.776989
Epoch 399 
Overall Loss: 14.316114
Rec Loss: 12.362706
KL Loss: 1.953407
Y Loss: 0.328444
T Loss: 11.705818
Epoch 449 
Overall Loss: 14.246047
Rec Loss: 12.268438
KL Loss: 1.977609
Y Loss: 0.306213
T Loss: 11.656013
Epoch 499 
Overall Loss: 14.232916
Rec Loss: 12.246455
KL Loss: 1.986461
Y Loss: 0.305553
T Loss: 11.635349
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.881910
Epoch 99
Rec Loss: 1.886953
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.008621
Epoch 99
Rec Loss: 10.003280
Epoch 149
Rec Loss: 9.998823
Epoch 199
Rec Loss: 10.003462
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.291938
Insample Error: 2.443016
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 28.623902
Rec Loss: 25.101956
KL Loss: 3.521946
Y Loss: 3.819400
T Loss: 12.535943
Epoch 99 
Overall Loss: 22.112884
Rec Loss: 18.747820
KL Loss: 3.365064
Y Loss: 1.009766
T Loss: 12.625130
Epoch 149 
Overall Loss: 20.628328
Rec Loss: 17.130615
KL Loss: 3.497712
Y Loss: 0.653577
T Loss: 12.542349
Epoch 199 
Overall Loss: 20.035032
Rec Loss: 16.496640
KL Loss: 3.538392
Y Loss: 0.542808
T Loss: 12.413060
Epoch 249 
Overall Loss: 19.731943
Rec Loss: 16.022759
KL Loss: 3.709184
Y Loss: 0.497223
T Loss: 12.290522
Epoch 299 
Overall Loss: 19.413779
Rec Loss: 15.287433
KL Loss: 4.126346
Y Loss: 0.436642
T Loss: 12.201391
Epoch 349 
Overall Loss: 19.113371
Rec Loss: 14.474149
KL Loss: 4.639223
Y Loss: 0.387442
T Loss: 12.099897
Epoch 399 
Overall Loss: 18.993328
Rec Loss: 14.037698
KL Loss: 4.955631
Y Loss: 0.365584
T Loss: 12.027393
Epoch 449 
Overall Loss: 18.845264
Rec Loss: 13.646336
KL Loss: 5.198927
Y Loss: 0.346366
T Loss: 11.958567
Epoch 499 
Overall Loss: 18.740850
Rec Loss: 13.316943
KL Loss: 5.423907
Y Loss: 0.328937
T Loss: 11.915923
Epoch 549 
Overall Loss: 18.679490
Rec Loss: 13.097997
KL Loss: 5.581493
Y Loss: 0.330075
T Loss: 11.859853
Epoch 599 
Overall Loss: 18.633215
Rec Loss: 12.977402
KL Loss: 5.655813
Y Loss: 0.326524
T Loss: 11.830579
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.931923
Epoch 99
Rec Loss: 1.924595
Epoch 149
Rec Loss: 1.929994
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.059382
Epoch 99
Rec Loss: 6.058883
Epoch 149
Rec Loss: 6.049755
Epoch 199
Rec Loss: 6.042949
Epoch 249
Rec Loss: 6.049553
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.268296
Insample Error 2.475463
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 22.916241
Rec Loss: 20.098119
KL Loss: 2.818123
Y Loss: 3.819029
T Loss: 12.460060
Epoch 99 
Overall Loss: 17.060783
Rec Loss: 14.379162
KL Loss: 2.681621
Y Loss: 0.923581
T Loss: 12.532000
Epoch 149 
Overall Loss: 16.399385
Rec Loss: 13.945306
KL Loss: 2.454079
Y Loss: 0.725037
T Loss: 12.495232
Epoch 199 
Overall Loss: 15.627808
Rec Loss: 13.442490
KL Loss: 2.185317
Y Loss: 0.581929
T Loss: 12.278633
Epoch 249 
Overall Loss: 14.891658
Rec Loss: 12.927373
KL Loss: 1.964285
Y Loss: 0.429581
T Loss: 12.068210
Epoch 299 
Overall Loss: 14.582886
Rec Loss: 12.690480
KL Loss: 1.892405
Y Loss: 0.356456
T Loss: 11.977568
Epoch 349 
Overall Loss: 14.432044
Rec Loss: 12.551357
KL Loss: 1.880688
Y Loss: 0.327127
T Loss: 11.897102
Epoch 399 
Overall Loss: 14.340700
Rec Loss: 12.475354
KL Loss: 1.865346
Y Loss: 0.318128
T Loss: 11.839097
Epoch 449 
Overall Loss: 14.246592
Rec Loss: 12.354178
KL Loss: 1.892415
Y Loss: 0.295315
T Loss: 11.763548
Epoch 499 
Overall Loss: 14.195085
Rec Loss: 12.298047
KL Loss: 1.897038
Y Loss: 0.291168
T Loss: 11.715712
Epoch 549 
Overall Loss: 14.160354
Rec Loss: 12.223863
KL Loss: 1.936490
Y Loss: 0.277422
T Loss: 11.669020
Epoch 599 
Overall Loss: 14.112209
Rec Loss: 12.163688
KL Loss: 1.948521
Y Loss: 0.269665
T Loss: 11.624357
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.831940
Epoch 99
Rec Loss: 1.839029
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.001111
Epoch 99
Rec Loss: 9.996572
Epoch 149
Rec Loss: 9.994297
Epoch 199
Rec Loss: 9.995055
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.248816
Insample Error: 2.333859
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 27.356281
Rec Loss: 23.907861
KL Loss: 3.448420
Y Loss: 3.235538
T Loss: 12.461883
Epoch 99 
Overall Loss: 22.061841
Rec Loss: 18.967513
KL Loss: 3.094328
Y Loss: 0.941201
T Loss: 12.596825
Epoch 149 
Overall Loss: 20.890258
Rec Loss: 17.717820
KL Loss: 3.172438
Y Loss: 0.706222
T Loss: 12.504035
Epoch 199 
Overall Loss: 20.173594
Rec Loss: 16.848293
KL Loss: 3.325300
Y Loss: 0.561656
T Loss: 12.407416
Epoch 249 
Overall Loss: 19.715649
Rec Loss: 16.300187
KL Loss: 3.415462
Y Loss: 0.457964
T Loss: 12.286754
Epoch 299 
Overall Loss: 19.375104
Rec Loss: 15.693777
KL Loss: 3.681327
Y Loss: 0.391781
T Loss: 12.192622
Epoch 349 
Overall Loss: 19.115319
Rec Loss: 14.950540
KL Loss: 4.164780
Y Loss: 0.366036
T Loss: 12.094133
Epoch 399 
Overall Loss: 18.953113
Rec Loss: 14.610864
KL Loss: 4.342249
Y Loss: 0.336239
T Loss: 12.019084
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.017912
Epoch 99
Rec Loss: 2.015028
Epoch 149
Rec Loss: 2.016216
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.124573
Epoch 99
Rec Loss: 6.119383
Epoch 149
Rec Loss: 6.134992
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.252313
Insample Error 2.380570
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 21.983628
Rec Loss: 19.546874
KL Loss: 2.436753
Y Loss: 3.603207
T Loss: 12.340461
Epoch 99 
Overall Loss: 16.427411
Rec Loss: 14.022023
KL Loss: 2.405388
Y Loss: 0.816956
T Loss: 12.388111
Epoch 149 
Overall Loss: 15.512354
Rec Loss: 13.403316
KL Loss: 2.109038
Y Loss: 0.564790
T Loss: 12.273737
Epoch 199 
Overall Loss: 14.858402
Rec Loss: 12.925398
KL Loss: 1.933004
Y Loss: 0.386140
T Loss: 12.153118
Epoch 249 
Overall Loss: 14.634218
Rec Loss: 12.716295
KL Loss: 1.917923
Y Loss: 0.329732
T Loss: 12.056830
Epoch 299 
Overall Loss: 14.486370
Rec Loss: 12.574300
KL Loss: 1.912070
Y Loss: 0.314998
T Loss: 11.944305
Epoch 349 
Overall Loss: 14.409256
Rec Loss: 12.493395
KL Loss: 1.915861
Y Loss: 0.305902
T Loss: 11.881590
Epoch 399 
Overall Loss: 14.326886
Rec Loss: 12.390903
KL Loss: 1.935983
Y Loss: 0.283155
T Loss: 11.824594
Epoch 449 
Overall Loss: 14.285123
Rec Loss: 12.334282
KL Loss: 1.950841
Y Loss: 0.290282
T Loss: 11.753717
Epoch 499 
Overall Loss: 14.250277
Rec Loss: 12.283016
KL Loss: 1.967262
Y Loss: 0.285520
T Loss: 11.711975
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.875946
Epoch 99
Rec Loss: 1.883620
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.012427
Epoch 99
Rec Loss: 10.006987
Epoch 149
Rec Loss: 10.009477
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.270212
Insample Error: 2.560953
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 27.931514
Rec Loss: 24.012924
KL Loss: 3.918590
Y Loss: 3.260635
T Loss: 12.485680
Epoch 99 
Overall Loss: 22.379514
Rec Loss: 19.291490
KL Loss: 3.088024
Y Loss: 1.014297
T Loss: 12.587019
Epoch 149 
Overall Loss: 20.658647
Rec Loss: 17.162963
KL Loss: 3.495685
Y Loss: 0.643304
T Loss: 12.514363
Epoch 199 
Overall Loss: 20.082080
Rec Loss: 16.537329
KL Loss: 3.544750
Y Loss: 0.552021
T Loss: 12.410810
Epoch 249 
Overall Loss: 19.754728
Rec Loss: 16.021321
KL Loss: 3.733407
Y Loss: 0.497791
T Loss: 12.305593
Epoch 299 
Overall Loss: 19.360844
Rec Loss: 15.043992
KL Loss: 4.316852
Y Loss: 0.438263
T Loss: 12.191474
Epoch 349 
Overall Loss: 19.117064
Rec Loss: 14.382416
KL Loss: 4.734648
Y Loss: 0.388420
T Loss: 12.120472
Epoch 399 
Overall Loss: 18.974357
Rec Loss: 13.973563
KL Loss: 5.000794
Y Loss: 0.360614
T Loss: 12.042101
Epoch 449 
Overall Loss: 18.839950
Rec Loss: 13.610728
KL Loss: 5.229222
Y Loss: 0.347143
T Loss: 11.978736
Epoch 499 
Overall Loss: 18.779419
Rec Loss: 13.403381
KL Loss: 5.376037
Y Loss: 0.349405
T Loss: 11.930491
Epoch 549 
Overall Loss: 18.728260
Rec Loss: 13.187064
KL Loss: 5.541196
Y Loss: 0.329414
T Loss: 11.882957
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.964701
Epoch 99
Rec Loss: 1.957242
Epoch 149
Rec Loss: 1.960849
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.892000
Epoch 99
Rec Loss: 5.883168
Epoch 149
Rec Loss: 5.888496
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.268903
Insample Error 2.425527
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 20.884206
Rec Loss: 18.130076
KL Loss: 2.754129
Y Loss: 2.826560
T Loss: 12.476957
Epoch 99 
Overall Loss: 16.779942
Rec Loss: 14.139345
KL Loss: 2.640597
Y Loss: 0.864095
T Loss: 12.411154
Epoch 149 
Overall Loss: 15.754454
Rec Loss: 13.473615
KL Loss: 2.280839
Y Loss: 0.645493
T Loss: 12.182629
Epoch 199 
Overall Loss: 14.941619
Rec Loss: 12.909830
KL Loss: 2.031788
Y Loss: 0.448530
T Loss: 12.012770
Epoch 249 
Overall Loss: 14.625520
Rec Loss: 12.649263
KL Loss: 1.976257
Y Loss: 0.362219
T Loss: 11.924825
Epoch 299 
Overall Loss: 14.469654
Rec Loss: 12.531022
KL Loss: 1.938632
Y Loss: 0.329428
T Loss: 11.872165
Epoch 349 
Overall Loss: 14.376403
Rec Loss: 12.432211
KL Loss: 1.944191
Y Loss: 0.312958
T Loss: 11.806295
Epoch 399 
Overall Loss: 14.294721
Rec Loss: 12.340925
KL Loss: 1.953796
Y Loss: 0.296456
T Loss: 11.748013
Epoch 449 
Overall Loss: 14.239570
Rec Loss: 12.276723
KL Loss: 1.962847
Y Loss: 0.294800
T Loss: 11.687123
Epoch 499 
Overall Loss: 14.172117
Rec Loss: 12.180296
KL Loss: 1.991821
Y Loss: 0.276045
T Loss: 11.628206
Epoch 549 
Overall Loss: 14.131397
Rec Loss: 12.119593
KL Loss: 2.011803
Y Loss: 0.268165
T Loss: 11.583262
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.837018
Epoch 99
Rec Loss: 1.837978
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.006996
Epoch 99
Rec Loss: 10.014979
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.254994
Insample Error: 2.432743
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 29.998519
Rec Loss: 26.745037
KL Loss: 3.253482
Y Loss: 4.650862
T Loss: 12.437630
Epoch 99 
Overall Loss: 22.412954
Rec Loss: 19.236882
KL Loss: 3.176072
Y Loss: 1.012200
T Loss: 12.568136
Epoch 149 
Overall Loss: 21.088874
Rec Loss: 17.986050
KL Loss: 3.102825
Y Loss: 0.724337
T Loss: 12.495727
Epoch 199 
Overall Loss: 20.196293
Rec Loss: 16.759126
KL Loss: 3.437166
Y Loss: 0.550488
T Loss: 12.388730
Epoch 249 
Overall Loss: 19.690679
Rec Loss: 15.966165
KL Loss: 3.724514
Y Loss: 0.484173
T Loss: 12.297339
Epoch 299 
Overall Loss: 19.376930
Rec Loss: 15.239030
KL Loss: 4.137901
Y Loss: 0.438378
T Loss: 12.200909
Epoch 349 
Overall Loss: 19.114344
Rec Loss: 14.648477
KL Loss: 4.465867
Y Loss: 0.373673
T Loss: 12.110634
Epoch 399 
Overall Loss: 18.946730
Rec Loss: 14.269740
KL Loss: 4.676991
Y Loss: 0.337680
T Loss: 12.027040
Epoch 449 
Overall Loss: 18.864915
Rec Loss: 14.051453
KL Loss: 4.813462
Y Loss: 0.329702
T Loss: 11.950360
Epoch 499 
Overall Loss: 18.735408
Rec Loss: 13.819932
KL Loss: 4.915476
Y Loss: 0.316128
T Loss: 11.894034
Epoch 549 
Overall Loss: 18.675817
Rec Loss: 13.650446
KL Loss: 5.025371
Y Loss: 0.299955
T Loss: 11.852879
Epoch 599 
Overall Loss: 18.642723
Rec Loss: 13.537658
KL Loss: 5.105065
Y Loss: 0.305509
T Loss: 11.806177
Epoch 649 
Overall Loss: 18.587360
Rec Loss: 13.444208
KL Loss: 5.143152
Y Loss: 0.306783
T Loss: 11.768097
Epoch 699 
Overall Loss: 18.519122
Rec Loss: 13.302302
KL Loss: 5.216820
Y Loss: 0.301738
T Loss: 11.740325
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.884306
Epoch 99
Rec Loss: 1.876678
Epoch 149
Rec Loss: 1.872069
Epoch 199
Rec Loss: 1.872925
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.920871
Epoch 99
Rec Loss: 5.894401
Epoch 149
Rec Loss: 5.921460
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.260964
Insample Error 2.411464
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 24.394960
Rec Loss: 22.352077
KL Loss: 2.042884
Y Loss: 4.969387
T Loss: 12.413304
Epoch 99 
Overall Loss: 17.335412
Rec Loss: 14.562820
KL Loss: 2.772593
Y Loss: 1.057243
T Loss: 12.448334
Epoch 149 
Overall Loss: 16.488029
Rec Loss: 13.970011
KL Loss: 2.518018
Y Loss: 0.850789
T Loss: 12.268432
Epoch 199 
Overall Loss: 15.305767
Rec Loss: 13.191610
KL Loss: 2.114157
Y Loss: 0.598463
T Loss: 11.994684
Epoch 249 
Overall Loss: 14.806152
Rec Loss: 12.815927
KL Loss: 1.990225
Y Loss: 0.451761
T Loss: 11.912405
Epoch 299 
Overall Loss: 14.587408
Rec Loss: 12.664251
KL Loss: 1.923158
Y Loss: 0.396191
T Loss: 11.871869
Epoch 349 
Overall Loss: 14.422476
Rec Loss: 12.515589
KL Loss: 1.906887
Y Loss: 0.343799
T Loss: 11.827992
Epoch 399 
Overall Loss: 14.356646
Rec Loss: 12.450140
KL Loss: 1.906506
Y Loss: 0.329598
T Loss: 11.790943
Epoch 449 
Overall Loss: 14.251916
Rec Loss: 12.321475
KL Loss: 1.930441
Y Loss: 0.301633
T Loss: 11.718210
Epoch 499 
Overall Loss: 14.223546
Rec Loss: 12.262875
KL Loss: 1.960672
Y Loss: 0.298506
T Loss: 11.665863
Epoch 549 
Overall Loss: 14.186919
Rec Loss: 12.205327
KL Loss: 1.981592
Y Loss: 0.288739
T Loss: 11.627849
Epoch 599 
Overall Loss: 14.134587
Rec Loss: 12.133922
KL Loss: 2.000665
Y Loss: 0.271607
T Loss: 11.590707
Epoch 649 
Overall Loss: 14.108695
Rec Loss: 12.093010
KL Loss: 2.015685
Y Loss: 0.266539
T Loss: 11.559932
Epoch 699 
Overall Loss: 14.063337
Rec Loss: 12.026955
KL Loss: 2.036382
Y Loss: 0.252179
T Loss: 11.522597
Epoch 749 
Overall Loss: 14.048422
Rec Loss: 12.026117
KL Loss: 2.022304
Y Loss: 0.255988
T Loss: 11.514141
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.811565
Epoch 99
Rec Loss: 1.803142
Epoch 149
Rec Loss: 1.809330
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.012670
Epoch 99
Rec Loss: 10.017517
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.222764
Insample Error: 2.322608
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 28.526573
Rec Loss: 24.695110
KL Loss: 3.831463
Y Loss: 3.641324
T Loss: 12.412745
Epoch 99 
Overall Loss: 22.551210
Rec Loss: 19.416914
KL Loss: 3.134296
Y Loss: 1.071152
T Loss: 12.560658
Epoch 149 
Overall Loss: 21.147106
Rec Loss: 18.017903
KL Loss: 3.129203
Y Loss: 0.708419
T Loss: 12.467259
Epoch 199 
Overall Loss: 20.283596
Rec Loss: 16.873992
KL Loss: 3.409604
Y Loss: 0.567379
T Loss: 12.328470
Epoch 249 
Overall Loss: 19.539252
Rec Loss: 15.500158
KL Loss: 4.039094
Y Loss: 0.466049
T Loss: 12.246443
Epoch 299 
Overall Loss: 19.159047
Rec Loss: 14.750779
KL Loss: 4.408268
Y Loss: 0.372338
T Loss: 12.156488
Epoch 349 
Overall Loss: 18.977698
Rec Loss: 14.350969
KL Loss: 4.626729
Y Loss: 0.354647
T Loss: 12.051700
Epoch 399 
Overall Loss: 18.843090
Rec Loss: 13.986484
KL Loss: 4.856606
Y Loss: 0.324485
T Loss: 11.983514
Epoch 449 
Overall Loss: 18.763205
Rec Loss: 13.764343
KL Loss: 4.998862
Y Loss: 0.321422
T Loss: 11.910916
Epoch 499 
Overall Loss: 18.682808
Rec Loss: 13.578083
KL Loss: 5.104726
Y Loss: 0.310584
T Loss: 11.869880
Epoch 549 
Overall Loss: 18.602078
Rec Loss: 13.405365
KL Loss: 5.196713
Y Loss: 0.309351
T Loss: 11.808247
Epoch 599 
Overall Loss: 18.585297
Rec Loss: 13.297647
KL Loss: 5.287649
Y Loss: 0.304611
T Loss: 11.774852
Epoch 649 
Overall Loss: 18.507790
Rec Loss: 13.162972
KL Loss: 5.344818
Y Loss: 0.299825
T Loss: 11.734019
Epoch 699 
Overall Loss: 18.466068
Rec Loss: 13.079070
KL Loss: 5.386998
Y Loss: 0.298893
T Loss: 11.699814
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.857610
Epoch 99
Rec Loss: 1.854330
Epoch 149
Rec Loss: 1.845682
Epoch 199
Rec Loss: 1.847222
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.879500
Epoch 99
Rec Loss: 5.878426
Epoch 149
Rec Loss: 5.866098
Epoch 199
Rec Loss: 5.852649
Epoch 249
Rec Loss: 5.880125
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.251794
Insample Error 2.313496
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 19.318824
Rec Loss: 16.519222
KL Loss: 2.799602
Y Loss: 2.041689
T Loss: 12.435842
Epoch 99 
Overall Loss: 16.844224
Rec Loss: 14.218439
KL Loss: 2.625785
Y Loss: 0.872717
T Loss: 12.473005
Epoch 149 
Overall Loss: 16.261519
Rec Loss: 13.811273
KL Loss: 2.450246
Y Loss: 0.739850
T Loss: 12.331572
Epoch 199 
Overall Loss: 15.188760
Rec Loss: 13.146548
KL Loss: 2.042212
Y Loss: 0.540349
T Loss: 12.065850
Epoch 249 
Overall Loss: 14.660376
Rec Loss: 12.721107
KL Loss: 1.939269
Y Loss: 0.391235
T Loss: 11.938638
Epoch 299 
Overall Loss: 14.468207
Rec Loss: 12.541836
KL Loss: 1.926370
Y Loss: 0.337748
T Loss: 11.866341
Epoch 349 
Overall Loss: 14.392133
Rec Loss: 12.453072
KL Loss: 1.939061
Y Loss: 0.314312
T Loss: 11.824449
Epoch 399 
Overall Loss: 14.331276
Rec Loss: 12.381876
KL Loss: 1.949400
Y Loss: 0.304016
T Loss: 11.773844
Epoch 449 
Overall Loss: 14.260502
Rec Loss: 12.297107
KL Loss: 1.963396
Y Loss: 0.288672
T Loss: 11.719763
Epoch 499 
Overall Loss: 14.242784
Rec Loss: 12.263968
KL Loss: 1.978815
Y Loss: 0.289334
T Loss: 11.685301
Epoch 549 
Overall Loss: 14.181565
Rec Loss: 12.190823
KL Loss: 1.990742
Y Loss: 0.274213
T Loss: 11.642397
Epoch 599 
Overall Loss: 14.160315
Rec Loss: 12.147364
KL Loss: 2.012951
Y Loss: 0.269910
T Loss: 11.607544
Epoch 649 
Overall Loss: 14.127101
Rec Loss: 12.111168
KL Loss: 2.015933
Y Loss: 0.261958
T Loss: 11.587253
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.835398
Epoch 99
Rec Loss: 1.825722
Epoch 149
Rec Loss: 1.821386
Epoch 199
Rec Loss: 1.821070
Epoch 249
Rec Loss: 1.819686
Epoch 299
Rec Loss: 1.826023
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.000940
Epoch 99
Rec Loss: 10.001168
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.249737
Insample Error: 2.542613
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 30.154133
Rec Loss: 26.794491
KL Loss: 3.359642
Y Loss: 4.671385
T Loss: 12.452961
Epoch 99 
Overall Loss: 22.636611
Rec Loss: 19.498533
KL Loss: 3.138078
Y Loss: 1.121550
T Loss: 12.590902
Epoch 149 
Overall Loss: 20.886461
Rec Loss: 17.247860
KL Loss: 3.638602
Y Loss: 0.758297
T Loss: 12.499667
Epoch 199 
Overall Loss: 20.065894
Rec Loss: 15.924552
KL Loss: 4.141341
Y Loss: 0.606626
T Loss: 12.438837
Epoch 249 
Overall Loss: 19.728339
Rec Loss: 15.427183
KL Loss: 4.301156
Y Loss: 0.556733
T Loss: 12.321277
Epoch 299 
Overall Loss: 19.464887
Rec Loss: 14.940501
KL Loss: 4.524386
Y Loss: 0.498567
T Loss: 12.239901
Epoch 349 
Overall Loss: 19.200816
Rec Loss: 14.366752
KL Loss: 4.834063
Y Loss: 0.430947
T Loss: 12.159978
Epoch 399 
Overall Loss: 19.000181
Rec Loss: 13.967298
KL Loss: 5.032883
Y Loss: 0.383350
T Loss: 12.072749
Epoch 449 
Overall Loss: 18.882160
Rec Loss: 13.660254
KL Loss: 5.221906
Y Loss: 0.357406
T Loss: 12.016848
Epoch 499 
Overall Loss: 18.784979
Rec Loss: 13.416454
KL Loss: 5.368525
Y Loss: 0.341868
T Loss: 11.968692
Epoch 549 
Overall Loss: 18.719985
Rec Loss: 13.194998
KL Loss: 5.524986
Y Loss: 0.337656
T Loss: 11.904995
Epoch 599 
Overall Loss: 18.672750
Rec Loss: 13.023809
KL Loss: 5.648941
Y Loss: 0.335665
T Loss: 11.875392
Epoch 649 
Overall Loss: 18.591100
Rec Loss: 12.813026
KL Loss: 5.778073
Y Loss: 0.323425
T Loss: 11.833989
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.957853
Epoch 99
Rec Loss: 1.950976
Epoch 149
Rec Loss: 1.951903
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.805152
Epoch 99
Rec Loss: 5.799128
Epoch 149
Rec Loss: 5.806549
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.270785
Insample Error 2.418189
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 20.884405
Rec Loss: 17.727698
KL Loss: 3.156708
Y Loss: 2.717834
T Loss: 12.292029
Epoch 99 
Overall Loss: 16.334463
Rec Loss: 13.927794
KL Loss: 2.406669
Y Loss: 0.781117
T Loss: 12.365561
Epoch 149 
Overall Loss: 15.280080
Rec Loss: 13.281369
KL Loss: 1.998710
Y Loss: 0.518629
T Loss: 12.244111
Epoch 199 
Overall Loss: 14.830458
Rec Loss: 12.879752
KL Loss: 1.950706
Y Loss: 0.381814
T Loss: 12.116123
Epoch 249 
Overall Loss: 14.634186
Rec Loss: 12.708262
KL Loss: 1.925924
Y Loss: 0.341486
T Loss: 12.025290
Epoch 299 
Overall Loss: 14.480462
Rec Loss: 12.571097
KL Loss: 1.909365
Y Loss: 0.319540
T Loss: 11.932017
Epoch 349 
Overall Loss: 14.369466
Rec Loss: 12.470956
KL Loss: 1.898510
Y Loss: 0.314307
T Loss: 11.842343
Epoch 399 
Overall Loss: 14.323737
Rec Loss: 12.410622
KL Loss: 1.913116
Y Loss: 0.304514
T Loss: 11.801594
Epoch 449 
Overall Loss: 14.262024
Rec Loss: 12.339328
KL Loss: 1.922697
Y Loss: 0.294254
T Loss: 11.750819
Epoch 499 
Overall Loss: 14.219192
Rec Loss: 12.277438
KL Loss: 1.941754
Y Loss: 0.287265
T Loss: 11.702909
Epoch 549 
Overall Loss: 14.191451
Rec Loss: 12.222888
KL Loss: 1.968563
Y Loss: 0.285652
T Loss: 11.651584
Epoch 599 
Overall Loss: 14.124268
Rec Loss: 12.132269
KL Loss: 1.991999
Y Loss: 0.267510
T Loss: 11.597250
Epoch 649 
Overall Loss: 14.112093
Rec Loss: 12.096645
KL Loss: 2.015448
Y Loss: 0.265762
T Loss: 11.565120
Epoch 699 
Overall Loss: 14.073785
Rec Loss: 12.051846
KL Loss: 2.021939
Y Loss: 0.263023
T Loss: 11.525801
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.805896
Epoch 99
Rec Loss: 1.796137
Epoch 149
Rec Loss: 1.798691
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.006095
Epoch 99
Rec Loss: 10.002618
Epoch 149
Rec Loss: 10.004037
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.242680
Insample Error: 2.452108
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 27.666419
Rec Loss: 23.988206
KL Loss: 3.678214
Y Loss: 3.300853
T Loss: 12.392008
Epoch 99 
Overall Loss: 22.402399
Rec Loss: 19.215430
KL Loss: 3.186968
Y Loss: 1.040957
T Loss: 12.572470
Epoch 149 
Overall Loss: 20.674170
Rec Loss: 16.767276
KL Loss: 3.906893
Y Loss: 0.694801
T Loss: 12.475656
Epoch 199 
Overall Loss: 20.075521
Rec Loss: 15.954939
KL Loss: 4.120582
Y Loss: 0.608537
T Loss: 12.368698
Epoch 249 
Overall Loss: 19.651645
Rec Loss: 15.278975
KL Loss: 4.372670
Y Loss: 0.532979
T Loss: 12.268577
Epoch 299 
Overall Loss: 19.347577
Rec Loss: 14.613266
KL Loss: 4.734311
Y Loss: 0.475247
T Loss: 12.201440
Epoch 349 
Overall Loss: 19.107969
Rec Loss: 14.066489
KL Loss: 5.041481
Y Loss: 0.436549
T Loss: 12.129025
Epoch 399 
Overall Loss: 18.945312
Rec Loss: 13.546657
KL Loss: 5.398656
Y Loss: 0.406788
T Loss: 12.058400
Epoch 449 
Overall Loss: 18.847633
Rec Loss: 13.178594
KL Loss: 5.669039
Y Loss: 0.373717
T Loss: 12.015548
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.031566
Epoch 99
Rec Loss: 2.033430
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.677376
Epoch 99
Rec Loss: 5.671347
Epoch 149
Rec Loss: 5.672269
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.299353
Insample Error 2.409594
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 20.719286
Rec Loss: 17.645388
KL Loss: 3.073898
Y Loss: 2.634665
T Loss: 12.376058
Epoch 99 
Overall Loss: 16.702636
Rec Loss: 14.111003
KL Loss: 2.591633
Y Loss: 0.833094
T Loss: 12.444815
Epoch 149 
Overall Loss: 15.802097
Rec Loss: 13.541280
KL Loss: 2.260817
Y Loss: 0.629043
T Loss: 12.283194
Epoch 199 
Overall Loss: 14.937886
Rec Loss: 12.990893
KL Loss: 1.946993
Y Loss: 0.442388
T Loss: 12.106118
Epoch 249 
Overall Loss: 14.656804
Rec Loss: 12.739229
KL Loss: 1.917575
Y Loss: 0.360989
T Loss: 12.017251
Epoch 299 
Overall Loss: 14.497637
Rec Loss: 12.615329
KL Loss: 1.882308
Y Loss: 0.337197
T Loss: 11.940936
Epoch 349 
Overall Loss: 14.394521
Rec Loss: 12.518665
KL Loss: 1.875856
Y Loss: 0.319861
T Loss: 11.878944
Epoch 399 
Overall Loss: 14.329220
Rec Loss: 12.451619
KL Loss: 1.877601
Y Loss: 0.310576
T Loss: 11.830466
Epoch 449 
Overall Loss: 14.274945
Rec Loss: 12.388240
KL Loss: 1.886704
Y Loss: 0.304697
T Loss: 11.778846
Epoch 499 
Overall Loss: 14.233257
Rec Loss: 12.316157
KL Loss: 1.917100
Y Loss: 0.291399
T Loss: 11.733359
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.883565
Epoch 99
Rec Loss: 1.889346
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.009685
Epoch 99
Rec Loss: 10.009024
Epoch 149
Rec Loss: 10.009509
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.304689
Insample Error: 2.477397
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 26.597387
Rec Loss: 22.887582
KL Loss: 3.709806
Y Loss: 2.707578
T Loss: 12.465256
Epoch 99 
Overall Loss: 22.283651
Rec Loss: 19.360883
KL Loss: 2.922768
Y Loss: 0.942669
T Loss: 12.631363
Epoch 149 
Overall Loss: 20.855400
Rec Loss: 17.699168
KL Loss: 3.156233
Y Loss: 0.644163
T Loss: 12.578228
Epoch 199 
Overall Loss: 20.176613
Rec Loss: 16.830374
KL Loss: 3.346239
Y Loss: 0.528941
T Loss: 12.490963
Epoch 249 
Overall Loss: 19.845300
Rec Loss: 16.434310
KL Loss: 3.410990
Y Loss: 0.484450
T Loss: 12.381291
Epoch 299 
Overall Loss: 19.532349
Rec Loss: 15.890102
KL Loss: 3.642246
Y Loss: 0.435732
T Loss: 12.275689
Epoch 349 
Overall Loss: 19.224500
Rec Loss: 15.096089
KL Loss: 4.128411
Y Loss: 0.398554
T Loss: 12.179078
Epoch 399 
Overall Loss: 18.974642
Rec Loss: 14.529229
KL Loss: 4.445413
Y Loss: 0.341064
T Loss: 12.108478
Epoch 449 
Overall Loss: 18.861429
Rec Loss: 14.199287
KL Loss: 4.662143
Y Loss: 0.329258
T Loss: 12.007765
Epoch 499 
Overall Loss: 18.716784
Rec Loss: 13.822409
KL Loss: 4.894375
Y Loss: 0.316638
T Loss: 11.932875
Epoch 549 
Overall Loss: 18.634830
Rec Loss: 13.558028
KL Loss: 5.076802
Y Loss: 0.305275
T Loss: 11.879120
Epoch 599 
Overall Loss: 18.605983
Rec Loss: 13.352897
KL Loss: 5.253087
Y Loss: 0.315088
T Loss: 11.833256
Epoch 649 
Overall Loss: 18.522735
Rec Loss: 13.135488
KL Loss: 5.387246
Y Loss: 0.292539
T Loss: 11.796781
Epoch 699 
Overall Loss: 18.481504
Rec Loss: 12.987285
KL Loss: 5.494219
Y Loss: 0.292272
T Loss: 11.762454
Epoch 749 
Overall Loss: 18.431878
Rec Loss: 12.841345
KL Loss: 5.590533
Y Loss: 0.287895
T Loss: 11.729758
Epoch 799 
Overall Loss: 18.376698
Rec Loss: 12.754175
KL Loss: 5.622523
Y Loss: 0.281799
T Loss: 11.706139
Epoch 849 
Overall Loss: 18.319642
Rec Loss: 12.601509
KL Loss: 5.718132
Y Loss: 0.279909
T Loss: 11.681076
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.835708
Epoch 99
Rec Loss: 1.832153
Epoch 149
Rec Loss: 1.838017
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.801506
Epoch 99
Rec Loss: 5.799957
Epoch 149
Rec Loss: 5.796798
Epoch 199
Rec Loss: 5.800864
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.242467
Insample Error 2.403123
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 19.472033
Rec Loss: 16.569484
KL Loss: 2.902549
Y Loss: 2.113866
T Loss: 12.341752
Epoch 99 
Overall Loss: 16.599321
Rec Loss: 14.015028
KL Loss: 2.584293
Y Loss: 0.825500
T Loss: 12.364027
Epoch 149 
Overall Loss: 15.800927
Rec Loss: 13.451376
KL Loss: 2.349552
Y Loss: 0.626235
T Loss: 12.198907
Epoch 199 
Overall Loss: 15.207776
Rec Loss: 13.038053
KL Loss: 2.169722
Y Loss: 0.489613
T Loss: 12.058826
Epoch 249 
Overall Loss: 14.784279
Rec Loss: 12.790769
KL Loss: 1.993509
Y Loss: 0.403301
T Loss: 11.984167
Epoch 299 
Overall Loss: 14.572473
Rec Loss: 12.649877
KL Loss: 1.922596
Y Loss: 0.358774
T Loss: 11.932330
Epoch 349 
Overall Loss: 14.414533
Rec Loss: 12.508850
KL Loss: 1.905683
Y Loss: 0.319163
T Loss: 11.870523
Epoch 399 
Overall Loss: 14.310498
Rec Loss: 12.404779
KL Loss: 1.905718
Y Loss: 0.299894
T Loss: 11.804992
Epoch 449 
Overall Loss: 14.249306
Rec Loss: 12.346100
KL Loss: 1.903206
Y Loss: 0.291722
T Loss: 11.762657
Epoch 499 
Overall Loss: 14.219614
Rec Loss: 12.304383
KL Loss: 1.915230
Y Loss: 0.292955
T Loss: 11.718472
Epoch 549 
Overall Loss: 14.181536
Rec Loss: 12.233308
KL Loss: 1.948228
Y Loss: 0.281190
T Loss: 11.670928
Epoch 599 
Overall Loss: 14.129862
Rec Loss: 12.169100
KL Loss: 1.960762
Y Loss: 0.274696
T Loss: 11.619709
Epoch 649 
Overall Loss: 14.094052
Rec Loss: 12.105553
KL Loss: 1.988499
Y Loss: 0.255380
T Loss: 11.594793
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.821284
Epoch 99
Rec Loss: 1.815012
Epoch 149
Rec Loss: 1.819138
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.979308
Epoch 99
Rec Loss: 9.968468
Epoch 149
Rec Loss: 9.968152
Epoch 199
Rec Loss: 9.980933
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.246340
Insample Error: 2.429006
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 31.052525
Rec Loss: 27.893389
KL Loss: 3.159136
Y Loss: 5.198576
T Loss: 12.503465
Epoch 99 
Overall Loss: 22.745725
Rec Loss: 19.389192
KL Loss: 3.356532
Y Loss: 1.187438
T Loss: 12.575554
Epoch 149 
Overall Loss: 21.143997
Rec Loss: 17.525344
KL Loss: 3.618653
Y Loss: 0.795320
T Loss: 12.450623
Epoch 199 
Overall Loss: 20.190069
Rec Loss: 16.268556
KL Loss: 3.921512
Y Loss: 0.602552
T Loss: 12.181260
Epoch 249 
Overall Loss: 19.728589
Rec Loss: 15.607528
KL Loss: 4.121061
Y Loss: 0.520553
T Loss: 12.082680
Epoch 299 
Overall Loss: 19.413487
Rec Loss: 15.061838
KL Loss: 4.351649
Y Loss: 0.445163
T Loss: 12.005591
Epoch 349 
Overall Loss: 19.216153
Rec Loss: 14.675474
KL Loss: 4.540680
Y Loss: 0.409908
T Loss: 11.971934
Epoch 399 
Overall Loss: 19.068812
Rec Loss: 14.319332
KL Loss: 4.749480
Y Loss: 0.351838
T Loss: 11.959440
Epoch 449 
Overall Loss: 18.948055
Rec Loss: 14.069109
KL Loss: 4.878947
Y Loss: 0.345580
T Loss: 11.932596
Epoch 499 
Overall Loss: 18.866915
Rec Loss: 13.862434
KL Loss: 5.004481
Y Loss: 0.338872
T Loss: 11.903522
Epoch 549 
Overall Loss: 18.781500
Rec Loss: 13.661801
KL Loss: 5.119699
Y Loss: 0.325828
T Loss: 11.878987
Epoch 599 
Overall Loss: 18.675876
Rec Loss: 13.466763
KL Loss: 5.209113
Y Loss: 0.322869
T Loss: 11.842566
Epoch 649 
Overall Loss: 18.552050
Rec Loss: 13.270835
KL Loss: 5.281215
Y Loss: 0.311322
T Loss: 11.786390
Epoch 699 
Overall Loss: 18.527007
Rec Loss: 13.159910
KL Loss: 5.367097
Y Loss: 0.307737
T Loss: 11.758335
Epoch 749 
Overall Loss: 18.480418
Rec Loss: 13.053231
KL Loss: 5.427187
Y Loss: 0.304957
T Loss: 11.730766
Epoch 799 
Overall Loss: 18.396791
Rec Loss: 12.911946
KL Loss: 5.484846
Y Loss: 0.290161
T Loss: 11.697429
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.852267
Epoch 99
Rec Loss: 1.850941
Epoch 149
Rec Loss: 1.843414
Epoch 199
Rec Loss: 1.840273
Epoch 249
Rec Loss: 1.844567
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.957838
Epoch 99
Rec Loss: 5.941258
Epoch 149
Rec Loss: 5.946781
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.269859
Insample Error 2.131554
Ours, Train RMSE
0.2796, 
0.2919, 
0.2488, 
0.2702, 
0.2550, 
0.2228, 
0.2497, 
0.2427, 
0.3047, 
0.2463, 
Ours, Insample RMSE
2.4572, 
2.4430, 
2.3339, 
2.5610, 
2.4327, 
2.3226, 
2.5426, 
2.4521, 
2.4774, 
2.4290, 
CEVAE, Insample RMSE
2.4628, 
2.4755, 
2.3806, 
2.4255, 
2.4115, 
2.3135, 
2.4182, 
2.4096, 
2.4031, 
2.1316, 
Train, RMSE mean 0.2612 std 0.0237
Ours, RMSE mean 2.4451 std 0.0721, reconstruct confounder 1.8411 (0.0317) noise 10.0016 (0.0127)
CEVAE, RMSE mean 2.3832 std 0.0938, reconstruct confounder 1.9228 (0.0687) noise 5.8822 (0.1221)
Experiment Start!
Namespace(decay=0.0, l=5e-05, latdim=4, mask=0, nlayer=50, obsm=0, ycof=0.5, ylayer=50)
Y Mean 1.514292, Std 3.653528 
Observe confounder 0, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.641600
Rec Loss: 15.544690
KL Loss: 1.096910
Y Loss: 5.921907
T Loss: 12.583737
Epoch 99 
Overall Loss: 14.459863
Rec Loss: 13.147397
KL Loss: 1.312466
Y Loss: 1.720315
T Loss: 12.287239
Epoch 149 
Overall Loss: 14.042454
Rec Loss: 12.704614
KL Loss: 1.337840
Y Loss: 1.157190
T Loss: 12.126019
Epoch 199 
Overall Loss: 13.773536
Rec Loss: 12.407581
KL Loss: 1.365955
Y Loss: 0.935569
T Loss: 11.939796
Epoch 249 
Overall Loss: 13.630519
Rec Loss: 12.237095
KL Loss: 1.393424
Y Loss: 0.876850
T Loss: 11.798669
Epoch 299 
Overall Loss: 13.544140
Rec Loss: 12.132099
KL Loss: 1.412042
Y Loss: 0.901453
T Loss: 11.681371
Epoch 349 
Overall Loss: 13.493156
Rec Loss: 12.087612
KL Loss: 1.405544
Y Loss: 0.912292
T Loss: 11.631466
Epoch 399 
Overall Loss: 13.461209
Rec Loss: 12.061145
KL Loss: 1.400064
Y Loss: 0.933806
T Loss: 11.594242
Epoch 449 
Overall Loss: 13.411878
Rec Loss: 12.017848
KL Loss: 1.394031
Y Loss: 0.930188
T Loss: 11.552754
Epoch 499 
Overall Loss: 13.379394
Rec Loss: 11.982204
KL Loss: 1.397190
Y Loss: 0.887968
T Loss: 11.538220
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.893222
Epoch 99
Rec Loss: 1.897774
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.000040
Epoch 99
Rec Loss: 10.003922
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.656235
Insample Error: 2.506579
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.561335
Rec Loss: 20.259505
KL Loss: 1.301830
Y Loss: 5.479711
T Loss: 12.563181
Epoch 99 
Overall Loss: 19.684899
Rec Loss: 17.863683
KL Loss: 1.821216
Y Loss: 2.339510
T Loss: 12.336912
Epoch 149 
Overall Loss: 18.996189
Rec Loss: 16.702309
KL Loss: 2.293880
Y Loss: 1.805759
T Loss: 12.129818
Epoch 199 
Overall Loss: 18.564341
Rec Loss: 15.796564
KL Loss: 2.767778
Y Loss: 1.552518
T Loss: 11.996255
Epoch 249 
Overall Loss: 18.293524
Rec Loss: 15.188878
KL Loss: 3.104646
Y Loss: 1.429615
T Loss: 11.857360
Epoch 299 
Overall Loss: 18.075525
Rec Loss: 14.684593
KL Loss: 3.390932
Y Loss: 1.326499
T Loss: 11.773567
Epoch 349 
Overall Loss: 17.937187
Rec Loss: 14.262880
KL Loss: 3.674306
Y Loss: 1.230425
T Loss: 11.715361
Epoch 399 
Overall Loss: 17.795937
Rec Loss: 13.908958
KL Loss: 3.886979
Y Loss: 1.170479
T Loss: 11.671157
Epoch 449 
Overall Loss: 17.739751
Rec Loss: 13.673631
KL Loss: 4.066120
Y Loss: 1.119223
T Loss: 11.625179
Epoch 499 
Overall Loss: 17.710054
Rec Loss: 13.529901
KL Loss: 4.180153
Y Loss: 1.119536
T Loss: 11.597114
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.924298
Epoch 99
Rec Loss: 1.924211
Epoch 149
Rec Loss: 1.933334
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.076625
Epoch 99
Rec Loss: 6.075912
Epoch 149
Rec Loss: 6.065706
Epoch 199
Rec Loss: 6.052872
Epoch 249
Rec Loss: 6.074576
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.758946
Insample Error 2.333654
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.729992
Rec Loss: 15.621986
KL Loss: 1.108006
Y Loss: 6.219542
T Loss: 12.512215
Epoch 99 
Overall Loss: 14.747448
Rec Loss: 13.352896
KL Loss: 1.394552
Y Loss: 1.936595
T Loss: 12.384598
Epoch 149 
Overall Loss: 14.151491
Rec Loss: 12.864924
KL Loss: 1.286568
Y Loss: 1.323674
T Loss: 12.203086
Epoch 199 
Overall Loss: 13.825014
Rec Loss: 12.531695
KL Loss: 1.293319
Y Loss: 1.024005
T Loss: 12.019693
Epoch 249 
Overall Loss: 13.638365
Rec Loss: 12.318836
KL Loss: 1.319528
Y Loss: 0.918110
T Loss: 11.859781
Epoch 299 
Overall Loss: 13.512439
Rec Loss: 12.164248
KL Loss: 1.348191
Y Loss: 0.887793
T Loss: 11.720352
Epoch 349 
Overall Loss: 13.462051
Rec Loss: 12.094964
KL Loss: 1.367087
Y Loss: 0.909616
T Loss: 11.640156
Epoch 399 
Overall Loss: 13.415146
Rec Loss: 12.030605
KL Loss: 1.384542
Y Loss: 0.913794
T Loss: 11.573707
Epoch 449 
Overall Loss: 13.377321
Rec Loss: 11.990698
KL Loss: 1.386623
Y Loss: 0.906731
T Loss: 11.537332
Epoch 499 
Overall Loss: 13.381782
Rec Loss: 12.003154
KL Loss: 1.378628
Y Loss: 0.945265
T Loss: 11.530522
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.889243
Epoch 99
Rec Loss: 1.887379
Epoch 149
Rec Loss: 1.891934
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.010528
Epoch 99
Rec Loss: 9.999801
Epoch 149
Rec Loss: 9.998462
Epoch 199
Rec Loss: 10.000770
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.656730
Insample Error: 2.485033
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.827273
Rec Loss: 20.677801
KL Loss: 1.149472
Y Loss: 6.184187
T Loss: 12.608929
Epoch 99 
Overall Loss: 19.828936
Rec Loss: 18.046593
KL Loss: 1.782342
Y Loss: 2.645866
T Loss: 12.356062
Epoch 149 
Overall Loss: 18.960709
Rec Loss: 16.550365
KL Loss: 2.410344
Y Loss: 1.984507
T Loss: 12.091302
Epoch 199 
Overall Loss: 18.482948
Rec Loss: 15.475121
KL Loss: 3.007828
Y Loss: 1.679390
T Loss: 11.968638
Epoch 249 
Overall Loss: 18.251188
Rec Loss: 14.925136
KL Loss: 3.326051
Y Loss: 1.486675
T Loss: 11.887305
Epoch 299 
Overall Loss: 17.982349
Rec Loss: 14.443052
KL Loss: 3.539297
Y Loss: 1.331398
T Loss: 11.811557
Epoch 349 
Overall Loss: 17.889303
Rec Loss: 14.039755
KL Loss: 3.849549
Y Loss: 1.252961
T Loss: 11.724638
Epoch 399 
Overall Loss: 17.749738
Rec Loss: 13.614535
KL Loss: 4.135203
Y Loss: 1.163353
T Loss: 11.668017
Epoch 449 
Overall Loss: 17.685004
Rec Loss: 13.337077
KL Loss: 4.347928
Y Loss: 1.153406
T Loss: 11.621620
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.934509
Epoch 99
Rec Loss: 1.932445
Epoch 149
Rec Loss: 1.938709
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.878507
Epoch 99
Rec Loss: 5.879958
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.759202
Insample Error 2.270754
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.881865
Rec Loss: 17.290118
KL Loss: 0.591747
Y Loss: 8.722387
T Loss: 12.928924
Epoch 99 
Overall Loss: 14.407172
Rec Loss: 13.075753
KL Loss: 1.331419
Y Loss: 1.778577
T Loss: 12.186465
Epoch 149 
Overall Loss: 13.936793
Rec Loss: 12.563099
KL Loss: 1.373694
Y Loss: 1.122389
T Loss: 12.001905
Epoch 199 
Overall Loss: 13.705134
Rec Loss: 12.306904
KL Loss: 1.398230
Y Loss: 0.961408
T Loss: 11.826199
Epoch 249 
Overall Loss: 13.570844
Rec Loss: 12.176435
KL Loss: 1.394409
Y Loss: 0.914038
T Loss: 11.719416
Epoch 299 
Overall Loss: 13.491401
Rec Loss: 12.092989
KL Loss: 1.398412
Y Loss: 0.904814
T Loss: 11.640583
Epoch 349 
Overall Loss: 13.474749
Rec Loss: 12.084547
KL Loss: 1.390202
Y Loss: 0.928352
T Loss: 11.620371
Epoch 399 
Overall Loss: 13.404891
Rec Loss: 12.013751
KL Loss: 1.391140
Y Loss: 0.903518
T Loss: 11.561992
Epoch 449 
Overall Loss: 13.385117
Rec Loss: 12.000799
KL Loss: 1.384318
Y Loss: 0.902699
T Loss: 11.549451
Epoch 499 
Overall Loss: 13.357257
Rec Loss: 11.962521
KL Loss: 1.394736
Y Loss: 0.882842
T Loss: 11.521100
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.892974
Epoch 99
Rec Loss: 1.891954
Epoch 149
Rec Loss: 1.888251
Epoch 199
Rec Loss: 1.884613
Epoch 249
Rec Loss: 1.878335
Epoch 299
Rec Loss: 1.884414
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.002228
Epoch 99
Rec Loss: 10.006965
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.628642
Insample Error: 2.291333
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.511452
Rec Loss: 20.250802
KL Loss: 1.260649
Y Loss: 5.421671
T Loss: 12.623114
Epoch 99 
Overall Loss: 19.528196
Rec Loss: 17.485422
KL Loss: 2.042775
Y Loss: 2.264425
T Loss: 12.401852
Epoch 149 
Overall Loss: 18.680330
Rec Loss: 15.837862
KL Loss: 2.842467
Y Loss: 1.661119
T Loss: 12.220762
Epoch 199 
Overall Loss: 18.396540
Rec Loss: 15.209743
KL Loss: 3.186797
Y Loss: 1.553424
T Loss: 12.048339
Epoch 249 
Overall Loss: 18.162835
Rec Loss: 14.742823
KL Loss: 3.420011
Y Loss: 1.399306
T Loss: 11.927597
Epoch 299 
Overall Loss: 18.013630
Rec Loss: 14.311392
KL Loss: 3.702239
Y Loss: 1.312825
T Loss: 11.832377
Epoch 349 
Overall Loss: 17.882255
Rec Loss: 13.870335
KL Loss: 4.011921
Y Loss: 1.244676
T Loss: 11.749504
Epoch 399 
Overall Loss: 17.772181
Rec Loss: 13.480162
KL Loss: 4.292019
Y Loss: 1.168329
T Loss: 11.676516
Epoch 449 
Overall Loss: 17.729157
Rec Loss: 13.259459
KL Loss: 4.469698
Y Loss: 1.157449
T Loss: 11.630666
Epoch 499 
Overall Loss: 17.708120
Rec Loss: 13.128382
KL Loss: 4.579739
Y Loss: 1.130787
T Loss: 11.601713
Epoch 549 
Overall Loss: 17.649548
Rec Loss: 12.932825
KL Loss: 4.716724
Y Loss: 1.094467
T Loss: 11.574086
Epoch 599 
Overall Loss: 17.620315
Rec Loss: 12.858727
KL Loss: 4.761588
Y Loss: 1.089390
T Loss: 11.557997
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.904741
Epoch 99
Rec Loss: 1.902282
Epoch 149
Rec Loss: 1.900814
Epoch 199
Rec Loss: 1.909592
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.816071
Epoch 99
Rec Loss: 5.811714
Epoch 149
Rec Loss: 5.804476
Epoch 199
Rec Loss: 5.805765
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.730484
Insample Error 2.301492
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.434963
Rec Loss: 15.335416
KL Loss: 1.099547
Y Loss: 5.797550
T Loss: 12.436641
Epoch 99 
Overall Loss: 14.239730
Rec Loss: 12.930099
KL Loss: 1.309630
Y Loss: 1.452176
T Loss: 12.204011
Epoch 149 
Overall Loss: 13.948558
Rec Loss: 12.610710
KL Loss: 1.337848
Y Loss: 1.083802
T Loss: 12.068809
Epoch 199 
Overall Loss: 13.733350
Rec Loss: 12.359852
KL Loss: 1.373498
Y Loss: 0.926081
T Loss: 11.896811
Epoch 249 
Overall Loss: 13.612317
Rec Loss: 12.214210
KL Loss: 1.398106
Y Loss: 0.918131
T Loss: 11.755145
Epoch 299 
Overall Loss: 13.531731
Rec Loss: 12.123228
KL Loss: 1.408504
Y Loss: 0.921803
T Loss: 11.662326
Epoch 349 
Overall Loss: 13.500045
Rec Loss: 12.091288
KL Loss: 1.408757
Y Loss: 0.920698
T Loss: 11.630939
Epoch 399 
Overall Loss: 13.435988
Rec Loss: 12.024307
KL Loss: 1.411681
Y Loss: 0.886345
T Loss: 11.581134
Epoch 449 
Overall Loss: 13.419601
Rec Loss: 12.008162
KL Loss: 1.411439
Y Loss: 0.923160
T Loss: 11.546582
Epoch 499 
Overall Loss: 13.396452
Rec Loss: 11.990199
KL Loss: 1.406254
Y Loss: 0.914016
T Loss: 11.533191
Epoch 549 
Overall Loss: 13.395228
Rec Loss: 11.995418
KL Loss: 1.399810
Y Loss: 0.940564
T Loss: 11.525136
Epoch 599 
Overall Loss: 13.360958
Rec Loss: 11.960433
KL Loss: 1.400524
Y Loss: 0.893541
T Loss: 11.513663
Epoch 649 
Overall Loss: 13.330816
Rec Loss: 11.934391
KL Loss: 1.396425
Y Loss: 0.876767
T Loss: 11.496008
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.893525
Epoch 99
Rec Loss: 1.889532
Epoch 149
Rec Loss: 1.879105
Epoch 199
Rec Loss: 1.879485
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.991038
Epoch 99
Rec Loss: 9.985878
Epoch 149
Rec Loss: 9.987039
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.641315
Insample Error: 2.395056
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.336818
Rec Loss: 20.103977
KL Loss: 1.232842
Y Loss: 4.863292
T Loss: 12.695747
Epoch 99 
Overall Loss: 19.533296
Rec Loss: 17.788557
KL Loss: 1.744739
Y Loss: 2.134245
T Loss: 12.313105
Epoch 149 
Overall Loss: 18.884544
Rec Loss: 16.818325
KL Loss: 2.066218
Y Loss: 1.706687
T Loss: 12.061304
Epoch 199 
Overall Loss: 18.377176
Rec Loss: 15.525415
KL Loss: 2.851762
Y Loss: 1.474899
T Loss: 11.955667
Epoch 249 
Overall Loss: 18.195034
Rec Loss: 15.001926
KL Loss: 3.193108
Y Loss: 1.406772
T Loss: 11.861743
Epoch 299 
Overall Loss: 18.072464
Rec Loss: 14.729886
KL Loss: 3.342578
Y Loss: 1.311587
T Loss: 11.809674
Epoch 349 
Overall Loss: 17.958162
Rec Loss: 14.512303
KL Loss: 3.445858
Y Loss: 1.282723
T Loss: 11.738391
Epoch 399 
Overall Loss: 17.859317
Rec Loss: 14.253499
KL Loss: 3.605818
Y Loss: 1.185298
T Loss: 11.683451
Epoch 449 
Overall Loss: 17.789529
Rec Loss: 14.045296
KL Loss: 3.744233
Y Loss: 1.147926
T Loss: 11.648513
Epoch 499 
Overall Loss: 17.707296
Rec Loss: 13.745943
KL Loss: 3.961353
Y Loss: 1.085654
T Loss: 11.608773
Epoch 549 
Overall Loss: 17.677972
Rec Loss: 13.554556
KL Loss: 4.123415
Y Loss: 1.073439
T Loss: 11.590034
Epoch 599 
Overall Loss: 17.594355
Rec Loss: 13.371548
KL Loss: 4.222807
Y Loss: 1.067616
T Loss: 11.571165
Epoch 649 
Overall Loss: 17.596602
Rec Loss: 13.271336
KL Loss: 4.325266
Y Loss: 1.026414
T Loss: 11.560147
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.907993
Epoch 99
Rec Loss: 1.910170
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.877684
Epoch 99
Rec Loss: 5.863698
Epoch 149
Rec Loss: 5.870120
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.715738
Insample Error 2.217575
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.847680
Rec Loss: 15.912271
KL Loss: 0.935410
Y Loss: 6.272226
T Loss: 12.776157
Epoch 99 
Overall Loss: 14.304013
Rec Loss: 12.945649
KL Loss: 1.358364
Y Loss: 1.440151
T Loss: 12.225574
Epoch 149 
Overall Loss: 13.937295
Rec Loss: 12.573456
KL Loss: 1.363839
Y Loss: 1.046162
T Loss: 12.050375
Epoch 199 
Overall Loss: 13.727323
Rec Loss: 12.341009
KL Loss: 1.386315
Y Loss: 0.913447
T Loss: 11.884285
Epoch 249 
Overall Loss: 13.596502
Rec Loss: 12.193051
KL Loss: 1.403452
Y Loss: 0.898532
T Loss: 11.743785
Epoch 299 
Overall Loss: 13.519716
Rec Loss: 12.120035
KL Loss: 1.399681
Y Loss: 0.891122
T Loss: 11.674474
Epoch 349 
Overall Loss: 13.476151
Rec Loss: 12.065394
KL Loss: 1.410756
Y Loss: 0.876232
T Loss: 11.627278
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.932896
Epoch 99
Rec Loss: 1.924732
Epoch 149
Rec Loss: 1.932142
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.010590
Epoch 99
Rec Loss: 10.014213
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.626227
Insample Error: 2.378738
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.625586
Rec Loss: 20.521788
KL Loss: 1.103798
Y Loss: 5.589454
T Loss: 12.735364
Epoch 99 
Overall Loss: 19.753506
Rec Loss: 18.080131
KL Loss: 1.673375
Y Loss: 2.380331
T Loss: 12.419864
Epoch 149 
Overall Loss: 18.867170
Rec Loss: 16.522532
KL Loss: 2.344639
Y Loss: 1.731024
T Loss: 12.174835
Epoch 199 
Overall Loss: 18.599466
Rec Loss: 16.027629
KL Loss: 2.571837
Y Loss: 1.555275
T Loss: 11.999649
Epoch 249 
Overall Loss: 18.429890
Rec Loss: 15.735762
KL Loss: 2.694128
Y Loss: 1.495925
T Loss: 11.890063
Epoch 299 
Overall Loss: 18.165667
Rec Loss: 15.111564
KL Loss: 3.054103
Y Loss: 1.324728
T Loss: 11.794895
Epoch 349 
Overall Loss: 17.955447
Rec Loss: 14.320411
KL Loss: 3.635037
Y Loss: 1.259164
T Loss: 11.739951
Epoch 399 
Overall Loss: 17.814612
Rec Loss: 13.978850
KL Loss: 3.835762
Y Loss: 1.216666
T Loss: 11.674002
Epoch 449 
Overall Loss: 17.745740
Rec Loss: 13.731576
KL Loss: 4.014164
Y Loss: 1.156558
T Loss: 11.624148
Epoch 499 
Overall Loss: 17.669489
Rec Loss: 13.544306
KL Loss: 4.125184
Y Loss: 1.124521
T Loss: 11.598747
Epoch 549 
Overall Loss: 17.660324
Rec Loss: 13.424659
KL Loss: 4.235665
Y Loss: 1.103388
T Loss: 11.577707
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.928826
Epoch 99
Rec Loss: 1.933318
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.186613
Epoch 99
Rec Loss: 6.169312
Epoch 149
Rec Loss: 6.169158
Epoch 199
Rec Loss: 6.157685
Epoch 249
Rec Loss: 6.155625
Epoch 299
Rec Loss: 6.147563
Epoch 349
Rec Loss: 6.164402
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.755867
Insample Error 2.320985
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.029017
Rec Loss: 16.011847
KL Loss: 1.017170
Y Loss: 6.795045
T Loss: 12.614326
Epoch 99 
Overall Loss: 14.781184
Rec Loss: 13.421672
KL Loss: 1.359512
Y Loss: 2.276796
T Loss: 12.283274
Epoch 149 
Overall Loss: 14.035096
Rec Loss: 12.683724
KL Loss: 1.351372
Y Loss: 1.331878
T Loss: 12.017785
Epoch 199 
Overall Loss: 13.760430
Rec Loss: 12.414170
KL Loss: 1.346259
Y Loss: 1.062160
T Loss: 11.883090
Epoch 249 
Overall Loss: 13.594585
Rec Loss: 12.242943
KL Loss: 1.351642
Y Loss: 0.978505
T Loss: 11.753690
Epoch 299 
Overall Loss: 13.504646
Rec Loss: 12.135730
KL Loss: 1.368916
Y Loss: 0.938898
T Loss: 11.666280
Epoch 349 
Overall Loss: 13.440200
Rec Loss: 12.058892
KL Loss: 1.381308
Y Loss: 0.919353
T Loss: 11.599216
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.916177
Epoch 99
Rec Loss: 1.908619
Epoch 149
Rec Loss: 1.909357
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.017966
Epoch 99
Rec Loss: 10.014486
Epoch 149
Rec Loss: 10.015912
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.679354
Insample Error: 2.432787
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.565287
Rec Loss: 20.367721
KL Loss: 1.197566
Y Loss: 5.363770
T Loss: 12.704662
Epoch 99 
Overall Loss: 19.642457
Rec Loss: 17.832038
KL Loss: 1.810419
Y Loss: 2.326488
T Loss: 12.344122
Epoch 149 
Overall Loss: 18.821802
Rec Loss: 16.385532
KL Loss: 2.436270
Y Loss: 1.663252
T Loss: 12.117366
Epoch 199 
Overall Loss: 18.501969
Rec Loss: 15.774252
KL Loss: 2.727716
Y Loss: 1.522447
T Loss: 11.944046
Epoch 249 
Overall Loss: 18.210535
Rec Loss: 15.031178
KL Loss: 3.179357
Y Loss: 1.321338
T Loss: 11.862265
Epoch 299 
Overall Loss: 18.004453
Rec Loss: 14.453492
KL Loss: 3.550961
Y Loss: 1.288789
T Loss: 11.759689
Epoch 349 
Overall Loss: 17.908653
Rec Loss: 14.129303
KL Loss: 3.779350
Y Loss: 1.244195
T Loss: 11.703439
Epoch 399 
Overall Loss: 17.808445
Rec Loss: 13.878872
KL Loss: 3.929573
Y Loss: 1.145628
T Loss: 11.667135
Epoch 449 
Overall Loss: 17.756179
Rec Loss: 13.706417
KL Loss: 4.049761
Y Loss: 1.142553
T Loss: 11.617483
Epoch 499 
Overall Loss: 17.696605
Rec Loss: 13.543012
KL Loss: 4.153594
Y Loss: 1.091886
T Loss: 11.603102
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.936729
Epoch 99
Rec Loss: 1.942785
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.013005
Epoch 99
Rec Loss: 5.988377
Epoch 149
Rec Loss: 6.007187
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.764404
Insample Error 2.358883
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.864334
Rec Loss: 14.490295
KL Loss: 1.374039
Y Loss: 3.863815
T Loss: 12.558387
Epoch 99 
Overall Loss: 14.774510
Rec Loss: 13.342578
KL Loss: 1.431932
Y Loss: 1.992494
T Loss: 12.346331
Epoch 149 
Overall Loss: 14.046788
Rec Loss: 12.685517
KL Loss: 1.361271
Y Loss: 1.382089
T Loss: 11.994473
Epoch 199 
Overall Loss: 13.747121
Rec Loss: 12.376158
KL Loss: 1.370963
Y Loss: 1.066521
T Loss: 11.842897
Epoch 249 
Overall Loss: 13.611704
Rec Loss: 12.235612
KL Loss: 1.376092
Y Loss: 0.989431
T Loss: 11.740896
Epoch 299 
Overall Loss: 13.521877
Rec Loss: 12.131893
KL Loss: 1.389984
Y Loss: 0.947865
T Loss: 11.657960
Epoch 349 
Overall Loss: 13.474741
Rec Loss: 12.080027
KL Loss: 1.394714
Y Loss: 0.928640
T Loss: 11.615707
Epoch 399 
Overall Loss: 13.439850
Rec Loss: 12.048220
KL Loss: 1.391630
Y Loss: 0.939362
T Loss: 11.578539
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.914258
Epoch 99
Rec Loss: 1.902907
Epoch 149
Rec Loss: 1.909070
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.005117
Epoch 99
Rec Loss: 10.010785
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.670474
Insample Error: 2.454733
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.925912
Rec Loss: 20.777325
KL Loss: 1.148587
Y Loss: 6.566226
T Loss: 12.595745
Epoch 99 
Overall Loss: 19.713779
Rec Loss: 17.892394
KL Loss: 1.821384
Y Loss: 2.618605
T Loss: 12.324820
Epoch 149 
Overall Loss: 18.667380
Rec Loss: 15.999123
KL Loss: 2.668256
Y Loss: 1.832166
T Loss: 12.085454
Epoch 199 
Overall Loss: 18.308652
Rec Loss: 15.024695
KL Loss: 3.283957
Y Loss: 1.560770
T Loss: 11.947519
Epoch 249 
Overall Loss: 18.097436
Rec Loss: 14.547688
KL Loss: 3.549748
Y Loss: 1.412136
T Loss: 11.847308
Epoch 299 
Overall Loss: 17.962722
Rec Loss: 14.120546
KL Loss: 3.842176
Y Loss: 1.286237
T Loss: 11.762234
Epoch 349 
Overall Loss: 17.883497
Rec Loss: 13.808229
KL Loss: 4.075269
Y Loss: 1.225885
T Loss: 11.715863
Epoch 399 
Overall Loss: 17.824596
Rec Loss: 13.565658
KL Loss: 4.258938
Y Loss: 1.162950
T Loss: 11.678912
Epoch 449 
Overall Loss: 17.756371
Rec Loss: 13.392807
KL Loss: 4.363563
Y Loss: 1.159229
T Loss: 11.638397
Epoch 499 
Overall Loss: 17.681600
Rec Loss: 13.227372
KL Loss: 4.454229
Y Loss: 1.121176
T Loss: 11.602710
Epoch 549 
Overall Loss: 17.624042
Rec Loss: 13.041459
KL Loss: 4.582582
Y Loss: 1.068775
T Loss: 11.570929
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.924502
Epoch 99
Rec Loss: 1.931350
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.867019
Epoch 99
Rec Loss: 5.861710
Epoch 149
Rec Loss: 5.847314
Epoch 199
Rec Loss: 5.859494
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.745079
Insample Error 2.301718
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.551154
Rec Loss: 15.374464
KL Loss: 1.176690
Y Loss: 5.796363
T Loss: 12.476283
Epoch 99 
Overall Loss: 14.365154
Rec Loss: 13.041162
KL Loss: 1.323992
Y Loss: 1.551689
T Loss: 12.265317
Epoch 149 
Overall Loss: 13.974188
Rec Loss: 12.631614
KL Loss: 1.342574
Y Loss: 1.085349
T Loss: 12.088940
Epoch 199 
Overall Loss: 13.752643
Rec Loss: 12.398878
KL Loss: 1.353765
Y Loss: 0.944823
T Loss: 11.926466
Epoch 249 
Overall Loss: 13.612220
Rec Loss: 12.248575
KL Loss: 1.363644
Y Loss: 0.897036
T Loss: 11.800058
Epoch 299 
Overall Loss: 13.515050
Rec Loss: 12.133108
KL Loss: 1.381941
Y Loss: 0.877906
T Loss: 11.694155
Epoch 349 
Overall Loss: 13.454475
Rec Loss: 12.069964
KL Loss: 1.384511
Y Loss: 0.908728
T Loss: 11.615600
Epoch 399 
Overall Loss: 13.429387
Rec Loss: 12.032075
KL Loss: 1.397312
Y Loss: 0.897926
T Loss: 11.583112
Epoch 449 
Overall Loss: 13.399658
Rec Loss: 12.002328
KL Loss: 1.397330
Y Loss: 0.903976
T Loss: 11.550340
Epoch 499 
Overall Loss: 13.371582
Rec Loss: 11.975834
KL Loss: 1.395748
Y Loss: 0.890457
T Loss: 11.530606
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.883718
Epoch 99
Rec Loss: 1.886999
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.015221
Epoch 99
Rec Loss: 10.011185
Epoch 149
Rec Loss: 10.016020
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.646281
Insample Error: 2.461214
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.036204
Rec Loss: 20.899701
KL Loss: 1.136502
Y Loss: 6.697604
T Loss: 12.614044
Epoch 99 
Overall Loss: 19.588211
Rec Loss: 17.602293
KL Loss: 1.985919
Y Loss: 2.554101
T Loss: 12.316159
Epoch 149 
Overall Loss: 18.771377
Rec Loss: 16.088793
KL Loss: 2.682585
Y Loss: 1.789316
T Loss: 12.159839
Epoch 199 
Overall Loss: 18.408610
Rec Loss: 15.335977
KL Loss: 3.072633
Y Loss: 1.539149
T Loss: 12.011825
Epoch 249 
Overall Loss: 18.139450
Rec Loss: 14.651543
KL Loss: 3.487907
Y Loss: 1.380611
T Loss: 11.895427
Epoch 299 
Overall Loss: 17.998485
Rec Loss: 14.201694
KL Loss: 3.796791
Y Loss: 1.258886
T Loss: 11.803858
Epoch 349 
Overall Loss: 17.865791
Rec Loss: 13.831131
KL Loss: 4.034661
Y Loss: 1.226761
T Loss: 11.724837
Epoch 399 
Overall Loss: 17.802371
Rec Loss: 13.562927
KL Loss: 4.239444
Y Loss: 1.160799
T Loss: 11.676807
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.967147
Epoch 99
Rec Loss: 1.963719
Epoch 149
Rec Loss: 1.957302
Epoch 199
Rec Loss: 1.964964
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.868434
Epoch 99
Rec Loss: 5.860391
Epoch 149
Rec Loss: 5.856086
Epoch 199
Rec Loss: 5.861029
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.774291
Insample Error 2.294278
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.646935
Rec Loss: 15.374949
KL Loss: 1.271987
Y Loss: 5.520178
T Loss: 12.614860
Epoch 99 
Overall Loss: 14.873637
Rec Loss: 13.398295
KL Loss: 1.475343
Y Loss: 1.991172
T Loss: 12.402708
Epoch 149 
Overall Loss: 14.422733
Rec Loss: 12.941892
KL Loss: 1.480841
Y Loss: 1.623215
T Loss: 12.130285
Epoch 199 
Overall Loss: 13.937299
Rec Loss: 12.467894
KL Loss: 1.469405
Y Loss: 1.396294
T Loss: 11.769747
Epoch 249 
Overall Loss: 13.696528
Rec Loss: 12.257879
KL Loss: 1.438649
Y Loss: 1.205945
T Loss: 11.654906
Epoch 299 
Overall Loss: 13.598032
Rec Loss: 12.197685
KL Loss: 1.400347
Y Loss: 1.112964
T Loss: 11.641204
Epoch 349 
Overall Loss: 13.511511
Rec Loss: 12.142587
KL Loss: 1.368924
Y Loss: 1.070002
T Loss: 11.607586
Epoch 399 
Overall Loss: 13.477586
Rec Loss: 12.124180
KL Loss: 1.353406
Y Loss: 1.036775
T Loss: 11.605793
Epoch 449 
Overall Loss: 13.441492
Rec Loss: 12.094115
KL Loss: 1.347377
Y Loss: 0.986834
T Loss: 11.600698
Epoch 499 
Overall Loss: 13.387990
Rec Loss: 12.046447
KL Loss: 1.341543
Y Loss: 0.964670
T Loss: 11.564112
Epoch 549 
Overall Loss: 13.374088
Rec Loss: 12.021041
KL Loss: 1.353047
Y Loss: 0.934356
T Loss: 11.553863
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.912514
Epoch 99
Rec Loss: 1.896336
Epoch 149
Rec Loss: 1.901862
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.005935
Epoch 99
Rec Loss: 9.997035
Epoch 149
Rec Loss: 10.003324
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.688285
Insample Error: 2.287778
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.997959
Rec Loss: 20.909654
KL Loss: 1.088305
Y Loss: 6.387759
T Loss: 12.750658
Epoch 99 
Overall Loss: 19.716480
Rec Loss: 17.806269
KL Loss: 1.910211
Y Loss: 2.460309
T Loss: 12.334617
Epoch 149 
Overall Loss: 18.703577
Rec Loss: 15.799239
KL Loss: 2.904338
Y Loss: 1.750545
T Loss: 12.114509
Epoch 199 
Overall Loss: 18.374112
Rec Loss: 15.127742
KL Loss: 3.246370
Y Loss: 1.567096
T Loss: 11.984900
Epoch 249 
Overall Loss: 18.147187
Rec Loss: 14.723583
KL Loss: 3.423604
Y Loss: 1.469155
T Loss: 11.881412
Epoch 299 
Overall Loss: 17.985543
Rec Loss: 14.312807
KL Loss: 3.672736
Y Loss: 1.346919
T Loss: 11.804955
Epoch 349 
Overall Loss: 17.878585
Rec Loss: 13.951612
KL Loss: 3.926973
Y Loss: 1.271497
T Loss: 11.729971
Epoch 399 
Overall Loss: 17.771591
Rec Loss: 13.583864
KL Loss: 4.187727
Y Loss: 1.185983
T Loss: 11.674693
Epoch 449 
Overall Loss: 17.706296
Rec Loss: 13.315650
KL Loss: 4.390645
Y Loss: 1.153695
T Loss: 11.637281
Epoch 499 
Overall Loss: 17.618407
Rec Loss: 13.101917
KL Loss: 4.516490
Y Loss: 1.105507
T Loss: 11.599569
Epoch 549 
Overall Loss: 17.587438
Rec Loss: 12.938364
KL Loss: 4.649073
Y Loss: 1.084005
T Loss: 11.579901
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.939163
Epoch 99
Rec Loss: 1.919235
Epoch 149
Rec Loss: 1.924655
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.832151
Epoch 99
Rec Loss: 5.821139
Epoch 149
Rec Loss: 5.825098
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.754357
Insample Error 2.224709
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.234763
Rec Loss: 14.926738
KL Loss: 1.308025
Y Loss: 4.729365
T Loss: 12.562056
Epoch 99 
Overall Loss: 14.698334
Rec Loss: 13.247338
KL Loss: 1.450997
Y Loss: 1.711676
T Loss: 12.391499
Epoch 149 
Overall Loss: 14.278347
Rec Loss: 12.903821
KL Loss: 1.374526
Y Loss: 1.370577
T Loss: 12.218532
Epoch 199 
Overall Loss: 13.785066
Rec Loss: 12.476878
KL Loss: 1.308188
Y Loss: 0.980032
T Loss: 11.986861
Epoch 249 
Overall Loss: 13.613318
Rec Loss: 12.276381
KL Loss: 1.336937
Y Loss: 0.881413
T Loss: 11.835674
Epoch 299 
Overall Loss: 13.519950
Rec Loss: 12.162392
KL Loss: 1.357558
Y Loss: 0.864509
T Loss: 11.730137
Epoch 349 
Overall Loss: 13.457584
Rec Loss: 12.086439
KL Loss: 1.371145
Y Loss: 0.891390
T Loss: 11.640744
Epoch 399 
Overall Loss: 13.413932
Rec Loss: 12.036722
KL Loss: 1.377210
Y Loss: 0.893121
T Loss: 11.590161
Epoch 449 
Overall Loss: 13.381859
Rec Loss: 11.998626
KL Loss: 1.383232
Y Loss: 0.912011
T Loss: 11.542621
Epoch 499 
Overall Loss: 13.381529
Rec Loss: 11.992225
KL Loss: 1.389304
Y Loss: 0.901732
T Loss: 11.541359
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.882229
Epoch 99
Rec Loss: 1.896437
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.013704
Epoch 99
Rec Loss: 10.014671
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.649307
Insample Error: 2.415560
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.885886
Rec Loss: 20.769117
KL Loss: 1.116769
Y Loss: 5.976469
T Loss: 12.819518
Epoch 99 
Overall Loss: 19.778469
Rec Loss: 17.936751
KL Loss: 1.841719
Y Loss: 2.513569
T Loss: 12.392500
Epoch 149 
Overall Loss: 18.872010
Rec Loss: 16.396243
KL Loss: 2.475767
Y Loss: 1.807195
T Loss: 12.108243
Epoch 199 
Overall Loss: 18.374535
Rec Loss: 15.272576
KL Loss: 3.101958
Y Loss: 1.576338
T Loss: 11.950175
Epoch 249 
Overall Loss: 18.206510
Rec Loss: 14.897123
KL Loss: 3.309387
Y Loss: 1.429595
T Loss: 11.862940
Epoch 299 
Overall Loss: 18.047789
Rec Loss: 14.610839
KL Loss: 3.436950
Y Loss: 1.339773
T Loss: 11.770938
Epoch 349 
Overall Loss: 17.886506
Rec Loss: 14.207527
KL Loss: 3.678979
Y Loss: 1.224398
T Loss: 11.715293
Epoch 399 
Overall Loss: 17.813542
Rec Loss: 13.919316
KL Loss: 3.894226
Y Loss: 1.135816
T Loss: 11.671781
Epoch 449 
Overall Loss: 17.710410
Rec Loss: 13.645015
KL Loss: 4.065395
Y Loss: 1.120907
T Loss: 11.630178
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.951092
Epoch 99
Rec Loss: 1.958035
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.968502
Epoch 99
Rec Loss: 5.967720
Epoch 149
Rec Loss: 5.965364
Epoch 199
Rec Loss: 5.963678
Epoch 249
Rec Loss: 5.949850
Epoch 299
Rec Loss: 5.943088
Epoch 349
Rec Loss: 5.956812
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.760129
Insample Error 2.284215
Ours, Train RMSE
0.6562, 
0.6567, 
0.6286, 
0.6413, 
0.6262, 
0.6794, 
0.6705, 
0.6463, 
0.6883, 
0.6493, 
Ours, Insample RMSE
2.5066, 
2.4850, 
2.2913, 
2.3951, 
2.3787, 
2.4328, 
2.4547, 
2.4612, 
2.2878, 
2.4156, 
CEVAE, Insample RMSE
2.3337, 
2.2708, 
2.3015, 
2.2176, 
2.3210, 
2.3589, 
2.3017, 
2.2943, 
2.2247, 
2.2842, 
Train, RMSE mean 0.6543 std 0.0194
Ours, RMSE mean 2.4109 std 0.0710, reconstruct confounder 1.8937 (0.0141) noise 10.0039 (0.0085)
CEVAE, RMSE mean 2.2908 std 0.0422, reconstruct confounder 1.9283 (0.0165) noise 5.9203 (0.1058)
Experiment Start!
Namespace(decay=0.0, l=5e-05, latdim=4, mask=0, nlayer=50, obsm=0, ycof=0.5, ylayer=50)
Y Mean 1.514292, Std 3.653528 
Observe confounder 0, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.860678
Rec Loss: 15.789945
KL Loss: 1.070733
Y Loss: 6.390849
T Loss: 12.594521
Epoch 99 
Overall Loss: 14.931929
Rec Loss: 13.494133
KL Loss: 1.437796
Y Loss: 2.150530
T Loss: 12.418868
Epoch 149 
Overall Loss: 14.348116
Rec Loss: 12.969158
KL Loss: 1.378958
Y Loss: 1.592564
T Loss: 12.172876
Epoch 199 
Overall Loss: 13.796921
Rec Loss: 12.453757
KL Loss: 1.343164
Y Loss: 1.030846
T Loss: 11.938334
Epoch 249 
Overall Loss: 13.637835
Rec Loss: 12.278586
KL Loss: 1.359250
Y Loss: 0.931967
T Loss: 11.812602
Epoch 299 
Overall Loss: 13.542425
Rec Loss: 12.174543
KL Loss: 1.367882
Y Loss: 0.917150
T Loss: 11.715969
Epoch 349 
Overall Loss: 13.477885
Rec Loss: 12.101654
KL Loss: 1.376231
Y Loss: 0.925852
T Loss: 11.638728
Epoch 399 
Overall Loss: 13.434266
Rec Loss: 12.055904
KL Loss: 1.378362
Y Loss: 0.909524
T Loss: 11.601142
Epoch 449 
Overall Loss: 13.419245
Rec Loss: 12.031426
KL Loss: 1.387820
Y Loss: 0.936650
T Loss: 11.563100
Epoch 499 
Overall Loss: 13.390133
Rec Loss: 12.003038
KL Loss: 1.387095
Y Loss: 0.933845
T Loss: 11.536115
Epoch 549 
Overall Loss: 13.353151
Rec Loss: 11.965819
KL Loss: 1.387333
Y Loss: 0.875936
T Loss: 11.527851
Epoch 599 
Overall Loss: 13.352772
Rec Loss: 11.960333
KL Loss: 1.392440
Y Loss: 0.874737
T Loss: 11.522964
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.892928
Epoch 99
Rec Loss: 1.893142
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.984417
Epoch 99
Rec Loss: 9.982343
Epoch 149
Rec Loss: 9.994878
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.647101
Insample Error: 2.389603
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.804052
Rec Loss: 20.697163
KL Loss: 1.106889
Y Loss: 6.125035
T Loss: 12.638628
Epoch 99 
Overall Loss: 19.725516
Rec Loss: 18.024858
KL Loss: 1.700659
Y Loss: 2.524715
T Loss: 12.347600
Epoch 149 
Overall Loss: 18.850763
Rec Loss: 16.323699
KL Loss: 2.527063
Y Loss: 1.898239
T Loss: 12.116435
Epoch 199 
Overall Loss: 18.393110
Rec Loss: 15.250036
KL Loss: 3.143074
Y Loss: 1.618677
T Loss: 11.983596
Epoch 249 
Overall Loss: 18.208867
Rec Loss: 14.855712
KL Loss: 3.353155
Y Loss: 1.514203
T Loss: 11.885237
Epoch 299 
Overall Loss: 17.997727
Rec Loss: 14.382507
KL Loss: 3.615220
Y Loss: 1.310374
T Loss: 11.793451
Epoch 349 
Overall Loss: 17.902935
Rec Loss: 14.108248
KL Loss: 3.794688
Y Loss: 1.248945
T Loss: 11.734862
Epoch 399 
Overall Loss: 17.794831
Rec Loss: 13.833151
KL Loss: 3.961679
Y Loss: 1.142959
T Loss: 11.680411
Epoch 449 
Overall Loss: 17.726049
Rec Loss: 13.630050
KL Loss: 4.095999
Y Loss: 1.127055
T Loss: 11.641564
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.949963
Epoch 99
Rec Loss: 1.943775
Epoch 149
Rec Loss: 1.941761
Epoch 199
Rec Loss: 1.935735
Epoch 249
Rec Loss: 1.944723
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.903092
Epoch 99
Rec Loss: 5.882572
Epoch 149
Rec Loss: 5.886315
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.755969
Insample Error 2.261994
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.282523
Rec Loss: 15.116620
KL Loss: 1.165903
Y Loss: 5.500258
T Loss: 12.366491
Epoch 99 
Overall Loss: 14.329600
Rec Loss: 12.971848
KL Loss: 1.357752
Y Loss: 1.524843
T Loss: 12.209427
Epoch 149 
Overall Loss: 14.011208
Rec Loss: 12.623191
KL Loss: 1.388017
Y Loss: 1.091998
T Loss: 12.077192
Epoch 199 
Overall Loss: 13.781602
Rec Loss: 12.375632
KL Loss: 1.405970
Y Loss: 0.952941
T Loss: 11.899161
Epoch 249 
Overall Loss: 13.610797
Rec Loss: 12.203605
KL Loss: 1.407193
Y Loss: 0.928226
T Loss: 11.739492
Epoch 299 
Overall Loss: 13.531585
Rec Loss: 12.110473
KL Loss: 1.421112
Y Loss: 0.912036
T Loss: 11.654455
Epoch 349 
Overall Loss: 13.485365
Rec Loss: 12.078537
KL Loss: 1.406828
Y Loss: 0.937690
T Loss: 11.609692
Epoch 399 
Overall Loss: 13.450881
Rec Loss: 12.036225
KL Loss: 1.414657
Y Loss: 0.932829
T Loss: 11.569810
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.934950
Epoch 99
Rec Loss: 1.931814
Epoch 149
Rec Loss: 1.920962
Epoch 199
Rec Loss: 1.917256
Epoch 249
Rec Loss: 1.933828
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.009115
Epoch 99
Rec Loss: 10.006097
Epoch 149
Rec Loss: 10.007733
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.676337
Insample Error: 2.542497
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.540928
Rec Loss: 21.645928
KL Loss: 0.895001
Y Loss: 7.811684
T Loss: 12.856881
Epoch 99 
Overall Loss: 19.718528
Rec Loss: 17.752785
KL Loss: 1.965743
Y Loss: 2.664670
T Loss: 12.332509
Epoch 149 
Overall Loss: 18.770356
Rec Loss: 16.000941
KL Loss: 2.769415
Y Loss: 1.821402
T Loss: 12.120611
Epoch 199 
Overall Loss: 18.415494
Rec Loss: 15.278012
KL Loss: 3.137481
Y Loss: 1.602365
T Loss: 12.021799
Epoch 249 
Overall Loss: 18.242702
Rec Loss: 14.892408
KL Loss: 3.350294
Y Loss: 1.480095
T Loss: 11.938228
Epoch 299 
Overall Loss: 18.090411
Rec Loss: 14.550825
KL Loss: 3.539586
Y Loss: 1.384095
T Loss: 11.851215
Epoch 349 
Overall Loss: 17.939540
Rec Loss: 14.187801
KL Loss: 3.751738
Y Loss: 1.244361
T Loss: 11.772296
Epoch 399 
Overall Loss: 17.786861
Rec Loss: 13.774623
KL Loss: 4.012238
Y Loss: 1.165092
T Loss: 11.690307
Epoch 449 
Overall Loss: 17.747995
Rec Loss: 13.521122
KL Loss: 4.226873
Y Loss: 1.131884
T Loss: 11.635421
Epoch 499 
Overall Loss: 17.661186
Rec Loss: 13.260398
KL Loss: 4.400788
Y Loss: 1.098144
T Loss: 11.602910
Epoch 549 
Overall Loss: 17.649767
Rec Loss: 13.162039
KL Loss: 4.487728
Y Loss: 1.088331
T Loss: 11.591426
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.926143
Epoch 99
Rec Loss: 1.918193
Epoch 149
Rec Loss: 1.921353
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.866462
Epoch 99
Rec Loss: 5.851458
Epoch 149
Rec Loss: 5.852355
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.728328
Insample Error 2.232155
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.854834
Rec Loss: 14.456260
KL Loss: 1.398574
Y Loss: 3.884420
T Loss: 12.514050
Epoch 99 
Overall Loss: 14.215899
Rec Loss: 12.876235
KL Loss: 1.339665
Y Loss: 1.314312
T Loss: 12.219078
Epoch 149 
Overall Loss: 13.881550
Rec Loss: 12.533528
KL Loss: 1.348022
Y Loss: 0.968752
T Loss: 12.049152
Epoch 199 
Overall Loss: 13.692371
Rec Loss: 12.336087
KL Loss: 1.356285
Y Loss: 0.907189
T Loss: 11.882493
Epoch 249 
Overall Loss: 13.584063
Rec Loss: 12.198136
KL Loss: 1.385927
Y Loss: 0.898426
T Loss: 11.748923
Epoch 299 
Overall Loss: 13.508745
Rec Loss: 12.115940
KL Loss: 1.392805
Y Loss: 0.913556
T Loss: 11.659162
Epoch 349 
Overall Loss: 13.446343
Rec Loss: 12.052100
KL Loss: 1.394244
Y Loss: 0.919852
T Loss: 11.592173
Epoch 399 
Overall Loss: 13.425080
Rec Loss: 12.022537
KL Loss: 1.402543
Y Loss: 0.905507
T Loss: 11.569784
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.905077
Epoch 99
Rec Loss: 1.908791
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.014961
Epoch 99
Rec Loss: 10.011107
Epoch 149
Rec Loss: 10.006048
Epoch 199
Rec Loss: 10.012814
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.655074
Insample Error: 2.544872
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.293119
Rec Loss: 19.942663
KL Loss: 1.350457
Y Loss: 4.741928
T Loss: 12.639099
Epoch 99 
Overall Loss: 19.408685
Rec Loss: 17.479637
KL Loss: 1.929047
Y Loss: 1.988215
T Loss: 12.345099
Epoch 149 
Overall Loss: 18.629250
Rec Loss: 16.064450
KL Loss: 2.564800
Y Loss: 1.587994
T Loss: 12.099275
Epoch 199 
Overall Loss: 18.282475
Rec Loss: 15.182658
KL Loss: 3.099817
Y Loss: 1.456860
T Loss: 11.939116
Epoch 249 
Overall Loss: 18.116588
Rec Loss: 14.800377
KL Loss: 3.316211
Y Loss: 1.324678
T Loss: 11.850373
Epoch 299 
Overall Loss: 17.975359
Rec Loss: 14.434419
KL Loss: 3.540941
Y Loss: 1.226741
T Loss: 11.758937
Epoch 349 
Overall Loss: 17.886016
Rec Loss: 14.176527
KL Loss: 3.709489
Y Loss: 1.148548
T Loss: 11.706979
Epoch 399 
Overall Loss: 17.826561
Rec Loss: 14.035645
KL Loss: 3.790916
Y Loss: 1.099064
T Loss: 11.666426
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.962681
Epoch 99
Rec Loss: 1.963297
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.129598
Epoch 99
Rec Loss: 6.114543
Epoch 149
Rec Loss: 6.115052
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.735726
Insample Error 2.197337
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.573883
Rec Loss: 15.502764
KL Loss: 1.071119
Y Loss: 6.000724
T Loss: 12.502402
Epoch 99 
Overall Loss: 14.340955
Rec Loss: 12.991544
KL Loss: 1.349410
Y Loss: 1.647065
T Loss: 12.168013
Epoch 149 
Overall Loss: 13.947106
Rec Loss: 12.565495
KL Loss: 1.381611
Y Loss: 1.078496
T Loss: 12.026247
Epoch 199 
Overall Loss: 13.751106
Rec Loss: 12.366680
KL Loss: 1.384427
Y Loss: 0.938878
T Loss: 11.897240
Epoch 249 
Overall Loss: 13.636472
Rec Loss: 12.220696
KL Loss: 1.415776
Y Loss: 0.899920
T Loss: 11.770736
Epoch 299 
Overall Loss: 13.521959
Rec Loss: 12.109556
KL Loss: 1.412403
Y Loss: 0.878416
T Loss: 11.670348
Epoch 349 
Overall Loss: 13.492977
Rec Loss: 12.068809
KL Loss: 1.424168
Y Loss: 0.899893
T Loss: 11.618863
Epoch 399 
Overall Loss: 13.449354
Rec Loss: 12.030889
KL Loss: 1.418465
Y Loss: 0.900393
T Loss: 11.580692
Epoch 449 
Overall Loss: 13.424230
Rec Loss: 12.007971
KL Loss: 1.416259
Y Loss: 0.898039
T Loss: 11.558952
Epoch 499 
Overall Loss: 13.397541
Rec Loss: 11.984506
KL Loss: 1.413035
Y Loss: 0.902736
T Loss: 11.533138
Epoch 549 
Overall Loss: 13.360897
Rec Loss: 11.956978
KL Loss: 1.403919
Y Loss: 0.877296
T Loss: 11.518331
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.890580
Epoch 99
Rec Loss: 1.886546
Epoch 149
Rec Loss: 1.892907
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.004128
Epoch 99
Rec Loss: 10.001755
Epoch 149
Rec Loss: 10.004437
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.640193
Insample Error: 2.494602
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.332581
Rec Loss: 21.339433
KL Loss: 0.993148
Y Loss: 7.477475
T Loss: 12.652624
Epoch 99 
Overall Loss: 19.719422
Rec Loss: 17.825401
KL Loss: 1.894022
Y Loss: 2.790495
T Loss: 12.213106
Epoch 149 
Overall Loss: 18.738332
Rec Loss: 16.152662
KL Loss: 2.585670
Y Loss: 1.798406
T Loss: 12.040774
Epoch 199 
Overall Loss: 18.331309
Rec Loss: 15.226777
KL Loss: 3.104532
Y Loss: 1.467597
T Loss: 11.931435
Epoch 249 
Overall Loss: 18.164498
Rec Loss: 14.896299
KL Loss: 3.268199
Y Loss: 1.379987
T Loss: 11.827673
Epoch 299 
Overall Loss: 18.015665
Rec Loss: 14.644412
KL Loss: 3.371253
Y Loss: 1.291248
T Loss: 11.758126
Epoch 349 
Overall Loss: 17.893028
Rec Loss: 14.377251
KL Loss: 3.515778
Y Loss: 1.179284
T Loss: 11.705172
Epoch 399 
Overall Loss: 17.823617
Rec Loss: 14.153289
KL Loss: 3.670328
Y Loss: 1.112857
T Loss: 11.655905
Epoch 449 
Overall Loss: 17.743723
Rec Loss: 13.923369
KL Loss: 3.820354
Y Loss: 1.059508
T Loss: 11.619669
Epoch 499 
Overall Loss: 17.689365
Rec Loss: 13.757269
KL Loss: 3.932096
Y Loss: 1.036560
T Loss: 11.602968
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.930127
Epoch 99
Rec Loss: 1.934578
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.966377
Epoch 99
Rec Loss: 5.961712
Epoch 149
Rec Loss: 5.954079
Epoch 199
Rec Loss: 5.956973
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.713655
Insample Error 2.112253
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.567940
Rec Loss: 15.378698
KL Loss: 1.189242
Y Loss: 5.585890
T Loss: 12.585753
Epoch 99 
Overall Loss: 14.756998
Rec Loss: 13.348170
KL Loss: 1.408828
Y Loss: 2.018819
T Loss: 12.338760
Epoch 149 
Overall Loss: 14.100181
Rec Loss: 12.796729
KL Loss: 1.303452
Y Loss: 1.312666
T Loss: 12.140396
Epoch 199 
Overall Loss: 13.756772
Rec Loss: 12.418002
KL Loss: 1.338769
Y Loss: 0.998111
T Loss: 11.918947
Epoch 249 
Overall Loss: 13.592004
Rec Loss: 12.223288
KL Loss: 1.368716
Y Loss: 0.929574
T Loss: 11.758501
Epoch 299 
Overall Loss: 13.494622
Rec Loss: 12.112368
KL Loss: 1.382253
Y Loss: 0.913745
T Loss: 11.655496
Epoch 349 
Overall Loss: 13.466114
Rec Loss: 12.071653
KL Loss: 1.394462
Y Loss: 0.932473
T Loss: 11.605416
Epoch 399 
Overall Loss: 13.408165
Rec Loss: 12.019715
KL Loss: 1.388450
Y Loss: 0.904735
T Loss: 11.567348
Epoch 449 
Overall Loss: 13.398204
Rec Loss: 12.005006
KL Loss: 1.393198
Y Loss: 0.929768
T Loss: 11.540122
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.901956
Epoch 99
Rec Loss: 1.899864
Epoch 149
Rec Loss: 1.895490
Epoch 199
Rec Loss: 1.896233
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.017467
Epoch 99
Rec Loss: 10.012069
Epoch 149
Rec Loss: 10.015191
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.670855
Insample Error: 2.480443
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.942371
Rec Loss: 20.781926
KL Loss: 1.160445
Y Loss: 6.313576
T Loss: 12.665179
Epoch 99 
Overall Loss: 19.801018
Rec Loss: 17.845303
KL Loss: 1.955714
Y Loss: 2.801685
T Loss: 12.361530
Epoch 149 
Overall Loss: 18.856449
Rec Loss: 16.218849
KL Loss: 2.637601
Y Loss: 1.879716
T Loss: 12.199507
Epoch 199 
Overall Loss: 18.413645
Rec Loss: 15.166138
KL Loss: 3.247507
Y Loss: 1.571288
T Loss: 12.054756
Epoch 249 
Overall Loss: 18.197478
Rec Loss: 14.783325
KL Loss: 3.414153
Y Loss: 1.439767
T Loss: 11.935565
Epoch 299 
Overall Loss: 18.022132
Rec Loss: 14.451393
KL Loss: 3.570738
Y Loss: 1.327080
T Loss: 11.830526
Epoch 349 
Overall Loss: 17.880267
Rec Loss: 14.060959
KL Loss: 3.819308
Y Loss: 1.235963
T Loss: 11.745592
Epoch 399 
Overall Loss: 17.782920
Rec Loss: 13.702724
KL Loss: 4.080195
Y Loss: 1.178639
T Loss: 11.668711
Epoch 449 
Overall Loss: 17.671304
Rec Loss: 13.345642
KL Loss: 4.325662
Y Loss: 1.089016
T Loss: 11.617831
Epoch 499 
Overall Loss: 17.571106
Rec Loss: 13.064950
KL Loss: 4.506156
Y Loss: 1.075008
T Loss: 11.588715
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.936783
Epoch 99
Rec Loss: 1.922687
Epoch 149
Rec Loss: 1.921022
Epoch 199
Rec Loss: 1.930059
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.858733
Epoch 99
Rec Loss: 5.857055
Epoch 149
Rec Loss: 5.858130
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.732758
Insample Error 2.204055
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.478136
Rec Loss: 15.306964
KL Loss: 1.171172
Y Loss: 5.571619
T Loss: 12.521154
Epoch 99 
Overall Loss: 14.362867
Rec Loss: 13.051734
KL Loss: 1.311133
Y Loss: 1.572570
T Loss: 12.265449
Epoch 149 
Overall Loss: 13.978689
Rec Loss: 12.643987
KL Loss: 1.334703
Y Loss: 1.091164
T Loss: 12.098405
Epoch 199 
Overall Loss: 13.754364
Rec Loss: 12.391669
KL Loss: 1.362694
Y Loss: 0.940526
T Loss: 11.921407
Epoch 249 
Overall Loss: 13.603758
Rec Loss: 12.214169
KL Loss: 1.389590
Y Loss: 0.908143
T Loss: 11.760097
Epoch 299 
Overall Loss: 13.514817
Rec Loss: 12.111765
KL Loss: 1.403052
Y Loss: 0.904203
T Loss: 11.659664
Epoch 349 
Overall Loss: 13.456939
Rec Loss: 12.058057
KL Loss: 1.398882
Y Loss: 0.918122
T Loss: 11.598996
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.920379
Epoch 99
Rec Loss: 1.906457
Epoch 149
Rec Loss: 1.919655
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.003353
Epoch 99
Rec Loss: 10.006844
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.658865
Insample Error: 2.458429
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.844347
Rec Loss: 20.647783
KL Loss: 1.196564
Y Loss: 5.896979
T Loss: 12.713806
Epoch 99 
Overall Loss: 19.649605
Rec Loss: 17.724752
KL Loss: 1.924853
Y Loss: 2.360029
T Loss: 12.389601
Epoch 149 
Overall Loss: 18.743845
Rec Loss: 16.122574
KL Loss: 2.621271
Y Loss: 1.729762
T Loss: 12.175305
Epoch 199 
Overall Loss: 18.296675
Rec Loss: 15.029633
KL Loss: 3.267042
Y Loss: 1.451441
T Loss: 12.000611
Epoch 249 
Overall Loss: 18.126537
Rec Loss: 14.704574
KL Loss: 3.421963
Y Loss: 1.406123
T Loss: 11.892754
Epoch 299 
Overall Loss: 17.992639
Rec Loss: 14.424486
KL Loss: 3.568153
Y Loss: 1.306262
T Loss: 11.812192
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.040863
Epoch 99
Rec Loss: 2.022212
Epoch 149
Rec Loss: 2.032746
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.023071
Epoch 99
Rec Loss: 6.016232
Epoch 149
Rec Loss: 6.011363
Epoch 199
Rec Loss: 5.998979
Epoch 249
Rec Loss: 5.997492
Epoch 299
Rec Loss: 6.019150
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.799913
Insample Error 2.168649
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.596244
Rec Loss: 15.446150
KL Loss: 1.150094
Y Loss: 5.757593
T Loss: 12.567354
Epoch 99 
Overall Loss: 14.824232
Rec Loss: 13.482816
KL Loss: 1.341417
Y Loss: 2.271840
T Loss: 12.346896
Epoch 149 
Overall Loss: 14.065475
Rec Loss: 12.751015
KL Loss: 1.314460
Y Loss: 1.303202
T Loss: 12.099414
Epoch 199 
Overall Loss: 13.781248
Rec Loss: 12.444555
KL Loss: 1.336693
Y Loss: 1.030579
T Loss: 11.929265
Epoch 249 
Overall Loss: 13.637050
Rec Loss: 12.262332
KL Loss: 1.374719
Y Loss: 0.948409
T Loss: 11.788127
Epoch 299 
Overall Loss: 13.554310
Rec Loss: 12.182767
KL Loss: 1.371543
Y Loss: 0.968828
T Loss: 11.698353
Epoch 349 
Overall Loss: 13.476435
Rec Loss: 12.096915
KL Loss: 1.379520
Y Loss: 0.928035
T Loss: 11.632898
Epoch 399 
Overall Loss: 13.433225
Rec Loss: 12.054053
KL Loss: 1.379172
Y Loss: 0.947788
T Loss: 11.580159
Epoch 449 
Overall Loss: 13.399228
Rec Loss: 12.018337
KL Loss: 1.380891
Y Loss: 0.955223
T Loss: 11.540726
Epoch 499 
Overall Loss: 13.376704
Rec Loss: 11.987943
KL Loss: 1.388761
Y Loss: 0.920273
T Loss: 11.527806
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.889359
Epoch 99
Rec Loss: 1.894536
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.004948
Epoch 99
Rec Loss: 10.003802
Epoch 149
Rec Loss: 9.986768
Epoch 199
Rec Loss: 10.000978
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.671953
Insample Error: 2.434712
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.996998
Rec Loss: 20.976521
KL Loss: 1.020478
Y Loss: 6.649121
T Loss: 12.721493
Epoch 99 
Overall Loss: 19.751459
Rec Loss: 17.938710
KL Loss: 1.812749
Y Loss: 2.593835
T Loss: 12.354443
Epoch 149 
Overall Loss: 18.725465
Rec Loss: 16.115814
KL Loss: 2.609651
Y Loss: 1.760990
T Loss: 12.127749
Epoch 199 
Overall Loss: 18.373389
Rec Loss: 15.278316
KL Loss: 3.095073
Y Loss: 1.552865
T Loss: 11.999490
Epoch 249 
Overall Loss: 18.171011
Rec Loss: 14.852260
KL Loss: 3.318751
Y Loss: 1.403366
T Loss: 11.883767
Epoch 299 
Overall Loss: 18.027487
Rec Loss: 14.560699
KL Loss: 3.466788
Y Loss: 1.307063
T Loss: 11.790191
Epoch 349 
Overall Loss: 17.937117
Rec Loss: 14.303485
KL Loss: 3.633632
Y Loss: 1.204644
T Loss: 11.724377
Epoch 399 
Overall Loss: 17.789606
Rec Loss: 13.965865
KL Loss: 3.823741
Y Loss: 1.153814
T Loss: 11.648971
Epoch 449 
Overall Loss: 17.733275
Rec Loss: 13.748643
KL Loss: 3.984631
Y Loss: 1.107006
T Loss: 11.613829
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.938233
Epoch 99
Rec Loss: 1.942672
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.019284
Epoch 99
Rec Loss: 6.000556
Epoch 149
Rec Loss: 6.016718
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.749659
Insample Error 2.236267
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.657378
Rec Loss: 15.480399
KL Loss: 1.176978
Y Loss: 5.941372
T Loss: 12.509714
Epoch 99 
Overall Loss: 14.807222
Rec Loss: 13.415420
KL Loss: 1.391802
Y Loss: 2.135065
T Loss: 12.347887
Epoch 149 
Overall Loss: 14.056562
Rec Loss: 12.742384
KL Loss: 1.314178
Y Loss: 1.251976
T Loss: 12.116396
Epoch 199 
Overall Loss: 13.752181
Rec Loss: 12.419411
KL Loss: 1.332771
Y Loss: 0.984692
T Loss: 11.927065
Epoch 249 
Overall Loss: 13.598403
Rec Loss: 12.236818
KL Loss: 1.361584
Y Loss: 0.920074
T Loss: 11.776781
Epoch 299 
Overall Loss: 13.503310
Rec Loss: 12.133305
KL Loss: 1.370005
Y Loss: 0.905468
T Loss: 11.680571
Epoch 349 
Overall Loss: 13.465063
Rec Loss: 12.082291
KL Loss: 1.382772
Y Loss: 0.924475
T Loss: 11.620054
Epoch 399 
Overall Loss: 13.439206
Rec Loss: 12.051138
KL Loss: 1.388067
Y Loss: 0.935520
T Loss: 11.583378
Epoch 449 
Overall Loss: 13.404966
Rec Loss: 12.013151
KL Loss: 1.391814
Y Loss: 0.913850
T Loss: 11.556226
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.911705
Epoch 99
Rec Loss: 1.897274
Epoch 149
Rec Loss: 1.899213
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.004454
Epoch 99
Rec Loss: 9.998723
Epoch 149
Rec Loss: 9.991292
Epoch 199
Rec Loss: 10.004318
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.672962
Insample Error: 2.476519
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.688075
Rec Loss: 20.433206
KL Loss: 1.254870
Y Loss: 5.685518
T Loss: 12.680713
Epoch 99 
Overall Loss: 19.428482
Rec Loss: 17.374955
KL Loss: 2.053527
Y Loss: 2.121438
T Loss: 12.315088
Epoch 149 
Overall Loss: 18.703420
Rec Loss: 15.983859
KL Loss: 2.719561
Y Loss: 1.705925
T Loss: 12.078457
Epoch 199 
Overall Loss: 18.361735
Rec Loss: 15.165285
KL Loss: 3.196450
Y Loss: 1.545131
T Loss: 11.965337
Epoch 249 
Overall Loss: 18.246840
Rec Loss: 14.907910
KL Loss: 3.338931
Y Loss: 1.478128
T Loss: 11.905850
Epoch 299 
Overall Loss: 18.145402
Rec Loss: 14.702705
KL Loss: 3.442697
Y Loss: 1.461652
T Loss: 11.850978
Epoch 349 
Overall Loss: 18.033008
Rec Loss: 14.436631
KL Loss: 3.596378
Y Loss: 1.346880
T Loss: 11.783742
Epoch 399 
Overall Loss: 17.965842
Rec Loss: 14.197770
KL Loss: 3.768073
Y Loss: 1.301732
T Loss: 11.736711
Epoch 449 
Overall Loss: 17.854166
Rec Loss: 13.880743
KL Loss: 3.973423
Y Loss: 1.235543
T Loss: 11.689548
Epoch 499 
Overall Loss: 17.788636
Rec Loss: 13.529344
KL Loss: 4.259292
Y Loss: 1.183860
T Loss: 11.631889
Epoch 549 
Overall Loss: 17.720377
Rec Loss: 13.285713
KL Loss: 4.434664
Y Loss: 1.166826
T Loss: 11.603556
Epoch 599 
Overall Loss: 17.672167
Rec Loss: 13.073336
KL Loss: 4.598831
Y Loss: 1.065997
T Loss: 11.589655
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.920573
Epoch 99
Rec Loss: 1.932630
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.830428
Epoch 99
Rec Loss: 5.823562
Epoch 149
Rec Loss: 5.822860
Epoch 199
Rec Loss: 5.809964
Epoch 249
Rec Loss: 5.820594
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.734148
Insample Error 2.248258
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.662505
Rec Loss: 15.494095
KL Loss: 1.168410
Y Loss: 5.900379
T Loss: 12.543905
Epoch 99 
Overall Loss: 14.844075
Rec Loss: 13.478152
KL Loss: 1.365923
Y Loss: 2.202335
T Loss: 12.376984
Epoch 149 
Overall Loss: 14.092752
Rec Loss: 12.779762
KL Loss: 1.312989
Y Loss: 1.301697
T Loss: 12.128914
Epoch 199 
Overall Loss: 13.780502
Rec Loss: 12.458335
KL Loss: 1.322167
Y Loss: 0.999674
T Loss: 11.958498
Epoch 249 
Overall Loss: 13.602064
Rec Loss: 12.253847
KL Loss: 1.348217
Y Loss: 0.896413
T Loss: 11.805641
Epoch 299 
Overall Loss: 13.533387
Rec Loss: 12.175035
KL Loss: 1.358353
Y Loss: 0.905964
T Loss: 11.722052
Epoch 349 
Overall Loss: 13.456457
Rec Loss: 12.082288
KL Loss: 1.374169
Y Loss: 0.899765
T Loss: 11.632406
Epoch 399 
Overall Loss: 13.429410
Rec Loss: 12.051006
KL Loss: 1.378404
Y Loss: 0.903495
T Loss: 11.599258
Epoch 449 
Overall Loss: 13.399764
Rec Loss: 12.009392
KL Loss: 1.390372
Y Loss: 0.895464
T Loss: 11.561659
Epoch 499 
Overall Loss: 13.371513
Rec Loss: 11.992377
KL Loss: 1.379136
Y Loss: 0.915154
T Loss: 11.534800
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.892163
Epoch 99
Rec Loss: 1.898710
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.998327
Epoch 99
Rec Loss: 10.002300
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.662673
Insample Error: 2.431894
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.962829
Rec Loss: 20.917743
KL Loss: 1.045087
Y Loss: 6.552117
T Loss: 12.667469
Epoch 99 
Overall Loss: 19.643992
Rec Loss: 17.643234
KL Loss: 2.000758
Y Loss: 2.484918
T Loss: 12.355419
Epoch 149 
Overall Loss: 18.674851
Rec Loss: 15.781395
KL Loss: 2.893455
Y Loss: 1.782904
T Loss: 12.154396
Epoch 199 
Overall Loss: 18.408628
Rec Loss: 15.165741
KL Loss: 3.242886
Y Loss: 1.583717
T Loss: 12.027042
Epoch 249 
Overall Loss: 18.228278
Rec Loss: 14.779011
KL Loss: 3.449267
Y Loss: 1.491488
T Loss: 11.941752
Epoch 299 
Overall Loss: 18.102951
Rec Loss: 14.385049
KL Loss: 3.717902
Y Loss: 1.403921
T Loss: 11.852812
Epoch 349 
Overall Loss: 17.966815
Rec Loss: 13.974661
KL Loss: 3.992154
Y Loss: 1.295623
T Loss: 11.776754
Epoch 399 
Overall Loss: 17.871077
Rec Loss: 13.651322
KL Loss: 4.219755
Y Loss: 1.241040
T Loss: 11.703009
Epoch 449 
Overall Loss: 17.809636
Rec Loss: 13.440214
KL Loss: 4.369421
Y Loss: 1.171241
T Loss: 11.657479
Epoch 499 
Overall Loss: 17.779478
Rec Loss: 13.248225
KL Loss: 4.531253
Y Loss: 1.152887
T Loss: 11.638329
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.962828
Epoch 99
Rec Loss: 1.962384
Epoch 149
Rec Loss: 1.963191
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.867060
Epoch 99
Rec Loss: 5.837749
Epoch 149
Rec Loss: 5.843893
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.778763
Insample Error 2.356534
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.867493
Rec Loss: 14.568072
KL Loss: 1.299421
Y Loss: 4.155226
T Loss: 12.490459
Epoch 99 
Overall Loss: 14.275859
Rec Loss: 12.987767
KL Loss: 1.288092
Y Loss: 1.510701
T Loss: 12.232417
Epoch 149 
Overall Loss: 13.911255
Rec Loss: 12.598143
KL Loss: 1.313112
Y Loss: 1.083671
T Loss: 12.056308
Epoch 199 
Overall Loss: 13.716414
Rec Loss: 12.360926
KL Loss: 1.355488
Y Loss: 0.975873
T Loss: 11.872989
Epoch 249 
Overall Loss: 13.605730
Rec Loss: 12.225005
KL Loss: 1.380726
Y Loss: 0.963038
T Loss: 11.743485
Epoch 299 
Overall Loss: 13.519201
Rec Loss: 12.132758
KL Loss: 1.386444
Y Loss: 0.916099
T Loss: 11.674708
Epoch 349 
Overall Loss: 13.467878
Rec Loss: 12.070891
KL Loss: 1.396986
Y Loss: 0.913149
T Loss: 11.614317
Epoch 399 
Overall Loss: 13.424643
Rec Loss: 12.036376
KL Loss: 1.388267
Y Loss: 0.927608
T Loss: 11.572572
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.908546
Epoch 99
Rec Loss: 1.899082
Epoch 149
Rec Loss: 1.894619
Epoch 199
Rec Loss: 1.897437
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.008171
Epoch 99
Rec Loss: 10.016403
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.663525
Insample Error: 2.580956
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.699190
Rec Loss: 20.511562
KL Loss: 1.187628
Y Loss: 5.879077
T Loss: 12.577121
Epoch 99 
Overall Loss: 19.624039
Rec Loss: 17.809240
KL Loss: 1.814799
Y Loss: 2.431967
T Loss: 12.281110
Epoch 149 
Overall Loss: 18.700085
Rec Loss: 16.135432
KL Loss: 2.564653
Y Loss: 1.690706
T Loss: 12.065948
Epoch 199 
Overall Loss: 18.280788
Rec Loss: 15.170752
KL Loss: 3.110036
Y Loss: 1.480775
T Loss: 11.911328
Epoch 249 
Overall Loss: 18.118693
Rec Loss: 14.740298
KL Loss: 3.378396
Y Loss: 1.354961
T Loss: 11.833395
Epoch 299 
Overall Loss: 17.984866
Rec Loss: 14.392830
KL Loss: 3.592037
Y Loss: 1.266441
T Loss: 11.752968
Epoch 349 
Overall Loss: 17.840492
Rec Loss: 14.083800
KL Loss: 3.756693
Y Loss: 1.225281
T Loss: 11.708867
Epoch 399 
Overall Loss: 17.769509
Rec Loss: 13.821136
KL Loss: 3.948373
Y Loss: 1.142750
T Loss: 11.663421
Epoch 449 
Overall Loss: 17.687645
Rec Loss: 13.611952
KL Loss: 4.075694
Y Loss: 1.110920
T Loss: 11.625355
Epoch 499 
Overall Loss: 17.676278
Rec Loss: 13.446986
KL Loss: 4.229292
Y Loss: 1.127303
T Loss: 11.590125
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.946507
Epoch 99
Rec Loss: 1.933153
Epoch 149
Rec Loss: 1.931498
Epoch 199
Rec Loss: 1.939876
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.957264
Epoch 99
Rec Loss: 5.940274
Epoch 149
Rec Loss: 5.930770
Epoch 199
Rec Loss: 5.948435
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.756554
Insample Error 2.330441
Ours, Train RMSE
0.6471, 
0.6763, 
0.6551, 
0.6402, 
0.6709, 
0.6589, 
0.6720, 
0.6730, 
0.6627, 
0.6635, 
Ours, Insample RMSE
2.3896, 
2.5425, 
2.5449, 
2.4946, 
2.4804, 
2.4584, 
2.4347, 
2.4765, 
2.4319, 
2.5810, 
CEVAE, Insample RMSE
2.2620, 
2.2322, 
2.1973, 
2.1123, 
2.2041, 
2.1686, 
2.2363, 
2.2483, 
2.3565, 
2.3304, 
Train, RMSE mean 0.6620 std 0.0112
Ours, RMSE mean 2.4835 std 0.0560, reconstruct confounder 1.8977 (0.0088) noise 9.9996 (0.0093)
CEVAE, RMSE mean 2.2348 std 0.0683, reconstruct confounder 1.9443 (0.0300) noise 5.9236 (0.0897)
Experiment Start!
Namespace(decay=0.0, l=5e-05, latdim=4, mask=0, nlayer=50, obsm=0, ycof=0.4, ylayer=50)
Y Mean 1.514292, Std 3.653528 
Observe confounder 0, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.288008
Rec Loss: 15.365215
KL Loss: 0.922793
Y Loss: 6.829239
T Loss: 12.633519
Epoch 99 
Overall Loss: 14.671455
Rec Loss: 13.380981
KL Loss: 1.290474
Y Loss: 2.475050
T Loss: 12.390962
Epoch 149 
Overall Loss: 14.067360
Rec Loss: 12.808552
KL Loss: 1.258808
Y Loss: 1.710250
T Loss: 12.124452
Epoch 199 
Overall Loss: 13.649915
Rec Loss: 12.379654
KL Loss: 1.270262
Y Loss: 1.186568
T Loss: 11.905027
Epoch 249 
Overall Loss: 13.502446
Rec Loss: 12.205179
KL Loss: 1.297267
Y Loss: 1.098442
T Loss: 11.765802
Epoch 299 
Overall Loss: 13.413361
Rec Loss: 12.102592
KL Loss: 1.310769
Y Loss: 1.079584
T Loss: 11.670759
Epoch 349 
Overall Loss: 13.353580
Rec Loss: 12.036165
KL Loss: 1.317415
Y Loss: 1.084958
T Loss: 11.602181
Epoch 399 
Overall Loss: 13.315489
Rec Loss: 11.997835
KL Loss: 1.317654
Y Loss: 1.060557
T Loss: 11.573612
Epoch 449 
Overall Loss: 13.303532
Rec Loss: 11.978976
KL Loss: 1.324556
Y Loss: 1.086927
T Loss: 11.544205
Epoch 499 
Overall Loss: 13.279080
Rec Loss: 11.958558
KL Loss: 1.320522
Y Loss: 1.082431
T Loss: 11.525586
Epoch 549 
Overall Loss: 13.245792
Rec Loss: 11.927527
KL Loss: 1.318265
Y Loss: 1.017459
T Loss: 11.520543
Epoch 599 
Overall Loss: 13.249391
Rec Loss: 11.927406
KL Loss: 1.321984
Y Loss: 1.016464
T Loss: 11.520820
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.917887
Epoch 99
Rec Loss: 1.918090
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.996445
Epoch 99
Rec Loss: 9.991943
Epoch 149
Rec Loss: 10.001403
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.712724
Insample Error: 2.409801
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.241408
Rec Loss: 20.304684
KL Loss: 0.936724
Y Loss: 6.529469
T Loss: 12.699014
Epoch 99 
Overall Loss: 19.440191
Rec Loss: 17.863712
KL Loss: 1.576478
Y Loss: 2.886885
T Loss: 12.308825
Epoch 149 
Overall Loss: 18.569888
Rec Loss: 16.079172
KL Loss: 2.490717
Y Loss: 2.180802
T Loss: 12.066528
Epoch 199 
Overall Loss: 18.212125
Rec Loss: 15.185581
KL Loss: 3.026544
Y Loss: 1.909384
T Loss: 11.932003
Epoch 249 
Overall Loss: 18.067866
Rec Loss: 14.899681
KL Loss: 3.168185
Y Loss: 1.790205
T Loss: 11.843968
Epoch 299 
Overall Loss: 17.880526
Rec Loss: 14.519912
KL Loss: 3.360614
Y Loss: 1.561172
T Loss: 11.760348
Epoch 349 
Overall Loss: 17.791474
Rec Loss: 14.256570
KL Loss: 3.534904
Y Loss: 1.480327
T Loss: 11.711466
Epoch 399 
Overall Loss: 17.690888
Rec Loss: 13.960954
KL Loss: 3.729935
Y Loss: 1.350118
T Loss: 11.658971
Epoch 449 
Overall Loss: 17.625573
Rec Loss: 13.744507
KL Loss: 3.881066
Y Loss: 1.321923
T Loss: 11.626990
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.974227
Epoch 99
Rec Loss: 1.969520
Epoch 149
Rec Loss: 1.967410
Epoch 199
Rec Loss: 1.961528
Epoch 249
Rec Loss: 1.970052
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.941381
Epoch 99
Rec Loss: 5.920443
Epoch 149
Rec Loss: 5.922774
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.843123
Insample Error 2.319790
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.800213
Rec Loss: 14.752563
KL Loss: 1.047649
Y Loss: 5.921759
T Loss: 12.383859
Epoch 99 
Overall Loss: 14.157182
Rec Loss: 12.888728
KL Loss: 1.268453
Y Loss: 1.769892
T Loss: 12.180772
Epoch 149 
Overall Loss: 13.861885
Rec Loss: 12.555302
KL Loss: 1.306582
Y Loss: 1.301775
T Loss: 12.034592
Epoch 199 
Overall Loss: 13.639898
Rec Loss: 12.303404
KL Loss: 1.336494
Y Loss: 1.152180
T Loss: 11.842532
Epoch 249 
Overall Loss: 13.478256
Rec Loss: 12.129907
KL Loss: 1.348349
Y Loss: 1.122619
T Loss: 11.680859
Epoch 299 
Overall Loss: 13.409431
Rec Loss: 12.050606
KL Loss: 1.358825
Y Loss: 1.087716
T Loss: 11.615520
Epoch 349 
Overall Loss: 13.367480
Rec Loss: 12.027137
KL Loss: 1.340342
Y Loss: 1.103251
T Loss: 11.585837
Epoch 399 
Overall Loss: 13.337023
Rec Loss: 11.990638
KL Loss: 1.346384
Y Loss: 1.091227
T Loss: 11.554148
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.954839
Epoch 99
Rec Loss: 1.951688
Epoch 149
Rec Loss: 1.940295
Epoch 199
Rec Loss: 1.935919
Epoch 249
Rec Loss: 1.954688
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.010604
Epoch 99
Rec Loss: 10.006675
Epoch 149
Rec Loss: 10.007083
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.741907
Insample Error: 2.529093
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.836424
Rec Loss: 21.081163
KL Loss: 0.755261
Y Loss: 8.140710
T Loss: 12.948389
Epoch 99 
Overall Loss: 19.460301
Rec Loss: 17.680720
KL Loss: 1.779581
Y Loss: 3.204621
T Loss: 12.299611
Epoch 149 
Overall Loss: 18.685857
Rec Loss: 16.362011
KL Loss: 2.323847
Y Loss: 2.200420
T Loss: 12.105646
Epoch 199 
Overall Loss: 18.317104
Rec Loss: 15.538128
KL Loss: 2.778977
Y Loss: 1.889887
T Loss: 11.965180
Epoch 249 
Overall Loss: 18.073200
Rec Loss: 14.873231
KL Loss: 3.199968
Y Loss: 1.711999
T Loss: 11.868235
Epoch 299 
Overall Loss: 17.880469
Rec Loss: 14.309090
KL Loss: 3.571379
Y Loss: 1.576680
T Loss: 11.779596
Epoch 349 
Overall Loss: 17.753067
Rec Loss: 13.970425
KL Loss: 3.782642
Y Loss: 1.419429
T Loss: 11.716661
Epoch 399 
Overall Loss: 17.608978
Rec Loss: 13.614603
KL Loss: 3.994375
Y Loss: 1.338128
T Loss: 11.653919
Epoch 449 
Overall Loss: 17.597279
Rec Loss: 13.403611
KL Loss: 4.193667
Y Loss: 1.309939
T Loss: 11.613131
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.972620
Epoch 99
Rec Loss: 1.973655
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.893472
Epoch 99
Rec Loss: 5.879649
Epoch 149
Rec Loss: 5.877435
Epoch 199
Rec Loss: 5.881516
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.834408
Insample Error 2.280309
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.601010
Rec Loss: 14.403751
KL Loss: 1.197259
Y Loss: 4.605880
T Loss: 12.561399
Epoch 99 
Overall Loss: 14.076112
Rec Loss: 12.820052
KL Loss: 1.256060
Y Loss: 1.547085
T Loss: 12.201218
Epoch 149 
Overall Loss: 13.745147
Rec Loss: 12.472337
KL Loss: 1.272810
Y Loss: 1.142734
T Loss: 12.015244
Epoch 199 
Overall Loss: 13.555237
Rec Loss: 12.261954
KL Loss: 1.293283
Y Loss: 1.085388
T Loss: 11.827799
Epoch 249 
Overall Loss: 13.454077
Rec Loss: 12.123133
KL Loss: 1.330944
Y Loss: 1.087561
T Loss: 11.688109
Epoch 299 
Overall Loss: 13.388282
Rec Loss: 12.053961
KL Loss: 1.334321
Y Loss: 1.093131
T Loss: 11.616709
Epoch 349 
Overall Loss: 13.329602
Rec Loss: 11.997720
KL Loss: 1.331882
Y Loss: 1.081643
T Loss: 11.565063
Epoch 399 
Overall Loss: 13.312963
Rec Loss: 11.976112
KL Loss: 1.336851
Y Loss: 1.055911
T Loss: 11.553748
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.924845
Epoch 99
Rec Loss: 1.929675
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.016585
Epoch 99
Rec Loss: 10.013472
Epoch 149
Rec Loss: 10.007394
Epoch 199
Rec Loss: 10.013837
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.718477
Insample Error: 2.542322
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 20.825173
Rec Loss: 19.666063
KL Loss: 1.159110
Y Loss: 5.176928
T Loss: 12.677509
Epoch 99 
Overall Loss: 19.145074
Rec Loss: 17.296722
KL Loss: 1.848353
Y Loss: 2.317544
T Loss: 12.292684
Epoch 149 
Overall Loss: 18.429402
Rec Loss: 15.950727
KL Loss: 2.478675
Y Loss: 1.899335
T Loss: 12.018829
Epoch 199 
Overall Loss: 18.108502
Rec Loss: 15.096765
KL Loss: 3.011737
Y Loss: 1.738963
T Loss: 11.874309
Epoch 249 
Overall Loss: 17.958290
Rec Loss: 14.742733
KL Loss: 3.215558
Y Loss: 1.574936
T Loss: 11.798147
Epoch 299 
Overall Loss: 17.823569
Rec Loss: 14.397650
KL Loss: 3.425920
Y Loss: 1.448455
T Loss: 11.715146
Epoch 349 
Overall Loss: 17.736879
Rec Loss: 14.150104
KL Loss: 3.586775
Y Loss: 1.344454
T Loss: 11.668655
Epoch 399 
Overall Loss: 17.681303
Rec Loss: 14.013875
KL Loss: 3.667427
Y Loss: 1.279335
T Loss: 11.632274
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.976164
Epoch 99
Rec Loss: 1.977976
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.136711
Epoch 99
Rec Loss: 6.121502
Epoch 149
Rec Loss: 6.122837
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.823417
Insample Error 2.185470
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.042076
Rec Loss: 15.098538
KL Loss: 0.943539
Y Loss: 6.398578
T Loss: 12.539107
Epoch 99 
Overall Loss: 14.166715
Rec Loss: 12.903924
KL Loss: 1.262791
Y Loss: 1.889173
T Loss: 12.148255
Epoch 149 
Overall Loss: 13.803845
Rec Loss: 12.499774
KL Loss: 1.304070
Y Loss: 1.259620
T Loss: 11.995927
Epoch 199 
Overall Loss: 13.616848
Rec Loss: 12.299080
KL Loss: 1.317768
Y Loss: 1.110492
T Loss: 11.854883
Epoch 249 
Overall Loss: 13.508321
Rec Loss: 12.152001
KL Loss: 1.356320
Y Loss: 1.075219
T Loss: 11.721914
Epoch 299 
Overall Loss: 13.403737
Rec Loss: 12.052584
KL Loss: 1.351154
Y Loss: 1.051289
T Loss: 11.632068
Epoch 349 
Overall Loss: 13.376768
Rec Loss: 12.017932
KL Loss: 1.358836
Y Loss: 1.066296
T Loss: 11.591414
Epoch 399 
Overall Loss: 13.332882
Rec Loss: 11.983118
KL Loss: 1.349764
Y Loss: 1.061744
T Loss: 11.558421
Epoch 449 
Overall Loss: 13.308583
Rec Loss: 11.962771
KL Loss: 1.345812
Y Loss: 1.054149
T Loss: 11.541111
Epoch 499 
Overall Loss: 13.285002
Rec Loss: 11.944523
KL Loss: 1.340479
Y Loss: 1.054888
T Loss: 11.522567
Epoch 549 
Overall Loss: 13.250488
Rec Loss: 11.921555
KL Loss: 1.328932
Y Loss: 1.021736
T Loss: 11.512861
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.916090
Epoch 99
Rec Loss: 1.911304
Epoch 149
Rec Loss: 1.917924
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.002231
Epoch 99
Rec Loss: 10.000402
Epoch 149
Rec Loss: 10.002369
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.707389
Insample Error: 2.476754
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.620737
Rec Loss: 20.762599
KL Loss: 0.858137
Y Loss: 7.764650
T Loss: 12.713762
Epoch 99 
Overall Loss: 19.407889
Rec Loss: 17.627599
KL Loss: 1.780291
Y Loss: 3.225693
T Loss: 12.160785
Epoch 149 
Overall Loss: 18.511652
Rec Loss: 16.009438
KL Loss: 2.502214
Y Loss: 2.139415
T Loss: 11.971752
Epoch 199 
Overall Loss: 18.138575
Rec Loss: 15.121342
KL Loss: 3.017233
Y Loss: 1.749082
T Loss: 11.860067
Epoch 249 
Overall Loss: 17.990607
Rec Loss: 14.824976
KL Loss: 3.165631
Y Loss: 1.630925
T Loss: 11.767155
Epoch 299 
Overall Loss: 17.858559
Rec Loss: 14.619556
KL Loss: 3.239003
Y Loss: 1.504726
T Loss: 11.709154
Epoch 349 
Overall Loss: 17.758477
Rec Loss: 14.439552
KL Loss: 3.318925
Y Loss: 1.368895
T Loss: 11.666387
Epoch 399 
Overall Loss: 17.706292
Rec Loss: 14.305831
KL Loss: 3.400462
Y Loss: 1.287957
T Loss: 11.624229
Epoch 449 
Overall Loss: 17.639127
Rec Loss: 14.146657
KL Loss: 3.492470
Y Loss: 1.222108
T Loss: 11.597276
Epoch 499 
Overall Loss: 17.591233
Rec Loss: 14.024722
KL Loss: 3.566511
Y Loss: 1.193390
T Loss: 11.587049
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.955589
Epoch 99
Rec Loss: 1.959471
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.053317
Epoch 99
Rec Loss: 6.053510
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.790831
Insample Error 2.129637
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.066672
Rec Loss: 15.061121
KL Loss: 1.005552
Y Loss: 6.083050
T Loss: 12.627900
Epoch 99 
Overall Loss: 14.561469
Rec Loss: 13.264244
KL Loss: 1.297225
Y Loss: 2.393363
T Loss: 12.306898
Epoch 149 
Overall Loss: 14.202604
Rec Loss: 12.856187
KL Loss: 1.346417
Y Loss: 1.860140
T Loss: 12.112131
Epoch 199 
Overall Loss: 13.715849
Rec Loss: 12.373122
KL Loss: 1.342727
Y Loss: 1.534218
T Loss: 11.759434
Epoch 249 
Overall Loss: 13.512767
Rec Loss: 12.181667
KL Loss: 1.331100
Y Loss: 1.272176
T Loss: 11.672797
Epoch 299 
Overall Loss: 13.431470
Rec Loss: 12.111478
KL Loss: 1.319992
Y Loss: 1.196595
T Loss: 11.632840
Epoch 349 
Overall Loss: 13.372678
Rec Loss: 12.065360
KL Loss: 1.307319
Y Loss: 1.148232
T Loss: 11.606067
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.963820
Epoch 99
Rec Loss: 1.944792
Epoch 149
Rec Loss: 1.952852
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.013086
Epoch 99
Rec Loss: 10.009813
Epoch 149
Rec Loss: 10.001785
Epoch 199
Rec Loss: 10.006624
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.748662
Insample Error: 2.266995
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.130105
Rec Loss: 20.112150
KL Loss: 1.017956
Y Loss: 6.391768
T Loss: 12.596696
Epoch 99 
Overall Loss: 19.246817
Rec Loss: 17.430023
KL Loss: 1.816794
Y Loss: 2.852925
T Loss: 12.217037
Epoch 149 
Overall Loss: 18.586766
Rec Loss: 16.334298
KL Loss: 2.252468
Y Loss: 2.112618
T Loss: 11.953538
Epoch 199 
Overall Loss: 18.280297
Rec Loss: 15.789655
KL Loss: 2.490642
Y Loss: 1.805365
T Loss: 11.856176
Epoch 249 
Overall Loss: 18.014573
Rec Loss: 14.941687
KL Loss: 3.072886
Y Loss: 1.654750
T Loss: 11.760646
Epoch 299 
Overall Loss: 17.860841
Rec Loss: 14.600002
KL Loss: 3.260838
Y Loss: 1.487242
T Loss: 11.708714
Epoch 349 
Overall Loss: 17.793747
Rec Loss: 14.434095
KL Loss: 3.359651
Y Loss: 1.404297
T Loss: 11.659592
Epoch 399 
Overall Loss: 17.734240
Rec Loss: 14.268887
KL Loss: 3.465353
Y Loss: 1.326577
T Loss: 11.625519
Epoch 449 
Overall Loss: 17.653157
Rec Loss: 14.139632
KL Loss: 3.513524
Y Loss: 1.278735
T Loss: 11.598495
Epoch 499 
Overall Loss: 17.589859
Rec Loss: 14.041149
KL Loss: 3.548710
Y Loss: 1.215711
T Loss: 11.581168
Epoch 549 
Overall Loss: 17.542547
Rec Loss: 13.944866
KL Loss: 3.597681
Y Loss: 1.174951
T Loss: 11.561625
Epoch 599 
Overall Loss: 17.525530
Rec Loss: 13.881831
KL Loss: 3.643699
Y Loss: 1.099475
T Loss: 11.551541
Epoch 649 
Overall Loss: 17.483410
Rec Loss: 13.817126
KL Loss: 3.666284
Y Loss: 1.090519
T Loss: 11.546568
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.912704
Epoch 99
Rec Loss: 1.924082
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.102551
Epoch 99
Rec Loss: 6.083650
Epoch 149
Rec Loss: 6.102798
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.757088
Insample Error 2.212015
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.007616
Rec Loss: 15.013613
KL Loss: 0.994003
Y Loss: 6.082051
T Loss: 12.580793
Epoch 99 
Overall Loss: 14.209875
Rec Loss: 12.991775
KL Loss: 1.218099
Y Loss: 1.879404
T Loss: 12.240014
Epoch 149 
Overall Loss: 13.830583
Rec Loss: 12.572423
KL Loss: 1.258159
Y Loss: 1.290447
T Loss: 12.056245
Epoch 199 
Overall Loss: 13.615439
Rec Loss: 12.317077
KL Loss: 1.298362
Y Loss: 1.118107
T Loss: 11.869834
Epoch 249 
Overall Loss: 13.474470
Rec Loss: 12.144142
KL Loss: 1.330328
Y Loss: 1.086342
T Loss: 11.709605
Epoch 299 
Overall Loss: 13.393043
Rec Loss: 12.050801
KL Loss: 1.342242
Y Loss: 1.072230
T Loss: 11.621909
Epoch 349 
Overall Loss: 13.339198
Rec Loss: 12.002730
KL Loss: 1.336468
Y Loss: 1.076084
T Loss: 11.572296
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.936891
Epoch 99
Rec Loss: 1.922611
Epoch 149
Rec Loss: 1.937400
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.004537
Epoch 99
Rec Loss: 10.005305
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.723596
Insample Error: 2.449591
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.272547
Rec Loss: 20.262390
KL Loss: 1.010157
Y Loss: 6.293503
T Loss: 12.771031
Epoch 99 
Overall Loss: 19.334038
Rec Loss: 17.456735
KL Loss: 1.877303
Y Loss: 2.675220
T Loss: 12.351087
Epoch 149 
Overall Loss: 18.527451
Rec Loss: 16.012857
KL Loss: 2.514594
Y Loss: 2.004264
T Loss: 12.103606
Epoch 199 
Overall Loss: 18.102547
Rec Loss: 14.922629
KL Loss: 3.179918
Y Loss: 1.694544
T Loss: 11.925679
Epoch 249 
Overall Loss: 17.947030
Rec Loss: 14.621240
KL Loss: 3.325790
Y Loss: 1.626605
T Loss: 11.830961
Epoch 299 
Overall Loss: 17.818906
Rec Loss: 14.347172
KL Loss: 3.471735
Y Loss: 1.494053
T Loss: 11.760840
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.045794
Epoch 99
Rec Loss: 2.027839
Epoch 149
Rec Loss: 2.035985
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.041792
Epoch 99
Rec Loss: 6.034658
Epoch 149
Rec Loss: 6.030770
Epoch 199
Rec Loss: 6.020084
Epoch 249
Rec Loss: 6.018293
Epoch 299
Rec Loss: 6.038566
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.877351
Insample Error 2.167657
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.076615
Rec Loss: 15.090643
KL Loss: 0.985973
Y Loss: 6.194711
T Loss: 12.612758
Epoch 99 
Overall Loss: 14.686102
Rec Loss: 13.451801
KL Loss: 1.234301
Y Loss: 2.711827
T Loss: 12.367070
Epoch 149 
Overall Loss: 13.942472
Rec Loss: 12.719021
KL Loss: 1.223451
Y Loss: 1.608612
T Loss: 12.075576
Epoch 199 
Overall Loss: 13.644600
Rec Loss: 12.381410
KL Loss: 1.263190
Y Loss: 1.244512
T Loss: 11.883605
Epoch 249 
Overall Loss: 13.500634
Rec Loss: 12.186828
KL Loss: 1.313805
Y Loss: 1.147049
T Loss: 11.728009
Epoch 299 
Overall Loss: 13.424210
Rec Loss: 12.108284
KL Loss: 1.315925
Y Loss: 1.155319
T Loss: 11.646157
Epoch 349 
Overall Loss: 13.352488
Rec Loss: 12.031519
KL Loss: 1.320969
Y Loss: 1.094467
T Loss: 11.593732
Epoch 399 
Overall Loss: 13.315582
Rec Loss: 11.996634
KL Loss: 1.318948
Y Loss: 1.108959
T Loss: 11.553050
Epoch 449 
Overall Loss: 13.286846
Rec Loss: 11.968874
KL Loss: 1.317973
Y Loss: 1.106912
T Loss: 11.526109
Epoch 499 
Overall Loss: 13.264823
Rec Loss: 11.941743
KL Loss: 1.323081
Y Loss: 1.061807
T Loss: 11.517020
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.914678
Epoch 99
Rec Loss: 1.919227
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.999836
Epoch 99
Rec Loss: 10.000001
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.729374
Insample Error: 2.415582
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.061931
Rec Loss: 19.994560
KL Loss: 1.067371
Y Loss: 6.132963
T Loss: 12.708550
Epoch 99 
Overall Loss: 19.160454
Rec Loss: 17.212828
KL Loss: 1.947627
Y Loss: 2.766437
T Loss: 12.301174
Epoch 149 
Overall Loss: 18.392430
Rec Loss: 15.624770
KL Loss: 2.767661
Y Loss: 2.025171
T Loss: 12.097310
Epoch 199 
Overall Loss: 18.168832
Rec Loss: 15.135336
KL Loss: 3.033496
Y Loss: 1.722337
T Loss: 11.936714
Epoch 249 
Overall Loss: 18.013025
Rec Loss: 14.872048
KL Loss: 3.140977
Y Loss: 1.596419
T Loss: 11.826306
Epoch 299 
Overall Loss: 17.888362
Rec Loss: 14.692287
KL Loss: 3.196075
Y Loss: 1.451153
T Loss: 11.761563
Epoch 349 
Overall Loss: 17.807346
Rec Loss: 14.549173
KL Loss: 3.258172
Y Loss: 1.357522
T Loss: 11.672032
Epoch 399 
Overall Loss: 17.744311
Rec Loss: 14.447893
KL Loss: 3.296418
Y Loss: 1.287344
T Loss: 11.627952
Epoch 449 
Overall Loss: 17.694551
Rec Loss: 14.362403
KL Loss: 3.332148
Y Loss: 1.282064
T Loss: 11.593665
Epoch 499 
Overall Loss: 17.604608
Rec Loss: 14.249182
KL Loss: 3.355426
Y Loss: 1.180279
T Loss: 11.578557
Epoch 549 
Overall Loss: 17.586496
Rec Loss: 14.183250
KL Loss: 3.403246
Y Loss: 1.152498
T Loss: 11.565103
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.935488
Epoch 99
Rec Loss: 1.942055
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.138831
Epoch 99
Rec Loss: 6.134654
Epoch 149
Rec Loss: 6.145484
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.776907
Insample Error 2.339712
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.133194
Rec Loss: 15.135075
KL Loss: 0.998119
Y Loss: 6.479598
T Loss: 12.543236
Epoch 99 
Overall Loss: 14.610390
Rec Loss: 13.314987
KL Loss: 1.295403
Y Loss: 2.495685
T Loss: 12.316712
Epoch 149 
Overall Loss: 14.204639
Rec Loss: 12.856786
KL Loss: 1.347853
Y Loss: 1.897178
T Loss: 12.097914
Epoch 199 
Overall Loss: 13.749444
Rec Loss: 12.431596
KL Loss: 1.317848
Y Loss: 1.535606
T Loss: 11.817353
Epoch 249 
Overall Loss: 13.535903
Rec Loss: 12.225446
KL Loss: 1.310457
Y Loss: 1.265210
T Loss: 11.719362
Epoch 299 
Overall Loss: 13.433526
Rec Loss: 12.120668
KL Loss: 1.312858
Y Loss: 1.145184
T Loss: 11.662594
Epoch 349 
Overall Loss: 13.367992
Rec Loss: 12.062657
KL Loss: 1.305335
Y Loss: 1.120392
T Loss: 11.614499
Epoch 399 
Overall Loss: 13.339829
Rec Loss: 12.028870
KL Loss: 1.310960
Y Loss: 1.124528
T Loss: 11.579058
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.926000
Epoch 99
Rec Loss: 1.929708
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.992126
Epoch 99
Rec Loss: 9.991980
Epoch 149
Rec Loss: 9.979682
Epoch 199
Rec Loss: 9.989481
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.746986
Insample Error: 2.378872
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.144462
Rec Loss: 20.125030
KL Loss: 1.019432
Y Loss: 5.972259
T Loss: 12.820980
Epoch 99 
Overall Loss: 19.351924
Rec Loss: 17.537058
KL Loss: 1.814865
Y Loss: 2.751381
T Loss: 12.340317
Epoch 149 
Overall Loss: 18.664535
Rec Loss: 16.304100
KL Loss: 2.360436
Y Loss: 2.085403
T Loss: 12.100377
Epoch 199 
Overall Loss: 18.281349
Rec Loss: 15.363233
KL Loss: 2.918115
Y Loss: 1.835434
T Loss: 11.952199
Epoch 249 
Overall Loss: 18.027027
Rec Loss: 14.695755
KL Loss: 3.331272
Y Loss: 1.647523
T Loss: 11.831775
Epoch 299 
Overall Loss: 17.819492
Rec Loss: 14.190115
KL Loss: 3.629376
Y Loss: 1.518397
T Loss: 11.739204
Epoch 349 
Overall Loss: 17.723711
Rec Loss: 13.844138
KL Loss: 3.879573
Y Loss: 1.401901
T Loss: 11.684193
Epoch 399 
Overall Loss: 17.661022
Rec Loss: 13.633115
KL Loss: 4.027906
Y Loss: 1.347367
T Loss: 11.654002
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.007620
Epoch 99
Rec Loss: 1.998893
Epoch 149
Rec Loss: 2.007801
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.980276
Epoch 99
Rec Loss: 5.963804
Epoch 149
Rec Loss: 5.979407
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.857277
Insample Error 2.342681
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.136739
Rec Loss: 15.133325
KL Loss: 1.003413
Y Loss: 6.372811
T Loss: 12.584201
Epoch 99 
Overall Loss: 14.636205
Rec Loss: 13.374671
KL Loss: 1.261534
Y Loss: 2.574716
T Loss: 12.344784
Epoch 149 
Overall Loss: 14.174010
Rec Loss: 12.853544
KL Loss: 1.320466
Y Loss: 1.809921
T Loss: 12.129575
Epoch 199 
Overall Loss: 13.716671
Rec Loss: 12.451119
KL Loss: 1.265552
Y Loss: 1.426068
T Loss: 11.880692
Epoch 249 
Overall Loss: 13.485959
Rec Loss: 12.200339
KL Loss: 1.285621
Y Loss: 1.162205
T Loss: 11.735456
Epoch 299 
Overall Loss: 13.401401
Rec Loss: 12.102666
KL Loss: 1.298735
Y Loss: 1.108140
T Loss: 11.659410
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.949734
Epoch 99
Rec Loss: 1.958816
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.989968
Epoch 99
Rec Loss: 9.992860
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.735008
Insample Error: 2.348579
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.291888
Rec Loss: 20.299883
KL Loss: 0.992004
Y Loss: 6.602883
T Loss: 12.698160
Epoch 99 
Overall Loss: 19.222034
Rec Loss: 17.220505
KL Loss: 2.001529
Y Loss: 2.782197
T Loss: 12.273726
Epoch 149 
Overall Loss: 18.398526
Rec Loss: 15.640999
KL Loss: 2.757527
Y Loss: 2.021618
T Loss: 12.031756
Epoch 199 
Overall Loss: 18.136442
Rec Loss: 15.061411
KL Loss: 3.075031
Y Loss: 1.798828
T Loss: 11.901463
Epoch 249 
Overall Loss: 17.966071
Rec Loss: 14.703358
KL Loss: 3.262713
Y Loss: 1.600952
T Loss: 11.821674
Epoch 299 
Overall Loss: 17.861435
Rec Loss: 14.447584
KL Loss: 3.413851
Y Loss: 1.532696
T Loss: 11.752675
Epoch 349 
Overall Loss: 17.722388
Rec Loss: 14.162466
KL Loss: 3.559922
Y Loss: 1.422096
T Loss: 11.681221
Epoch 399 
Overall Loss: 17.662204
Rec Loss: 13.894777
KL Loss: 3.767427
Y Loss: 1.347313
T Loss: 11.643185
Epoch 449 
Overall Loss: 17.592109
Rec Loss: 13.617162
KL Loss: 3.974948
Y Loss: 1.284816
T Loss: 11.613956
Epoch 499 
Overall Loss: 17.516081
Rec Loss: 13.371634
KL Loss: 4.144447
Y Loss: 1.271049
T Loss: 11.584988
Epoch 549 
Overall Loss: 17.508042
Rec Loss: 13.225111
KL Loss: 4.282931
Y Loss: 1.195366
T Loss: 11.585259
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.957529
Epoch 99
Rec Loss: 1.952766
Epoch 149
Rec Loss: 1.955872
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.869057
Epoch 99
Rec Loss: 5.846811
Epoch 149
Rec Loss: 5.849945
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.787070
Insample Error 2.183424
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.524122
Rec Loss: 14.399858
KL Loss: 1.124263
Y Loss: 4.700445
T Loss: 12.519681
Epoch 99 
Overall Loss: 14.088977
Rec Loss: 12.875157
KL Loss: 1.213819
Y Loss: 1.687982
T Loss: 12.199965
Epoch 149 
Overall Loss: 13.761819
Rec Loss: 12.516811
KL Loss: 1.245007
Y Loss: 1.253335
T Loss: 12.015477
Epoch 199 
Overall Loss: 13.578296
Rec Loss: 12.284341
KL Loss: 1.293954
Y Loss: 1.153736
T Loss: 11.822847
Epoch 249 
Overall Loss: 13.477326
Rec Loss: 12.156336
KL Loss: 1.320990
Y Loss: 1.139103
T Loss: 11.700694
Epoch 299 
Overall Loss: 13.394938
Rec Loss: 12.069854
KL Loss: 1.325084
Y Loss: 1.075000
T Loss: 11.639854
Epoch 349 
Overall Loss: 13.349064
Rec Loss: 12.015126
KL Loss: 1.333939
Y Loss: 1.067511
T Loss: 11.588122
Epoch 399 
Overall Loss: 13.312353
Rec Loss: 11.989014
KL Loss: 1.323339
Y Loss: 1.081839
T Loss: 11.556278
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.931139
Epoch 99
Rec Loss: 1.920813
Epoch 149
Rec Loss: 1.917070
Epoch 199
Rec Loss: 1.919989
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.005917
Epoch 99
Rec Loss: 10.014524
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.726416
Insample Error: 2.585765
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.141062
Rec Loss: 20.130536
KL Loss: 1.010526
Y Loss: 6.312371
T Loss: 12.615374
Epoch 99 
Overall Loss: 19.319209
Rec Loss: 17.639404
KL Loss: 1.679806
Y Loss: 2.782392
T Loss: 12.232197
Epoch 149 
Overall Loss: 18.538731
Rec Loss: 16.177846
KL Loss: 2.360885
Y Loss: 1.978588
T Loss: 12.012061
Epoch 199 
Overall Loss: 18.093190
Rec Loss: 15.113330
KL Loss: 2.979861
Y Loss: 1.729383
T Loss: 11.845649
Epoch 249 
Overall Loss: 17.923968
Rec Loss: 14.526022
KL Loss: 3.397947
Y Loss: 1.568323
T Loss: 11.770996
Epoch 299 
Overall Loss: 17.814917
Rec Loss: 14.218456
KL Loss: 3.596460
Y Loss: 1.458077
T Loss: 11.701657
Epoch 349 
Overall Loss: 17.688847
Rec Loss: 13.987281
KL Loss: 3.701566
Y Loss: 1.400506
T Loss: 11.668679
Epoch 399 
Overall Loss: 17.636196
Rec Loss: 13.812398
KL Loss: 3.823798
Y Loss: 1.306108
T Loss: 11.631004
Epoch 449 
Overall Loss: 17.569677
Rec Loss: 13.673213
KL Loss: 3.896464
Y Loss: 1.271416
T Loss: 11.601088
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.963197
Epoch 99
Rec Loss: 1.968661
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.065361
Epoch 99
Rec Loss: 6.051099
Epoch 149
Rec Loss: 6.044899
Epoch 199
Rec Loss: 6.048762
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.826418
Insample Error 2.321375
Ours, Train RMSE
0.7127, 
0.7419, 
0.7185, 
0.7074, 
0.7487, 
0.7236, 
0.7294, 
0.7470, 
0.7350, 
0.7264, 
Ours, Insample RMSE
2.4098, 
2.5291, 
2.5423, 
2.4768, 
2.2670, 
2.4496, 
2.4156, 
2.3789, 
2.3486, 
2.5858, 
CEVAE, Insample RMSE
2.3198, 
2.2803, 
2.1855, 
2.1296, 
2.2120, 
2.1677, 
2.3397, 
2.3427, 
2.1834, 
2.3214, 
Train, RMSE mean 0.7291 std 0.0134
Ours, RMSE mean 2.4403 std 0.0920, reconstruct confounder 1.9265 (0.0123) noise 9.9988 (0.0085)
CEVAE, RMSE mean 2.2482 std 0.0767, reconstruct confounder 1.9657 (0.0302) noise 6.0065 (0.0953)
Experiment Start!
Namespace(decay=0.0, l=5e-05, latdim=4, mask=0, nlayer=50, obsm=0, ycof=0.3, ylayer=50)
Y Mean 1.514292, Std 3.653528 
Observe confounder 0, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.652239
Rec Loss: 14.871055
KL Loss: 0.781185
Y Loss: 7.278613
T Loss: 12.687471
Epoch 99 
Overall Loss: 14.375145
Rec Loss: 13.240711
KL Loss: 1.134434
Y Loss: 2.951005
T Loss: 12.355410
Epoch 149 
Overall Loss: 13.932014
Rec Loss: 12.771112
KL Loss: 1.160902
Y Loss: 2.165471
T Loss: 12.121470
Epoch 199 
Overall Loss: 13.501395
Rec Loss: 12.316877
KL Loss: 1.184517
Y Loss: 1.526791
T Loss: 11.858840
Epoch 249 
Overall Loss: 13.351530
Rec Loss: 12.125668
KL Loss: 1.225862
Y Loss: 1.398539
T Loss: 11.706106
Epoch 299 
Overall Loss: 13.269948
Rec Loss: 12.025999
KL Loss: 1.243949
Y Loss: 1.342391
T Loss: 11.623282
Epoch 349 
Overall Loss: 13.214866
Rec Loss: 11.967805
KL Loss: 1.247061
Y Loss: 1.319197
T Loss: 11.572046
Epoch 399 
Overall Loss: 13.183246
Rec Loss: 11.938603
KL Loss: 1.244643
Y Loss: 1.275050
T Loss: 11.556088
Epoch 449 
Overall Loss: 13.174771
Rec Loss: 11.927369
KL Loss: 1.247402
Y Loss: 1.300352
T Loss: 11.537264
Epoch 499 
Overall Loss: 13.152631
Rec Loss: 11.911428
KL Loss: 1.241204
Y Loss: 1.286796
T Loss: 11.525389
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.956560
Epoch 99
Rec Loss: 1.955257
Epoch 149
Rec Loss: 1.963479
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.011328
Epoch 99
Rec Loss: 10.003740
Epoch 149
Rec Loss: 10.001016
Epoch 199
Rec Loss: 9.996516
Epoch 249
Rec Loss: 10.002971
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.797185
Insample Error: 2.438645
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 20.668229
Rec Loss: 19.840768
KL Loss: 0.827460
Y Loss: 6.984652
T Loss: 12.768526
Epoch 99 
Overall Loss: 18.996671
Rec Loss: 17.268117
KL Loss: 1.728554
Y Loss: 3.394289
T Loss: 12.183184
Epoch 149 
Overall Loss: 18.350541
Rec Loss: 16.075376
KL Loss: 2.275165
Y Loss: 2.602035
T Loss: 11.939177
Epoch 199 
Overall Loss: 17.965224
Rec Loss: 15.047397
KL Loss: 2.917827
Y Loss: 2.184903
T Loss: 11.857881
Epoch 249 
Overall Loss: 17.793891
Rec Loss: 14.651145
KL Loss: 3.142746
Y Loss: 1.996833
T Loss: 11.756391
Epoch 299 
Overall Loss: 17.653742
Rec Loss: 14.279091
KL Loss: 3.374651
Y Loss: 1.808257
T Loss: 11.703897
Epoch 349 
Overall Loss: 17.530581
Rec Loss: 13.902327
KL Loss: 3.628255
Y Loss: 1.620257
T Loss: 11.648627
Epoch 399 
Overall Loss: 17.463419
Rec Loss: 13.624171
KL Loss: 3.839248
Y Loss: 1.541998
T Loss: 11.606632
Epoch 449 
Overall Loss: 17.402886
Rec Loss: 13.390496
KL Loss: 4.012390
Y Loss: 1.488739
T Loss: 11.586373
Epoch 499 
Overall Loss: 17.381707
Rec Loss: 13.257582
KL Loss: 4.124125
Y Loss: 1.451965
T Loss: 11.567169
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.974432
Epoch 99
Rec Loss: 1.978160
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.918904
Epoch 99
Rec Loss: 5.917715
Epoch 149
Rec Loss: 5.915396
Epoch 199
Rec Loss: 5.918885
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.879872
Insample Error 2.287567
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.269789
Rec Loss: 14.351784
KL Loss: 0.918005
Y Loss: 6.448613
T Loss: 12.417200
Epoch 99 
Overall Loss: 13.952125
Rec Loss: 12.794072
KL Loss: 1.158053
Y Loss: 2.179243
T Loss: 12.140299
Epoch 149 
Overall Loss: 13.674661
Rec Loss: 12.463907
KL Loss: 1.210754
Y Loss: 1.646069
T Loss: 11.970086
Epoch 199 
Overall Loss: 13.465163
Rec Loss: 12.208684
KL Loss: 1.256479
Y Loss: 1.476502
T Loss: 11.765734
Epoch 249 
Overall Loss: 13.327032
Rec Loss: 12.053055
KL Loss: 1.273977
Y Loss: 1.408280
T Loss: 11.630571
Epoch 299 
Overall Loss: 13.268181
Rec Loss: 11.988744
KL Loss: 1.279437
Y Loss: 1.325936
T Loss: 11.590963
Epoch 349 
Overall Loss: 13.230439
Rec Loss: 11.970966
KL Loss: 1.259472
Y Loss: 1.330923
T Loss: 11.571690
Epoch 399 
Overall Loss: 13.205942
Rec Loss: 11.940463
KL Loss: 1.265479
Y Loss: 1.314049
T Loss: 11.546248
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.985580
Epoch 99
Rec Loss: 1.982571
Epoch 149
Rec Loss: 1.970599
Epoch 199
Rec Loss: 1.965253
Epoch 249
Rec Loss: 1.987022
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.007397
Epoch 99
Rec Loss: 10.003076
Epoch 149
Rec Loss: 10.001836
Epoch 199
Rec Loss: 9.996244
Epoch 249
Rec Loss: 10.006557
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.827559
Insample Error: 2.495029
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 20.664033
Rec Loss: 19.803284
KL Loss: 0.860748
Y Loss: 6.832721
T Loss: 12.830924
Epoch 99 
Overall Loss: 18.913237
Rec Loss: 17.074885
KL Loss: 1.838353
Y Loss: 2.982170
T Loss: 12.235150
Epoch 149 
Overall Loss: 18.154682
Rec Loss: 15.544984
KL Loss: 2.609698
Y Loss: 2.280473
T Loss: 11.971729
Epoch 199 
Overall Loss: 17.921081
Rec Loss: 14.936903
KL Loss: 2.984178
Y Loss: 2.100865
T Loss: 11.839046
Epoch 249 
Overall Loss: 17.809886
Rec Loss: 14.708925
KL Loss: 3.100961
Y Loss: 1.909825
T Loss: 11.766589
Epoch 299 
Overall Loss: 17.700584
Rec Loss: 14.517952
KL Loss: 3.182632
Y Loss: 1.834205
T Loss: 11.703060
Epoch 349 
Overall Loss: 17.661242
Rec Loss: 14.361141
KL Loss: 3.300101
Y Loss: 1.740859
T Loss: 11.675348
Epoch 399 
Overall Loss: 17.541808
Rec Loss: 14.077433
KL Loss: 3.464375
Y Loss: 1.612409
T Loss: 11.634537
Epoch 449 
Overall Loss: 17.509066
Rec Loss: 13.905217
KL Loss: 3.603848
Y Loss: 1.515374
T Loss: 11.612313
Epoch 499 
Overall Loss: 17.466168
Rec Loss: 13.742550
KL Loss: 3.723618
Y Loss: 1.462520
T Loss: 11.585173
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.998969
Epoch 99
Rec Loss: 2.003737
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.961217
Epoch 99
Rec Loss: 5.955144
Epoch 149
Rec Loss: 5.973283
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.895318
Insample Error 2.300003
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.248745
Rec Loss: 14.275074
KL Loss: 0.973671
Y Loss: 5.478084
T Loss: 12.631649
Epoch 99 
Overall Loss: 13.910186
Rec Loss: 12.753950
KL Loss: 1.156236
Y Loss: 1.943350
T Loss: 12.170945
Epoch 149 
Overall Loss: 13.575996
Rec Loss: 12.386261
KL Loss: 1.189735
Y Loss: 1.438513
T Loss: 11.954707
Epoch 199 
Overall Loss: 13.392685
Rec Loss: 12.166642
KL Loss: 1.226043
Y Loss: 1.390381
T Loss: 11.749528
Epoch 249 
Overall Loss: 13.309270
Rec Loss: 12.042363
KL Loss: 1.266907
Y Loss: 1.376055
T Loss: 11.629547
Epoch 299 
Overall Loss: 13.253497
Rec Loss: 11.990451
KL Loss: 1.263046
Y Loss: 1.347747
T Loss: 11.586127
Epoch 349 
Overall Loss: 13.197542
Rec Loss: 11.939429
KL Loss: 1.258113
Y Loss: 1.305274
T Loss: 11.547847
Epoch 399 
Overall Loss: 13.185657
Rec Loss: 11.924957
KL Loss: 1.260699
Y Loss: 1.263788
T Loss: 11.545821
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.954258
Epoch 99
Rec Loss: 1.960761
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.017682
Epoch 99
Rec Loss: 10.013828
Epoch 149
Rec Loss: 10.005974
Epoch 199
Rec Loss: 10.012822
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.796515
Insample Error: 2.532347
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 20.326100
Rec Loss: 19.359711
KL Loss: 0.966388
Y Loss: 5.726956
T Loss: 12.739220
Epoch 99 
Overall Loss: 18.863587
Rec Loss: 17.127597
KL Loss: 1.735991
Y Loss: 2.815778
T Loss: 12.223842
Epoch 149 
Overall Loss: 18.235356
Rec Loss: 15.928970
KL Loss: 2.306386
Y Loss: 2.374329
T Loss: 11.923814
Epoch 199 
Overall Loss: 17.908186
Rec Loss: 15.011439
KL Loss: 2.896747
Y Loss: 2.144375
T Loss: 11.805386
Epoch 249 
Overall Loss: 17.772857
Rec Loss: 14.669992
KL Loss: 3.102865
Y Loss: 1.930483
T Loss: 11.746942
Epoch 299 
Overall Loss: 17.649230
Rec Loss: 14.342349
KL Loss: 3.306882
Y Loss: 1.753841
T Loss: 11.675952
Epoch 349 
Overall Loss: 17.565927
Rec Loss: 14.084919
KL Loss: 3.481009
Y Loss: 1.609560
T Loss: 11.637122
Epoch 399 
Overall Loss: 17.515430
Rec Loss: 13.911678
KL Loss: 3.603752
Y Loss: 1.519918
T Loss: 11.608089
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.006391
Epoch 99
Rec Loss: 2.010102
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.126900
Epoch 99
Rec Loss: 6.108158
Epoch 149
Rec Loss: 6.109938
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.925807
Insample Error 2.183358
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.462621
Rec Loss: 14.654366
KL Loss: 0.808255
Y Loss: 6.862772
T Loss: 12.595534
Epoch 99 
Overall Loss: 13.967773
Rec Loss: 12.809798
KL Loss: 1.157975
Y Loss: 2.287617
T Loss: 12.123512
Epoch 149 
Overall Loss: 13.629716
Rec Loss: 12.415931
KL Loss: 1.213785
Y Loss: 1.563032
T Loss: 11.947021
Epoch 199 
Overall Loss: 13.452654
Rec Loss: 12.211526
KL Loss: 1.241128
Y Loss: 1.412123
T Loss: 11.787889
Epoch 249 
Overall Loss: 13.356973
Rec Loss: 12.071282
KL Loss: 1.285691
Y Loss: 1.372042
T Loss: 11.659669
Epoch 299 
Overall Loss: 13.265627
Rec Loss: 11.990507
KL Loss: 1.275120
Y Loss: 1.315237
T Loss: 11.595935
Epoch 349 
Overall Loss: 13.241588
Rec Loss: 11.961574
KL Loss: 1.280014
Y Loss: 1.306540
T Loss: 11.569611
Epoch 399 
Overall Loss: 13.198990
Rec Loss: 11.929925
KL Loss: 1.269065
Y Loss: 1.286418
T Loss: 11.544000
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.953902
Epoch 99
Rec Loss: 1.954602
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.003368
Epoch 99
Rec Loss: 10.005256
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.796184
Insample Error: 2.481392
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 20.757935
Rec Loss: 19.973131
KL Loss: 0.784804
Y Loss: 7.517148
T Loss: 12.727095
Epoch 99 
Overall Loss: 19.341694
Rec Loss: 18.033796
KL Loss: 1.307898
Y Loss: 4.125322
T Loss: 12.165516
Epoch 149 
Overall Loss: 18.596296
Rec Loss: 16.699927
KL Loss: 1.896370
Y Loss: 2.889979
T Loss: 11.895593
Epoch 199 
Overall Loss: 18.048950
Rec Loss: 15.513605
KL Loss: 2.535344
Y Loss: 2.348694
T Loss: 11.750876
Epoch 249 
Overall Loss: 17.823013
Rec Loss: 14.970980
KL Loss: 2.852033
Y Loss: 1.964016
T Loss: 11.692380
Epoch 299 
Overall Loss: 17.744325
Rec Loss: 14.811555
KL Loss: 2.932770
Y Loss: 1.732288
T Loss: 11.652456
Epoch 349 
Overall Loss: 17.627865
Rec Loss: 14.653099
KL Loss: 2.974767
Y Loss: 1.562380
T Loss: 11.618569
Epoch 399 
Overall Loss: 17.536368
Rec Loss: 14.535896
KL Loss: 3.000472
Y Loss: 1.445173
T Loss: 11.567438
Epoch 449 
Overall Loss: 17.496184
Rec Loss: 14.455678
KL Loss: 3.040506
Y Loss: 1.370014
T Loss: 11.565442
Epoch 499 
Overall Loss: 17.473872
Rec Loss: 14.408655
KL Loss: 3.065217
Y Loss: 1.325315
T Loss: 11.553436
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.983562
Epoch 99
Rec Loss: 1.984926
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.270172
Epoch 99
Rec Loss: 6.274905
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.858209
Insample Error 2.282780
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.514204
Rec Loss: 14.691014
KL Loss: 0.823190
Y Loss: 6.665890
T Loss: 12.691247
Epoch 99 
Overall Loss: 14.228077
Rec Loss: 13.089862
KL Loss: 1.138215
Y Loss: 2.929356
T Loss: 12.211055
Epoch 149 
Overall Loss: 13.689261
Rec Loss: 12.521024
KL Loss: 1.168237
Y Loss: 1.961731
T Loss: 11.932505
Epoch 199 
Overall Loss: 13.419117
Rec Loss: 12.188667
KL Loss: 1.230450
Y Loss: 1.569232
T Loss: 11.717898
Epoch 249 
Overall Loss: 13.311001
Rec Loss: 12.058635
KL Loss: 1.252366
Y Loss: 1.420485
T Loss: 11.632490
Epoch 299 
Overall Loss: 13.258923
Rec Loss: 11.995057
KL Loss: 1.263867
Y Loss: 1.363516
T Loss: 11.586002
Epoch 349 
Overall Loss: 13.218135
Rec Loss: 11.960321
KL Loss: 1.257815
Y Loss: 1.324286
T Loss: 11.563035
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.971346
Epoch 99
Rec Loss: 1.957028
Epoch 149
Rec Loss: 1.965169
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.012749
Epoch 99
Rec Loss: 10.009428
Epoch 149
Rec Loss: 10.001732
Epoch 199
Rec Loss: 10.006738
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.817502
Insample Error: 2.362337
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 20.512310
Rec Loss: 19.645942
KL Loss: 0.866368
Y Loss: 6.847132
T Loss: 12.644734
Epoch 99 
Overall Loss: 18.897576
Rec Loss: 17.149204
KL Loss: 1.748372
Y Loss: 3.400982
T Loss: 12.144174
Epoch 149 
Overall Loss: 18.342555
Rec Loss: 16.198004
KL Loss: 2.144552
Y Loss: 2.578238
T Loss: 11.877891
Epoch 199 
Overall Loss: 18.107541
Rec Loss: 15.781595
KL Loss: 2.325946
Y Loss: 2.199525
T Loss: 11.794335
Epoch 249 
Overall Loss: 17.877766
Rec Loss: 15.128507
KL Loss: 2.749259
Y Loss: 2.011373
T Loss: 11.712278
Epoch 299 
Overall Loss: 17.688521
Rec Loss: 14.571273
KL Loss: 3.117247
Y Loss: 1.790117
T Loss: 11.670595
Epoch 349 
Overall Loss: 17.621656
Rec Loss: 14.390037
KL Loss: 3.231618
Y Loss: 1.666683
T Loss: 11.630373
Epoch 399 
Overall Loss: 17.565824
Rec Loss: 14.219887
KL Loss: 3.345936
Y Loss: 1.558984
T Loss: 11.601827
Epoch 449 
Overall Loss: 17.495129
Rec Loss: 14.090890
KL Loss: 3.404239
Y Loss: 1.498444
T Loss: 11.581077
Epoch 499 
Overall Loss: 17.441700
Rec Loss: 13.993482
KL Loss: 3.448218
Y Loss: 1.423418
T Loss: 11.569531
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.976233
Epoch 99
Rec Loss: 1.978032
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.203106
Epoch 99
Rec Loss: 6.188197
Epoch 149
Rec Loss: 6.180342
Epoch 199
Rec Loss: 6.177043
Epoch 249
Rec Loss: 6.201489
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.881941
Insample Error 2.241503
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.473568
Rec Loss: 14.652656
KL Loss: 0.820912
Y Loss: 6.624133
T Loss: 12.665416
Epoch 99 
Overall Loss: 14.045883
Rec Loss: 12.940952
KL Loss: 1.104931
Y Loss: 2.399408
T Loss: 12.221129
Epoch 149 
Overall Loss: 13.658570
Rec Loss: 12.494188
KL Loss: 1.164382
Y Loss: 1.623582
T Loss: 12.007114
Epoch 199 
Overall Loss: 13.456596
Rec Loss: 12.240742
KL Loss: 1.215854
Y Loss: 1.417042
T Loss: 11.815629
Epoch 249 
Overall Loss: 13.330345
Rec Loss: 12.078336
KL Loss: 1.252009
Y Loss: 1.368943
T Loss: 11.667653
Epoch 299 
Overall Loss: 13.256796
Rec Loss: 11.992197
KL Loss: 1.264600
Y Loss: 1.321995
T Loss: 11.595598
Epoch 349 
Overall Loss: 13.206065
Rec Loss: 11.945954
KL Loss: 1.260112
Y Loss: 1.303539
T Loss: 11.554891
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.962860
Epoch 99
Rec Loss: 1.948475
Epoch 149
Rec Loss: 1.964863
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.004973
Epoch 99
Rec Loss: 10.003742
Epoch 149
Rec Loss: 10.005924
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.806428
Insample Error: 2.434794
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 20.484387
Rec Loss: 19.554960
KL Loss: 0.929427
Y Loss: 6.569261
T Loss: 12.682300
Epoch 99 
Overall Loss: 18.937168
Rec Loss: 17.238574
KL Loss: 1.698593
Y Loss: 3.089060
T Loss: 12.233799
Epoch 149 
Overall Loss: 18.345001
Rec Loss: 16.216325
KL Loss: 2.128676
Y Loss: 2.415055
T Loss: 11.955002
Epoch 199 
Overall Loss: 18.063341
Rec Loss: 15.674615
KL Loss: 2.388725
Y Loss: 2.099686
T Loss: 11.782890
Epoch 249 
Overall Loss: 17.847092
Rec Loss: 14.984561
KL Loss: 2.862530
Y Loss: 1.936317
T Loss: 11.709839
Epoch 299 
Overall Loss: 17.651304
Rec Loss: 14.417256
KL Loss: 3.234048
Y Loss: 1.757017
T Loss: 11.660850
Epoch 349 
Overall Loss: 17.564115
Rec Loss: 14.102271
KL Loss: 3.461844
Y Loss: 1.632773
T Loss: 11.632894
Epoch 399 
Overall Loss: 17.453120
Rec Loss: 13.817109
KL Loss: 3.636011
Y Loss: 1.510711
T Loss: 11.595877
Epoch 449 
Overall Loss: 17.421321
Rec Loss: 13.618786
KL Loss: 3.802535
Y Loss: 1.464021
T Loss: 11.575563
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.984671
Epoch 99
Rec Loss: 1.982065
Epoch 149
Rec Loss: 1.979468
Epoch 199
Rec Loss: 1.980990
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.021310
Epoch 99
Rec Loss: 6.029920
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.902759
Insample Error 2.260701
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.498462
Rec Loss: 14.676166
KL Loss: 0.822296
Y Loss: 6.681984
T Loss: 12.671571
Epoch 99 
Overall Loss: 14.365879
Rec Loss: 13.291856
KL Loss: 1.074023
Y Loss: 3.249414
T Loss: 12.317032
Epoch 149 
Overall Loss: 13.747104
Rec Loss: 12.605887
KL Loss: 1.141217
Y Loss: 1.992745
T Loss: 12.008063
Epoch 199 
Overall Loss: 13.491446
Rec Loss: 12.296057
KL Loss: 1.195390
Y Loss: 1.617944
T Loss: 11.810674
Epoch 249 
Overall Loss: 13.332711
Rec Loss: 12.095474
KL Loss: 1.237237
Y Loss: 1.458736
T Loss: 11.657853
Epoch 299 
Overall Loss: 13.271164
Rec Loss: 12.012041
KL Loss: 1.259122
Y Loss: 1.390431
T Loss: 11.594912
Epoch 349 
Overall Loss: 13.217351
Rec Loss: 11.971786
KL Loss: 1.245565
Y Loss: 1.344261
T Loss: 11.568507
Epoch 399 
Overall Loss: 13.191497
Rec Loss: 11.940405
KL Loss: 1.251092
Y Loss: 1.315427
T Loss: 11.545777
Epoch 449 
Overall Loss: 13.162557
Rec Loss: 11.914710
KL Loss: 1.247846
Y Loss: 1.288644
T Loss: 11.528117
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.957908
Epoch 99
Rec Loss: 1.955001
Epoch 149
Rec Loss: 1.945589
Epoch 199
Rec Loss: 1.959068
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.008301
Epoch 99
Rec Loss: 10.009456
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.809961
Insample Error: 2.446552
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 20.844931
Rec Loss: 20.055787
KL Loss: 0.789144
Y Loss: 7.363760
T Loss: 12.987186
Epoch 99 
Overall Loss: 18.950526
Rec Loss: 17.150192
KL Loss: 1.800334
Y Loss: 3.193681
T Loss: 12.233365
Epoch 149 
Overall Loss: 18.339614
Rec Loss: 16.121577
KL Loss: 2.218037
Y Loss: 2.376878
T Loss: 11.988055
Epoch 199 
Overall Loss: 17.954018
Rec Loss: 15.079241
KL Loss: 2.874777
Y Loss: 2.159671
T Loss: 11.827486
Epoch 249 
Overall Loss: 17.796053
Rec Loss: 14.719011
KL Loss: 3.077042
Y Loss: 1.958725
T Loss: 11.736355
Epoch 299 
Overall Loss: 17.679995
Rec Loss: 14.497096
KL Loss: 3.182899
Y Loss: 1.814410
T Loss: 11.681087
Epoch 349 
Overall Loss: 17.586182
Rec Loss: 14.233221
KL Loss: 3.352961
Y Loss: 1.657197
T Loss: 11.648485
Epoch 399 
Overall Loss: 17.488083
Rec Loss: 13.913439
KL Loss: 3.574645
Y Loss: 1.514932
T Loss: 11.605694
Epoch 449 
Overall Loss: 17.453161
Rec Loss: 13.706327
KL Loss: 3.746834
Y Loss: 1.500942
T Loss: 11.584802
Epoch 499 
Overall Loss: 17.392394
Rec Loss: 13.505825
KL Loss: 3.886569
Y Loss: 1.434135
T Loss: 11.560365
Epoch 549 
Overall Loss: 17.322802
Rec Loss: 13.360127
KL Loss: 3.962674
Y Loss: 1.372116
T Loss: 11.559804
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.977708
Epoch 99
Rec Loss: 1.963655
Epoch 149
Rec Loss: 1.979108
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.956667
Epoch 99
Rec Loss: 5.942938
Epoch 149
Rec Loss: 5.955401
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.871311
Insample Error 2.290760
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.534688
Rec Loss: 14.702625
KL Loss: 0.832063
Y Loss: 7.065841
T Loss: 12.582872
Epoch 99 
Overall Loss: 14.187300
Rec Loss: 13.065688
KL Loss: 1.121612
Y Loss: 2.897619
T Loss: 12.196402
Epoch 149 
Overall Loss: 13.688677
Rec Loss: 12.508301
KL Loss: 1.180375
Y Loss: 1.856238
T Loss: 11.951430
Epoch 199 
Overall Loss: 13.476378
Rec Loss: 12.243073
KL Loss: 1.233304
Y Loss: 1.605313
T Loss: 11.761479
Epoch 249 
Overall Loss: 13.346176
Rec Loss: 12.091861
KL Loss: 1.254315
Y Loss: 1.449158
T Loss: 11.657114
Epoch 299 
Overall Loss: 13.271936
Rec Loss: 12.003043
KL Loss: 1.268894
Y Loss: 1.322449
T Loss: 11.606308
Epoch 349 
Overall Loss: 13.225523
Rec Loss: 11.967670
KL Loss: 1.257853
Y Loss: 1.311450
T Loss: 11.574235
Epoch 399 
Overall Loss: 13.205640
Rec Loss: 11.948921
KL Loss: 1.256718
Y Loss: 1.317401
T Loss: 11.553701
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.952230
Epoch 99
Rec Loss: 1.955603
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.002660
Epoch 99
Rec Loss: 10.003068
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.815184
Insample Error: 2.459560
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 20.414595
Rec Loss: 19.543699
KL Loss: 0.870896
Y Loss: 6.257214
T Loss: 12.737476
Epoch 99 
Overall Loss: 18.946712
Rec Loss: 17.211418
KL Loss: 1.735295
Y Loss: 3.058922
T Loss: 12.277698
Epoch 149 
Overall Loss: 18.241495
Rec Loss: 15.650434
KL Loss: 2.591061
Y Loss: 2.449302
T Loss: 11.985027
Epoch 199 
Overall Loss: 17.996721
Rec Loss: 15.023187
KL Loss: 2.973534
Y Loss: 2.229164
T Loss: 11.846575
Epoch 249 
Overall Loss: 17.829045
Rec Loss: 14.704801
KL Loss: 3.124245
Y Loss: 1.976502
T Loss: 11.798916
Epoch 299 
Overall Loss: 17.724987
Rec Loss: 14.539652
KL Loss: 3.185335
Y Loss: 1.844072
T Loss: 11.744979
Epoch 349 
Overall Loss: 17.663115
Rec Loss: 14.379826
KL Loss: 3.283289
Y Loss: 1.756327
T Loss: 11.695757
Epoch 399 
Overall Loss: 17.601398
Rec Loss: 14.194509
KL Loss: 3.406889
Y Loss: 1.688404
T Loss: 11.675188
Epoch 449 
Overall Loss: 17.527103
Rec Loss: 13.906639
KL Loss: 3.620464
Y Loss: 1.585471
T Loss: 11.632448
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.024134
Epoch 99
Rec Loss: 2.027719
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.982920
Epoch 99
Rec Loss: 5.968480
Epoch 149
Rec Loss: 5.977257
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.931968
Insample Error 2.330375
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.540561
Rec Loss: 14.695514
KL Loss: 0.845048
Y Loss: 6.867470
T Loss: 12.635273
Epoch 99 
Overall Loss: 14.219151
Rec Loss: 13.106400
KL Loss: 1.112751
Y Loss: 2.947689
T Loss: 12.222094
Epoch 149 
Overall Loss: 13.609439
Rec Loss: 12.428033
KL Loss: 1.181406
Y Loss: 1.708447
T Loss: 11.915499
Epoch 199 
Overall Loss: 13.436344
Rec Loss: 12.225397
KL Loss: 1.210947
Y Loss: 1.516102
T Loss: 11.770567
Epoch 249 
Overall Loss: 13.307811
Rec Loss: 12.072418
KL Loss: 1.235393
Y Loss: 1.377013
T Loss: 11.659314
Epoch 299 
Overall Loss: 13.243862
Rec Loss: 11.996641
KL Loss: 1.247221
Y Loss: 1.316010
T Loss: 11.601838
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.962065
Epoch 99
Rec Loss: 1.972418
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.999789
Epoch 99
Rec Loss: 10.002297
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.813839
Insample Error: 2.407039
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 20.669821
Rec Loss: 19.850313
KL Loss: 0.819509
Y Loss: 7.030191
T Loss: 12.784339
Epoch 99 
Overall Loss: 18.923301
Rec Loss: 17.069436
KL Loss: 1.853865
Y Loss: 3.374195
T Loss: 12.222241
Epoch 149 
Overall Loss: 18.160834
Rec Loss: 15.506406
KL Loss: 2.654428
Y Loss: 2.486614
T Loss: 11.954836
Epoch 199 
Overall Loss: 17.928286
Rec Loss: 14.964765
KL Loss: 2.963521
Y Loss: 2.181135
T Loss: 11.841114
Epoch 249 
Overall Loss: 17.775805
Rec Loss: 14.637068
KL Loss: 3.138737
Y Loss: 1.914291
T Loss: 11.773301
Epoch 299 
Overall Loss: 17.682576
Rec Loss: 14.407956
KL Loss: 3.274620
Y Loss: 1.805355
T Loss: 11.716857
Epoch 349 
Overall Loss: 17.556273
Rec Loss: 14.145117
KL Loss: 3.411156
Y Loss: 1.660498
T Loss: 11.654879
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.039528
Epoch 99
Rec Loss: 2.036524
Epoch 149
Rec Loss: 2.036426
Epoch 199
Rec Loss: 2.041099
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.006848
Epoch 99
Rec Loss: 5.990851
Epoch 149
Rec Loss: 5.992502
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.937419
Insample Error 2.184371
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.195696
Rec Loss: 14.278888
KL Loss: 0.916809
Y Loss: 5.647589
T Loss: 12.584611
Epoch 99 
Overall Loss: 13.893842
Rec Loss: 12.769318
KL Loss: 1.124524
Y Loss: 2.025246
T Loss: 12.161745
Epoch 149 
Overall Loss: 13.591006
Rec Loss: 12.426274
KL Loss: 1.164732
Y Loss: 1.545861
T Loss: 11.962516
Epoch 199 
Overall Loss: 13.420710
Rec Loss: 12.199035
KL Loss: 1.221676
Y Loss: 1.446149
T Loss: 11.765190
Epoch 249 
Overall Loss: 13.330727
Rec Loss: 12.080672
KL Loss: 1.250054
Y Loss: 1.403847
T Loss: 11.659518
Epoch 299 
Overall Loss: 13.254482
Rec Loss: 12.000777
KL Loss: 1.253705
Y Loss: 1.302473
T Loss: 11.610035
Epoch 349 
Overall Loss: 13.214335
Rec Loss: 11.952152
KL Loss: 1.262183
Y Loss: 1.280351
T Loss: 11.568047
Epoch 399 
Overall Loss: 13.183884
Rec Loss: 11.933354
KL Loss: 1.250529
Y Loss: 1.292664
T Loss: 11.545555
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.960846
Epoch 99
Rec Loss: 1.949602
Epoch 149
Rec Loss: 1.946425
Epoch 199
Rec Loss: 1.949782
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.003621
Epoch 99
Rec Loss: 10.012128
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.799670
Insample Error: 2.568405
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 20.533815
Rec Loss: 19.685608
KL Loss: 0.848208
Y Loss: 6.737807
T Loss: 12.679894
Epoch 99 
Overall Loss: 18.992480
Rec Loss: 17.431582
KL Loss: 1.560898
Y Loss: 3.318516
T Loss: 12.171128
Epoch 149 
Overall Loss: 18.289103
Rec Loss: 16.019365
KL Loss: 2.269738
Y Loss: 2.433462
T Loss: 11.926791
Epoch 199 
Overall Loss: 17.863565
Rec Loss: 14.895160
KL Loss: 2.968405
Y Loss: 2.102401
T Loss: 11.773890
Epoch 249 
Overall Loss: 17.725208
Rec Loss: 14.421360
KL Loss: 3.303848
Y Loss: 1.879554
T Loss: 11.718219
Epoch 299 
Overall Loss: 17.627517
Rec Loss: 14.127920
KL Loss: 3.499597
Y Loss: 1.724622
T Loss: 11.660166
Epoch 349 
Overall Loss: 17.505650
Rec Loss: 13.885197
KL Loss: 3.620453
Y Loss: 1.633810
T Loss: 11.635264
Epoch 399 
Overall Loss: 17.460990
Rec Loss: 13.692394
KL Loss: 3.768595
Y Loss: 1.517851
T Loss: 11.603790
Epoch 449 
Overall Loss: 17.402048
Rec Loss: 13.532807
KL Loss: 3.869241
Y Loss: 1.470773
T Loss: 11.581963
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.991531
Epoch 99
Rec Loss: 1.996488
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.012590
Epoch 99
Rec Loss: 5.999297
Epoch 149
Rec Loss: 5.994455
Epoch 199
Rec Loss: 5.996636
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.904418
Insample Error 2.318496
Ours, Train RMSE
0.7972, 
0.8276, 
0.7965, 
0.7962, 
0.8175, 
0.8064, 
0.8100, 
0.8152, 
0.8138, 
0.7997, 
Ours, Insample RMSE
2.4386, 
2.4950, 
2.5323, 
2.4814, 
2.3623, 
2.4348, 
2.4466, 
2.4596, 
2.4070, 
2.5684, 
CEVAE, Insample RMSE
2.2876, 
2.3000, 
2.1834, 
2.2828, 
2.2415, 
2.2607, 
2.2908, 
2.3304, 
2.1844, 
2.3185, 
Train, RMSE mean 0.8080 std 0.0101
Ours, RMSE mean 2.4626 std 0.0568, reconstruct confounder 1.9540 (0.0060) noise 10.0022 (0.0036)
CEVAE, RMSE mean 2.2680 std 0.0485, reconstruct confounder 1.9935 (0.0220) noise 6.0344 (0.1087)
Experiment Start!
Namespace(decay=0.0, l=5e-05, latdim=4, mask=0, nlayer=50, obsm=0, ycof=0.6, ylayer=50)
Y Mean 1.514292, Std 3.653528 
Observe confounder 0, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.389242
Rec Loss: 16.175444
KL Loss: 1.213798
Y Loss: 6.016163
T Loss: 12.565746
Epoch 99 
Overall Loss: 15.144148
Rec Loss: 13.578556
KL Loss: 1.565592
Y Loss: 1.904935
T Loss: 12.435595
Epoch 149 
Overall Loss: 14.701543
Rec Loss: 13.172265
KL Loss: 1.529278
Y Loss: 1.495982
T Loss: 12.274676
Epoch 199 
Overall Loss: 13.991765
Rec Loss: 12.583403
KL Loss: 1.408362
Y Loss: 1.010670
T Loss: 11.977001
Epoch 249 
Overall Loss: 13.773448
Rec Loss: 12.361765
KL Loss: 1.411683
Y Loss: 0.833125
T Loss: 11.861891
Epoch 299 
Overall Loss: 13.664643
Rec Loss: 12.253420
KL Loss: 1.411224
Y Loss: 0.802993
T Loss: 11.771624
Epoch 349 
Overall Loss: 13.594333
Rec Loss: 12.174614
KL Loss: 1.419719
Y Loss: 0.805351
T Loss: 11.691404
Epoch 399 
Overall Loss: 13.544499
Rec Loss: 12.119447
KL Loss: 1.425052
Y Loss: 0.793516
T Loss: 11.643337
Epoch 449 
Overall Loss: 13.524739
Rec Loss: 12.085065
KL Loss: 1.439674
Y Loss: 0.818641
T Loss: 11.593880
Epoch 499 
Overall Loss: 13.490449
Rec Loss: 12.046487
KL Loss: 1.443962
Y Loss: 0.816802
T Loss: 11.556406
Epoch 549 
Overall Loss: 13.450554
Rec Loss: 12.002421
KL Loss: 1.448134
Y Loss: 0.764631
T Loss: 11.543642
Epoch 599 
Overall Loss: 13.447259
Rec Loss: 11.991223
KL Loss: 1.456036
Y Loss: 0.764577
T Loss: 11.532478
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.875409
Epoch 99
Rec Loss: 1.875771
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.986548
Epoch 99
Rec Loss: 9.983862
Epoch 149
Rec Loss: 9.994310
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.590872
Insample Error: 2.382533
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.340750
Rec Loss: 21.063792
KL Loss: 1.276957
Y Loss: 5.779930
T Loss: 12.598991
Epoch 99 
Overall Loss: 19.965417
Rec Loss: 18.135195
KL Loss: 1.830222
Y Loss: 2.244582
T Loss: 12.373055
Epoch 149 
Overall Loss: 19.064064
Rec Loss: 16.465775
KL Loss: 2.598289
Y Loss: 1.657570
T Loss: 12.132210
Epoch 199 
Overall Loss: 18.552387
Rec Loss: 15.318251
KL Loss: 3.234136
Y Loss: 1.391817
T Loss: 12.017102
Epoch 249 
Overall Loss: 18.355965
Rec Loss: 14.876971
KL Loss: 3.478994
Y Loss: 1.304754
T Loss: 11.927066
Epoch 299 
Overall Loss: 18.151202
Rec Loss: 14.419818
KL Loss: 3.731384
Y Loss: 1.142038
T Loss: 11.839265
Epoch 349 
Overall Loss: 18.064797
Rec Loss: 14.171507
KL Loss: 3.893290
Y Loss: 1.102517
T Loss: 11.779994
Epoch 399 
Overall Loss: 17.959054
Rec Loss: 13.904147
KL Loss: 4.054907
Y Loss: 1.005073
T Loss: 11.730954
Epoch 449 
Overall Loss: 17.881071
Rec Loss: 13.706239
KL Loss: 4.174831
Y Loss: 0.985441
T Loss: 11.691758
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.944827
Epoch 99
Rec Loss: 1.937556
Epoch 149
Rec Loss: 1.936662
Epoch 199
Rec Loss: 1.928165
Epoch 249
Rec Loss: 1.937628
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.911821
Epoch 99
Rec Loss: 5.890592
Epoch 149
Rec Loss: 5.893409
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.682018
Insample Error 2.266981
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.735902
Rec Loss: 15.449107
KL Loss: 1.286795
Y Loss: 5.152631
T Loss: 12.357528
Epoch 99 
Overall Loss: 14.486746
Rec Loss: 13.051740
KL Loss: 1.435005
Y Loss: 1.370188
T Loss: 12.229627
Epoch 149 
Overall Loss: 14.140217
Rec Loss: 12.681476
KL Loss: 1.458740
Y Loss: 0.955954
T Loss: 12.107904
Epoch 199 
Overall Loss: 13.903652
Rec Loss: 12.435013
KL Loss: 1.468639
Y Loss: 0.827284
T Loss: 11.938643
Epoch 249 
Overall Loss: 13.730187
Rec Loss: 12.267453
KL Loss: 1.462734
Y Loss: 0.803562
T Loss: 11.785316
Epoch 299 
Overall Loss: 13.643691
Rec Loss: 12.165561
KL Loss: 1.478130
Y Loss: 0.786269
T Loss: 11.693800
Epoch 349 
Overall Loss: 13.593654
Rec Loss: 12.126249
KL Loss: 1.467405
Y Loss: 0.812014
T Loss: 11.639040
Epoch 399 
Overall Loss: 13.556761
Rec Loss: 12.079945
KL Loss: 1.476816
Y Loss: 0.813422
T Loss: 11.591892
Epoch 449 
Overall Loss: 13.518168
Rec Loss: 12.053781
KL Loss: 1.464386
Y Loss: 0.818787
T Loss: 11.562509
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.897127
Epoch 99
Rec Loss: 1.891372
Epoch 149
Rec Loss: 1.896238
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.003042
Epoch 99
Rec Loss: 10.003702
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.614653
Insample Error: 2.557841
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.620015
Rec Loss: 21.248644
KL Loss: 1.371371
Y Loss: 6.313442
T Loss: 12.598811
Epoch 99 
Overall Loss: 19.828571
Rec Loss: 17.668650
KL Loss: 2.159921
Y Loss: 2.114630
T Loss: 12.381148
Epoch 149 
Overall Loss: 18.874351
Rec Loss: 15.849529
KL Loss: 3.024822
Y Loss: 1.511657
T Loss: 12.191685
Epoch 199 
Overall Loss: 18.484084
Rec Loss: 15.112629
KL Loss: 3.371454
Y Loss: 1.348204
T Loss: 12.049174
Epoch 249 
Overall Loss: 18.312177
Rec Loss: 14.692415
KL Loss: 3.619762
Y Loss: 1.286737
T Loss: 11.936712
Epoch 299 
Overall Loss: 18.164560
Rec Loss: 14.296615
KL Loss: 3.867945
Y Loss: 1.183565
T Loss: 11.858446
Epoch 349 
Overall Loss: 17.980739
Rec Loss: 13.822294
KL Loss: 4.158445
Y Loss: 1.080631
T Loss: 11.771162
Epoch 399 
Overall Loss: 17.889620
Rec Loss: 13.479983
KL Loss: 4.409637
Y Loss: 1.033622
T Loss: 11.710829
Epoch 449 
Overall Loss: 17.872059
Rec Loss: 13.306561
KL Loss: 4.565498
Y Loss: 1.028440
T Loss: 11.666164
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.926400
Epoch 99
Rec Loss: 1.925285
Epoch 149
Rec Loss: 1.932629
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.833285
Epoch 99
Rec Loss: 5.833901
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.704627
Insample Error 2.279602
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.058718
Rec Loss: 14.493042
KL Loss: 1.565676
Y Loss: 3.354022
T Loss: 12.480629
Epoch 99 
Overall Loss: 14.339679
Rec Loss: 12.928886
KL Loss: 1.410792
Y Loss: 1.165978
T Loss: 12.229299
Epoch 149 
Overall Loss: 13.996488
Rec Loss: 12.582990
KL Loss: 1.413499
Y Loss: 0.854156
T Loss: 12.070496
Epoch 199 
Overall Loss: 13.805530
Rec Loss: 12.390785
KL Loss: 1.414746
Y Loss: 0.792295
T Loss: 11.915408
Epoch 249 
Overall Loss: 13.693044
Rec Loss: 12.255280
KL Loss: 1.437763
Y Loss: 0.776175
T Loss: 11.789575
Epoch 299 
Overall Loss: 13.613617
Rec Loss: 12.170047
KL Loss: 1.443571
Y Loss: 0.786202
T Loss: 11.698325
Epoch 349 
Overall Loss: 13.550257
Rec Loss: 12.103866
KL Loss: 1.446391
Y Loss: 0.796476
T Loss: 11.625980
Epoch 399 
Overall Loss: 13.526515
Rec Loss: 12.068762
KL Loss: 1.457753
Y Loss: 0.787004
T Loss: 11.596560
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.895633
Epoch 99
Rec Loss: 1.898484
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.012557
Epoch 99
Rec Loss: 10.009743
Epoch 149
Rec Loss: 10.003503
Epoch 199
Rec Loss: 10.009538
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.598246
Insample Error: 2.541374
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.730074
Rec Loss: 20.195009
KL Loss: 1.535065
Y Loss: 4.400193
T Loss: 12.610082
Epoch 99 
Overall Loss: 19.657116
Rec Loss: 17.657534
KL Loss: 1.999581
Y Loss: 1.762103
T Loss: 12.383819
Epoch 149 
Overall Loss: 18.832992
Rec Loss: 16.238465
KL Loss: 2.594527
Y Loss: 1.380614
T Loss: 12.159132
Epoch 199 
Overall Loss: 18.440175
Rec Loss: 15.274593
KL Loss: 3.165582
Y Loss: 1.254691
T Loss: 11.997489
Epoch 249 
Overall Loss: 18.256700
Rec Loss: 14.856504
KL Loss: 3.400196
Y Loss: 1.140232
T Loss: 11.901835
Epoch 299 
Overall Loss: 18.109516
Rec Loss: 14.471038
KL Loss: 3.638477
Y Loss: 1.057195
T Loss: 11.803509
Epoch 349 
Overall Loss: 18.017216
Rec Loss: 14.197336
KL Loss: 3.819880
Y Loss: 0.995390
T Loss: 11.746227
Epoch 399 
Overall Loss: 17.959786
Rec Loss: 14.051837
KL Loss: 3.907950
Y Loss: 0.957443
T Loss: 11.702811
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.959501
Epoch 99
Rec Loss: 1.958891
Epoch 149
Rec Loss: 1.963402
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.119493
Epoch 99
Rec Loss: 6.115616
Epoch 149
Rec Loss: 6.099672
Epoch 199
Rec Loss: 6.123576
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.658159
Insample Error 2.226317
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.066778
Rec Loss: 15.876102
KL Loss: 1.190676
Y Loss: 5.665735
T Loss: 12.476661
Epoch 99 
Overall Loss: 14.502219
Rec Loss: 13.076030
KL Loss: 1.426190
Y Loss: 1.486716
T Loss: 12.184000
Epoch 149 
Overall Loss: 14.070749
Rec Loss: 12.619955
KL Loss: 1.450794
Y Loss: 0.957342
T Loss: 12.045550
Epoch 199 
Overall Loss: 13.865755
Rec Loss: 12.420582
KL Loss: 1.445174
Y Loss: 0.826208
T Loss: 11.924857
Epoch 249 
Overall Loss: 13.746542
Rec Loss: 12.277585
KL Loss: 1.468957
Y Loss: 0.786327
T Loss: 11.805788
Epoch 299 
Overall Loss: 13.624299
Rec Loss: 12.159640
KL Loss: 1.464659
Y Loss: 0.762013
T Loss: 11.702431
Epoch 349 
Overall Loss: 13.593248
Rec Loss: 12.114035
KL Loss: 1.479213
Y Loss: 0.781588
T Loss: 11.645082
Epoch 399 
Overall Loss: 13.550325
Rec Loss: 12.072958
KL Loss: 1.477367
Y Loss: 0.782173
T Loss: 11.603654
Epoch 449 
Overall Loss: 13.524981
Rec Loss: 12.047239
KL Loss: 1.477742
Y Loss: 0.780686
T Loss: 11.578827
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.883838
Epoch 99
Rec Loss: 1.898849
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.008495
Epoch 99
Rec Loss: 10.003495
Epoch 149
Rec Loss: 10.005522
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.589724
Insample Error: 2.526373
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.006629
Rec Loss: 20.577959
KL Loss: 1.428671
Y Loss: 4.999756
T Loss: 12.608352
Epoch 99 
Overall Loss: 19.895274
Rec Loss: 17.915209
KL Loss: 1.980065
Y Loss: 2.040565
T Loss: 12.453953
Epoch 149 
Overall Loss: 19.184856
Rec Loss: 16.653694
KL Loss: 2.531163
Y Loss: 1.571127
T Loss: 12.279752
Epoch 199 
Overall Loss: 18.610866
Rec Loss: 15.438065
KL Loss: 3.172801
Y Loss: 1.348420
T Loss: 12.119329
Epoch 249 
Overall Loss: 18.382204
Rec Loss: 14.992330
KL Loss: 3.389874
Y Loss: 1.287713
T Loss: 11.996623
Epoch 299 
Overall Loss: 18.235026
Rec Loss: 14.642144
KL Loss: 3.592882
Y Loss: 1.196460
T Loss: 11.890275
Epoch 349 
Overall Loss: 18.110370
Rec Loss: 14.286336
KL Loss: 3.824034
Y Loss: 1.160820
T Loss: 11.812945
Epoch 399 
Overall Loss: 17.954712
Rec Loss: 13.849572
KL Loss: 4.105140
Y Loss: 1.088967
T Loss: 11.741108
Epoch 449 
Overall Loss: 17.926119
Rec Loss: 13.566369
KL Loss: 4.359750
Y Loss: 1.046834
T Loss: 11.678122
Epoch 499 
Overall Loss: 17.841708
Rec Loss: 13.315116
KL Loss: 4.526592
Y Loss: 0.993491
T Loss: 11.635261
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.940637
Epoch 99
Rec Loss: 1.943351
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.876883
Epoch 99
Rec Loss: 5.873378
Epoch 149
Rec Loss: 5.870964
Epoch 199
Rec Loss: 5.858402
Epoch 249
Rec Loss: 5.871072
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.716452
Insample Error 2.310011
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.008404
Rec Loss: 15.633174
KL Loss: 1.375230
Y Loss: 5.130778
T Loss: 12.554707
Epoch 99 
Overall Loss: 14.939654
Rec Loss: 13.421248
KL Loss: 1.518405
Y Loss: 1.784134
T Loss: 12.350768
Epoch 149 
Overall Loss: 14.225367
Rec Loss: 12.843386
KL Loss: 1.381981
Y Loss: 1.159349
T Loss: 12.147777
Epoch 199 
Overall Loss: 13.874851
Rec Loss: 12.472059
KL Loss: 1.402792
Y Loss: 0.876582
T Loss: 11.946110
Epoch 249 
Overall Loss: 13.702279
Rec Loss: 12.278778
KL Loss: 1.423500
Y Loss: 0.810675
T Loss: 11.792373
Epoch 299 
Overall Loss: 13.601400
Rec Loss: 12.166591
KL Loss: 1.434809
Y Loss: 0.796567
T Loss: 11.688651
Epoch 349 
Overall Loss: 13.570410
Rec Loss: 12.122976
KL Loss: 1.447434
Y Loss: 0.816389
T Loss: 11.633143
Epoch 399 
Overall Loss: 13.509145
Rec Loss: 12.065549
KL Loss: 1.443596
Y Loss: 0.791743
T Loss: 11.590503
Epoch 449 
Overall Loss: 13.496942
Rec Loss: 12.046561
KL Loss: 1.450381
Y Loss: 0.815509
T Loss: 11.557256
Epoch 499 
Overall Loss: 13.462795
Rec Loss: 12.004486
KL Loss: 1.458309
Y Loss: 0.790747
T Loss: 11.530038
Epoch 549 
Overall Loss: 13.442319
Rec Loss: 11.991745
KL Loss: 1.450574
Y Loss: 0.790547
T Loss: 11.517417
Epoch 599 
Overall Loss: 13.438221
Rec Loss: 11.996101
KL Loss: 1.442120
Y Loss: 0.804136
T Loss: 11.513619
Epoch 649 
Overall Loss: 13.409367
Rec Loss: 11.964755
KL Loss: 1.444612
Y Loss: 0.768759
T Loss: 11.503500
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.856150
Epoch 99
Rec Loss: 1.857945
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.015469
Epoch 99
Rec Loss: 10.014631
Epoch 149
Rec Loss: 10.017205
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.585503
Insample Error: 2.364455
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.353879
Rec Loss: 21.064329
KL Loss: 1.289550
Y Loss: 5.627816
T Loss: 12.690899
Epoch 99 
Overall Loss: 19.996092
Rec Loss: 18.146080
KL Loss: 1.850012
Y Loss: 2.246744
T Loss: 12.377883
Epoch 149 
Overall Loss: 19.107130
Rec Loss: 16.772009
KL Loss: 2.335121
Y Loss: 1.597690
T Loss: 12.149557
Epoch 199 
Overall Loss: 18.722904
Rec Loss: 16.084844
KL Loss: 2.638060
Y Loss: 1.346304
T Loss: 11.996865
Epoch 249 
Overall Loss: 18.410118
Rec Loss: 15.361124
KL Loss: 3.048994
Y Loss: 1.202225
T Loss: 11.893435
Epoch 299 
Overall Loss: 18.192146
Rec Loss: 14.699796
KL Loss: 3.492350
Y Loss: 1.081582
T Loss: 11.809423
Epoch 349 
Overall Loss: 18.056471
Rec Loss: 14.396057
KL Loss: 3.660414
Y Loss: 1.028142
T Loss: 11.749234
Epoch 399 
Overall Loss: 17.927287
Rec Loss: 14.102414
KL Loss: 3.824873
Y Loss: 0.982442
T Loss: 11.687697
Epoch 449 
Overall Loss: 17.858567
Rec Loss: 13.915436
KL Loss: 3.943131
Y Loss: 0.934473
T Loss: 11.668118
Epoch 499 
Overall Loss: 17.803430
Rec Loss: 13.732878
KL Loss: 4.070553
Y Loss: 0.901876
T Loss: 11.620354
Epoch 549 
Overall Loss: 17.734568
Rec Loss: 13.550602
KL Loss: 4.183966
Y Loss: 0.877765
T Loss: 11.586920
Epoch 599 
Overall Loss: 17.711598
Rec Loss: 13.436245
KL Loss: 4.275352
Y Loss: 0.849588
T Loss: 11.576520
Epoch 649 
Overall Loss: 17.690460
Rec Loss: 13.325538
KL Loss: 4.364922
Y Loss: 0.830757
T Loss: 11.554650
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.874727
Epoch 99
Rec Loss: 1.870466
Epoch 149
Rec Loss: 1.870771
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.945955
Epoch 99
Rec Loss: 5.926933
Epoch 149
Rec Loss: 5.928781
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.626445
Insample Error 2.136302
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.855102
Rec Loss: 15.505608
KL Loss: 1.349493
Y Loss: 5.041795
T Loss: 12.480531
Epoch 99 
Overall Loss: 14.500756
Rec Loss: 13.113739
KL Loss: 1.387017
Y Loss: 1.369615
T Loss: 12.291970
Epoch 149 
Overall Loss: 14.115005
Rec Loss: 12.717006
KL Loss: 1.397999
Y Loss: 0.965570
T Loss: 12.137664
Epoch 199 
Overall Loss: 13.887957
Rec Loss: 12.475700
KL Loss: 1.412257
Y Loss: 0.827153
T Loss: 11.979408
Epoch 249 
Overall Loss: 13.729195
Rec Loss: 12.298958
KL Loss: 1.430237
Y Loss: 0.782524
T Loss: 11.829444
Epoch 299 
Overall Loss: 13.628718
Rec Loss: 12.183712
KL Loss: 1.445006
Y Loss: 0.776208
T Loss: 11.717988
Epoch 349 
Overall Loss: 13.564907
Rec Loss: 12.118925
KL Loss: 1.445982
Y Loss: 0.795691
T Loss: 11.641510
Epoch 399 
Overall Loss: 13.522668
Rec Loss: 12.071941
KL Loss: 1.450728
Y Loss: 0.785315
T Loss: 11.600752
Epoch 449 
Overall Loss: 13.502210
Rec Loss: 12.055919
KL Loss: 1.446292
Y Loss: 0.807125
T Loss: 11.571644
Epoch 499 
Overall Loss: 13.467315
Rec Loss: 12.013412
KL Loss: 1.453902
Y Loss: 0.798545
T Loss: 11.534286
Epoch 549 
Overall Loss: 13.449596
Rec Loss: 11.981425
KL Loss: 1.468171
Y Loss: 0.781594
T Loss: 11.512468
Epoch 599 
Overall Loss: 13.425024
Rec Loss: 11.971096
KL Loss: 1.453928
Y Loss: 0.770829
T Loss: 11.508598
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.856231
Epoch 99
Rec Loss: 1.859778
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.012169
Epoch 99
Rec Loss: 10.007520
Epoch 149
Rec Loss: 10.005659
Epoch 199
Rec Loss: 10.008389
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.584728
Insample Error: 2.343996
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.524939
Rec Loss: 21.193354
KL Loss: 1.331585
Y Loss: 6.114684
T Loss: 12.542399
Epoch 99 
Overall Loss: 19.870674
Rec Loss: 17.810375
KL Loss: 2.060299
Y Loss: 2.245043
T Loss: 12.340064
Epoch 149 
Overall Loss: 19.029355
Rec Loss: 16.471412
KL Loss: 2.557942
Y Loss: 1.575507
T Loss: 12.188468
Epoch 199 
Overall Loss: 18.527194
Rec Loss: 15.325936
KL Loss: 3.201258
Y Loss: 1.329642
T Loss: 12.043070
Epoch 249 
Overall Loss: 18.318271
Rec Loss: 14.910705
KL Loss: 3.407565
Y Loss: 1.228847
T Loss: 11.937582
Epoch 299 
Overall Loss: 18.158242
Rec Loss: 14.612430
KL Loss: 3.545812
Y Loss: 1.127611
T Loss: 11.848327
Epoch 349 
Overall Loss: 18.056285
Rec Loss: 14.305534
KL Loss: 3.750752
Y Loss: 1.088067
T Loss: 11.777002
Epoch 399 
Overall Loss: 17.911858
Rec Loss: 13.984848
KL Loss: 3.927010
Y Loss: 1.035880
T Loss: 11.707874
Epoch 449 
Overall Loss: 17.824209
Rec Loss: 13.690039
KL Loss: 4.134170
Y Loss: 1.014680
T Loss: 11.655129
Epoch 499 
Overall Loss: 17.737279
Rec Loss: 13.416788
KL Loss: 4.320491
Y Loss: 0.974038
T Loss: 11.618994
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.939775
Epoch 99
Rec Loss: 1.935653
Epoch 149
Rec Loss: 1.926141
Epoch 199
Rec Loss: 1.926696
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.904024
Epoch 99
Rec Loss: 5.894081
Epoch 149
Rec Loss: 5.889835
Epoch 199
Rec Loss: 5.887294
Epoch 249
Rec Loss: 5.885420
Epoch 299
Rec Loss: 5.894960
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.697891
Insample Error 2.307257
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.066047
Rec Loss: 15.757724
KL Loss: 1.308323
Y Loss: 5.376271
T Loss: 12.531961
Epoch 99 
Overall Loss: 14.977852
Rec Loss: 13.538796
KL Loss: 1.439056
Y Loss: 1.981029
T Loss: 12.350179
Epoch 149 
Overall Loss: 14.193317
Rec Loss: 12.807012
KL Loss: 1.386305
Y Loss: 1.134587
T Loss: 12.126260
Epoch 199 
Overall Loss: 13.902170
Rec Loss: 12.501697
KL Loss: 1.400473
Y Loss: 0.896889
T Loss: 11.963564
Epoch 249 
Overall Loss: 13.752635
Rec Loss: 12.322318
KL Loss: 1.430317
Y Loss: 0.822166
T Loss: 11.829019
Epoch 299 
Overall Loss: 13.666736
Rec Loss: 12.244633
KL Loss: 1.422103
Y Loss: 0.840737
T Loss: 11.740191
Epoch 349 
Overall Loss: 13.585899
Rec Loss: 12.155693
KL Loss: 1.430205
Y Loss: 0.805825
T Loss: 11.672198
Epoch 399 
Overall Loss: 13.538876
Rec Loss: 12.108047
KL Loss: 1.430829
Y Loss: 0.823891
T Loss: 11.613713
Epoch 449 
Overall Loss: 13.500372
Rec Loss: 12.065897
KL Loss: 1.434474
Y Loss: 0.836265
T Loss: 11.564138
Epoch 499 
Overall Loss: 13.479609
Rec Loss: 12.034869
KL Loss: 1.444741
Y Loss: 0.810005
T Loss: 11.548866
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.873858
Epoch 99
Rec Loss: 1.879636
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.007943
Epoch 99
Rec Loss: 10.006920
Epoch 149
Rec Loss: 9.993281
Epoch 199
Rec Loss: 10.005661
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.622975
Insample Error: 2.440770
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.477764
Rec Loss: 21.251249
KL Loss: 1.226515
Y Loss: 6.050843
T Loss: 12.675827
Epoch 99 
Overall Loss: 20.012325
Rec Loss: 18.074568
KL Loss: 1.937758
Y Loss: 2.252835
T Loss: 12.408025
Epoch 149 
Overall Loss: 18.903885
Rec Loss: 16.141360
KL Loss: 2.762524
Y Loss: 1.531994
T Loss: 12.193799
Epoch 199 
Overall Loss: 18.540772
Rec Loss: 15.333132
KL Loss: 3.207641
Y Loss: 1.359176
T Loss: 12.063810
Epoch 249 
Overall Loss: 18.328611
Rec Loss: 14.903838
KL Loss: 3.424773
Y Loss: 1.237299
T Loss: 11.950420
Epoch 299 
Overall Loss: 18.176011
Rec Loss: 14.593780
KL Loss: 3.582231
Y Loss: 1.162652
T Loss: 11.851326
Epoch 349 
Overall Loss: 18.067059
Rec Loss: 14.270037
KL Loss: 3.797022
Y Loss: 1.082423
T Loss: 11.778702
Epoch 399 
Overall Loss: 17.907693
Rec Loss: 13.866327
KL Loss: 4.041366
Y Loss: 1.042524
T Loss: 11.690297
Epoch 449 
Overall Loss: 17.847519
Rec Loss: 13.622082
KL Loss: 4.225436
Y Loss: 1.005648
T Loss: 11.645842
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.930207
Epoch 99
Rec Loss: 1.934649
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.954135
Epoch 99
Rec Loss: 5.937108
Epoch 149
Rec Loss: 5.951756
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.702245
Insample Error 2.247132
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.122106
Rec Loss: 15.765257
KL Loss: 1.356849
Y Loss: 5.470430
T Loss: 12.482999
Epoch 99 
Overall Loss: 14.958641
Rec Loss: 13.490630
KL Loss: 1.468012
Y Loss: 1.892131
T Loss: 12.355351
Epoch 149 
Overall Loss: 14.153360
Rec Loss: 12.770340
KL Loss: 1.383020
Y Loss: 1.071347
T Loss: 12.127531
Epoch 199 
Overall Loss: 13.863507
Rec Loss: 12.471436
KL Loss: 1.392070
Y Loss: 0.857876
T Loss: 11.956711
Epoch 249 
Overall Loss: 13.705390
Rec Loss: 12.291773
KL Loss: 1.413617
Y Loss: 0.798340
T Loss: 11.812769
Epoch 299 
Overall Loss: 13.607922
Rec Loss: 12.188716
KL Loss: 1.419205
Y Loss: 0.786915
T Loss: 11.716567
Epoch 349 
Overall Loss: 13.566136
Rec Loss: 12.132841
KL Loss: 1.433295
Y Loss: 0.805023
T Loss: 11.649827
Epoch 399 
Overall Loss: 13.539564
Rec Loss: 12.098248
KL Loss: 1.441316
Y Loss: 0.818840
T Loss: 11.606944
Epoch 449 
Overall Loss: 13.502405
Rec Loss: 12.056102
KL Loss: 1.446303
Y Loss: 0.803010
T Loss: 11.574296
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.897684
Epoch 99
Rec Loss: 1.883731
Epoch 149
Rec Loss: 1.884823
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.006417
Epoch 99
Rec Loss: 10.001315
Epoch 149
Rec Loss: 9.993909
Epoch 199
Rec Loss: 10.007042
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.622951
Insample Error: 2.481984
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.153595
Rec Loss: 20.687900
KL Loss: 1.465694
Y Loss: 5.217275
T Loss: 12.636536
Epoch 99 
Overall Loss: 19.666775
Rec Loss: 17.520344
KL Loss: 2.146431
Y Loss: 1.880854
T Loss: 12.348039
Epoch 149 
Overall Loss: 18.884954
Rec Loss: 16.073260
KL Loss: 2.811694
Y Loss: 1.508764
T Loss: 12.121011
Epoch 199 
Overall Loss: 18.524465
Rec Loss: 15.238545
KL Loss: 3.285920
Y Loss: 1.360072
T Loss: 12.011638
Epoch 249 
Overall Loss: 18.403409
Rec Loss: 14.979240
KL Loss: 3.424169
Y Loss: 1.304239
T Loss: 11.951884
Epoch 299 
Overall Loss: 18.307663
Rec Loss: 14.795351
KL Loss: 3.512312
Y Loss: 1.299592
T Loss: 11.896947
Epoch 349 
Overall Loss: 18.186648
Rec Loss: 14.531402
KL Loss: 3.655246
Y Loss: 1.203256
T Loss: 11.832702
Epoch 399 
Overall Loss: 18.070240
Rec Loss: 14.140165
KL Loss: 3.930075
Y Loss: 1.149170
T Loss: 11.774058
Epoch 449 
Overall Loss: 17.915335
Rec Loss: 13.618998
KL Loss: 4.296337
Y Loss: 1.071827
T Loss: 11.712506
Epoch 499 
Overall Loss: 17.850735
Rec Loss: 13.280102
KL Loss: 4.570633
Y Loss: 1.029407
T Loss: 11.652943
Epoch 549 
Overall Loss: 17.784252
Rec Loss: 13.073709
KL Loss: 4.710543
Y Loss: 1.021567
T Loss: 11.620042
Epoch 599 
Overall Loss: 17.725639
Rec Loss: 12.860084
KL Loss: 4.865554
Y Loss: 0.935350
T Loss: 11.600964
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.899236
Epoch 99
Rec Loss: 1.910105
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.804314
Epoch 99
Rec Loss: 5.793018
Epoch 149
Rec Loss: 5.788737
Epoch 199
Rec Loss: 5.784302
Epoch 249
Rec Loss: 5.793312
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.672433
Insample Error 2.231962
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.130232
Rec Loss: 15.799033
KL Loss: 1.331198
Y Loss: 5.478767
T Loss: 12.511773
Epoch 99 
Overall Loss: 15.020493
Rec Loss: 13.558798
KL Loss: 1.461695
Y Loss: 1.955807
T Loss: 12.385313
Epoch 149 
Overall Loss: 14.191023
Rec Loss: 12.801998
KL Loss: 1.389025
Y Loss: 1.111152
T Loss: 12.135307
Epoch 199 
Overall Loss: 13.885013
Rec Loss: 12.496609
KL Loss: 1.388404
Y Loss: 0.870517
T Loss: 11.974298
Epoch 249 
Overall Loss: 13.706395
Rec Loss: 12.301460
KL Loss: 1.404935
Y Loss: 0.783807
T Loss: 11.831176
Epoch 299 
Overall Loss: 13.639438
Rec Loss: 12.228369
KL Loss: 1.411069
Y Loss: 0.791793
T Loss: 11.753292
Epoch 349 
Overall Loss: 13.560373
Rec Loss: 12.134198
KL Loss: 1.426174
Y Loss: 0.781815
T Loss: 11.665109
Epoch 399 
Overall Loss: 13.533584
Rec Loss: 12.101599
KL Loss: 1.431985
Y Loss: 0.785428
T Loss: 11.630342
Epoch 449 
Overall Loss: 13.501979
Rec Loss: 12.056830
KL Loss: 1.445150
Y Loss: 0.778398
T Loss: 11.589791
Epoch 499 
Overall Loss: 13.471417
Rec Loss: 12.034547
KL Loss: 1.436870
Y Loss: 0.796827
T Loss: 11.556451
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.880639
Epoch 99
Rec Loss: 1.887539
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.998851
Epoch 99
Rec Loss: 10.002070
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.605691
Insample Error: 2.441356
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.538671
Rec Loss: 21.323987
KL Loss: 1.214683
Y Loss: 6.194081
T Loss: 12.627745
Epoch 99 
Overall Loss: 19.889674
Rec Loss: 17.766065
KL Loss: 2.123608
Y Loss: 2.176602
T Loss: 12.397213
Epoch 149 
Overall Loss: 18.852160
Rec Loss: 15.851097
KL Loss: 3.001063
Y Loss: 1.539247
T Loss: 12.210882
Epoch 199 
Overall Loss: 18.559850
Rec Loss: 15.212407
KL Loss: 3.347443
Y Loss: 1.369277
T Loss: 12.079486
Epoch 249 
Overall Loss: 18.363047
Rec Loss: 14.783599
KL Loss: 3.579447
Y Loss: 1.288031
T Loss: 11.985384
Epoch 299 
Overall Loss: 18.229912
Rec Loss: 14.356571
KL Loss: 3.873341
Y Loss: 1.213834
T Loss: 11.892307
Epoch 349 
Overall Loss: 18.091769
Rec Loss: 13.946979
KL Loss: 4.144790
Y Loss: 1.127768
T Loss: 11.811363
Epoch 399 
Overall Loss: 17.996926
Rec Loss: 13.639508
KL Loss: 4.357418
Y Loss: 1.086826
T Loss: 11.734887
Epoch 449 
Overall Loss: 17.930288
Rec Loss: 13.434291
KL Loss: 4.495998
Y Loss: 1.029010
T Loss: 11.688643
Epoch 499 
Overall Loss: 17.893894
Rec Loss: 13.243218
KL Loss: 4.650675
Y Loss: 1.013165
T Loss: 11.662708
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.947555
Epoch 99
Rec Loss: 1.949889
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.862961
Epoch 99
Rec Loss: 5.844183
Epoch 149
Rec Loss: 5.824071
Epoch 199
Rec Loss: 5.831865
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.718195
Insample Error 2.354333
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.200780
Rec Loss: 14.736242
KL Loss: 1.464537
Y Loss: 3.775113
T Loss: 12.471175
Epoch 99 
Overall Loss: 14.461316
Rec Loss: 13.105498
KL Loss: 1.355818
Y Loss: 1.407870
T Loss: 12.260777
Epoch 149 
Overall Loss: 14.041860
Rec Loss: 12.667790
KL Loss: 1.374070
Y Loss: 0.969803
T Loss: 12.085908
Epoch 199 
Overall Loss: 13.835390
Rec Loss: 12.424473
KL Loss: 1.410917
Y Loss: 0.854642
T Loss: 11.911687
Epoch 249 
Overall Loss: 13.716002
Rec Loss: 12.282967
KL Loss: 1.433034
Y Loss: 0.835223
T Loss: 11.781834
Epoch 299 
Overall Loss: 13.626470
Rec Loss: 12.186818
KL Loss: 1.439651
Y Loss: 0.795554
T Loss: 11.709486
Epoch 349 
Overall Loss: 13.571510
Rec Loss: 12.119623
KL Loss: 1.451887
Y Loss: 0.794708
T Loss: 11.642798
Epoch 399 
Overall Loss: 13.523628
Rec Loss: 12.078369
KL Loss: 1.445259
Y Loss: 0.808696
T Loss: 11.593152
Epoch 449 
Overall Loss: 13.484160
Rec Loss: 12.030042
KL Loss: 1.454119
Y Loss: 0.797311
T Loss: 11.551655
Epoch 499 
Overall Loss: 13.461999
Rec Loss: 12.013481
KL Loss: 1.448519
Y Loss: 0.805106
T Loss: 11.530417
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.879176
Epoch 99
Rec Loss: 1.872147
Epoch 149
Rec Loss: 1.873327
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.021092
Epoch 99
Rec Loss: 10.011559
Epoch 149
Rec Loss: 10.014296
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.605075
Insample Error: 2.495477
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.060787
Rec Loss: 20.658486
KL Loss: 1.402300
Y Loss: 5.101424
T Loss: 12.682536
Epoch 99 
Overall Loss: 19.566743
Rec Loss: 17.383726
KL Loss: 2.183017
Y Loss: 1.780153
T Loss: 12.358243
Epoch 149 
Overall Loss: 18.904041
Rec Loss: 16.408584
KL Loss: 2.495458
Y Loss: 1.442885
T Loss: 12.146761
Epoch 199 
Overall Loss: 18.497567
Rec Loss: 15.409895
KL Loss: 3.087673
Y Loss: 1.277793
T Loss: 11.988364
Epoch 249 
Overall Loss: 18.295300
Rec Loss: 14.989624
KL Loss: 3.305676
Y Loss: 1.208769
T Loss: 11.904930
Epoch 299 
Overall Loss: 18.201866
Rec Loss: 14.693933
KL Loss: 3.507933
Y Loss: 1.130210
T Loss: 11.829335
Epoch 349 
Overall Loss: 18.093264
Rec Loss: 14.413330
KL Loss: 3.679933
Y Loss: 1.082191
T Loss: 11.771501
Epoch 399 
Overall Loss: 17.987856
Rec Loss: 14.087471
KL Loss: 3.900385
Y Loss: 1.016782
T Loss: 11.710631
Epoch 449 
Overall Loss: 17.911880
Rec Loss: 13.854963
KL Loss: 4.056917
Y Loss: 0.981437
T Loss: 11.673057
Epoch 499 
Overall Loss: 17.857139
Rec Loss: 13.674835
KL Loss: 4.182304
Y Loss: 0.940581
T Loss: 11.635303
Epoch 549 
Overall Loss: 17.790558
Rec Loss: 13.543130
KL Loss: 4.247428
Y Loss: 0.899984
T Loss: 11.614679
Epoch 599 
Overall Loss: 17.771782
Rec Loss: 13.430614
KL Loss: 4.341167
Y Loss: 0.901814
T Loss: 11.585424
Epoch 649 
Overall Loss: 17.679197
Rec Loss: 13.289679
KL Loss: 4.389518
Y Loss: 0.856632
T Loss: 11.564018
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.898895
Epoch 99
Rec Loss: 1.899482
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.916377
Epoch 99
Rec Loss: 5.898459
Epoch 149
Rec Loss: 5.906483
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.625404
Insample Error 2.232545
Ours, Train RMSE
0.5909, 
0.6147, 
0.5982, 
0.5897, 
0.5855, 
0.5847, 
0.6230, 
0.6230, 
0.6057, 
0.6051, 
Ours, Insample RMSE
2.3825, 
2.5578, 
2.5414, 
2.5264, 
2.3645, 
2.3440, 
2.4408, 
2.4820, 
2.4414, 
2.4955, 
CEVAE, Insample RMSE
2.2670, 
2.2796, 
2.2263, 
2.3100, 
2.1363, 
2.3073, 
2.2471, 
2.2320, 
2.3543, 
2.2325, 
Train, RMSE mean 0.6020 std 0.0139
Ours, RMSE mean 2.4576 std 0.0718, reconstruct confounder 1.8769 (0.0125) noise 10.0012 (0.0086)
CEVAE, RMSE mean 2.2592 std 0.0567, reconstruct confounder 1.9225 (0.0249) noise 5.8938 (0.0820)
Experiment Start!
Namespace(decay=0.0, l=5e-05, latdim=4, mask=0, nlayer=50, obsm=0, ycof=0.35, ylayer=50)
Y Mean 1.514292, Std 3.653528 
Observe confounder 0, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.977976
Rec Loss: 15.126728
KL Loss: 0.851247
Y Loss: 7.052985
T Loss: 12.658184
Epoch 99 
Overall Loss: 14.527206
Rec Loss: 13.314516
KL Loss: 1.212690
Y Loss: 2.686176
T Loss: 12.374355
Epoch 149 
Overall Loss: 13.975502
Rec Loss: 12.768185
KL Loss: 1.207317
Y Loss: 1.871900
T Loss: 12.113020
Epoch 199 
Overall Loss: 13.574610
Rec Loss: 12.344547
KL Loss: 1.230063
Y Loss: 1.325773
T Loss: 11.880526
Epoch 249 
Overall Loss: 13.428333
Rec Loss: 12.164554
KL Loss: 1.263779
Y Loss: 1.229212
T Loss: 11.734330
Epoch 299 
Overall Loss: 13.341823
Rec Loss: 12.061690
KL Loss: 1.280134
Y Loss: 1.195798
T Loss: 11.643160
Epoch 349 
Overall Loss: 13.284478
Rec Loss: 11.999071
KL Loss: 1.285407
Y Loss: 1.190097
T Loss: 11.582537
Epoch 399 
Overall Loss: 13.249368
Rec Loss: 11.965018
KL Loss: 1.284349
Y Loss: 1.156093
T Loss: 11.560386
Epoch 449 
Overall Loss: 13.239138
Rec Loss: 11.950006
KL Loss: 1.289133
Y Loss: 1.180960
T Loss: 11.536670
Epoch 499 
Overall Loss: 13.216200
Rec Loss: 11.932520
KL Loss: 1.283680
Y Loss: 1.172791
T Loss: 11.522043
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.936273
Epoch 99
Rec Loss: 1.934735
Epoch 149
Rec Loss: 1.942594
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.009387
Epoch 99
Rec Loss: 10.003861
Epoch 149
Rec Loss: 9.999675
Epoch 199
Rec Loss: 9.995296
Epoch 249
Rec Loss: 10.002405
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.753457
Insample Error: 2.456735
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 20.950922
Rec Loss: 20.020603
KL Loss: 0.930319
Y Loss: 6.634836
T Loss: 12.719968
Epoch 99 
Overall Loss: 19.161558
Rec Loss: 17.348111
KL Loss: 1.813447
Y Loss: 3.106375
T Loss: 12.212259
Epoch 149 
Overall Loss: 18.445606
Rec Loss: 16.029179
KL Loss: 2.416427
Y Loss: 2.358295
T Loss: 11.971508
Epoch 199 
Overall Loss: 18.074198
Rec Loss: 15.066249
KL Loss: 3.007949
Y Loss: 1.985195
T Loss: 11.890745
Epoch 249 
Overall Loss: 17.897036
Rec Loss: 14.679726
KL Loss: 3.217310
Y Loss: 1.819456
T Loss: 11.781660
Epoch 299 
Overall Loss: 17.748634
Rec Loss: 14.297188
KL Loss: 3.451446
Y Loss: 1.656286
T Loss: 11.724001
Epoch 349 
Overall Loss: 17.617205
Rec Loss: 13.902399
KL Loss: 3.714805
Y Loss: 1.493842
T Loss: 11.664423
Epoch 399 
Overall Loss: 17.543689
Rec Loss: 13.610443
KL Loss: 3.933246
Y Loss: 1.427534
T Loss: 11.617399
Epoch 449 
Overall Loss: 17.480338
Rec Loss: 13.366639
KL Loss: 4.113699
Y Loss: 1.382738
T Loss: 11.593960
Epoch 499 
Overall Loss: 17.455259
Rec Loss: 13.224114
KL Loss: 4.231145
Y Loss: 1.350485
T Loss: 11.571306
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.956946
Epoch 99
Rec Loss: 1.960301
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.899681
Epoch 99
Rec Loss: 5.898766
Epoch 149
Rec Loss: 5.896889
Epoch 199
Rec Loss: 5.899972
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.841732
Insample Error 2.286819
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.542524
Rec Loss: 14.558294
KL Loss: 0.984230
Y Loss: 6.172602
T Loss: 12.397883
Epoch 99 
Overall Loss: 14.059793
Rec Loss: 12.843399
KL Loss: 1.216394
Y Loss: 1.946060
T Loss: 12.162278
Epoch 149 
Overall Loss: 13.773669
Rec Loss: 12.512824
KL Loss: 1.260844
Y Loss: 1.449373
T Loss: 12.005544
Epoch 199 
Overall Loss: 13.556696
Rec Loss: 12.258778
KL Loss: 1.297919
Y Loss: 1.292125
T Loss: 11.806534
Epoch 249 
Overall Loss: 13.404950
Rec Loss: 12.091389
KL Loss: 1.313562
Y Loss: 1.249425
T Loss: 11.654090
Epoch 299 
Overall Loss: 13.341398
Rec Loss: 12.019914
KL Loss: 1.321484
Y Loss: 1.194430
T Loss: 11.601863
Epoch 349 
Overall Loss: 13.301482
Rec Loss: 11.999854
KL Loss: 1.301628
Y Loss: 1.205238
T Loss: 11.578021
Epoch 399 
Overall Loss: 13.273937
Rec Loss: 11.966357
KL Loss: 1.307580
Y Loss: 1.191030
T Loss: 11.549496
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.968582
Epoch 99
Rec Loss: 1.965469
Epoch 149
Rec Loss: 1.953834
Epoch 199
Rec Loss: 1.948939
Epoch 249
Rec Loss: 1.969211
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.009395
Epoch 99
Rec Loss: 10.004040
Epoch 149
Rec Loss: 10.003978
Epoch 199
Rec Loss: 9.998247
Epoch 249
Rec Loss: 10.007550
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.780848
Insample Error: 2.514688
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 20.935780
Rec Loss: 19.962925
KL Loss: 0.972855
Y Loss: 6.482223
T Loss: 12.766920
Epoch 99 
Overall Loss: 19.060700
Rec Loss: 17.147416
KL Loss: 1.913283
Y Loss: 2.694843
T Loss: 12.258356
Epoch 149 
Overall Loss: 18.280261
Rec Loss: 15.620917
KL Loss: 2.659344
Y Loss: 2.050271
T Loss: 12.009385
Epoch 199 
Overall Loss: 18.029725
Rec Loss: 14.990140
KL Loss: 3.039584
Y Loss: 1.901868
T Loss: 11.868804
Epoch 249 
Overall Loss: 17.910580
Rec Loss: 14.754414
KL Loss: 3.156166
Y Loss: 1.739110
T Loss: 11.789795
Epoch 299 
Overall Loss: 17.800484
Rec Loss: 14.569674
KL Loss: 3.230810
Y Loss: 1.683582
T Loss: 11.720673
Epoch 349 
Overall Loss: 17.767004
Rec Loss: 14.450990
KL Loss: 3.316014
Y Loss: 1.606656
T Loss: 11.692247
Epoch 399 
Overall Loss: 17.643158
Rec Loss: 14.203596
KL Loss: 3.439562
Y Loss: 1.496681
T Loss: 11.650677
Epoch 449 
Overall Loss: 17.596839
Rec Loss: 14.014931
KL Loss: 3.581908
Y Loss: 1.406849
T Loss: 11.623553
Epoch 499 
Overall Loss: 17.545148
Rec Loss: 13.827150
KL Loss: 3.717999
Y Loss: 1.354082
T Loss: 11.591604
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.982621
Epoch 99
Rec Loss: 1.987105
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.964659
Epoch 99
Rec Loss: 5.958292
Epoch 149
Rec Loss: 5.976607
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.856776
Insample Error 2.294245
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.437683
Rec Loss: 14.350379
KL Loss: 1.087304
Y Loss: 5.022349
T Loss: 12.592557
Epoch 99 
Overall Loss: 13.996225
Rec Loss: 12.787387
KL Loss: 1.208839
Y Loss: 1.714154
T Loss: 12.187433
Epoch 149 
Overall Loss: 13.664062
Rec Loss: 12.431114
KL Loss: 1.232948
Y Loss: 1.268036
T Loss: 11.987302
Epoch 199 
Overall Loss: 13.476154
Rec Loss: 12.214677
KL Loss: 1.261477
Y Loss: 1.214511
T Loss: 11.789599
Epoch 249 
Overall Loss: 13.383006
Rec Loss: 12.081839
KL Loss: 1.301167
Y Loss: 1.214624
T Loss: 11.656721
Epoch 299 
Overall Loss: 13.322526
Rec Loss: 12.021638
KL Loss: 1.300889
Y Loss: 1.207542
T Loss: 11.598998
Epoch 349 
Overall Loss: 13.265963
Rec Loss: 11.969328
KL Loss: 1.296635
Y Loss: 1.183950
T Loss: 11.554946
Epoch 399 
Overall Loss: 13.251894
Rec Loss: 11.951630
KL Loss: 1.300263
Y Loss: 1.150941
T Loss: 11.548800
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.938903
Epoch 99
Rec Loss: 1.944582
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.017716
Epoch 99
Rec Loss: 10.014387
Epoch 149
Rec Loss: 10.007642
Epoch 199
Rec Loss: 10.013819
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.755761
Insample Error: 2.539358
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 20.578497
Rec Loss: 19.515122
KL Loss: 1.063375
Y Loss: 5.430312
T Loss: 12.704346
Epoch 99 
Overall Loss: 19.007403
Rec Loss: 17.210229
KL Loss: 1.797174
Y Loss: 2.537882
T Loss: 12.261337
Epoch 149 
Overall Loss: 18.333886
Rec Loss: 15.934346
KL Loss: 2.399540
Y Loss: 2.111306
T Loss: 11.972898
Epoch 199 
Overall Loss: 18.012853
Rec Loss: 15.055631
KL Loss: 2.957221
Y Loss: 1.922306
T Loss: 11.840256
Epoch 249 
Overall Loss: 17.870593
Rec Loss: 14.712414
KL Loss: 3.158178
Y Loss: 1.736629
T Loss: 11.772454
Epoch 299 
Overall Loss: 17.741275
Rec Loss: 14.379762
KL Loss: 3.361513
Y Loss: 1.588733
T Loss: 11.694943
Epoch 349 
Overall Loss: 17.656895
Rec Loss: 14.135054
KL Loss: 3.521841
Y Loss: 1.466937
T Loss: 11.652020
Epoch 399 
Overall Loss: 17.606006
Rec Loss: 13.999280
KL Loss: 3.606726
Y Loss: 1.390776
T Loss: 11.619114
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.989341
Epoch 99
Rec Loss: 1.991974
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.148832
Epoch 99
Rec Loss: 6.132210
Epoch 149
Rec Loss: 6.134292
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.872602
Insample Error 2.184491
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.758852
Rec Loss: 14.882016
KL Loss: 0.876836
Y Loss: 6.622244
T Loss: 12.564231
Epoch 99 
Overall Loss: 14.071361
Rec Loss: 12.858035
KL Loss: 1.213325
Y Loss: 2.061162
T Loss: 12.136629
Epoch 149 
Overall Loss: 13.721789
Rec Loss: 12.460865
KL Loss: 1.260924
Y Loss: 1.389342
T Loss: 11.974595
Epoch 199 
Overall Loss: 13.539513
Rec Loss: 12.258470
KL Loss: 1.281042
Y Loss: 1.237611
T Loss: 11.825306
Epoch 249 
Overall Loss: 13.435844
Rec Loss: 12.112867
KL Loss: 1.322977
Y Loss: 1.203534
T Loss: 11.691630
Epoch 299 
Overall Loss: 13.337498
Rec Loss: 12.022103
KL Loss: 1.315395
Y Loss: 1.169601
T Loss: 11.612743
Epoch 349 
Overall Loss: 13.311731
Rec Loss: 11.990231
KL Loss: 1.321500
Y Loss: 1.175007
T Loss: 11.578978
Epoch 399 
Overall Loss: 13.268277
Rec Loss: 11.956965
KL Loss: 1.311312
Y Loss: 1.164445
T Loss: 11.549410
Epoch 449 
Overall Loss: 13.244789
Rec Loss: 11.938064
KL Loss: 1.306725
Y Loss: 1.151568
T Loss: 11.535015
Epoch 499 
Overall Loss: 13.223109
Rec Loss: 11.922783
KL Loss: 1.300326
Y Loss: 1.149502
T Loss: 11.520457
Epoch 549 
Overall Loss: 13.189814
Rec Loss: 11.902191
KL Loss: 1.287622
Y Loss: 1.110755
T Loss: 11.513427
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.933371
Epoch 99
Rec Loss: 1.928122
Epoch 149
Rec Loss: 1.935093
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.001843
Epoch 99
Rec Loss: 9.999911
Epoch 149
Rec Loss: 10.001689
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.745743
Insample Error: 2.465252
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.256107
Rec Loss: 20.463861
KL Loss: 0.792246
Y Loss: 7.914599
T Loss: 12.754035
Epoch 99 
Overall Loss: 19.233054
Rec Loss: 17.507212
KL Loss: 1.725842
Y Loss: 3.494866
T Loss: 12.130360
Epoch 149 
Overall Loss: 18.376328
Rec Loss: 15.891632
KL Loss: 2.484696
Y Loss: 2.360368
T Loss: 11.927862
Epoch 199 
Overall Loss: 18.032092
Rec Loss: 15.063162
KL Loss: 2.968929
Y Loss: 1.930132
T Loss: 11.820808
Epoch 249 
Overall Loss: 17.893961
Rec Loss: 14.783843
KL Loss: 3.110118
Y Loss: 1.788803
T Loss: 11.736574
Epoch 299 
Overall Loss: 17.768257
Rec Loss: 14.590335
KL Loss: 3.177923
Y Loss: 1.637025
T Loss: 11.685463
Epoch 349 
Overall Loss: 17.676988
Rec Loss: 14.429843
KL Loss: 3.247145
Y Loss: 1.483512
T Loss: 11.648414
Epoch 399 
Overall Loss: 17.634139
Rec Loss: 14.323204
KL Loss: 3.310935
Y Loss: 1.392832
T Loss: 11.610090
Epoch 449 
Overall Loss: 17.573185
Rec Loss: 14.189275
KL Loss: 3.383909
Y Loss: 1.319435
T Loss: 11.587843
Epoch 499 
Overall Loss: 17.532761
Rec Loss: 14.094555
KL Loss: 3.438207
Y Loss: 1.289010
T Loss: 11.580706
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.973245
Epoch 99
Rec Loss: 1.976619
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.102360
Epoch 99
Rec Loss: 6.103236
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.835005
Insample Error 2.139623
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.796452
Rec Loss: 14.881836
KL Loss: 0.914617
Y Loss: 6.360607
T Loss: 12.655623
Epoch 99 
Overall Loss: 14.412196
Rec Loss: 13.188140
KL Loss: 1.224056
Y Loss: 2.640862
T Loss: 12.263838
Epoch 149 
Overall Loss: 13.856833
Rec Loss: 12.636747
KL Loss: 1.220087
Y Loss: 1.884718
T Loss: 11.977096
Epoch 199 
Overall Loss: 13.518349
Rec Loss: 12.248512
KL Loss: 1.269836
Y Loss: 1.417194
T Loss: 11.752494
Epoch 249 
Overall Loss: 13.388956
Rec Loss: 12.101680
KL Loss: 1.287276
Y Loss: 1.275821
T Loss: 11.655142
Epoch 299 
Overall Loss: 13.329649
Rec Loss: 12.031664
KL Loss: 1.297985
Y Loss: 1.233416
T Loss: 11.599969
Epoch 349 
Overall Loss: 13.285730
Rec Loss: 11.992741
KL Loss: 1.292989
Y Loss: 1.203193
T Loss: 11.571624
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.956215
Epoch 99
Rec Loss: 1.941389
Epoch 149
Rec Loss: 1.949364
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.012692
Epoch 99
Rec Loss: 10.009067
Epoch 149
Rec Loss: 10.001844
Epoch 199
Rec Loss: 10.006012
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.772638
Insample Error: 2.355781
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 20.826007
Rec Loss: 19.885239
KL Loss: 0.940767
Y Loss: 6.612153
T Loss: 12.617857
Epoch 99 
Overall Loss: 19.076860
Rec Loss: 17.290113
KL Loss: 1.786747
Y Loss: 3.100758
T Loss: 12.181388
Epoch 149 
Overall Loss: 18.469640
Rec Loss: 16.269890
KL Loss: 2.199750
Y Loss: 2.322124
T Loss: 11.916007
Epoch 199 
Overall Loss: 18.203887
Rec Loss: 15.802991
KL Loss: 2.400896
Y Loss: 1.983925
T Loss: 11.824812
Epoch 249 
Overall Loss: 17.936653
Rec Loss: 14.975703
KL Loss: 2.960949
Y Loss: 1.815341
T Loss: 11.734977
Epoch 299 
Overall Loss: 17.776942
Rec Loss: 14.579338
KL Loss: 3.197604
Y Loss: 1.625002
T Loss: 11.688485
Epoch 349 
Overall Loss: 17.710337
Rec Loss: 14.408465
KL Loss: 3.301872
Y Loss: 1.524698
T Loss: 11.643867
Epoch 399 
Overall Loss: 17.652312
Rec Loss: 14.240895
KL Loss: 3.411417
Y Loss: 1.434106
T Loss: 11.612574
Epoch 449 
Overall Loss: 17.576654
Rec Loss: 14.111784
KL Loss: 3.464870
Y Loss: 1.380071
T Loss: 11.588453
Epoch 499 
Overall Loss: 17.518342
Rec Loss: 14.014092
KL Loss: 3.504249
Y Loss: 1.311417
T Loss: 11.574082
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.957013
Epoch 99
Rec Loss: 1.958909
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.202593
Epoch 99
Rec Loss: 6.187253
Epoch 149
Rec Loss: 6.178888
Epoch 199
Rec Loss: 6.175742
Epoch 249
Rec Loss: 6.200310
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.838352
Insample Error 2.241037
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.747455
Rec Loss: 14.840197
KL Loss: 0.907258
Y Loss: 6.345228
T Loss: 12.619367
Epoch 99 
Overall Loss: 14.127543
Rec Loss: 12.962582
KL Loss: 1.164962
Y Loss: 2.097498
T Loss: 12.228457
Epoch 149 
Overall Loss: 13.748197
Rec Loss: 12.534607
KL Loss: 1.213591
Y Loss: 1.433159
T Loss: 12.033001
Epoch 199 
Overall Loss: 13.539196
Rec Loss: 12.279723
KL Loss: 1.259473
Y Loss: 1.245723
T Loss: 11.843720
Epoch 249 
Overall Loss: 13.404754
Rec Loss: 12.111118
KL Loss: 1.293636
Y Loss: 1.209324
T Loss: 11.687855
Epoch 299 
Overall Loss: 13.326969
Rec Loss: 12.021164
KL Loss: 1.305805
Y Loss: 1.183182
T Loss: 11.607051
Epoch 349 
Overall Loss: 13.274615
Rec Loss: 11.974269
KL Loss: 1.300346
Y Loss: 1.178687
T Loss: 11.561728
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.948144
Epoch 99
Rec Loss: 1.933858
Epoch 149
Rec Loss: 1.949400
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.004661
Epoch 99
Rec Loss: 10.004049
Epoch 149
Rec Loss: 10.005552
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.762177
Insample Error: 2.443368
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 20.790525
Rec Loss: 19.782967
KL Loss: 1.007559
Y Loss: 6.342520
T Loss: 12.647463
Epoch 99 
Overall Loss: 19.088154
Rec Loss: 17.333868
KL Loss: 1.754285
Y Loss: 2.772599
T Loss: 12.265129
Epoch 149 
Overall Loss: 18.466401
Rec Loss: 16.281110
KL Loss: 2.185292
Y Loss: 2.161235
T Loss: 11.999297
Epoch 199 
Overall Loss: 18.182516
Rec Loss: 15.761499
KL Loss: 2.421016
Y Loss: 1.890773
T Loss: 11.819860
Epoch 249 
Overall Loss: 18.067733
Rec Loss: 15.452373
KL Loss: 2.615359
Y Loss: 1.760841
T Loss: 11.740407
Epoch 299 
Overall Loss: 17.834484
Rec Loss: 14.776590
KL Loss: 3.057893
Y Loss: 1.595915
T Loss: 11.681212
Epoch 349 
Overall Loss: 17.697633
Rec Loss: 14.300549
KL Loss: 3.397084
Y Loss: 1.494695
T Loss: 11.648488
Epoch 399 
Overall Loss: 17.576729
Rec Loss: 14.018291
KL Loss: 3.558438
Y Loss: 1.394636
T Loss: 11.608758
Epoch 449 
Overall Loss: 17.538102
Rec Loss: 13.862529
KL Loss: 3.675573
Y Loss: 1.353672
T Loss: 11.586106
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.973091
Epoch 99
Rec Loss: 1.970381
Epoch 149
Rec Loss: 1.967625
Epoch 199
Rec Loss: 1.969202
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.076668
Epoch 99
Rec Loss: 6.085255
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.863307
Insample Error 2.268504
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.795467
Rec Loss: 14.891868
KL Loss: 0.903600
Y Loss: 6.432281
T Loss: 12.640569
Epoch 99 
Overall Loss: 14.596639
Rec Loss: 13.427518
KL Loss: 1.169120
Y Loss: 2.996848
T Loss: 12.378622
Epoch 149 
Overall Loss: 14.124852
Rec Loss: 12.930462
KL Loss: 1.194390
Y Loss: 2.172610
T Loss: 12.170049
Epoch 199 
Overall Loss: 13.614558
Rec Loss: 12.408894
KL Loss: 1.205664
Y Loss: 1.474382
T Loss: 11.892861
Epoch 249 
Overall Loss: 13.436207
Rec Loss: 12.167065
KL Loss: 1.269142
Y Loss: 1.307124
T Loss: 11.709572
Epoch 299 
Overall Loss: 13.356242
Rec Loss: 12.080096
KL Loss: 1.276146
Y Loss: 1.286035
T Loss: 11.629983
Epoch 349 
Overall Loss: 13.285628
Rec Loss: 12.003450
KL Loss: 1.282178
Y Loss: 1.204417
T Loss: 11.581904
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.955006
Epoch 99
Rec Loss: 1.956420
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.992078
Epoch 99
Rec Loss: 9.986774
Epoch 149
Rec Loss: 9.994974
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.789057
Insample Error: 2.394354
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.088944
Rec Loss: 20.249697
KL Loss: 0.839247
Y Loss: 7.294407
T Loss: 12.763199
Epoch 99 
Overall Loss: 19.304724
Rec Loss: 17.668097
KL Loss: 1.636628
Y Loss: 3.265125
T Loss: 12.288449
Epoch 149 
Overall Loss: 18.507972
Rec Loss: 16.152693
KL Loss: 2.355279
Y Loss: 2.373310
T Loss: 12.056391
Epoch 199 
Overall Loss: 18.045602
Rec Loss: 15.011461
KL Loss: 3.034142
Y Loss: 1.988772
T Loss: 11.881867
Epoch 249 
Overall Loss: 17.860824
Rec Loss: 14.567310
KL Loss: 3.293514
Y Loss: 1.796135
T Loss: 11.798869
Epoch 299 
Overall Loss: 17.754148
Rec Loss: 14.231578
KL Loss: 3.522570
Y Loss: 1.639525
T Loss: 11.731787
Epoch 349 
Overall Loss: 17.613140
Rec Loss: 13.885619
KL Loss: 3.727521
Y Loss: 1.479952
T Loss: 11.662464
Epoch 399 
Overall Loss: 17.579204
Rec Loss: 13.665828
KL Loss: 3.913377
Y Loss: 1.446203
T Loss: 11.610124
Epoch 449 
Overall Loss: 17.504621
Rec Loss: 13.466019
KL Loss: 4.038602
Y Loss: 1.383986
T Loss: 11.582097
Epoch 499 
Overall Loss: 17.444438
Rec Loss: 13.335950
KL Loss: 4.108488
Y Loss: 1.313113
T Loss: 11.564070
Epoch 549 
Overall Loss: 17.420196
Rec Loss: 13.223455
KL Loss: 4.196741
Y Loss: 1.305358
T Loss: 11.564391
Epoch 599 
Overall Loss: 17.434109
Rec Loss: 13.173227
KL Loss: 4.260882
Y Loss: 1.284854
T Loss: 11.550857
Epoch 649 
Overall Loss: 17.424465
Rec Loss: 13.119014
KL Loss: 4.305451
Y Loss: 1.282747
T Loss: 11.546554
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.954955
Epoch 99
Rec Loss: 1.941087
Epoch 149
Rec Loss: 1.946168
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.901210
Epoch 99
Rec Loss: 5.868400
Epoch 149
Rec Loss: 5.880661
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.821435
Insample Error 2.235113
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.844517
Rec Loss: 14.931956
KL Loss: 0.912561
Y Loss: 6.770821
T Loss: 12.562169
Epoch 99 
Overall Loss: 14.421371
Rec Loss: 13.207996
KL Loss: 1.213374
Y Loss: 2.707466
T Loss: 12.260383
Epoch 149 
Overall Loss: 13.833826
Rec Loss: 12.606881
KL Loss: 1.226945
Y Loss: 1.773810
T Loss: 11.986047
Epoch 199 
Overall Loss: 13.575323
Rec Loss: 12.303776
KL Loss: 1.271547
Y Loss: 1.440625
T Loss: 11.799557
Epoch 249 
Overall Loss: 13.426423
Rec Loss: 12.140605
KL Loss: 1.285817
Y Loss: 1.292927
T Loss: 11.688081
Epoch 299 
Overall Loss: 13.343897
Rec Loss: 12.044093
KL Loss: 1.299804
Y Loss: 1.190979
T Loss: 11.627251
Epoch 349 
Overall Loss: 13.293419
Rec Loss: 12.002281
KL Loss: 1.291138
Y Loss: 1.190095
T Loss: 11.585748
Epoch 399 
Overall Loss: 13.271970
Rec Loss: 11.979782
KL Loss: 1.292188
Y Loss: 1.200894
T Loss: 11.559469
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.935172
Epoch 99
Rec Loss: 1.938740
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.997360
Epoch 99
Rec Loss: 9.996971
Epoch 149
Rec Loss: 9.984095
Epoch 199
Rec Loss: 9.993648
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.773980
Insample Error: 2.447024
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 20.885719
Rec Loss: 19.964335
KL Loss: 0.921383
Y Loss: 6.266305
T Loss: 12.863534
Epoch 99 
Overall Loss: 19.191617
Rec Loss: 17.424675
KL Loss: 1.766942
Y Loss: 2.983798
T Loss: 12.311645
Epoch 149 
Overall Loss: 18.522291
Rec Loss: 16.171862
KL Loss: 2.350429
Y Loss: 2.303166
T Loss: 12.055025
Epoch 199 
Overall Loss: 18.184654
Rec Loss: 15.304940
KL Loss: 2.879714
Y Loss: 2.034139
T Loss: 11.915205
Epoch 249 
Overall Loss: 17.963646
Rec Loss: 14.755224
KL Loss: 3.208421
Y Loss: 1.827695
T Loss: 11.800583
Epoch 299 
Overall Loss: 17.751199
Rec Loss: 14.260583
KL Loss: 3.490616
Y Loss: 1.678596
T Loss: 11.716817
Epoch 349 
Overall Loss: 17.650779
Rec Loss: 13.900887
KL Loss: 3.749892
Y Loss: 1.531910
T Loss: 11.667896
Epoch 399 
Overall Loss: 17.588908
Rec Loss: 13.672909
KL Loss: 3.915999
Y Loss: 1.461538
T Loss: 11.642382
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.021256
Epoch 99
Rec Loss: 2.011544
Epoch 149
Rec Loss: 2.021202
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.996256
Epoch 99
Rec Loss: 5.980396
Epoch 149
Rec Loss: 5.996548
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.900483
Insample Error 2.340062
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.847722
Rec Loss: 14.924681
KL Loss: 0.923042
Y Loss: 6.618753
T Loss: 12.608117
Epoch 99 
Overall Loss: 14.445839
Rec Loss: 13.255538
KL Loss: 1.190301
Y Loss: 2.757986
T Loss: 12.290243
Epoch 149 
Overall Loss: 13.745297
Rec Loss: 12.530271
KL Loss: 1.215026
Y Loss: 1.609082
T Loss: 11.967092
Epoch 199 
Overall Loss: 13.526360
Rec Loss: 12.281452
KL Loss: 1.244908
Y Loss: 1.343379
T Loss: 11.811270
Epoch 249 
Overall Loss: 13.383294
Rec Loss: 12.115718
KL Loss: 1.267576
Y Loss: 1.223957
T Loss: 11.687333
Epoch 299 
Overall Loss: 13.315239
Rec Loss: 12.034863
KL Loss: 1.280376
Y Loss: 1.183681
T Loss: 11.620574
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.949040
Epoch 99
Rec Loss: 1.958947
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.998278
Epoch 99
Rec Loss: 10.000707
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.767343
Insample Error: 2.410612
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 20.984848
Rec Loss: 20.079818
KL Loss: 0.905029
Y Loss: 6.812520
T Loss: 12.736707
Epoch 99 
Overall Loss: 19.079159
Rec Loss: 17.150575
KL Loss: 1.928584
Y Loss: 3.052245
T Loss: 12.247498
Epoch 149 
Overall Loss: 18.283519
Rec Loss: 15.576783
KL Loss: 2.706736
Y Loss: 2.226647
T Loss: 11.993690
Epoch 199 
Overall Loss: 18.035141
Rec Loss: 15.013982
KL Loss: 3.021159
Y Loss: 1.968766
T Loss: 11.870515
Epoch 249 
Overall Loss: 17.873496
Rec Loss: 14.670803
KL Loss: 3.202692
Y Loss: 1.742161
T Loss: 11.796445
Epoch 299 
Overall Loss: 17.773984
Rec Loss: 14.426567
KL Loss: 3.347418
Y Loss: 1.656485
T Loss: 11.733338
Epoch 349 
Overall Loss: 17.641282
Rec Loss: 14.152178
KL Loss: 3.489105
Y Loss: 1.530928
T Loss: 11.666706
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.023584
Epoch 99
Rec Loss: 2.020156
Epoch 149
Rec Loss: 2.019965
Epoch 199
Rec Loss: 2.024899
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.987771
Epoch 99
Rec Loss: 5.971710
Epoch 149
Rec Loss: 5.973195
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.893450
Insample Error 2.181319
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.361571
Rec Loss: 14.337725
KL Loss: 1.023847
Y Loss: 5.121751
T Loss: 12.545112
Epoch 99 
Overall Loss: 13.996058
Rec Loss: 12.824530
KL Loss: 1.171527
Y Loss: 1.835672
T Loss: 12.182045
Epoch 149 
Overall Loss: 13.682700
Rec Loss: 12.476064
KL Loss: 1.206637
Y Loss: 1.380720
T Loss: 11.992811
Epoch 199 
Overall Loss: 13.504906
Rec Loss: 12.245545
KL Loss: 1.259361
Y Loss: 1.279649
T Loss: 11.797667
Epoch 249 
Overall Loss: 13.408330
Rec Loss: 12.121175
KL Loss: 1.287155
Y Loss: 1.254506
T Loss: 11.682097
Epoch 299 
Overall Loss: 13.327348
Rec Loss: 12.036160
KL Loss: 1.291188
Y Loss: 1.174182
T Loss: 11.625196
Epoch 349 
Overall Loss: 13.283775
Rec Loss: 11.983627
KL Loss: 1.300148
Y Loss: 1.161360
T Loss: 11.577150
Epoch 399 
Overall Loss: 13.250166
Rec Loss: 11.960870
KL Loss: 1.289295
Y Loss: 1.174869
T Loss: 11.549666
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.944075
Epoch 99
Rec Loss: 1.933352
Epoch 149
Rec Loss: 1.929891
Epoch 199
Rec Loss: 1.932979
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.004960
Epoch 99
Rec Loss: 10.013720
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.758131
Insample Error: 2.572389
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 20.841127
Rec Loss: 19.912285
KL Loss: 0.928842
Y Loss: 6.518397
T Loss: 12.643485
Epoch 99 
Overall Loss: 19.162826
Rec Loss: 17.542556
KL Loss: 1.620271
Y Loss: 3.028337
T Loss: 12.202642
Epoch 149 
Overall Loss: 18.420742
Rec Loss: 16.106111
KL Loss: 2.314631
Y Loss: 2.183425
T Loss: 11.970293
Epoch 199 
Overall Loss: 17.981097
Rec Loss: 15.001184
KL Loss: 2.979914
Y Loss: 1.897300
T Loss: 11.809353
Epoch 249 
Overall Loss: 17.827156
Rec Loss: 14.470789
KL Loss: 3.356366
Y Loss: 1.709341
T Loss: 11.743396
Epoch 299 
Overall Loss: 17.723800
Rec Loss: 14.172211
KL Loss: 3.551589
Y Loss: 1.579158
T Loss: 11.679541
Epoch 349 
Overall Loss: 17.599172
Rec Loss: 13.936776
KL Loss: 3.662395
Y Loss: 1.506492
T Loss: 11.650362
Epoch 399 
Overall Loss: 17.550051
Rec Loss: 13.753845
KL Loss: 3.796206
Y Loss: 1.402820
T Loss: 11.615872
Epoch 449 
Overall Loss: 17.486533
Rec Loss: 13.601857
KL Loss: 3.884677
Y Loss: 1.362441
T Loss: 11.590163
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.975352
Epoch 99
Rec Loss: 1.980582
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.030143
Epoch 99
Rec Loss: 6.016305
Epoch 149
Rec Loss: 6.010943
Epoch 199
Rec Loss: 6.014107
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.862295
Insample Error 2.319086
Ours, Train RMSE
0.7535, 
0.7808, 
0.7558, 
0.7457, 
0.7726, 
0.7622, 
0.7891, 
0.7740, 
0.7673, 
0.7581, 
Ours, Insample RMSE
2.4567, 
2.5147, 
2.5394, 
2.4653, 
2.3558, 
2.4434, 
2.3944, 
2.4470, 
2.4106, 
2.5724, 
CEVAE, Insample RMSE
2.2868, 
2.2942, 
2.1845, 
2.1396, 
2.2410, 
2.2685, 
2.2351, 
2.3401, 
2.1813, 
2.3191, 
Train, RMSE mean 0.7659 std 0.0127
Ours, RMSE mean 2.4600 std 0.0633, reconstruct confounder 1.9395 (0.0085) noise 9.9981 (0.0072)
CEVAE, RMSE mean 2.2490 std 0.0617, reconstruct confounder 1.9775 (0.0233) noise 6.0174 (0.0963)
Experiment Start!
Namespace(decay=0.0, l=5e-05, latdim=4, mask=9, nlayer=50, obsm=0, ycof=0.5, ylayer=50)
Y Mean 1.514292, Std 3.653528 
Observe confounder 0, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.448187
Rec Loss: 15.195968
KL Loss: 1.252219
Y Loss: 5.456824
T Loss: 12.467556
Epoch 99 
Overall Loss: 14.594290
Rec Loss: 13.250217
KL Loss: 1.344073
Y Loss: 1.899837
T Loss: 12.300298
Epoch 149 
Overall Loss: 14.045865
Rec Loss: 12.702487
KL Loss: 1.343377
Y Loss: 1.265739
T Loss: 12.069618
Epoch 199 
Overall Loss: 13.783677
Rec Loss: 12.409736
KL Loss: 1.373941
Y Loss: 1.026431
T Loss: 11.896521
Epoch 249 
Overall Loss: 13.631735
Rec Loss: 12.228578
KL Loss: 1.403157
Y Loss: 0.951904
T Loss: 11.752626
Epoch 299 
Overall Loss: 13.558286
Rec Loss: 12.141189
KL Loss: 1.417097
Y Loss: 0.949161
T Loss: 11.666608
Epoch 349 
Overall Loss: 13.499109
Rec Loss: 12.089035
KL Loss: 1.410074
Y Loss: 0.937495
T Loss: 11.620287
Epoch 399 
Overall Loss: 13.438256
Rec Loss: 12.037504
KL Loss: 1.400752
Y Loss: 0.924964
T Loss: 11.575022
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.905165
Epoch 99
Rec Loss: 1.897700
Epoch 149
Rec Loss: 1.893801
Epoch 199
Rec Loss: 1.900352
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.997197
Epoch 99
Rec Loss: 0.995620
Epoch 149
Rec Loss: 0.995400
Epoch 199
Rec Loss: 0.996921
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.666140
Insample Error: 2.482497
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 16.815608
Rec Loss: 15.505448
KL Loss: 1.310160
Y Loss: 4.881477
T Loss: 12.566539
X Loss: 0.498171
Epoch 99 
Overall Loss: 15.235570
Rec Loss: 13.843083
KL Loss: 1.392488
Y Loss: 2.164657
T Loss: 12.262291
X Loss: 0.498464
Epoch 149 
Overall Loss: 14.699489
Rec Loss: 13.192035
KL Loss: 1.507454
Y Loss: 1.711394
T Loss: 11.839223
X Loss: 0.497114
Epoch 199 
Overall Loss: 14.413413
Rec Loss: 12.863232
KL Loss: 1.550181
Y Loss: 1.454641
T Loss: 11.638260
X Loss: 0.497652
Epoch 249 
Overall Loss: 14.294025
Rec Loss: 12.722044
KL Loss: 1.571981
Y Loss: 1.283658
T Loss: 11.582803
X Loss: 0.497412
Epoch 299 
Overall Loss: 14.208573
Rec Loss: 12.645886
KL Loss: 1.562688
Y Loss: 1.159825
T Loss: 11.568687
X Loss: 0.497286
Epoch 349 
Overall Loss: 14.151667
Rec Loss: 12.604551
KL Loss: 1.547117
Y Loss: 1.092463
T Loss: 11.560358
X Loss: 0.497961
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.000858
Epoch 99
Rec Loss: 1.989680
Epoch 149
Rec Loss: 1.973887
Epoch 199
Rec Loss: 1.987971
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.994465
Epoch 99
Rec Loss: 0.995766
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.600213
Insample Error 2.429623
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.566584
Rec Loss: 15.284650
KL Loss: 1.281934
Y Loss: 5.609581
T Loss: 12.479860
Epoch 99 
Overall Loss: 14.776071
Rec Loss: 13.409546
KL Loss: 1.366525
Y Loss: 2.279340
T Loss: 12.269876
Epoch 149 
Overall Loss: 13.969249
Rec Loss: 12.615203
KL Loss: 1.354047
Y Loss: 1.221413
T Loss: 12.004496
Epoch 199 
Overall Loss: 13.657492
Rec Loss: 12.265435
KL Loss: 1.392057
Y Loss: 0.958800
T Loss: 11.786035
Epoch 249 
Overall Loss: 13.529155
Rec Loss: 12.130219
KL Loss: 1.398935
Y Loss: 0.923413
T Loss: 11.668513
Epoch 299 
Overall Loss: 13.472813
Rec Loss: 12.072685
KL Loss: 1.400128
Y Loss: 0.923229
T Loss: 11.611070
Epoch 349 
Overall Loss: 13.406383
Rec Loss: 12.015091
KL Loss: 1.391292
Y Loss: 0.908929
T Loss: 11.560626
Epoch 399 
Overall Loss: 13.397044
Rec Loss: 12.008191
KL Loss: 1.388853
Y Loss: 0.898551
T Loss: 11.558915
Epoch 449 
Overall Loss: 13.372910
Rec Loss: 11.971690
KL Loss: 1.401220
Y Loss: 0.872243
T Loss: 11.535569
Epoch 499 
Overall Loss: 13.345696
Rec Loss: 11.941393
KL Loss: 1.404303
Y Loss: 0.866587
T Loss: 11.508100
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.889842
Epoch 99
Rec Loss: 1.881611
Epoch 149
Rec Loss: 1.879239
Epoch 199
Rec Loss: 1.889195
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.994043
Epoch 99
Rec Loss: 0.995166
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.633222
Insample Error: 2.374707
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.231055
Rec Loss: 16.100471
KL Loss: 1.130584
Y Loss: 5.735549
T Loss: 12.735321
X Loss: 0.497376
Epoch 99 
Overall Loss: 15.417058
Rec Loss: 14.027512
KL Loss: 1.389546
Y Loss: 2.307386
T Loss: 12.379714
X Loss: 0.494104
Epoch 149 
Overall Loss: 14.830527
Rec Loss: 13.355580
KL Loss: 1.474948
Y Loss: 1.871001
T Loss: 11.930030
X Loss: 0.490049
Epoch 199 
Overall Loss: 14.454459
Rec Loss: 12.911671
KL Loss: 1.542788
Y Loss: 1.532958
T Loss: 11.653287
X Loss: 0.491905
Epoch 249 
Overall Loss: 14.317320
Rec Loss: 12.745669
KL Loss: 1.571651
Y Loss: 1.332112
T Loss: 11.587059
X Loss: 0.492555
Epoch 299 
Overall Loss: 14.208510
Rec Loss: 12.643701
KL Loss: 1.564808
Y Loss: 1.177577
T Loss: 11.564437
X Loss: 0.490475
Epoch 349 
Overall Loss: 14.149301
Rec Loss: 12.601539
KL Loss: 1.547762
Y Loss: 1.108519
T Loss: 11.554748
X Loss: 0.492531
Epoch 399 
Overall Loss: 14.129268
Rec Loss: 12.583243
KL Loss: 1.546025
Y Loss: 1.052848
T Loss: 11.563551
X Loss: 0.493268
Epoch 449 
Overall Loss: 14.061373
Rec Loss: 12.557233
KL Loss: 1.504140
Y Loss: 0.986157
T Loss: 11.571747
X Loss: 0.492408
Epoch 499 
Overall Loss: 13.993538
Rec Loss: 12.540881
KL Loss: 1.452658
Y Loss: 0.957373
T Loss: 11.569210
X Loss: 0.492984
Epoch 549 
Overall Loss: 13.930557
Rec Loss: 12.517512
KL Loss: 1.413046
Y Loss: 0.908727
T Loss: 11.571747
X Loss: 0.491401
Epoch 599 
Overall Loss: 13.884125
Rec Loss: 12.495273
KL Loss: 1.388852
Y Loss: 0.900262
T Loss: 11.551824
X Loss: 0.493318
Epoch 649 
Overall Loss: 13.848315
Rec Loss: 12.466524
KL Loss: 1.381792
Y Loss: 0.884429
T Loss: 11.531165
X Loss: 0.493144
Epoch 699 
Overall Loss: 13.830112
Rec Loss: 12.468675
KL Loss: 1.361437
Y Loss: 0.863760
T Loss: 11.541437
X Loss: 0.495358
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.905161
Epoch 99
Rec Loss: 1.904477
Epoch 149
Rec Loss: 1.902868
Epoch 199
Rec Loss: 1.899251
Epoch 249
Rec Loss: 1.899876
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.989413
Epoch 99
Rec Loss: 0.985590
Epoch 149
Rec Loss: 0.986802
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.645887
Insample Error 2.142637
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.141072
Rec Loss: 14.901454
KL Loss: 1.239618
Y Loss: 4.830564
T Loss: 12.486172
Epoch 99 
Overall Loss: 14.207017
Rec Loss: 12.925970
KL Loss: 1.281047
Y Loss: 1.438030
T Loss: 12.206955
Epoch 149 
Overall Loss: 13.866390
Rec Loss: 12.550054
KL Loss: 1.316336
Y Loss: 1.020996
T Loss: 12.039556
Epoch 199 
Overall Loss: 13.675794
Rec Loss: 12.324860
KL Loss: 1.350934
Y Loss: 0.956130
T Loss: 11.846795
Epoch 249 
Overall Loss: 13.583432
Rec Loss: 12.204536
KL Loss: 1.378897
Y Loss: 0.934446
T Loss: 11.737313
Epoch 299 
Overall Loss: 13.512088
Rec Loss: 12.113009
KL Loss: 1.399080
Y Loss: 0.928536
T Loss: 11.648741
Epoch 349 
Overall Loss: 13.468759
Rec Loss: 12.066379
KL Loss: 1.402380
Y Loss: 0.908843
T Loss: 11.611957
Epoch 399 
Overall Loss: 13.429633
Rec Loss: 12.035228
KL Loss: 1.394404
Y Loss: 0.911714
T Loss: 11.579371
Epoch 449 
Overall Loss: 13.398799
Rec Loss: 11.998211
KL Loss: 1.400588
Y Loss: 0.908016
T Loss: 11.544203
Epoch 499 
Overall Loss: 13.376666
Rec Loss: 11.988313
KL Loss: 1.388353
Y Loss: 0.920874
T Loss: 11.527877
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.905449
Epoch 99
Rec Loss: 1.889965
Epoch 149
Rec Loss: 1.901840
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.996246
Epoch 99
Rec Loss: 0.995907
Epoch 149
Rec Loss: 0.996742
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.666692
Insample Error: 2.484343
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.420131
Rec Loss: 16.342168
KL Loss: 1.077964
Y Loss: 6.450173
T Loss: 12.618761
X Loss: 0.498320
Epoch 99 
Overall Loss: 15.371881
Rec Loss: 14.014889
KL Loss: 1.356992
Y Loss: 2.515925
T Loss: 12.258870
X Loss: 0.498056
Epoch 149 
Overall Loss: 14.699795
Rec Loss: 13.334165
KL Loss: 1.365629
Y Loss: 1.815104
T Loss: 11.935071
X Loss: 0.491543
Epoch 199 
Overall Loss: 14.405104
Rec Loss: 13.007932
KL Loss: 1.397172
Y Loss: 1.506483
T Loss: 11.763008
X Loss: 0.491682
Epoch 249 
Overall Loss: 14.252181
Rec Loss: 12.843103
KL Loss: 1.409078
Y Loss: 1.290142
T Loss: 11.703156
X Loss: 0.494877
Epoch 299 
Overall Loss: 14.176264
Rec Loss: 12.731495
KL Loss: 1.444769
Y Loss: 1.137154
T Loss: 11.668059
X Loss: 0.494858
Epoch 349 
Overall Loss: 14.127723
Rec Loss: 12.680289
KL Loss: 1.447434
Y Loss: 1.091191
T Loss: 11.639829
X Loss: 0.494865
Epoch 399 
Overall Loss: 14.066469
Rec Loss: 12.631843
KL Loss: 1.434626
Y Loss: 1.017199
T Loss: 11.625910
X Loss: 0.497334
Epoch 449 
Overall Loss: 14.016386
Rec Loss: 12.574503
KL Loss: 1.441883
Y Loss: 0.982344
T Loss: 11.585558
X Loss: 0.497772
Epoch 499 
Overall Loss: 13.953468
Rec Loss: 12.546353
KL Loss: 1.407115
Y Loss: 0.930310
T Loss: 11.583882
X Loss: 0.497316
Epoch 549 
Overall Loss: 13.893034
Rec Loss: 12.501740
KL Loss: 1.391294
Y Loss: 0.882508
T Loss: 11.563529
X Loss: 0.496957
Epoch 599 
Overall Loss: 13.858049
Rec Loss: 12.475885
KL Loss: 1.382164
Y Loss: 0.865877
T Loss: 11.545538
X Loss: 0.497408
Epoch 649 
Overall Loss: 13.833557
Rec Loss: 12.474374
KL Loss: 1.359184
Y Loss: 0.895293
T Loss: 11.529320
X Loss: 0.497407
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.880013
Epoch 99
Rec Loss: 1.870634
Epoch 149
Rec Loss: 1.888475
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.995395
Epoch 99
Rec Loss: 0.995840
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.643701
Insample Error 2.031252
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.191881
Rec Loss: 16.160964
KL Loss: 1.030918
Y Loss: 7.307669
T Loss: 12.507129
Epoch 99 
Overall Loss: 14.426012
Rec Loss: 13.087443
KL Loss: 1.338570
Y Loss: 1.807751
T Loss: 12.183567
Epoch 149 
Overall Loss: 13.925308
Rec Loss: 12.555823
KL Loss: 1.369486
Y Loss: 1.125115
T Loss: 11.993265
Epoch 199 
Overall Loss: 13.680101
Rec Loss: 12.290976
KL Loss: 1.389124
Y Loss: 0.970393
T Loss: 11.805780
Epoch 249 
Overall Loss: 13.537109
Rec Loss: 12.137816
KL Loss: 1.399293
Y Loss: 0.895203
T Loss: 11.690215
Epoch 299 
Overall Loss: 13.483297
Rec Loss: 12.084185
KL Loss: 1.399112
Y Loss: 0.928602
T Loss: 11.619884
Epoch 349 
Overall Loss: 13.446904
Rec Loss: 12.056057
KL Loss: 1.390846
Y Loss: 0.926528
T Loss: 11.592794
Epoch 399 
Overall Loss: 13.403260
Rec Loss: 12.015642
KL Loss: 1.387619
Y Loss: 0.917260
T Loss: 11.557011
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.900851
Epoch 99
Rec Loss: 1.900770
Epoch 149
Rec Loss: 1.896512
Epoch 199
Rec Loss: 1.905260
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.995145
Epoch 99
Rec Loss: 0.997296
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.668536
Insample Error: 2.439924
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.241929
Rec Loss: 16.052049
KL Loss: 1.189880
Y Loss: 5.828548
T Loss: 12.638013
X Loss: 0.499762
Epoch 99 
Overall Loss: 15.487423
Rec Loss: 14.111560
KL Loss: 1.375863
Y Loss: 2.601252
T Loss: 12.314756
X Loss: 0.496178
Epoch 149 
Overall Loss: 14.890623
Rec Loss: 13.418813
KL Loss: 1.471810
Y Loss: 2.040686
T Loss: 11.921712
X Loss: 0.476758
Epoch 199 
Overall Loss: 14.509911
Rec Loss: 13.007947
KL Loss: 1.501964
Y Loss: 1.711304
T Loss: 11.672598
X Loss: 0.479697
Epoch 249 
Overall Loss: 14.352634
Rec Loss: 12.863274
KL Loss: 1.489360
Y Loss: 1.506305
T Loss: 11.634329
X Loss: 0.475792
Epoch 299 
Overall Loss: 14.233883
Rec Loss: 12.737796
KL Loss: 1.496088
Y Loss: 1.283246
T Loss: 11.626619
X Loss: 0.469554
Epoch 349 
Overall Loss: 14.195435
Rec Loss: 12.691363
KL Loss: 1.504071
Y Loss: 1.191988
T Loss: 11.632717
X Loss: 0.462653
Epoch 399 
Overall Loss: 14.110711
Rec Loss: 12.621367
KL Loss: 1.489345
Y Loss: 1.118847
T Loss: 11.606668
X Loss: 0.455276
Epoch 449 
Overall Loss: 14.059782
Rec Loss: 12.588547
KL Loss: 1.471235
Y Loss: 1.043934
T Loss: 11.612298
X Loss: 0.454282
Epoch 499 
Overall Loss: 13.990907
Rec Loss: 12.549580
KL Loss: 1.441327
Y Loss: 0.992120
T Loss: 11.601418
X Loss: 0.452102
Epoch 549 
Overall Loss: 13.909786
Rec Loss: 12.495194
KL Loss: 1.414593
Y Loss: 0.962699
T Loss: 11.555142
X Loss: 0.458702
Epoch 599 
Overall Loss: 13.853729
Rec Loss: 12.448384
KL Loss: 1.405345
Y Loss: 0.905332
T Loss: 11.533074
X Loss: 0.462643
Epoch 649 
Overall Loss: 13.859768
Rec Loss: 12.461044
KL Loss: 1.398724
Y Loss: 0.896090
T Loss: 11.539795
X Loss: 0.473204
Epoch 699 
Overall Loss: 13.830455
Rec Loss: 12.432153
KL Loss: 1.398302
Y Loss: 0.887233
T Loss: 11.515632
X Loss: 0.472905
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.885544
Epoch 99
Rec Loss: 1.887712
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.952106
Epoch 99
Rec Loss: 0.945233
Epoch 149
Rec Loss: 0.955547
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.652743
Insample Error 2.212103
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.588296
Rec Loss: 15.408032
KL Loss: 1.180264
Y Loss: 5.717338
T Loss: 12.549364
Epoch 99 
Overall Loss: 14.628934
Rec Loss: 13.338185
KL Loss: 1.290749
Y Loss: 1.949966
T Loss: 12.363202
Epoch 149 
Overall Loss: 13.980989
Rec Loss: 12.688341
KL Loss: 1.292648
Y Loss: 1.222960
T Loss: 12.076861
Epoch 199 
Overall Loss: 13.735676
Rec Loss: 12.390887
KL Loss: 1.344789
Y Loss: 1.003813
T Loss: 11.888980
Epoch 249 
Overall Loss: 13.587427
Rec Loss: 12.226342
KL Loss: 1.361084
Y Loss: 0.965168
T Loss: 11.743758
Epoch 299 
Overall Loss: 13.492435
Rec Loss: 12.109294
KL Loss: 1.383141
Y Loss: 0.930033
T Loss: 11.644278
Epoch 349 
Overall Loss: 13.457986
Rec Loss: 12.068378
KL Loss: 1.389608
Y Loss: 0.941877
T Loss: 11.597439
Epoch 399 
Overall Loss: 13.426782
Rec Loss: 12.033469
KL Loss: 1.393313
Y Loss: 0.919257
T Loss: 11.573841
Epoch 449 
Overall Loss: 13.416903
Rec Loss: 12.029063
KL Loss: 1.387840
Y Loss: 0.949866
T Loss: 11.554130
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.898093
Epoch 99
Rec Loss: 1.900592
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.996357
Epoch 99
Rec Loss: 0.995270
Epoch 149
Rec Loss: 0.994496
Epoch 199
Rec Loss: 0.995631
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.682195
Insample Error: 2.488517
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.013243
Rec Loss: 15.738413
KL Loss: 1.274830
Y Loss: 5.262441
T Loss: 12.608219
X Loss: 0.498973
Epoch 99 
Overall Loss: 15.413048
Rec Loss: 13.985687
KL Loss: 1.427362
Y Loss: 2.351025
T Loss: 12.315118
X Loss: 0.495057
Epoch 149 
Overall Loss: 15.016958
Rec Loss: 13.470330
KL Loss: 1.546627
Y Loss: 2.048757
T Loss: 11.967139
X Loss: 0.478813
Epoch 199 
Overall Loss: 14.635680
Rec Loss: 13.026492
KL Loss: 1.609187
Y Loss: 1.737641
T Loss: 11.677133
X Loss: 0.480539
Epoch 249 
Overall Loss: 14.358159
Rec Loss: 12.746743
KL Loss: 1.611417
Y Loss: 1.395241
T Loss: 11.581524
X Loss: 0.467598
Epoch 299 
Overall Loss: 14.237657
Rec Loss: 12.628835
KL Loss: 1.608821
Y Loss: 1.231104
T Loss: 11.542261
X Loss: 0.471022
Epoch 349 
Overall Loss: 14.190533
Rec Loss: 12.629203
KL Loss: 1.561330
Y Loss: 1.165986
T Loss: 11.572622
X Loss: 0.473588
Epoch 399 
Overall Loss: 14.139853
Rec Loss: 12.613498
KL Loss: 1.526355
Y Loss: 1.100569
T Loss: 11.583967
X Loss: 0.479247
Epoch 449 
Overall Loss: 14.082351
Rec Loss: 12.581656
KL Loss: 1.500695
Y Loss: 1.014756
T Loss: 11.591776
X Loss: 0.482502
Epoch 499 
Overall Loss: 14.029489
Rec Loss: 12.568821
KL Loss: 1.460668
Y Loss: 0.984517
T Loss: 11.591888
X Loss: 0.484675
Epoch 549 
Overall Loss: 13.979727
Rec Loss: 12.571532
KL Loss: 1.408195
Y Loss: 0.996669
T Loss: 11.583932
X Loss: 0.489265
Epoch 599 
Overall Loss: 13.935214
Rec Loss: 12.555856
KL Loss: 1.379358
Y Loss: 0.962368
T Loss: 11.585966
X Loss: 0.488706
Epoch 649 
Overall Loss: 13.908563
Rec Loss: 12.538547
KL Loss: 1.370016
Y Loss: 0.937383
T Loss: 11.580311
X Loss: 0.489545
Epoch 699 
Overall Loss: 13.862900
Rec Loss: 12.508845
KL Loss: 1.354054
Y Loss: 0.909441
T Loss: 11.563178
X Loss: 0.490946
Epoch 749 
Overall Loss: 13.845279
Rec Loss: 12.499775
KL Loss: 1.345504
Y Loss: 0.925387
T Loss: 11.544834
X Loss: 0.492248
Epoch 799 
Overall Loss: 13.821222
Rec Loss: 12.483221
KL Loss: 1.338001
Y Loss: 0.903266
T Loss: 11.538726
X Loss: 0.492862
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.914845
Epoch 99
Rec Loss: 1.899464
Epoch 149
Rec Loss: 1.901856
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.988844
Epoch 99
Rec Loss: 0.985077
Epoch 149
Rec Loss: 0.986320
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.656172
Insample Error 2.165084
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.214363
Rec Loss: 14.997894
KL Loss: 1.216470
Y Loss: 5.050237
T Loss: 12.472775
Epoch 99 
Overall Loss: 14.273067
Rec Loss: 12.952576
KL Loss: 1.320491
Y Loss: 1.475124
T Loss: 12.215014
Epoch 149 
Overall Loss: 13.884811
Rec Loss: 12.554274
KL Loss: 1.330538
Y Loss: 1.013278
T Loss: 12.047635
Epoch 199 
Overall Loss: 13.726233
Rec Loss: 12.363108
KL Loss: 1.363124
Y Loss: 0.953405
T Loss: 11.886406
Epoch 249 
Overall Loss: 13.589642
Rec Loss: 12.206013
KL Loss: 1.383630
Y Loss: 0.929079
T Loss: 11.741473
Epoch 299 
Overall Loss: 13.519534
Rec Loss: 12.107526
KL Loss: 1.412008
Y Loss: 0.891404
T Loss: 11.661824
Epoch 349 
Overall Loss: 13.477146
Rec Loss: 12.069197
KL Loss: 1.407950
Y Loss: 0.897460
T Loss: 11.620467
Epoch 399 
Overall Loss: 13.447690
Rec Loss: 12.036995
KL Loss: 1.410694
Y Loss: 0.898370
T Loss: 11.587811
Epoch 449 
Overall Loss: 13.418560
Rec Loss: 12.015315
KL Loss: 1.403246
Y Loss: 0.930049
T Loss: 11.550290
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.905154
Epoch 99
Rec Loss: 1.913449
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.994195
Epoch 99
Rec Loss: 0.990481
Epoch 149
Rec Loss: 0.993725
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.662002
Insample Error: 2.482158
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.256511
Rec Loss: 16.134469
KL Loss: 1.122041
Y Loss: 6.105265
T Loss: 12.585647
X Loss: 0.496190
Epoch 99 
Overall Loss: 15.454836
Rec Loss: 14.078172
KL Loss: 1.376664
Y Loss: 2.621350
T Loss: 12.294385
X Loss: 0.473112
Epoch 149 
Overall Loss: 14.772415
Rec Loss: 12.971043
KL Loss: 1.801372
Y Loss: 1.841407
T Loss: 12.017829
X Loss: 0.032511
Epoch 199 
Overall Loss: 14.431627
Rec Loss: 12.217459
KL Loss: 2.214167
Y Loss: 1.481088
T Loss: 11.837763
X Loss: -0.360848
Epoch 249 
Overall Loss: 14.274642
Rec Loss: 11.869423
KL Loss: 2.405219
Y Loss: 1.291724
T Loss: 11.739277
X Loss: -0.515716
Epoch 299 
Overall Loss: 14.209413
Rec Loss: 11.718750
KL Loss: 2.490663
Y Loss: 1.228065
T Loss: 11.690062
X Loss: -0.585345
Epoch 349 
Overall Loss: 14.128703
Rec Loss: 11.591611
KL Loss: 2.537092
Y Loss: 1.104851
T Loss: 11.666953
X Loss: -0.627767
Epoch 399 
Overall Loss: 14.046110
Rec Loss: 11.507366
KL Loss: 2.538744
Y Loss: 1.059412
T Loss: 11.630732
X Loss: -0.653071
Epoch 449 
Overall Loss: 13.997306
Rec Loss: 11.450543
KL Loss: 2.546762
Y Loss: 1.013229
T Loss: 11.602663
X Loss: -0.658734
Epoch 499 
Overall Loss: 13.955907
Rec Loss: 11.406717
KL Loss: 2.549190
Y Loss: 1.005688
T Loss: 11.576744
X Loss: -0.672871
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.918826
Epoch 99
Rec Loss: 1.928223
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.099288
Epoch 99
Rec Loss: 0.097600
Epoch 149
Rec Loss: 0.092425
Epoch 199
Rec Loss: 0.094976
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.683164
Insample Error 2.183250
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.866028
Rec Loss: 15.744574
KL Loss: 1.121454
Y Loss: 6.475044
T Loss: 12.507052
Epoch 99 
Overall Loss: 14.793106
Rec Loss: 13.446886
KL Loss: 1.346220
Y Loss: 2.442889
T Loss: 12.225441
Epoch 149 
Overall Loss: 14.043900
Rec Loss: 12.696673
KL Loss: 1.347227
Y Loss: 1.411743
T Loss: 11.990801
Epoch 199 
Overall Loss: 13.721602
Rec Loss: 12.335150
KL Loss: 1.386452
Y Loss: 1.046818
T Loss: 11.811741
Epoch 249 
Overall Loss: 13.581214
Rec Loss: 12.193422
KL Loss: 1.387792
Y Loss: 0.968086
T Loss: 11.709379
Epoch 299 
Overall Loss: 13.501407
Rec Loss: 12.115718
KL Loss: 1.385689
Y Loss: 0.972278
T Loss: 11.629579
Epoch 349 
Overall Loss: 13.450400
Rec Loss: 12.076990
KL Loss: 1.373410
Y Loss: 0.955334
T Loss: 11.599323
Epoch 399 
Overall Loss: 13.412426
Rec Loss: 12.024308
KL Loss: 1.388118
Y Loss: 0.905717
T Loss: 11.571450
Epoch 449 
Overall Loss: 13.389725
Rec Loss: 12.005170
KL Loss: 1.384554
Y Loss: 0.914462
T Loss: 11.547940
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.896803
Epoch 99
Rec Loss: 1.898579
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.994575
Epoch 99
Rec Loss: 0.995246
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.661537
Insample Error: 2.392860
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.478696
Rec Loss: 16.415389
KL Loss: 1.063306
Y Loss: 6.580494
T Loss: 12.629657
X Loss: 0.495485
Epoch 99 
Overall Loss: 15.450638
Rec Loss: 14.040420
KL Loss: 1.410218
Y Loss: 2.731509
T Loss: 12.178453
X Loss: 0.496213
Epoch 149 
Overall Loss: 14.693337
Rec Loss: 13.124625
KL Loss: 1.568712
Y Loss: 1.922618
T Loss: 11.667297
X Loss: 0.496019
Epoch 199 
Overall Loss: 14.458787
Rec Loss: 12.912399
KL Loss: 1.546389
Y Loss: 1.633563
T Loss: 11.600357
X Loss: 0.495260
Epoch 249 
Overall Loss: 14.320493
Rec Loss: 12.769661
KL Loss: 1.550832
Y Loss: 1.387181
T Loss: 11.586626
X Loss: 0.489444
Epoch 299 
Overall Loss: 14.237361
Rec Loss: 12.676568
KL Loss: 1.560793
Y Loss: 1.237275
T Loss: 11.567571
X Loss: 0.490359
Epoch 349 
Overall Loss: 14.172232
Rec Loss: 12.621207
KL Loss: 1.551025
Y Loss: 1.107931
T Loss: 11.576954
X Loss: 0.490287
Epoch 399 
Overall Loss: 14.125012
Rec Loss: 12.610806
KL Loss: 1.514206
Y Loss: 1.072303
T Loss: 11.584210
X Loss: 0.490444
Epoch 449 
Overall Loss: 14.040682
Rec Loss: 12.575623
KL Loss: 1.465059
Y Loss: 1.020766
T Loss: 11.573918
X Loss: 0.491322
Epoch 499 
Overall Loss: 13.964332
Rec Loss: 12.548048
KL Loss: 1.416284
Y Loss: 0.979009
T Loss: 11.565298
X Loss: 0.493245
Epoch 549 
Overall Loss: 13.930449
Rec Loss: 12.545760
KL Loss: 1.384688
Y Loss: 0.955514
T Loss: 11.573007
X Loss: 0.494996
Epoch 599 
Overall Loss: 13.885024
Rec Loss: 12.507880
KL Loss: 1.377144
Y Loss: 0.917253
T Loss: 11.554396
X Loss: 0.494857
Epoch 649 
Overall Loss: 13.862099
Rec Loss: 12.493453
KL Loss: 1.368646
Y Loss: 0.905086
T Loss: 11.545496
X Loss: 0.495414
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.905946
Epoch 99
Rec Loss: 1.915156
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.990503
Epoch 99
Rec Loss: 0.990630
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.678723
Insample Error 2.220509
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.694811
Rec Loss: 15.519666
KL Loss: 1.175145
Y Loss: 5.875797
T Loss: 12.581767
Epoch 99 
Overall Loss: 14.621487
Rec Loss: 13.312024
KL Loss: 1.309464
Y Loss: 1.895003
T Loss: 12.364522
Epoch 149 
Overall Loss: 14.007940
Rec Loss: 12.681220
KL Loss: 1.326720
Y Loss: 1.129926
T Loss: 12.116257
Epoch 199 
Overall Loss: 13.716937
Rec Loss: 12.360031
KL Loss: 1.356907
Y Loss: 0.900985
T Loss: 11.909538
Epoch 249 
Overall Loss: 13.556782
Rec Loss: 12.180610
KL Loss: 1.376172
Y Loss: 0.870898
T Loss: 11.745161
Epoch 299 
Overall Loss: 13.500384
Rec Loss: 12.114425
KL Loss: 1.385959
Y Loss: 0.911776
T Loss: 11.658537
Epoch 349 
Overall Loss: 13.466366
Rec Loss: 12.080329
KL Loss: 1.386037
Y Loss: 0.934653
T Loss: 11.613002
Epoch 399 
Overall Loss: 13.432956
Rec Loss: 12.051433
KL Loss: 1.381523
Y Loss: 0.948298
T Loss: 11.577284
Epoch 449 
Overall Loss: 13.390766
Rec Loss: 12.000358
KL Loss: 1.390408
Y Loss: 0.912883
T Loss: 11.543917
Epoch 499 
Overall Loss: 13.377907
Rec Loss: 11.975527
KL Loss: 1.402380
Y Loss: 0.901282
T Loss: 11.524886
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.888789
Epoch 99
Rec Loss: 1.898075
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.995888
Epoch 99
Rec Loss: 0.994597
Epoch 149
Rec Loss: 0.994593
Epoch 199
Rec Loss: 0.994265
Epoch 249
Rec Loss: 0.995300
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.659202
Insample Error: 2.471206
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.146391
Rec Loss: 15.954895
KL Loss: 1.191496
Y Loss: 5.644373
T Loss: 12.636613
X Loss: 0.496095
Epoch 99 
Overall Loss: 15.551627
Rec Loss: 14.199492
KL Loss: 1.352135
Y Loss: 2.669209
T Loss: 12.371156
X Loss: 0.493732
Epoch 149 
Overall Loss: 14.973200
Rec Loss: 13.545260
KL Loss: 1.427939
Y Loss: 2.142495
T Loss: 11.987305
X Loss: 0.486707
Epoch 199 
Overall Loss: 14.517654
Rec Loss: 13.042073
KL Loss: 1.475582
Y Loss: 1.708195
T Loss: 11.711328
X Loss: 0.476647
Epoch 249 
Overall Loss: 14.282443
Rec Loss: 12.796959
KL Loss: 1.485484
Y Loss: 1.386842
T Loss: 11.644119
X Loss: 0.459420
Epoch 299 
Overall Loss: 14.201372
Rec Loss: 12.697047
KL Loss: 1.504326
Y Loss: 1.222953
T Loss: 11.633730
X Loss: 0.451840
Epoch 349 
Overall Loss: 14.132989
Rec Loss: 12.628851
KL Loss: 1.504138
Y Loss: 1.118410
T Loss: 11.621741
X Loss: 0.447905
Epoch 399 
Overall Loss: 14.048796
Rec Loss: 12.563589
KL Loss: 1.485207
Y Loss: 1.029092
T Loss: 11.600191
X Loss: 0.448852
Epoch 449 
Overall Loss: 13.970437
Rec Loss: 12.520998
KL Loss: 1.449439
Y Loss: 0.967426
T Loss: 11.586122
X Loss: 0.451163
Epoch 499 
Overall Loss: 13.934519
Rec Loss: 12.501434
KL Loss: 1.433085
Y Loss: 0.942246
T Loss: 11.572809
X Loss: 0.457501
Epoch 549 
Overall Loss: 13.883645
Rec Loss: 12.472043
KL Loss: 1.411602
Y Loss: 0.919748
T Loss: 11.548756
X Loss: 0.463412
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.910848
Epoch 99
Rec Loss: 1.905711
Epoch 149
Rec Loss: 1.910960
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.937283
Epoch 99
Rec Loss: 0.939797
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.664399
Insample Error 2.229823
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.358532
Rec Loss: 15.048659
KL Loss: 1.309873
Y Loss: 5.115091
T Loss: 12.491114
Epoch 99 
Overall Loss: 14.645565
Rec Loss: 13.272793
KL Loss: 1.372772
Y Loss: 1.989928
T Loss: 12.277829
Epoch 149 
Overall Loss: 13.972370
Rec Loss: 12.644997
KL Loss: 1.327372
Y Loss: 1.224095
T Loss: 12.032950
Epoch 199 
Overall Loss: 13.721491
Rec Loss: 12.371071
KL Loss: 1.350421
Y Loss: 0.954028
T Loss: 11.894056
Epoch 249 
Overall Loss: 13.577106
Rec Loss: 12.197771
KL Loss: 1.379335
Y Loss: 0.909484
T Loss: 11.743029
Epoch 299 
Overall Loss: 13.520309
Rec Loss: 12.130532
KL Loss: 1.389778
Y Loss: 0.905817
T Loss: 11.677623
Epoch 349 
Overall Loss: 13.462236
Rec Loss: 12.060764
KL Loss: 1.401472
Y Loss: 0.905732
T Loss: 11.607898
Epoch 399 
Overall Loss: 13.419427
Rec Loss: 12.026958
KL Loss: 1.392469
Y Loss: 0.900259
T Loss: 11.576828
Epoch 449 
Overall Loss: 13.395434
Rec Loss: 12.005738
KL Loss: 1.389695
Y Loss: 0.909298
T Loss: 11.551089
Epoch 499 
Overall Loss: 13.363041
Rec Loss: 11.963883
KL Loss: 1.399157
Y Loss: 0.890551
T Loss: 11.518608
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.893198
Epoch 99
Rec Loss: 1.897031
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.996187
Epoch 99
Rec Loss: 0.993469
Epoch 149
Rec Loss: 0.994210
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.647405
Insample Error: 2.392640
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.136114
Rec Loss: 15.957417
KL Loss: 1.178697
Y Loss: 5.863757
T Loss: 12.527084
X Loss: 0.498454
Epoch 99 
Overall Loss: 15.196516
Rec Loss: 13.781431
KL Loss: 1.415085
Y Loss: 2.256612
T Loss: 12.156714
X Loss: 0.496411
Epoch 149 
Overall Loss: 14.640250
Rec Loss: 13.161534
KL Loss: 1.478716
Y Loss: 1.833854
T Loss: 11.749526
X Loss: 0.495081
Epoch 199 
Overall Loss: 14.410439
Rec Loss: 12.918432
KL Loss: 1.492008
Y Loss: 1.538315
T Loss: 11.655111
X Loss: 0.494163
Epoch 249 
Overall Loss: 14.305278
Rec Loss: 12.826856
KL Loss: 1.478422
Y Loss: 1.381033
T Loss: 11.642197
X Loss: 0.494142
Epoch 299 
Overall Loss: 14.232283
Rec Loss: 12.755955
KL Loss: 1.476328
Y Loss: 1.239805
T Loss: 11.643116
X Loss: 0.492936
Epoch 349 
Overall Loss: 14.178613
Rec Loss: 12.688431
KL Loss: 1.490181
Y Loss: 1.136480
T Loss: 11.628830
X Loss: 0.491362
Epoch 399 
Overall Loss: 14.120779
Rec Loss: 12.643253
KL Loss: 1.477526
Y Loss: 1.046029
T Loss: 11.625638
X Loss: 0.494600
Epoch 449 
Overall Loss: 14.047494
Rec Loss: 12.618604
KL Loss: 1.428891
Y Loss: 1.025701
T Loss: 11.612129
X Loss: 0.493624
Epoch 499 
Overall Loss: 13.988459
Rec Loss: 12.579907
KL Loss: 1.408553
Y Loss: 0.985751
T Loss: 11.591958
X Loss: 0.495073
Epoch 549 
Overall Loss: 13.924825
Rec Loss: 12.532903
KL Loss: 1.391922
Y Loss: 0.929258
T Loss: 11.573764
X Loss: 0.494510
Epoch 599 
Overall Loss: 13.904098
Rec Loss: 12.536042
KL Loss: 1.368056
Y Loss: 0.928937
T Loss: 11.576426
X Loss: 0.495147
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.937662
Epoch 99
Rec Loss: 1.926302
Epoch 149
Rec Loss: 1.929224
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.992070
Epoch 99
Rec Loss: 0.990953
Epoch 149
Rec Loss: 0.986273
Epoch 199
Rec Loss: 0.989875
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.662137
Insample Error 2.268928
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.816755
Rec Loss: 14.516932
KL Loss: 1.299822
Y Loss: 3.939918
T Loss: 12.546974
Epoch 99 
Overall Loss: 14.312439
Rec Loss: 13.021333
KL Loss: 1.291105
Y Loss: 1.632926
T Loss: 12.204871
Epoch 149 
Overall Loss: 13.907933
Rec Loss: 12.574477
KL Loss: 1.333457
Y Loss: 1.106613
T Loss: 12.021170
Epoch 199 
Overall Loss: 13.718120
Rec Loss: 12.352825
KL Loss: 1.365295
Y Loss: 0.988407
T Loss: 11.858622
Epoch 249 
Overall Loss: 13.595344
Rec Loss: 12.211992
KL Loss: 1.383352
Y Loss: 0.926028
T Loss: 11.748978
Epoch 299 
Overall Loss: 13.527454
Rec Loss: 12.131799
KL Loss: 1.395655
Y Loss: 0.903395
T Loss: 11.680102
Epoch 349 
Overall Loss: 13.482828
Rec Loss: 12.085404
KL Loss: 1.397424
Y Loss: 0.902178
T Loss: 11.634314
Epoch 399 
Overall Loss: 13.444234
Rec Loss: 12.046012
KL Loss: 1.398222
Y Loss: 0.914351
T Loss: 11.588836
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.912464
Epoch 99
Rec Loss: 1.914362
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.996421
Epoch 99
Rec Loss: 0.996022
Epoch 149
Rec Loss: 0.995964
Epoch 199
Rec Loss: 0.995752
Epoch 249
Rec Loss: 0.996573
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.656230
Insample Error: 2.384545
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 16.835888
Rec Loss: 15.559917
KL Loss: 1.275971
Y Loss: 4.914230
T Loss: 12.604468
X Loss: 0.498334
Epoch 99 
Overall Loss: 15.428548
Rec Loss: 14.081048
KL Loss: 1.347500
Y Loss: 2.405723
T Loss: 12.385013
X Loss: 0.493173
Epoch 149 
Overall Loss: 14.938931
Rec Loss: 13.451568
KL Loss: 1.487363
Y Loss: 1.869950
T Loss: 12.182170
X Loss: 0.334422
Epoch 199 
Overall Loss: 14.486515
Rec Loss: 12.471274
KL Loss: 2.015241
Y Loss: 1.496165
T Loss: 11.960297
X Loss: -0.237106
Epoch 249 
Overall Loss: 14.283540
Rec Loss: 11.983037
KL Loss: 2.300504
Y Loss: 1.326820
T Loss: 11.802963
X Loss: -0.483336
Epoch 299 
Overall Loss: 14.196374
Rec Loss: 11.764151
KL Loss: 2.432223
Y Loss: 1.215147
T Loss: 11.728169
X Loss: -0.571592
Epoch 349 
Overall Loss: 14.098973
Rec Loss: 11.615143
KL Loss: 2.483829
Y Loss: 1.107792
T Loss: 11.683157
X Loss: -0.621910
Epoch 399 
Overall Loss: 14.016019
Rec Loss: 11.529335
KL Loss: 2.486685
Y Loss: 1.046194
T Loss: 11.631904
X Loss: -0.625666
Epoch 449 
Overall Loss: 13.965162
Rec Loss: 11.460331
KL Loss: 2.504832
Y Loss: 1.040180
T Loss: 11.604683
X Loss: -0.664443
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.940634
Epoch 99
Rec Loss: 1.926499
Epoch 149
Rec Loss: 1.937128
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.105366
Epoch 99
Rec Loss: 0.103287
Epoch 149
Rec Loss: 0.103918
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.741153
Insample Error 2.308552
Ours, Train RMSE
0.6661, 
0.6332, 
0.6667, 
0.6685, 
0.6822, 
0.6620, 
0.6615, 
0.6592, 
0.6474, 
0.6562, 
Ours, Insample RMSE
2.4825, 
2.3747, 
2.4843, 
2.4399, 
2.4885, 
2.4822, 
2.3929, 
2.4712, 
2.3926, 
2.3845, 
CEVAE, Insample RMSE
2.4296, 
2.1426, 
2.0313, 
2.2121, 
2.1651, 
2.1832, 
2.2205, 
2.2298, 
2.2689, 
2.3086, 
Train, RMSE mean 0.6603 std 0.0124
Ours, RMSE mean 2.4393 std 0.0455, reconstruct confounder 1.8954 (0.0086) noise 0.9944 (0.0015)
CEVAE, RMSE mean 2.2192 std 0.1002, reconstruct confounder 1.9112 (0.0266) noise 0.8016 (0.3524)
Experiment Start!, Ours obsx=0
Namespace(decay=0.0, l=5e-05, latdim=4, mask=9, nlayer=50, obsm=0, ycof=0.5, ylayer=50)
Y Mean 1.514292, Std 3.653528 
Observe confounder 0, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.018348
Rec Loss: 14.744347
KL Loss: 1.274001
Y Loss: 4.619460
T Loss: 12.434617
Epoch 99 
Overall Loss: 14.512020
Rec Loss: 13.188161
KL Loss: 1.323859
Y Loss: 1.759065
T Loss: 12.308628
Epoch 149 
Overall Loss: 14.009634
Rec Loss: 12.688882
KL Loss: 1.320752
Y Loss: 1.142208
T Loss: 12.117778
Epoch 199 
Overall Loss: 13.773464
Rec Loss: 12.420379
KL Loss: 1.353086
Y Loss: 0.934884
T Loss: 11.952937
Epoch 249 
Overall Loss: 13.624533
Rec Loss: 12.245626
KL Loss: 1.378907
Y Loss: 0.877305
T Loss: 11.806973
Epoch 299 
Overall Loss: 13.548021
Rec Loss: 12.151324
KL Loss: 1.396697
Y Loss: 0.898992
T Loss: 11.701828
Epoch 349 
Overall Loss: 13.490900
Rec Loss: 12.094972
KL Loss: 1.395928
Y Loss: 0.910132
T Loss: 11.639906
Epoch 399 
Overall Loss: 13.432177
Rec Loss: 12.038931
KL Loss: 1.393247
Y Loss: 0.908737
T Loss: 11.584562
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.906412
Epoch 99
Rec Loss: 1.898482
Epoch 149
Rec Loss: 1.895254
Epoch 199
Rec Loss: 1.901880
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000007
Epoch 99
Rec Loss: 0.000003
Epoch 149
Rec Loss: 0.000001
Epoch 199
Rec Loss: 0.000001
Epoch 249
Rec Loss: 0.000000
Epoch 299
Rec Loss: 0.000000
Epoch 349
Rec Loss: 0.000000
Epoch 399
Rec Loss: 0.000000
Epoch 449
Rec Loss: 0.000002
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.656254
Insample Error: 2.517326
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.714198
Rec Loss: 16.774659
KL Loss: 0.939539
Y Loss: 7.178563
T Loss: 12.690011
X Loss: 0.495366
Epoch 99 
Overall Loss: 15.576266
Rec Loss: 14.246091
KL Loss: 1.330175
Y Loss: 2.906059
T Loss: 12.322123
X Loss: 0.470939
Epoch 149 
Overall Loss: 14.851805
Rec Loss: 13.307475
KL Loss: 1.544330
Y Loss: 2.002204
T Loss: 11.905467
X Loss: 0.400906
Epoch 199 
Overall Loss: 14.474342
Rec Loss: 12.835095
KL Loss: 1.639246
Y Loss: 1.532429
T Loss: 11.607108
X Loss: 0.461773
Epoch 249 
Overall Loss: 14.314501
Rec Loss: 12.658273
KL Loss: 1.656228
Y Loss: 1.273903
T Loss: 11.556194
X Loss: 0.465128
Epoch 299 
Overall Loss: 14.239330
Rec Loss: 12.602485
KL Loss: 1.636845
Y Loss: 1.173541
T Loss: 11.544661
X Loss: 0.471053
Epoch 349 
Overall Loss: 14.193248
Rec Loss: 12.573002
KL Loss: 1.620246
Y Loss: 1.098954
T Loss: 11.544430
X Loss: 0.479094
Epoch 399 
Overall Loss: 14.159532
Rec Loss: 12.565810
KL Loss: 1.593721
Y Loss: 1.051213
T Loss: 11.561811
X Loss: 0.478393
Epoch 449 
Overall Loss: 14.124180
Rec Loss: 12.586963
KL Loss: 1.537217
Y Loss: 1.075435
T Loss: 11.568770
X Loss: 0.480475
Epoch 499 
Overall Loss: 14.064616
Rec Loss: 12.554153
KL Loss: 1.510463
Y Loss: 1.014588
T Loss: 11.566042
X Loss: 0.480816
Epoch 549 
Overall Loss: 14.032664
Rec Loss: 12.548632
KL Loss: 1.484031
Y Loss: 0.998564
T Loss: 11.563145
X Loss: 0.486205
Epoch 599 
Overall Loss: 13.986766
Rec Loss: 12.547974
KL Loss: 1.438792
Y Loss: 0.986982
T Loss: 11.569296
X Loss: 0.485187
Epoch 649 
Overall Loss: 13.958432
Rec Loss: 12.546060
KL Loss: 1.412372
Y Loss: 0.979632
T Loss: 11.567024
X Loss: 0.489219
Epoch 699 
Overall Loss: 13.916485
Rec Loss: 12.521900
KL Loss: 1.394584
Y Loss: 0.918516
T Loss: 11.574487
X Loss: 0.488155
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.962670
Epoch 99
Rec Loss: 1.978494
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.983148
Epoch 99
Rec Loss: 0.981577
Epoch 149
Rec Loss: 0.981421
Epoch 199
Rec Loss: 0.983256
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.674650
Insample Error 2.334467
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.126963
Rec Loss: 14.839603
KL Loss: 1.287360
Y Loss: 4.815328
T Loss: 12.431939
Epoch 99 
Overall Loss: 14.717986
Rec Loss: 13.313876
KL Loss: 1.404110
Y Loss: 1.949153
T Loss: 12.339299
Epoch 149 
Overall Loss: 13.959121
Rec Loss: 12.665002
KL Loss: 1.294119
Y Loss: 1.083039
T Loss: 12.123483
Epoch 199 
Overall Loss: 13.682299
Rec Loss: 12.347006
KL Loss: 1.335293
Y Loss: 0.846539
T Loss: 11.923737
Epoch 249 
Overall Loss: 13.552642
Rec Loss: 12.198361
KL Loss: 1.354281
Y Loss: 0.844506
T Loss: 11.776108
Epoch 299 
Overall Loss: 13.491103
Rec Loss: 12.115245
KL Loss: 1.375858
Y Loss: 0.875933
T Loss: 11.677278
Epoch 349 
Overall Loss: 13.419005
Rec Loss: 12.039861
KL Loss: 1.379144
Y Loss: 0.888766
T Loss: 11.595478
Epoch 399 
Overall Loss: 13.407181
Rec Loss: 12.021307
KL Loss: 1.385874
Y Loss: 0.890508
T Loss: 11.576053
Epoch 449 
Overall Loss: 13.381509
Rec Loss: 11.976990
KL Loss: 1.404519
Y Loss: 0.871961
T Loss: 11.541010
Epoch 499 
Overall Loss: 13.353373
Rec Loss: 11.943522
KL Loss: 1.409851
Y Loss: 0.870035
T Loss: 11.508504
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.888453
Epoch 99
Rec Loss: 1.880593
Epoch 149
Rec Loss: 1.877564
Epoch 199
Rec Loss: 1.887595
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000003
Epoch 99
Rec Loss: 0.000001
Epoch 149
Rec Loss: 0.000000
Epoch 199
Rec Loss: 0.000000
Epoch 249
Rec Loss: 0.000000
Epoch 299
Rec Loss: 0.000000
Epoch 349
Rec Loss: 0.000000
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.635201
Insample Error: 2.434350
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.089868
Rec Loss: 15.846877
KL Loss: 1.242990
Y Loss: 5.625060
T Loss: 12.536290
X Loss: 0.498057
Epoch 99 
Overall Loss: 15.536561
Rec Loss: 14.120899
KL Loss: 1.415662
Y Loss: 2.578191
T Loss: 12.337827
X Loss: 0.493977
Epoch 149 
Overall Loss: 14.965667
Rec Loss: 13.493555
KL Loss: 1.472111
Y Loss: 2.036074
T Loss: 12.027363
X Loss: 0.448155
Epoch 199 
Overall Loss: 14.579103
Rec Loss: 12.970341
KL Loss: 1.608762
Y Loss: 1.753200
T Loss: 11.735752
X Loss: 0.357988
Epoch 249 
Overall Loss: 14.322603
Rec Loss: 12.628883
KL Loss: 1.693720
Y Loss: 1.482805
T Loss: 11.595456
X Loss: 0.292025
Epoch 299 
Overall Loss: 14.232654
Rec Loss: 12.564758
KL Loss: 1.667895
Y Loss: 1.316317
T Loss: 11.602184
X Loss: 0.304416
Epoch 349 
Overall Loss: 14.143344
Rec Loss: 12.505530
KL Loss: 1.637814
Y Loss: 1.211795
T Loss: 11.575163
X Loss: 0.324470
Epoch 399 
Overall Loss: 14.068618
Rec Loss: 12.509334
KL Loss: 1.559283
Y Loss: 1.137456
T Loss: 11.582778
X Loss: 0.357828
Epoch 449 
Overall Loss: 13.998097
Rec Loss: 12.507693
KL Loss: 1.490403
Y Loss: 1.049515
T Loss: 11.592579
X Loss: 0.390357
Epoch 499 
Overall Loss: 13.941992
Rec Loss: 12.499414
KL Loss: 1.442578
Y Loss: 1.010354
T Loss: 11.582019
X Loss: 0.412218
Epoch 549 
Overall Loss: 13.899781
Rec Loss: 12.475221
KL Loss: 1.424560
Y Loss: 0.986193
T Loss: 11.552657
X Loss: 0.429468
Epoch 599 
Overall Loss: 13.873112
Rec Loss: 12.475610
KL Loss: 1.397502
Y Loss: 0.965627
T Loss: 11.550419
X Loss: 0.442377
Epoch 649 
Overall Loss: 13.833755
Rec Loss: 12.451218
KL Loss: 1.382536
Y Loss: 0.932192
T Loss: 11.536056
X Loss: 0.449067
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.905915
Epoch 99
Rec Loss: 1.900388
Epoch 149
Rec Loss: 1.895384
Epoch 199
Rec Loss: 1.893307
Epoch 249
Rec Loss: 1.896729
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.917062
Epoch 99
Rec Loss: 0.911950
Epoch 149
Rec Loss: 0.911800
Epoch 199
Rec Loss: 0.920656
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.695116
Insample Error 2.274201
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.761394
Rec Loss: 14.595239
KL Loss: 1.166155
Y Loss: 4.259333
T Loss: 12.465572
Epoch 99 
Overall Loss: 14.184542
Rec Loss: 12.945264
KL Loss: 1.239278
Y Loss: 1.396945
T Loss: 12.246792
Epoch 149 
Overall Loss: 13.878015
Rec Loss: 12.587828
KL Loss: 1.290186
Y Loss: 0.975681
T Loss: 12.099988
Epoch 199 
Overall Loss: 13.697665
Rec Loss: 12.374236
KL Loss: 1.323429
Y Loss: 0.906140
T Loss: 11.921166
Epoch 249 
Overall Loss: 13.597849
Rec Loss: 12.245938
KL Loss: 1.351912
Y Loss: 0.878490
T Loss: 11.806693
Epoch 299 
Overall Loss: 13.515114
Rec Loss: 12.136834
KL Loss: 1.378281
Y Loss: 0.885696
T Loss: 11.693986
Epoch 349 
Overall Loss: 13.467644
Rec Loss: 12.076042
KL Loss: 1.391602
Y Loss: 0.886129
T Loss: 11.632977
Epoch 399 
Overall Loss: 13.427452
Rec Loss: 12.036041
KL Loss: 1.391410
Y Loss: 0.895770
T Loss: 11.588156
Epoch 449 
Overall Loss: 13.397134
Rec Loss: 11.996001
KL Loss: 1.401133
Y Loss: 0.896139
T Loss: 11.547932
Epoch 499 
Overall Loss: 13.375307
Rec Loss: 11.985232
KL Loss: 1.390074
Y Loss: 0.911068
T Loss: 11.529698
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.902382
Epoch 99
Rec Loss: 1.886541
Epoch 149
Rec Loss: 1.898627
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000005
Epoch 99
Rec Loss: 0.000001
Epoch 149
Rec Loss: 0.000001
Epoch 199
Rec Loss: 0.000000
Epoch 249
Rec Loss: 0.000002
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.656986
Insample Error: 2.463660
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.660970
Rec Loss: 16.668489
KL Loss: 0.992481
Y Loss: 7.069857
T Loss: 12.635039
X Loss: 0.498521
Epoch 99 
Overall Loss: 15.553756
Rec Loss: 14.167920
KL Loss: 1.385836
Y Loss: 3.052206
T Loss: 12.147692
X Loss: 0.494125
Epoch 149 
Overall Loss: 14.777748
Rec Loss: 13.159259
KL Loss: 1.618490
Y Loss: 2.065299
T Loss: 11.641337
X Loss: 0.485272
Epoch 199 
Overall Loss: 14.480207
Rec Loss: 12.823503
KL Loss: 1.656704
Y Loss: 1.639331
T Loss: 11.553456
X Loss: 0.450381
Epoch 249 
Overall Loss: 14.324233
Rec Loss: 12.624160
KL Loss: 1.700073
Y Loss: 1.357167
T Loss: 11.549795
X Loss: 0.395782
Epoch 299 
Overall Loss: 14.245021
Rec Loss: 12.533981
KL Loss: 1.711040
Y Loss: 1.236257
T Loss: 11.539367
X Loss: 0.376485
Epoch 349 
Overall Loss: 14.200655
Rec Loss: 12.506301
KL Loss: 1.694354
Y Loss: 1.133371
T Loss: 11.546615
X Loss: 0.392999
Epoch 399 
Overall Loss: 14.136620
Rec Loss: 12.503206
KL Loss: 1.633413
Y Loss: 1.115186
T Loss: 11.543268
X Loss: 0.402345
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.994334
Epoch 99
Rec Loss: 1.995974
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.825505
Epoch 99
Rec Loss: 0.823280
Epoch 149
Rec Loss: 0.811481
Epoch 199
Rec Loss: 0.827770
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.594841
Insample Error 2.557666
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.837653
Rec Loss: 15.822063
KL Loss: 1.015591
Y Loss: 6.772781
T Loss: 12.435672
Epoch 99 
Overall Loss: 14.320393
Rec Loss: 13.038378
KL Loss: 1.282015
Y Loss: 1.577346
T Loss: 12.249705
Epoch 149 
Overall Loss: 13.944910
Rec Loss: 12.639646
KL Loss: 1.305265
Y Loss: 1.025171
T Loss: 12.127060
Epoch 199 
Overall Loss: 13.737007
Rec Loss: 12.414604
KL Loss: 1.322403
Y Loss: 0.890195
T Loss: 11.969507
Epoch 249 
Overall Loss: 13.578021
Rec Loss: 12.226076
KL Loss: 1.351945
Y Loss: 0.808614
T Loss: 11.821769
Epoch 299 
Overall Loss: 13.507079
Rec Loss: 12.124023
KL Loss: 1.383057
Y Loss: 0.848996
T Loss: 11.699525
Epoch 349 
Overall Loss: 13.459391
Rec Loss: 12.069954
KL Loss: 1.389438
Y Loss: 0.874201
T Loss: 11.632853
Epoch 399 
Overall Loss: 13.409572
Rec Loss: 12.016843
KL Loss: 1.392729
Y Loss: 0.883592
T Loss: 11.575047
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.898158
Epoch 99
Rec Loss: 1.896849
Epoch 149
Rec Loss: 1.892958
Epoch 199
Rec Loss: 1.902256
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000013
Epoch 99
Rec Loss: 0.000004
Epoch 149
Rec Loss: 0.000002
Epoch 199
Rec Loss: 0.000001
Epoch 249
Rec Loss: 0.000001
Epoch 299
Rec Loss: 0.000000
Epoch 349
Rec Loss: 0.000000
Epoch 399
Rec Loss: 0.000000
Epoch 449
Rec Loss: 0.000000
Epoch 499
Rec Loss: 0.000000
Epoch 549
Rec Loss: 0.000000
Epoch 599
Rec Loss: 0.000000
Epoch 649
Rec Loss: 0.000002
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.645828
Insample Error: 2.472723
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 18.002908
Rec Loss: 17.154514
KL Loss: 0.848393
Y Loss: 7.758007
T Loss: 12.778574
X Loss: 0.496937
Epoch 99 
Overall Loss: 15.592215
Rec Loss: 14.225464
KL Loss: 1.366752
Y Loss: 2.915834
T Loss: 12.271590
X Loss: 0.495957
Epoch 149 
Overall Loss: 14.886510
Rec Loss: 13.380475
KL Loss: 1.506035
Y Loss: 2.111287
T Loss: 11.837237
X Loss: 0.487595
Epoch 199 
Overall Loss: 14.515829
Rec Loss: 12.977370
KL Loss: 1.538459
Y Loss: 1.695973
T Loss: 11.646689
X Loss: 0.482694
Epoch 249 
Overall Loss: 14.344617
Rec Loss: 12.827931
KL Loss: 1.516686
Y Loss: 1.450254
T Loss: 11.628156
X Loss: 0.474648
Epoch 299 
Overall Loss: 14.247108
Rec Loss: 12.732873
KL Loss: 1.514235
Y Loss: 1.248327
T Loss: 11.636171
X Loss: 0.472539
Epoch 349 
Overall Loss: 14.195026
Rec Loss: 12.685700
KL Loss: 1.509326
Y Loss: 1.162930
T Loss: 11.630916
X Loss: 0.473319
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.002466
Epoch 99
Rec Loss: 1.984373
Epoch 149
Rec Loss: 2.004135
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.947212
Epoch 99
Rec Loss: 0.943008
Epoch 149
Rec Loss: 0.946486
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.701321
Insample Error 2.247125
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.156276
Rec Loss: 14.938407
KL Loss: 1.217869
Y Loss: 4.901442
T Loss: 12.487686
Epoch 99 
Overall Loss: 14.414620
Rec Loss: 13.143641
KL Loss: 1.270979
Y Loss: 1.670449
T Loss: 12.308416
Epoch 149 
Overall Loss: 13.925061
Rec Loss: 12.643239
KL Loss: 1.281822
Y Loss: 1.090030
T Loss: 12.098224
Epoch 199 
Overall Loss: 13.727569
Rec Loss: 12.400200
KL Loss: 1.327369
Y Loss: 0.911888
T Loss: 11.944256
Epoch 249 
Overall Loss: 13.592150
Rec Loss: 12.252139
KL Loss: 1.340012
Y Loss: 0.891927
T Loss: 11.806175
Epoch 299 
Overall Loss: 13.497935
Rec Loss: 12.131309
KL Loss: 1.366626
Y Loss: 0.877622
T Loss: 11.692498
Epoch 349 
Overall Loss: 13.466163
Rec Loss: 12.083880
KL Loss: 1.382283
Y Loss: 0.907382
T Loss: 11.630189
Epoch 399 
Overall Loss: 13.436426
Rec Loss: 12.044153
KL Loss: 1.392273
Y Loss: 0.897327
T Loss: 11.595490
Epoch 449 
Overall Loss: 13.427426
Rec Loss: 12.034687
KL Loss: 1.392739
Y Loss: 0.936142
T Loss: 11.566616
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.897182
Epoch 99
Rec Loss: 1.899810
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000001
Epoch 99
Rec Loss: 0.000001
Epoch 149
Rec Loss: 0.000000
Epoch 199
Rec Loss: 0.000000
Epoch 249
Rec Loss: 0.000000
Epoch 299
Rec Loss: 0.000000
Epoch 349
Rec Loss: 0.000000
Epoch 399
Rec Loss: 0.000000
Epoch 449
Rec Loss: 0.000000
Epoch 499
Rec Loss: 0.000000
Epoch 549
Rec Loss: 0.000000
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.666924
Insample Error: 2.517391
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.307043
Rec Loss: 16.135232
KL Loss: 1.171811
Y Loss: 5.959851
T Loss: 12.656857
X Loss: 0.498450
Epoch 99 
Overall Loss: 15.388219
Rec Loss: 13.950919
KL Loss: 1.437301
Y Loss: 2.315778
T Loss: 12.297938
X Loss: 0.495092
Epoch 149 
Overall Loss: 14.663843
Rec Loss: 13.098388
KL Loss: 1.565455
Y Loss: 1.695644
T Loss: 11.772652
X Loss: 0.477915
Epoch 199 
Overall Loss: 14.404448
Rec Loss: 12.805616
KL Loss: 1.598833
Y Loss: 1.421135
T Loss: 11.602116
X Loss: 0.492932
Epoch 249 
Overall Loss: 14.290123
Rec Loss: 12.695131
KL Loss: 1.594992
Y Loss: 1.272029
T Loss: 11.563020
X Loss: 0.496096
Epoch 299 
Overall Loss: 14.204342
Rec Loss: 12.629941
KL Loss: 1.574401
Y Loss: 1.192237
T Loss: 11.536728
X Loss: 0.497094
Epoch 349 
Overall Loss: 14.169818
Rec Loss: 12.628368
KL Loss: 1.541450
Y Loss: 1.151187
T Loss: 11.556228
X Loss: 0.496547
Epoch 399 
Overall Loss: 14.157253
Rec Loss: 12.624191
KL Loss: 1.533063
Y Loss: 1.094484
T Loss: 11.579537
X Loss: 0.497412
Epoch 449 
Overall Loss: 14.084769
Rec Loss: 12.581098
KL Loss: 1.503671
Y Loss: 1.033915
T Loss: 11.567551
X Loss: 0.496590
Epoch 499 
Overall Loss: 14.041888
Rec Loss: 12.575333
KL Loss: 1.466555
Y Loss: 0.987386
T Loss: 11.585217
X Loss: 0.496423
Epoch 549 
Overall Loss: 14.006888
Rec Loss: 12.571569
KL Loss: 1.435319
Y Loss: 0.966248
T Loss: 11.591172
X Loss: 0.497273
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.981565
Epoch 99
Rec Loss: 1.988214
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.991951
Epoch 99
Rec Loss: 0.993676
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.654546
Insample Error 2.327580
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.801669
Rec Loss: 14.625252
KL Loss: 1.176416
Y Loss: 4.423738
T Loss: 12.413383
Epoch 99 
Overall Loss: 14.160511
Rec Loss: 12.866711
KL Loss: 1.293800
Y Loss: 1.301173
T Loss: 12.216125
Epoch 149 
Overall Loss: 13.869872
Rec Loss: 12.549809
KL Loss: 1.320063
Y Loss: 0.936952
T Loss: 12.081333
Epoch 199 
Overall Loss: 13.728253
Rec Loss: 12.386377
KL Loss: 1.341876
Y Loss: 0.893097
T Loss: 11.939828
Epoch 249 
Overall Loss: 13.588572
Rec Loss: 12.230349
KL Loss: 1.358223
Y Loss: 0.875018
T Loss: 11.792839
Epoch 299 
Overall Loss: 13.515528
Rec Loss: 12.120865
KL Loss: 1.394663
Y Loss: 0.851401
T Loss: 11.695165
Epoch 349 
Overall Loss: 13.475324
Rec Loss: 12.075590
KL Loss: 1.399734
Y Loss: 0.875421
T Loss: 11.637880
Epoch 399 
Overall Loss: 13.446161
Rec Loss: 12.035811
KL Loss: 1.410349
Y Loss: 0.879737
T Loss: 11.595943
Epoch 449 
Overall Loss: 13.415408
Rec Loss: 12.009068
KL Loss: 1.406340
Y Loss: 0.912213
T Loss: 11.552961
Epoch 499 
Overall Loss: 13.387086
Rec Loss: 11.976208
KL Loss: 1.410879
Y Loss: 0.888397
T Loss: 11.532009
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.904138
Epoch 99
Rec Loss: 1.898328
Epoch 149
Rec Loss: 1.892403
Epoch 199
Rec Loss: 1.890463
Epoch 249
Rec Loss: 1.904389
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000019
Epoch 99
Rec Loss: 0.000004
Epoch 149
Rec Loss: 0.000002
Epoch 199
Rec Loss: 0.000001
Epoch 249
Rec Loss: 0.000001
Epoch 299
Rec Loss: 0.000001
Epoch 349
Rec Loss: 0.000000
Epoch 399
Rec Loss: 0.000000
Epoch 449
Rec Loss: 0.000000
Epoch 499
Rec Loss: 0.000003
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.644490
Insample Error: 2.474941
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.318477
Rec Loss: 16.097439
KL Loss: 1.221039
Y Loss: 6.006657
T Loss: 12.596011
X Loss: 0.498100
Epoch 99 
Overall Loss: 15.322549
Rec Loss: 13.856433
KL Loss: 1.466116
Y Loss: 2.271925
T Loss: 12.239480
X Loss: 0.480991
Epoch 149 
Overall Loss: 14.770877
Rec Loss: 13.134230
KL Loss: 1.636647
Y Loss: 1.848652
T Loss: 11.821354
X Loss: 0.388550
Epoch 199 
Overall Loss: 14.455491
Rec Loss: 12.522129
KL Loss: 1.933361
Y Loss: 1.493786
T Loss: 11.630970
X Loss: 0.144266
Epoch 249 
Overall Loss: 14.302687
Rec Loss: 12.220698
KL Loss: 2.081989
Y Loss: 1.290906
T Loss: 11.580538
X Loss: -0.005293
Epoch 299 
Overall Loss: 14.243778
Rec Loss: 12.141447
KL Loss: 2.102331
Y Loss: 1.197563
T Loss: 11.572138
X Loss: -0.029473
Epoch 349 
Overall Loss: 14.188078
Rec Loss: 12.099744
KL Loss: 2.088333
Y Loss: 1.137164
T Loss: 11.563257
X Loss: -0.032094
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.004679
Epoch 99
Rec Loss: 1.991733
Epoch 149
Rec Loss: 1.998969
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.370899
Epoch 99
Rec Loss: 0.377706
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.568589
Insample Error 2.519323
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.725518
Rec Loss: 15.570850
KL Loss: 1.154668
Y Loss: 6.178946
T Loss: 12.481377
Epoch 99 
Overall Loss: 14.873183
Rec Loss: 13.460923
KL Loss: 1.412261
Y Loss: 2.235377
T Loss: 12.343234
Epoch 149 
Overall Loss: 14.277720
Rec Loss: 12.845861
KL Loss: 1.431859
Y Loss: 1.514743
T Loss: 12.088490
Epoch 199 
Overall Loss: 13.765068
Rec Loss: 12.395244
KL Loss: 1.369824
Y Loss: 1.070164
T Loss: 11.860161
Epoch 249 
Overall Loss: 13.611080
Rec Loss: 12.259178
KL Loss: 1.351902
Y Loss: 0.998330
T Loss: 11.760013
Epoch 299 
Overall Loss: 13.511053
Rec Loss: 12.160180
KL Loss: 1.350873
Y Loss: 0.993217
T Loss: 11.663572
Epoch 349 
Overall Loss: 13.443531
Rec Loss: 12.094648
KL Loss: 1.348883
Y Loss: 0.959408
T Loss: 11.614944
Epoch 399 
Overall Loss: 13.397038
Rec Loss: 12.023006
KL Loss: 1.374032
Y Loss: 0.899328
T Loss: 11.573342
Epoch 449 
Overall Loss: 13.373001
Rec Loss: 11.996566
KL Loss: 1.376435
Y Loss: 0.902527
T Loss: 11.545303
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.889301
Epoch 99
Rec Loss: 1.891799
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000004
Epoch 99
Rec Loss: 0.000001
Epoch 149
Rec Loss: 0.000001
Epoch 199
Rec Loss: 0.000001
Epoch 249
Rec Loss: 0.000000
Epoch 299
Rec Loss: 0.000003
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.649342
Insample Error: 2.305476
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.573468
Rec Loss: 16.608922
KL Loss: 0.964546
Y Loss: 6.882803
T Loss: 12.669362
X Loss: 0.498159
Epoch 99 
Overall Loss: 15.403042
Rec Loss: 14.071078
KL Loss: 1.331964
Y Loss: 2.720157
T Loss: 12.212680
X Loss: 0.498320
Epoch 149 
Overall Loss: 14.677155
Rec Loss: 13.260340
KL Loss: 1.416816
Y Loss: 1.825858
T Loss: 11.849508
X Loss: 0.497902
Epoch 199 
Overall Loss: 14.418794
Rec Loss: 12.930967
KL Loss: 1.487827
Y Loss: 1.499707
T Loss: 11.682736
X Loss: 0.498378
Epoch 249 
Overall Loss: 14.306675
Rec Loss: 12.792352
KL Loss: 1.514324
Y Loss: 1.287170
T Loss: 11.650191
X Loss: 0.498576
Epoch 299 
Overall Loss: 14.214077
Rec Loss: 12.674208
KL Loss: 1.539869
Y Loss: 1.118201
T Loss: 11.616217
X Loss: 0.498890
Epoch 349 
Overall Loss: 14.189589
Rec Loss: 12.645935
KL Loss: 1.543654
Y Loss: 1.059273
T Loss: 11.618295
X Loss: 0.498003
Epoch 399 
Overall Loss: 14.129253
Rec Loss: 12.627569
KL Loss: 1.501684
Y Loss: 1.044269
T Loss: 11.607508
X Loss: 0.497927
Epoch 449 
Overall Loss: 14.048216
Rec Loss: 12.576657
KL Loss: 1.471559
Y Loss: 0.957855
T Loss: 11.600056
X Loss: 0.497673
Epoch 499 
Overall Loss: 13.976304
Rec Loss: 12.558732
KL Loss: 1.417572
Y Loss: 0.934829
T Loss: 11.593848
X Loss: 0.497469
Epoch 549 
Overall Loss: 13.926502
Rec Loss: 12.532188
KL Loss: 1.394314
Y Loss: 0.923865
T Loss: 11.571764
X Loss: 0.498491
Epoch 599 
Overall Loss: 13.870381
Rec Loss: 12.493575
KL Loss: 1.376806
Y Loss: 0.872994
T Loss: 11.558824
X Loss: 0.498254
Epoch 649 
Overall Loss: 13.861864
Rec Loss: 12.496381
KL Loss: 1.365482
Y Loss: 0.876821
T Loss: 11.560151
X Loss: 0.497820
Epoch 699 
Overall Loss: 13.832115
Rec Loss: 12.470932
KL Loss: 1.361183
Y Loss: 0.882439
T Loss: 11.531568
X Loss: 0.498144
Epoch 749 
Overall Loss: 13.813847
Rec Loss: 12.464805
KL Loss: 1.349042
Y Loss: 0.869010
T Loss: 11.532010
X Loss: 0.498290
Epoch 799 
Overall Loss: 13.809091
Rec Loss: 12.466840
KL Loss: 1.342251
Y Loss: 0.863573
T Loss: 11.536717
X Loss: 0.498337
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.885298
Epoch 99
Rec Loss: 1.868798
Epoch 149
Rec Loss: 1.882958
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.996933
Epoch 99
Rec Loss: 0.996986
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.641259
Insample Error 2.050688
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.356203
Rec Loss: 15.169364
KL Loss: 1.186839
Y Loss: 5.283879
T Loss: 12.527425
Epoch 99 
Overall Loss: 14.665754
Rec Loss: 13.294416
KL Loss: 1.371338
Y Loss: 1.808120
T Loss: 12.390356
Epoch 149 
Overall Loss: 13.997231
Rec Loss: 12.684920
KL Loss: 1.312310
Y Loss: 1.065727
T Loss: 12.152057
Epoch 199 
Overall Loss: 13.720012
Rec Loss: 12.388876
KL Loss: 1.331137
Y Loss: 0.841582
T Loss: 11.968084
Epoch 249 
Overall Loss: 13.571692
Rec Loss: 12.217171
KL Loss: 1.354521
Y Loss: 0.817799
T Loss: 11.808272
Epoch 299 
Overall Loss: 13.512518
Rec Loss: 12.136944
KL Loss: 1.375574
Y Loss: 0.864047
T Loss: 11.704921
Epoch 349 
Overall Loss: 13.474872
Rec Loss: 12.088105
KL Loss: 1.386766
Y Loss: 0.892083
T Loss: 11.642064
Epoch 399 
Overall Loss: 13.438953
Rec Loss: 12.052787
KL Loss: 1.386166
Y Loss: 0.913350
T Loss: 11.596112
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.928146
Epoch 99
Rec Loss: 1.904901
Epoch 149
Rec Loss: 1.903946
Epoch 199
Rec Loss: 1.908254
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000009
Epoch 99
Rec Loss: 0.000004
Epoch 149
Rec Loss: 0.000002
Epoch 199
Rec Loss: 0.000001
Epoch 249
Rec Loss: 0.000001
Epoch 299
Rec Loss: 0.000000
Epoch 349
Rec Loss: 0.000000
Epoch 399
Rec Loss: 0.000000
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.639755
Insample Error: 2.474744
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.461648
Rec Loss: 16.263523
KL Loss: 1.198125
Y Loss: 6.325547
T Loss: 12.603874
X Loss: 0.496876
Epoch 99 
Overall Loss: 15.631220
Rec Loss: 14.210163
KL Loss: 1.421057
Y Loss: 2.716888
T Loss: 12.357347
X Loss: 0.494372
Epoch 149 
Overall Loss: 15.125782
Rec Loss: 13.631626
KL Loss: 1.494156
Y Loss: 2.180578
T Loss: 12.083195
X Loss: 0.458142
Epoch 199 
Overall Loss: 14.648309
Rec Loss: 12.727855
KL Loss: 1.920454
Y Loss: 1.747855
T Loss: 11.839218
X Loss: 0.014710
Epoch 249 
Overall Loss: 14.357832
Rec Loss: 12.090342
KL Loss: 2.267490
Y Loss: 1.468669
T Loss: 11.698320
X Loss: -0.342312
Epoch 299 
Overall Loss: 14.220493
Rec Loss: 11.846192
KL Loss: 2.374301
Y Loss: 1.292374
T Loss: 11.670835
X Loss: -0.470830
Epoch 349 
Overall Loss: 14.137647
Rec Loss: 11.692233
KL Loss: 2.445414
Y Loss: 1.167688
T Loss: 11.647835
X Loss: -0.539446
Epoch 399 
Overall Loss: 14.073348
Rec Loss: 11.612529
KL Loss: 2.460819
Y Loss: 1.091818
T Loss: 11.631245
X Loss: -0.564625
Epoch 449 
Overall Loss: 14.014589
Rec Loss: 11.531286
KL Loss: 2.483303
Y Loss: 1.063566
T Loss: 11.597742
X Loss: -0.598240
Epoch 499 
Overall Loss: 13.952116
Rec Loss: 11.449971
KL Loss: 2.502144
Y Loss: 1.014333
T Loss: 11.588998
X Loss: -0.646193
Epoch 549 
Overall Loss: 13.927624
Rec Loss: 11.419816
KL Loss: 2.507808
Y Loss: 0.985001
T Loss: 11.578762
X Loss: -0.651446
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.923767
Epoch 99
Rec Loss: 1.908444
Epoch 149
Rec Loss: 1.918541
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.097450
Epoch 99
Rec Loss: 0.100207
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.712610
Insample Error 2.215179
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.006677
Rec Loss: 14.623839
KL Loss: 1.382839
Y Loss: 4.411213
T Loss: 12.418232
Epoch 99 
Overall Loss: 14.330709
Rec Loss: 13.026932
KL Loss: 1.303777
Y Loss: 1.574411
T Loss: 12.239726
Epoch 149 
Overall Loss: 13.886443
Rec Loss: 12.582135
KL Loss: 1.304308
Y Loss: 1.020329
T Loss: 12.071970
Epoch 199 
Overall Loss: 13.700120
Rec Loss: 12.367711
KL Loss: 1.332409
Y Loss: 0.856525
T Loss: 11.939449
Epoch 249 
Overall Loss: 13.575840
Rec Loss: 12.213528
KL Loss: 1.362313
Y Loss: 0.845917
T Loss: 11.790569
Epoch 299 
Overall Loss: 13.521856
Rec Loss: 12.142985
KL Loss: 1.378871
Y Loss: 0.860423
T Loss: 11.712774
Epoch 349 
Overall Loss: 13.462766
Rec Loss: 12.063903
KL Loss: 1.398863
Y Loss: 0.874846
T Loss: 11.626480
Epoch 399 
Overall Loss: 13.416425
Rec Loss: 12.022275
KL Loss: 1.394150
Y Loss: 0.879930
T Loss: 11.582310
Epoch 449 
Overall Loss: 13.391787
Rec Loss: 11.997815
KL Loss: 1.393972
Y Loss: 0.896270
T Loss: 11.549680
Epoch 499 
Overall Loss: 13.359162
Rec Loss: 11.955221
KL Loss: 1.403942
Y Loss: 0.882282
T Loss: 11.514080
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.888590
Epoch 99
Rec Loss: 1.892314
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000011
Epoch 99
Rec Loss: 0.000005
Epoch 149
Rec Loss: 0.000002
Epoch 199
Rec Loss: 0.000002
Epoch 249
Rec Loss: 0.000001
Epoch 299
Rec Loss: 0.000001
Epoch 349
Rec Loss: 0.000003
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.639147
Insample Error: 2.388951
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.479577
Rec Loss: 16.334696
KL Loss: 1.144882
Y Loss: 6.197790
T Loss: 12.737940
X Loss: 0.497861
Epoch 99 
Overall Loss: 15.611497
Rec Loss: 14.232276
KL Loss: 1.379221
Y Loss: 2.700701
T Loss: 12.394920
X Loss: 0.487006
Epoch 149 
Overall Loss: 15.056998
Rec Loss: 13.481070
KL Loss: 1.575928
Y Loss: 2.134990
T Loss: 12.030078
X Loss: 0.383497
Epoch 199 
Overall Loss: 14.614604
Rec Loss: 12.688285
KL Loss: 1.926319
Y Loss: 1.786507
T Loss: 11.704744
X Loss: 0.090287
Epoch 249 
Overall Loss: 14.417461
Rec Loss: 12.292512
KL Loss: 2.124950
Y Loss: 1.522420
T Loss: 11.638449
X Loss: -0.107147
Epoch 299 
Overall Loss: 14.304928
Rec Loss: 12.092369
KL Loss: 2.212559
Y Loss: 1.346462
T Loss: 11.664264
X Loss: -0.245126
Epoch 349 
Overall Loss: 14.185177
Rec Loss: 11.896502
KL Loss: 2.288674
Y Loss: 1.225122
T Loss: 11.650891
X Loss: -0.366950
Epoch 399 
Overall Loss: 14.111539
Rec Loss: 11.763857
KL Loss: 2.347681
Y Loss: 1.140090
T Loss: 11.647253
X Loss: -0.453440
Epoch 449 
Overall Loss: 14.018220
Rec Loss: 11.650821
KL Loss: 2.367399
Y Loss: 1.079461
T Loss: 11.633963
X Loss: -0.522872
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.970776
Epoch 99
Rec Loss: 1.958309
Epoch 149
Rec Loss: 1.961913
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.128637
Epoch 99
Rec Loss: 0.123687
Epoch 149
Rec Loss: 0.123070
Epoch 199
Rec Loss: 0.123293
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.742505
Insample Error 2.272783
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.492833
Rec Loss: 14.276586
KL Loss: 1.216247
Y Loss: 3.495982
T Loss: 12.528595
Epoch 99 
Overall Loss: 14.267895
Rec Loss: 13.022890
KL Loss: 1.245006
Y Loss: 1.544151
T Loss: 12.250814
Epoch 149 
Overall Loss: 13.912989
Rec Loss: 12.612764
KL Loss: 1.300226
Y Loss: 1.030114
T Loss: 12.097707
Epoch 199 
Overall Loss: 13.723882
Rec Loss: 12.396742
KL Loss: 1.327141
Y Loss: 0.914060
T Loss: 11.939711
Epoch 249 
Overall Loss: 13.598615
Rec Loss: 12.249972
KL Loss: 1.348643
Y Loss: 0.859140
T Loss: 11.820402
Epoch 299 
Overall Loss: 13.527898
Rec Loss: 12.157023
KL Loss: 1.370875
Y Loss: 0.854291
T Loss: 11.729878
Epoch 349 
Overall Loss: 13.481313
Rec Loss: 12.097005
KL Loss: 1.384308
Y Loss: 0.868967
T Loss: 11.662522
Epoch 399 
Overall Loss: 13.441549
Rec Loss: 12.048998
KL Loss: 1.392550
Y Loss: 0.889229
T Loss: 11.604383
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.912316
Epoch 99
Rec Loss: 1.912998
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000003
Epoch 99
Rec Loss: 0.000001
Epoch 149
Rec Loss: 0.000000
Epoch 199
Rec Loss: 0.000000
Epoch 249
Rec Loss: 0.000000
Epoch 299
Rec Loss: 0.000000
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.634057
Insample Error: 2.398906
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.399650
Rec Loss: 16.330940
KL Loss: 1.068710
Y Loss: 6.417218
T Loss: 12.624415
X Loss: 0.497915
Epoch 99 
Overall Loss: 15.577686
Rec Loss: 14.264538
KL Loss: 1.313148
Y Loss: 2.748763
T Loss: 12.395655
X Loss: 0.494501
Epoch 149 
Overall Loss: 15.057761
Rec Loss: 13.613410
KL Loss: 1.444350
Y Loss: 2.120351
T Loss: 12.085769
X Loss: 0.467466
Epoch 199 
Overall Loss: 14.611498
Rec Loss: 12.839035
KL Loss: 1.772463
Y Loss: 1.730943
T Loss: 11.780355
X Loss: 0.193208
Epoch 249 
Overall Loss: 14.391745
Rec Loss: 12.275942
KL Loss: 2.115803
Y Loss: 1.452446
T Loss: 11.686108
X Loss: -0.136389
Epoch 299 
Overall Loss: 14.254562
Rec Loss: 11.900298
KL Loss: 2.354263
Y Loss: 1.256067
T Loss: 11.621531
X Loss: -0.349267
Epoch 349 
Overall Loss: 14.143865
Rec Loss: 11.723374
KL Loss: 2.420491
Y Loss: 1.107099
T Loss: 11.613739
X Loss: -0.443914
Epoch 399 
Overall Loss: 14.094081
Rec Loss: 11.626590
KL Loss: 2.467491
Y Loss: 1.063215
T Loss: 11.595953
X Loss: -0.500970
Epoch 449 
Overall Loss: 14.027984
Rec Loss: 11.580383
KL Loss: 2.447601
Y Loss: 1.023087
T Loss: 11.599518
X Loss: -0.530679
Epoch 499 
Overall Loss: 14.017986
Rec Loss: 11.531682
KL Loss: 2.486304
Y Loss: 1.034164
T Loss: 11.592332
X Loss: -0.577733
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.942211
Epoch 99
Rec Loss: 1.943812
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.115496
Epoch 99
Rec Loss: 0.118306
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.690522
Insample Error 2.305506
Ours, Train RMSE
0.6563, 
0.6352, 
0.6570, 
0.6458, 
0.6669, 
0.6445, 
0.6493, 
0.6398, 
0.6391, 
0.6341, 
Ours, Insample RMSE
2.5173, 
2.4343, 
2.4637, 
2.4727, 
2.5174, 
2.4749, 
2.3055, 
2.4747, 
2.3890, 
2.3989, 
CEVAE, Insample RMSE
2.3345, 
2.2742, 
2.5577, 
2.2471, 
2.3276, 
2.5193, 
2.0507, 
2.2152, 
2.2728, 
2.3055, 
Train, RMSE mean 0.6468 std 0.0101
Ours, RMSE mean 2.4448 std 0.0618, reconstruct confounder 1.8934 (0.0091) noise 0.0000 (0.0000)
CEVAE, RMSE mean 2.3105 std 0.1375, reconstruct confounder 1.9486 (0.0421) noise 0.6344 (0.3836)
Experiment Start!, Ours obsx=0, prior=0
Namespace(decay=0.0, l=5e-05, latdim=4, mask=9, nlayer=50, obsm=0, ycof=0.5, ylayer=50)
Y Mean 1.514292, Std 3.653528 
Observe confounder 0, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.818424
Rec Loss: 15.661116
KL Loss: 1.157308
Y Loss: 6.254261
T Loss: 12.533985
Epoch 99 
Overall Loss: 14.990654
Rec Loss: 13.592991
KL Loss: 1.397663
Y Loss: 2.527806
T Loss: 12.329088
Epoch 149 
Overall Loss: 14.550188
Rec Loss: 13.058668
KL Loss: 1.491521
Y Loss: 2.129333
T Loss: 11.994001
Epoch 199 
Overall Loss: 14.141585
Rec Loss: 12.570953
KL Loss: 1.570632
Y Loss: 1.838301
T Loss: 11.651802
Epoch 249 
Overall Loss: 13.948616
Rec Loss: 12.391886
KL Loss: 1.556731
Y Loss: 1.617331
T Loss: 11.583220
Epoch 299 
Overall Loss: 13.813379
Rec Loss: 12.303324
KL Loss: 1.510055
Y Loss: 1.433063
T Loss: 11.586793
Epoch 349 
Overall Loss: 13.713537
Rec Loss: 12.219154
KL Loss: 1.494382
Y Loss: 1.256029
T Loss: 11.591140
Epoch 399 
Overall Loss: 13.616439
Rec Loss: 12.134875
KL Loss: 1.481564
Y Loss: 1.110035
T Loss: 11.579858
Epoch 449 
Overall Loss: 13.554148
Rec Loss: 12.089688
KL Loss: 1.464460
Y Loss: 1.043866
T Loss: 11.567755
Epoch 499 
Overall Loss: 13.496141
Rec Loss: 12.054257
KL Loss: 1.441884
Y Loss: 0.958251
T Loss: 11.575132
Epoch 549 
Overall Loss: 13.463173
Rec Loss: 12.045140
KL Loss: 1.418033
Y Loss: 0.957499
T Loss: 11.566391
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.957659
Epoch 99
Rec Loss: 1.930827
Epoch 149
Rec Loss: 1.940447
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000005
Epoch 99
Rec Loss: 0.000001
Epoch 149
Rec Loss: 0.000001
Epoch 199
Rec Loss: 0.000000
Epoch 249
Rec Loss: 0.000000
Epoch 299
Rec Loss: 0.000000
Epoch 349
Rec Loss: 0.000000
Epoch 399
Rec Loss: 0.000000
Epoch 449
Rec Loss: 0.000000
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.681527
Insample Error: 2.321282
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.673463
Rec Loss: 16.624229
KL Loss: 1.049234
Y Loss: 7.064597
T Loss: 12.594157
X Loss: 0.497773
Epoch 99 
Overall Loss: 15.599826
Rec Loss: 14.195866
KL Loss: 1.403961
Y Loss: 2.842881
T Loss: 12.280197
X Loss: 0.494229
Epoch 149 
Overall Loss: 14.965195
Rec Loss: 13.276921
KL Loss: 1.688275
Y Loss: 2.060290
T Loss: 11.936639
X Loss: 0.310136
Epoch 199 
Overall Loss: 14.453594
Rec Loss: 12.251150
KL Loss: 2.202444
Y Loss: 1.514471
T Loss: 11.652295
X Loss: -0.158381
Epoch 249 
Overall Loss: 14.356183
Rec Loss: 11.925310
KL Loss: 2.430874
Y Loss: 1.311389
T Loss: 11.609651
X Loss: -0.340036
Epoch 299 
Overall Loss: 14.256451
Rec Loss: 11.745299
KL Loss: 2.511152
Y Loss: 1.193603
T Loss: 11.566926
X Loss: -0.418429
Epoch 349 
Overall Loss: 14.188837
Rec Loss: 11.714434
KL Loss: 2.474403
Y Loss: 1.127913
T Loss: 11.590743
X Loss: -0.440266
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.014858
Epoch 99
Rec Loss: 2.009296
Epoch 149
Rec Loss: 2.014501
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.153816
Epoch 99
Rec Loss: 0.157466
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.554209
Insample Error 2.524634
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.890610
Rec Loss: 15.704208
KL Loss: 1.186402
Y Loss: 6.261249
T Loss: 12.573583
Epoch 99 
Overall Loss: 15.229512
Rec Loss: 13.874440
KL Loss: 1.355072
Y Loss: 3.159261
T Loss: 12.294809
Epoch 149 
Overall Loss: 14.485938
Rec Loss: 12.952540
KL Loss: 1.533398
Y Loss: 2.281118
T Loss: 11.811981
Epoch 199 
Overall Loss: 14.078823
Rec Loss: 12.483796
KL Loss: 1.595027
Y Loss: 1.764685
T Loss: 11.601454
Epoch 249 
Overall Loss: 13.865589
Rec Loss: 12.304126
KL Loss: 1.561464
Y Loss: 1.462487
T Loss: 11.572882
Epoch 299 
Overall Loss: 13.759409
Rec Loss: 12.217883
KL Loss: 1.541525
Y Loss: 1.281920
T Loss: 11.576924
Epoch 349 
Overall Loss: 13.646024
Rec Loss: 12.127788
KL Loss: 1.518236
Y Loss: 1.147309
T Loss: 11.554134
Epoch 399 
Overall Loss: 13.604906
Rec Loss: 12.116198
KL Loss: 1.488709
Y Loss: 1.071512
T Loss: 11.580442
Epoch 449 
Overall Loss: 13.505689
Rec Loss: 12.053084
KL Loss: 1.452604
Y Loss: 0.977481
T Loss: 11.564344
Epoch 499 
Overall Loss: 13.426321
Rec Loss: 12.004582
KL Loss: 1.421739
Y Loss: 0.927420
T Loss: 11.540872
Epoch 549 
Overall Loss: 13.384929
Rec Loss: 12.006643
KL Loss: 1.378286
Y Loss: 0.939821
T Loss: 11.536732
Epoch 599 
Overall Loss: 13.349925
Rec Loss: 11.969131
KL Loss: 1.380795
Y Loss: 0.888285
T Loss: 11.524988
Epoch 649 
Overall Loss: 13.323141
Rec Loss: 11.942260
KL Loss: 1.380881
Y Loss: 0.869312
T Loss: 11.507604
Epoch 699 
Overall Loss: 13.322461
Rec Loss: 11.951746
KL Loss: 1.370715
Y Loss: 0.860060
T Loss: 11.521716
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.869019
Epoch 99
Rec Loss: 1.883207
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000003
Epoch 99
Rec Loss: 0.000001
Epoch 149
Rec Loss: 0.000000
Epoch 199
Rec Loss: 0.000000
Epoch 249
Rec Loss: 0.000000
Epoch 299
Rec Loss: 0.000000
Epoch 349
Rec Loss: 0.000000
Epoch 399
Rec Loss: 0.000000
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.633540
Insample Error: 2.049503
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.165359
Rec Loss: 16.039224
KL Loss: 1.126135
Y Loss: 5.886979
T Loss: 12.596068
X Loss: 0.499666
Epoch 99 
Overall Loss: 15.506622
Rec Loss: 14.175074
KL Loss: 1.331547
Y Loss: 2.683958
T Loss: 12.337128
X Loss: 0.495967
Epoch 149 
Overall Loss: 15.105435
Rec Loss: 13.641730
KL Loss: 1.463705
Y Loss: 2.243800
T Loss: 12.044363
X Loss: 0.475467
Epoch 199 
Overall Loss: 14.629276
Rec Loss: 12.822324
KL Loss: 1.806951
Y Loss: 1.711151
T Loss: 11.768689
X Loss: 0.198060
Epoch 249 
Overall Loss: 14.380338
Rec Loss: 12.172712
KL Loss: 2.207626
Y Loss: 1.403905
T Loss: 11.661343
X Loss: -0.190583
Epoch 299 
Overall Loss: 14.256076
Rec Loss: 11.879428
KL Loss: 2.376648
Y Loss: 1.206969
T Loss: 11.630117
X Loss: -0.354173
Epoch 349 
Overall Loss: 14.185814
Rec Loss: 11.735911
KL Loss: 2.449903
Y Loss: 1.111080
T Loss: 11.613144
X Loss: -0.432773
Epoch 399 
Overall Loss: 14.129146
Rec Loss: 11.655847
KL Loss: 2.473299
Y Loss: 1.049404
T Loss: 11.616334
X Loss: -0.485188
Epoch 449 
Overall Loss: 14.100738
Rec Loss: 11.633089
KL Loss: 2.467650
Y Loss: 1.030088
T Loss: 11.627322
X Loss: -0.509277
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.005258
Epoch 99
Rec Loss: 2.009504
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.132659
Epoch 99
Rec Loss: 0.130955
Epoch 149
Rec Loss: 0.131999
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.627186
Insample Error 2.370297
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.550777
Rec Loss: 15.322458
KL Loss: 1.228320
Y Loss: 5.505061
T Loss: 12.569927
Epoch 99 
Overall Loss: 14.694253
Rec Loss: 13.244899
KL Loss: 1.449354
Y Loss: 2.209477
T Loss: 12.140161
Epoch 149 
Overall Loss: 14.142876
Rec Loss: 12.629289
KL Loss: 1.513587
Y Loss: 1.813465
T Loss: 11.722556
Epoch 199 
Overall Loss: 13.905499
Rec Loss: 12.384879
KL Loss: 1.520620
Y Loss: 1.573053
T Loss: 11.598353
Epoch 249 
Overall Loss: 13.797177
Rec Loss: 12.312206
KL Loss: 1.484971
Y Loss: 1.381224
T Loss: 11.621594
Epoch 299 
Overall Loss: 13.710633
Rec Loss: 12.218887
KL Loss: 1.491746
Y Loss: 1.220226
T Loss: 11.608774
Epoch 349 
Overall Loss: 13.667713
Rec Loss: 12.162164
KL Loss: 1.505549
Y Loss: 1.096235
T Loss: 11.614047
Epoch 399 
Overall Loss: 13.603343
Rec Loss: 12.118850
KL Loss: 1.484492
Y Loss: 1.027854
T Loss: 11.604923
Epoch 449 
Overall Loss: 13.553390
Rec Loss: 12.076235
KL Loss: 1.477155
Y Loss: 0.987521
T Loss: 11.582475
Epoch 499 
Overall Loss: 13.491699
Rec Loss: 12.054262
KL Loss: 1.437437
Y Loss: 0.961346
T Loss: 11.573589
Epoch 549 
Overall Loss: 13.444488
Rec Loss: 12.009597
KL Loss: 1.434890
Y Loss: 0.911815
T Loss: 11.553690
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.919818
Epoch 99
Rec Loss: 1.915545
Epoch 149
Rec Loss: 1.914008
Epoch 199
Rec Loss: 1.919510
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000002
Epoch 99
Rec Loss: 0.000001
Epoch 149
Rec Loss: 0.000000
Epoch 199
Rec Loss: 0.000000
Epoch 249
Rec Loss: 0.000000
Epoch 299
Rec Loss: 0.000000
Epoch 349
Rec Loss: 0.000000
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.648046
Insample Error: 2.323099
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.713556
Rec Loss: 16.706450
KL Loss: 1.007105
Y Loss: 7.061878
T Loss: 12.677606
X Loss: 0.497906
Epoch 99 
Overall Loss: 15.645191
Rec Loss: 14.255900
KL Loss: 1.389291
Y Loss: 2.913367
T Loss: 12.301391
X Loss: 0.497825
Epoch 149 
Overall Loss: 15.031914
Rec Loss: 13.526877
KL Loss: 1.505036
Y Loss: 2.208404
T Loss: 11.927769
X Loss: 0.494906
Epoch 199 
Overall Loss: 14.588167
Rec Loss: 13.003854
KL Loss: 1.584313
Y Loss: 1.734159
T Loss: 11.645495
X Loss: 0.491280
Epoch 249 
Overall Loss: 14.374336
Rec Loss: 12.782024
KL Loss: 1.592312
Y Loss: 1.429484
T Loss: 11.575138
X Loss: 0.492144
Epoch 299 
Overall Loss: 14.240300
Rec Loss: 12.651581
KL Loss: 1.588718
Y Loss: 1.208842
T Loss: 11.560389
X Loss: 0.486771
Epoch 349 
Overall Loss: 14.177137
Rec Loss: 12.602813
KL Loss: 1.574323
Y Loss: 1.110912
T Loss: 11.555059
X Loss: 0.492298
Epoch 399 
Overall Loss: 14.153639
Rec Loss: 12.615558
KL Loss: 1.538081
Y Loss: 1.106714
T Loss: 11.571720
X Loss: 0.490481
Epoch 449 
Overall Loss: 14.096389
Rec Loss: 12.577819
KL Loss: 1.518569
Y Loss: 1.054686
T Loss: 11.556861
X Loss: 0.493615
Epoch 499 
Overall Loss: 14.055926
Rec Loss: 12.587898
KL Loss: 1.468027
Y Loss: 1.065760
T Loss: 11.562868
X Loss: 0.492150
Epoch 549 
Overall Loss: 14.014000
Rec Loss: 12.579922
KL Loss: 1.434078
Y Loss: 1.016836
T Loss: 11.578584
X Loss: 0.492920
Epoch 599 
Overall Loss: 13.955549
Rec Loss: 12.558251
KL Loss: 1.397297
Y Loss: 0.956100
T Loss: 11.587298
X Loss: 0.492903
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.994126
Epoch 99
Rec Loss: 1.989915
Epoch 149
Rec Loss: 1.995305
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.986289
Epoch 99
Rec Loss: 0.985999
Epoch 149
Rec Loss: 0.987239
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.686719
Insample Error 2.346127
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.510253
Rec Loss: 16.561960
KL Loss: 0.948293
Y Loss: 7.854957
T Loss: 12.634482
Epoch 99 
Overall Loss: 15.066837
Rec Loss: 13.641755
KL Loss: 1.425082
Y Loss: 3.010136
T Loss: 12.136687
Epoch 149 
Overall Loss: 14.310279
Rec Loss: 12.692999
KL Loss: 1.617280
Y Loss: 2.080000
T Loss: 11.652998
Epoch 199 
Overall Loss: 14.037108
Rec Loss: 12.401689
KL Loss: 1.635419
Y Loss: 1.653059
T Loss: 11.575160
Epoch 249 
Overall Loss: 13.882863
Rec Loss: 12.317759
KL Loss: 1.565104
Y Loss: 1.486648
T Loss: 11.574435
Epoch 299 
Overall Loss: 13.789455
Rec Loss: 12.271494
KL Loss: 1.517962
Y Loss: 1.378811
T Loss: 11.582088
Epoch 349 
Overall Loss: 13.704308
Rec Loss: 12.225829
KL Loss: 1.478480
Y Loss: 1.244651
T Loss: 11.603503
Epoch 399 
Overall Loss: 13.610888
Rec Loss: 12.170281
KL Loss: 1.440607
Y Loss: 1.140470
T Loss: 11.600046
Epoch 449 
Overall Loss: 13.528442
Rec Loss: 12.120816
KL Loss: 1.407626
Y Loss: 1.061129
T Loss: 11.590251
Epoch 499 
Overall Loss: 13.483111
Rec Loss: 12.107175
KL Loss: 1.375936
Y Loss: 1.009418
T Loss: 11.602466
Epoch 549 
Overall Loss: 13.408699
Rec Loss: 12.049170
KL Loss: 1.359529
Y Loss: 0.964941
T Loss: 11.566699
Epoch 599 
Overall Loss: 13.366784
Rec Loss: 12.030020
KL Loss: 1.336765
Y Loss: 0.959199
T Loss: 11.550420
Epoch 649 
Overall Loss: 13.332304
Rec Loss: 11.989391
KL Loss: 1.342912
Y Loss: 0.908050
T Loss: 11.535366
Epoch 699 
Overall Loss: 13.322984
Rec Loss: 11.981750
KL Loss: 1.341234
Y Loss: 0.902256
T Loss: 11.530622
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.894107
Epoch 99
Rec Loss: 1.884925
Epoch 149
Rec Loss: 1.896023
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000002
Epoch 99
Rec Loss: 0.000001
Epoch 149
Rec Loss: 0.000000
Epoch 199
Rec Loss: 0.000000
Epoch 249
Rec Loss: 0.000000
Epoch 299
Rec Loss: 0.000000
Epoch 349
Rec Loss: 0.000000
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.669770
Insample Error: 2.175649
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.533265
Rec Loss: 16.465457
KL Loss: 1.067807
Y Loss: 6.553281
T Loss: 12.692079
X Loss: 0.496737
Epoch 99 
Overall Loss: 15.726463
Rec Loss: 14.375762
KL Loss: 1.350701
Y Loss: 2.938380
T Loss: 12.433192
X Loss: 0.473381
Epoch 149 
Overall Loss: 15.048352
Rec Loss: 13.381449
KL Loss: 1.666904
Y Loss: 2.164198
T Loss: 12.132867
X Loss: 0.166483
Epoch 199 
Overall Loss: 14.588157
Rec Loss: 12.512056
KL Loss: 2.076101
Y Loss: 1.699589
T Loss: 11.868365
X Loss: -0.206104
Epoch 249 
Overall Loss: 14.369704
Rec Loss: 12.105035
KL Loss: 2.264670
Y Loss: 1.451082
T Loss: 11.758728
X Loss: -0.379234
Epoch 299 
Overall Loss: 14.196242
Rec Loss: 11.841403
KL Loss: 2.354839
Y Loss: 1.250966
T Loss: 11.696120
X Loss: -0.480200
Epoch 349 
Overall Loss: 14.087135
Rec Loss: 11.706827
KL Loss: 2.380308
Y Loss: 1.134162
T Loss: 11.664825
X Loss: -0.525079
Epoch 399 
Overall Loss: 14.036830
Rec Loss: 11.597887
KL Loss: 2.438942
Y Loss: 1.072634
T Loss: 11.623324
X Loss: -0.561754
Epoch 449 
Overall Loss: 13.976579
Rec Loss: 11.520620
KL Loss: 2.455959
Y Loss: 1.042622
T Loss: 11.609836
X Loss: -0.610528
Epoch 499 
Overall Loss: 13.935104
Rec Loss: 11.445034
KL Loss: 2.490071
Y Loss: 1.001358
T Loss: 11.588555
X Loss: -0.644200
Epoch 549 
Overall Loss: 13.914355
Rec Loss: 11.394357
KL Loss: 2.519998
Y Loss: 0.994448
T Loss: 11.557860
X Loss: -0.660727
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.908730
Epoch 99
Rec Loss: 1.902369
Epoch 149
Rec Loss: 1.913147
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.098196
Epoch 99
Rec Loss: 0.102167
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.719526
Insample Error 2.230178
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.727583
Rec Loss: 15.562521
KL Loss: 1.165062
Y Loss: 5.932947
T Loss: 12.596048
Epoch 99 
Overall Loss: 14.950510
Rec Loss: 13.609356
KL Loss: 1.341154
Y Loss: 2.454503
T Loss: 12.382105
Epoch 149 
Overall Loss: 14.559748
Rec Loss: 13.100813
KL Loss: 1.458935
Y Loss: 2.089429
T Loss: 12.056098
Epoch 199 
Overall Loss: 14.303874
Rec Loss: 12.698202
KL Loss: 1.605672
Y Loss: 1.741653
T Loss: 11.827376
Epoch 249 
Overall Loss: 14.047435
Rec Loss: 12.435823
KL Loss: 1.611612
Y Loss: 1.439411
T Loss: 11.716117
Epoch 299 
Overall Loss: 13.804798
Rec Loss: 12.174871
KL Loss: 1.629927
Y Loss: 1.038720
T Loss: 11.655511
Epoch 349 
Overall Loss: 13.703954
Rec Loss: 12.084086
KL Loss: 1.619868
Y Loss: 0.883595
T Loss: 11.642289
Epoch 399 
Overall Loss: 13.627590
Rec Loss: 12.022842
KL Loss: 1.604747
Y Loss: 0.814952
T Loss: 11.615366
Epoch 449 
Overall Loss: 13.592696
Rec Loss: 12.035625
KL Loss: 1.557071
Y Loss: 0.832753
T Loss: 11.619249
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.024105
Epoch 99
Rec Loss: 2.003576
Epoch 149
Rec Loss: 2.028066
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000001
Epoch 99
Rec Loss: 0.000000
Epoch 149
Rec Loss: 0.000000
Epoch 199
Rec Loss: 0.000000
Epoch 249
Rec Loss: 0.000001
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.504774
Insample Error: 2.573355
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.141544
Rec Loss: 15.927855
KL Loss: 1.213688
Y Loss: 5.677710
T Loss: 12.589891
X Loss: 0.499109
Epoch 99 
Overall Loss: 15.476169
Rec Loss: 14.110241
KL Loss: 1.365928
Y Loss: 2.631231
T Loss: 12.298623
X Loss: 0.496002
Epoch 149 
Overall Loss: 14.939620
Rec Loss: 13.494661
KL Loss: 1.444958
Y Loss: 2.105604
T Loss: 11.954839
X Loss: 0.487020
Epoch 199 
Overall Loss: 14.507285
Rec Loss: 12.969588
KL Loss: 1.537697
Y Loss: 1.661357
T Loss: 11.676581
X Loss: 0.462329
Epoch 249 
Overall Loss: 14.355841
Rec Loss: 12.782143
KL Loss: 1.573698
Y Loss: 1.485400
T Loss: 11.612236
X Loss: 0.427207
Epoch 299 
Overall Loss: 14.201449
Rec Loss: 12.624374
KL Loss: 1.577075
Y Loss: 1.292737
T Loss: 11.602955
X Loss: 0.375050
Epoch 349 
Overall Loss: 14.113323
Rec Loss: 12.516639
KL Loss: 1.596684
Y Loss: 1.139741
T Loss: 11.591591
X Loss: 0.355177
Epoch 399 
Overall Loss: 14.070808
Rec Loss: 12.485139
KL Loss: 1.585670
Y Loss: 1.073168
T Loss: 11.589602
X Loss: 0.358952
Epoch 449 
Overall Loss: 13.993187
Rec Loss: 12.467552
KL Loss: 1.525635
Y Loss: 0.989304
T Loss: 11.592305
X Loss: 0.380596
Epoch 499 
Overall Loss: 13.948606
Rec Loss: 12.471831
KL Loss: 1.476775
Y Loss: 0.966946
T Loss: 11.579889
X Loss: 0.408469
Epoch 549 
Overall Loss: 13.907077
Rec Loss: 12.466797
KL Loss: 1.440281
Y Loss: 0.977815
T Loss: 11.556103
X Loss: 0.421786
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.924114
Epoch 99
Rec Loss: 1.913583
Epoch 149
Rec Loss: 1.923821
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.868913
Epoch 99
Rec Loss: 0.874608
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.690613
Insample Error 2.251900
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.629104
Rec Loss: 15.422179
KL Loss: 1.206925
Y Loss: 5.689938
T Loss: 12.577210
Epoch 99 
Overall Loss: 14.738966
Rec Loss: 13.298169
KL Loss: 1.440796
Y Loss: 2.274074
T Loss: 12.161132
Epoch 149 
Overall Loss: 14.151754
Rec Loss: 12.620575
KL Loss: 1.531178
Y Loss: 1.765734
T Loss: 11.737708
Epoch 199 
Overall Loss: 13.965460
Rec Loss: 12.443723
KL Loss: 1.521737
Y Loss: 1.613791
T Loss: 11.636828
Epoch 249 
Overall Loss: 13.823436
Rec Loss: 12.338460
KL Loss: 1.484976
Y Loss: 1.436140
T Loss: 11.620390
Epoch 299 
Overall Loss: 13.724433
Rec Loss: 12.232484
KL Loss: 1.491949
Y Loss: 1.212072
T Loss: 11.626448
Epoch 349 
Overall Loss: 13.673657
Rec Loss: 12.209269
KL Loss: 1.464388
Y Loss: 1.146754
T Loss: 11.635892
Epoch 399 
Overall Loss: 13.604480
Rec Loss: 12.154363
KL Loss: 1.450117
Y Loss: 1.048305
T Loss: 11.630210
Epoch 449 
Overall Loss: 13.532638
Rec Loss: 12.120929
KL Loss: 1.411709
Y Loss: 1.021755
T Loss: 11.610052
Epoch 499 
Overall Loss: 13.469468
Rec Loss: 12.079749
KL Loss: 1.389719
Y Loss: 0.980053
T Loss: 11.589722
Epoch 549 
Overall Loss: 13.443099
Rec Loss: 12.064589
KL Loss: 1.378509
Y Loss: 0.967183
T Loss: 11.580998
Epoch 599 
Overall Loss: 13.395275
Rec Loss: 12.028665
KL Loss: 1.366610
Y Loss: 0.952517
T Loss: 11.552407
Epoch 649 
Overall Loss: 13.351278
Rec Loss: 11.982751
KL Loss: 1.368527
Y Loss: 0.911662
T Loss: 11.526920
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.909667
Epoch 99
Rec Loss: 1.899925
Epoch 149
Rec Loss: 1.896381
Epoch 199
Rec Loss: 1.904328
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000001
Epoch 99
Rec Loss: 0.000000
Epoch 149
Rec Loss: 0.000000
Epoch 199
Rec Loss: 0.000000
Epoch 249
Rec Loss: 0.000000
Epoch 299
Rec Loss: 0.000000
Epoch 349
Rec Loss: 0.000000
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.666835
Insample Error: 2.298372
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 16.840730
Rec Loss: 15.518746
KL Loss: 1.321984
Y Loss: 4.775760
T Loss: 12.635001
X Loss: 0.495865
Epoch 99 
Overall Loss: 15.416785
Rec Loss: 13.995172
KL Loss: 1.421612
Y Loss: 2.269679
T Loss: 12.374501
X Loss: 0.485831
Epoch 149 
Overall Loss: 14.919502
Rec Loss: 13.392785
KL Loss: 1.526717
Y Loss: 1.930048
T Loss: 12.010954
X Loss: 0.416807
Epoch 199 
Overall Loss: 14.597275
Rec Loss: 12.846886
KL Loss: 1.750389
Y Loss: 1.693107
T Loss: 11.751356
X Loss: 0.248976
Epoch 249 
Overall Loss: 14.412450
Rec Loss: 12.557701
KL Loss: 1.854750
Y Loss: 1.490024
T Loss: 11.668915
X Loss: 0.143774
Epoch 299 
Overall Loss: 14.322064
Rec Loss: 12.406201
KL Loss: 1.915863
Y Loss: 1.347615
T Loss: 11.628746
X Loss: 0.103647
Epoch 349 
Overall Loss: 14.220243
Rec Loss: 12.274829
KL Loss: 1.945414
Y Loss: 1.232115
T Loss: 11.582241
X Loss: 0.076531
Epoch 399 
Overall Loss: 14.174283
Rec Loss: 12.228495
KL Loss: 1.945788
Y Loss: 1.177305
T Loss: 11.560597
X Loss: 0.079246
Epoch 449 
Overall Loss: 14.091076
Rec Loss: 12.240288
KL Loss: 1.850788
Y Loss: 1.094895
T Loss: 11.568348
X Loss: 0.124493
Epoch 499 
Overall Loss: 14.064095
Rec Loss: 12.289204
KL Loss: 1.774891
Y Loss: 1.037721
T Loss: 11.577911
X Loss: 0.192432
Epoch 549 
Overall Loss: 13.986137
Rec Loss: 12.314247
KL Loss: 1.671891
Y Loss: 0.991626
T Loss: 11.569964
X Loss: 0.248470
Epoch 599 
Overall Loss: 13.920487
Rec Loss: 12.324255
KL Loss: 1.596232
Y Loss: 0.943742
T Loss: 11.560380
X Loss: 0.292005
Epoch 649 
Overall Loss: 13.859927
Rec Loss: 12.333865
KL Loss: 1.526061
Y Loss: 0.884668
T Loss: 11.561776
X Loss: 0.329755
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.936492
Epoch 99
Rec Loss: 1.928886
Epoch 149
Rec Loss: 1.925851
Epoch 199
Rec Loss: 1.937522
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.739138
Epoch 99
Rec Loss: 0.734984
Epoch 149
Rec Loss: 0.738697
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.673444
Insample Error 2.173567
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.041884
Rec Loss: 15.995504
KL Loss: 1.046380
Y Loss: 6.849055
T Loss: 12.570977
Epoch 99 
Overall Loss: 15.169233
Rec Loss: 13.792510
KL Loss: 1.376723
Y Loss: 3.020380
T Loss: 12.282320
Epoch 149 
Overall Loss: 14.573417
Rec Loss: 13.042890
KL Loss: 1.530527
Y Loss: 2.283264
T Loss: 11.901258
Epoch 199 
Overall Loss: 14.089333
Rec Loss: 12.452372
KL Loss: 1.636961
Y Loss: 1.698328
T Loss: 11.603208
Epoch 249 
Overall Loss: 13.874276
Rec Loss: 12.253345
KL Loss: 1.620930
Y Loss: 1.394758
T Loss: 11.555967
Epoch 299 
Overall Loss: 13.747009
Rec Loss: 12.139765
KL Loss: 1.607245
Y Loss: 1.229472
T Loss: 11.525029
Epoch 349 
Overall Loss: 13.672760
Rec Loss: 12.098134
KL Loss: 1.574626
Y Loss: 1.112812
T Loss: 11.541728
Epoch 399 
Overall Loss: 13.624784
Rec Loss: 12.077055
KL Loss: 1.547728
Y Loss: 1.085469
T Loss: 11.534321
Epoch 449 
Overall Loss: 13.565489
Rec Loss: 12.055683
KL Loss: 1.509806
Y Loss: 1.050023
T Loss: 11.530671
Epoch 499 
Overall Loss: 13.535387
Rec Loss: 12.069805
KL Loss: 1.465582
Y Loss: 1.064465
T Loss: 11.537573
Epoch 549 
Overall Loss: 13.490976
Rec Loss: 12.046407
KL Loss: 1.444569
Y Loss: 1.025883
T Loss: 11.533466
Epoch 599 
Overall Loss: 13.433592
Rec Loss: 12.029217
KL Loss: 1.404375
Y Loss: 0.954839
T Loss: 11.551798
Epoch 649 
Overall Loss: 13.389322
Rec Loss: 11.999317
KL Loss: 1.390005
Y Loss: 0.924351
T Loss: 11.537142
Epoch 699 
Overall Loss: 13.371459
Rec Loss: 12.002563
KL Loss: 1.368895
Y Loss: 0.913507
T Loss: 11.545810
Epoch 749 
Overall Loss: 13.344644
Rec Loss: 11.976067
KL Loss: 1.368578
Y Loss: 0.863045
T Loss: 11.544544
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.908301
Epoch 99
Rec Loss: 1.899724
Epoch 149
Rec Loss: 1.915635
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000003
Epoch 99
Rec Loss: 0.000001
Epoch 149
Rec Loss: 0.000000
Epoch 199
Rec Loss: 0.000000
Epoch 249
Rec Loss: 0.000000
Epoch 299
Rec Loss: 0.000000
Epoch 349
Rec Loss: 0.000000
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.674451
Insample Error: 2.194124
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.217836
Rec Loss: 16.057013
KL Loss: 1.160822
Y Loss: 6.076609
T Loss: 12.520285
X Loss: 0.498424
Epoch 99 
Overall Loss: 15.306151
Rec Loss: 13.844027
KL Loss: 1.462124
Y Loss: 2.409811
T Loss: 12.150522
X Loss: 0.488600
Epoch 149 
Overall Loss: 14.705998
Rec Loss: 13.120933
KL Loss: 1.585064
Y Loss: 1.852947
T Loss: 11.705539
X Loss: 0.488921
Epoch 199 
Overall Loss: 14.439496
Rec Loss: 12.832073
KL Loss: 1.607423
Y Loss: 1.514934
T Loss: 11.591823
X Loss: 0.482783
Epoch 249 
Overall Loss: 14.312069
Rec Loss: 12.660321
KL Loss: 1.651748
Y Loss: 1.273809
T Loss: 11.541352
X Loss: 0.482065
Epoch 299 
Overall Loss: 14.245757
Rec Loss: 12.610632
KL Loss: 1.635125
Y Loss: 1.204972
T Loss: 11.523624
X Loss: 0.484522
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.994913
Epoch 99
Rec Loss: 1.997859
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.972716
Epoch 99
Rec Loss: 0.969693
Epoch 149
Rec Loss: 0.972909
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.545311
Insample Error 2.706362
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.992400
Rec Loss: 15.907733
KL Loss: 1.084667
Y Loss: 6.525235
T Loss: 12.645115
Epoch 99 
Overall Loss: 15.156628
Rec Loss: 13.795380
KL Loss: 1.361248
Y Loss: 2.808469
T Loss: 12.391146
Epoch 149 
Overall Loss: 14.536065
Rec Loss: 13.105065
KL Loss: 1.431001
Y Loss: 1.992602
T Loss: 12.108763
Epoch 199 
Overall Loss: 14.021115
Rec Loss: 12.555690
KL Loss: 1.465425
Y Loss: 1.294292
T Loss: 11.908545
Epoch 249 
Overall Loss: 13.779584
Rec Loss: 12.244886
KL Loss: 1.534698
Y Loss: 1.047111
T Loss: 11.721331
Epoch 299 
Overall Loss: 13.701207
Rec Loss: 12.161099
KL Loss: 1.540109
Y Loss: 1.013244
T Loss: 11.654476
Epoch 349 
Overall Loss: 13.640359
Rec Loss: 12.123876
KL Loss: 1.516483
Y Loss: 0.985538
T Loss: 11.631106
Epoch 399 
Overall Loss: 13.560895
Rec Loss: 12.088591
KL Loss: 1.472303
Y Loss: 0.953512
T Loss: 11.611836
Epoch 449 
Overall Loss: 13.470586
Rec Loss: 12.029795
KL Loss: 1.440791
Y Loss: 0.902256
T Loss: 11.578668
Epoch 499 
Overall Loss: 13.429676
Rec Loss: 11.996559
KL Loss: 1.433117
Y Loss: 0.867940
T Loss: 11.562590
Epoch 549 
Overall Loss: 13.371275
Rec Loss: 11.963996
KL Loss: 1.407279
Y Loss: 0.855871
T Loss: 11.536061
Epoch 599 
Overall Loss: 13.367425
Rec Loss: 11.977903
KL Loss: 1.389522
Y Loss: 0.884271
T Loss: 11.535768
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.894687
Epoch 99
Rec Loss: 1.907203
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000002
Epoch 99
Rec Loss: 0.000001
Epoch 149
Rec Loss: 0.000001
Epoch 199
Rec Loss: 0.000000
Epoch 249
Rec Loss: 0.000000
Epoch 299
Rec Loss: 0.000000
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.629399
Insample Error: 2.195490
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.063684
Rec Loss: 15.837382
KL Loss: 1.226303
Y Loss: 5.515837
T Loss: 12.580803
X Loss: 0.498660
Epoch 99 
Overall Loss: 15.415334
Rec Loss: 14.033790
KL Loss: 1.381544
Y Loss: 2.573052
T Loss: 12.251426
X Loss: 0.495838
Epoch 149 
Overall Loss: 14.742793
Rec Loss: 13.216964
KL Loss: 1.525829
Y Loss: 1.938428
T Loss: 11.750294
X Loss: 0.497456
Epoch 199 
Overall Loss: 14.451593
Rec Loss: 12.876537
KL Loss: 1.575057
Y Loss: 1.546104
T Loss: 11.604998
X Loss: 0.498486
Epoch 249 
Overall Loss: 14.293419
Rec Loss: 12.714398
KL Loss: 1.579022
Y Loss: 1.316125
T Loss: 11.557860
X Loss: 0.498475
Epoch 299 
Overall Loss: 14.221324
Rec Loss: 12.656012
KL Loss: 1.565312
Y Loss: 1.220643
T Loss: 11.547896
X Loss: 0.497794
Epoch 349 
Overall Loss: 14.166660
Rec Loss: 12.644073
KL Loss: 1.522587
Y Loss: 1.142586
T Loss: 11.574446
X Loss: 0.498334
Epoch 399 
Overall Loss: 14.101780
Rec Loss: 12.596157
KL Loss: 1.505623
Y Loss: 1.068405
T Loss: 11.563851
X Loss: 0.498103
Epoch 449 
Overall Loss: 14.059563
Rec Loss: 12.609922
KL Loss: 1.449641
Y Loss: 1.052179
T Loss: 11.586108
X Loss: 0.497724
Epoch 499 
Overall Loss: 14.018455
Rec Loss: 12.617116
KL Loss: 1.401339
Y Loss: 1.034298
T Loss: 11.601778
X Loss: 0.498188
Epoch 549 
Overall Loss: 13.953644
Rec Loss: 12.592751
KL Loss: 1.360893
Y Loss: 1.003317
T Loss: 11.592818
X Loss: 0.498274
Epoch 599 
Overall Loss: 13.897849
Rec Loss: 12.554270
KL Loss: 1.343578
Y Loss: 0.958094
T Loss: 11.577117
X Loss: 0.498107
Epoch 649 
Overall Loss: 13.872610
Rec Loss: 12.526308
KL Loss: 1.346302
Y Loss: 0.938777
T Loss: 11.559719
X Loss: 0.497201
Epoch 699 
Overall Loss: 13.845805
Rec Loss: 12.509877
KL Loss: 1.335927
Y Loss: 0.904357
T Loss: 11.560621
X Loss: 0.497078
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.883853
Epoch 99
Rec Loss: 1.892048
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.995503
Epoch 99
Rec Loss: 0.991663
Epoch 149
Rec Loss: 0.994617
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.676405
Insample Error 2.220790
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.598993
Rec Loss: 15.372423
KL Loss: 1.226570
Y Loss: 5.687882
T Loss: 12.528482
Epoch 99 
Overall Loss: 15.002891
Rec Loss: 13.573698
KL Loss: 1.429194
Y Loss: 2.513308
T Loss: 12.317043
Epoch 149 
Overall Loss: 14.406020
Rec Loss: 12.862867
KL Loss: 1.543153
Y Loss: 2.079087
T Loss: 11.823324
Epoch 199 
Overall Loss: 14.083799
Rec Loss: 12.509729
KL Loss: 1.574070
Y Loss: 1.774365
T Loss: 11.622547
Epoch 249 
Overall Loss: 13.892938
Rec Loss: 12.360288
KL Loss: 1.532650
Y Loss: 1.569109
T Loss: 11.575733
Epoch 299 
Overall Loss: 13.796388
Rec Loss: 12.302048
KL Loss: 1.494340
Y Loss: 1.384102
T Loss: 11.609997
Epoch 349 
Overall Loss: 13.694097
Rec Loss: 12.238184
KL Loss: 1.455913
Y Loss: 1.258202
T Loss: 11.609083
Epoch 399 
Overall Loss: 13.618969
Rec Loss: 12.200123
KL Loss: 1.418846
Y Loss: 1.140863
T Loss: 11.629691
Epoch 449 
Overall Loss: 13.535789
Rec Loss: 12.146656
KL Loss: 1.389133
Y Loss: 1.057577
T Loss: 11.617868
Epoch 499 
Overall Loss: 13.457561
Rec Loss: 12.082362
KL Loss: 1.375198
Y Loss: 0.976109
T Loss: 11.594308
Epoch 549 
Overall Loss: 13.404038
Rec Loss: 12.060902
KL Loss: 1.343136
Y Loss: 0.953971
T Loss: 11.583916
Epoch 599 
Overall Loss: 13.373898
Rec Loss: 12.032348
KL Loss: 1.341551
Y Loss: 0.933999
T Loss: 11.565348
Epoch 649 
Overall Loss: 13.329496
Rec Loss: 11.988980
KL Loss: 1.340515
Y Loss: 0.911726
T Loss: 11.533117
Epoch 699 
Overall Loss: 13.334501
Rec Loss: 11.981842
KL Loss: 1.352659
Y Loss: 0.882775
T Loss: 11.540454
Epoch 749 
Overall Loss: 13.315396
Rec Loss: 11.958440
KL Loss: 1.356956
Y Loss: 0.857581
T Loss: 11.529649
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.878887
Epoch 99
Rec Loss: 1.884214
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000001
Epoch 99
Rec Loss: 0.000001
Epoch 149
Rec Loss: 0.000000
Epoch 199
Rec Loss: 0.000000
Epoch 249
Rec Loss: 0.000000
Epoch 299
Rec Loss: 0.000000
Epoch 349
Rec Loss: 0.000000
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.661053
Insample Error: 2.093768
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.390884
Rec Loss: 16.281559
KL Loss: 1.109325
Y Loss: 6.187632
T Loss: 12.691255
X Loss: 0.496488
Epoch 99 
Overall Loss: 15.603726
Rec Loss: 14.203363
KL Loss: 1.400363
Y Loss: 2.616902
T Loss: 12.414666
X Loss: 0.480245
Epoch 149 
Overall Loss: 14.974825
Rec Loss: 13.323566
KL Loss: 1.651260
Y Loss: 1.997483
T Loss: 11.946855
X Loss: 0.377969
Epoch 199 
Overall Loss: 14.551709
Rec Loss: 12.467835
KL Loss: 2.083874
Y Loss: 1.527209
T Loss: 11.668366
X Loss: 0.035865
Epoch 249 
Overall Loss: 14.383098
Rec Loss: 12.070540
KL Loss: 2.312557
Y Loss: 1.220146
T Loss: 11.590338
X Loss: -0.129871
Epoch 299 
Overall Loss: 14.287112
Rec Loss: 11.932122
KL Loss: 2.354990
Y Loss: 1.107561
T Loss: 11.583279
X Loss: -0.204937
Epoch 349 
Overall Loss: 14.219205
Rec Loss: 11.873506
KL Loss: 2.345698
Y Loss: 1.030699
T Loss: 11.590380
X Loss: -0.232223
Epoch 399 
Overall Loss: 14.180197
Rec Loss: 11.848085
KL Loss: 2.332112
Y Loss: 0.956688
T Loss: 11.589050
X Loss: -0.219310
Epoch 449 
Overall Loss: 14.133855
Rec Loss: 11.836138
KL Loss: 2.297718
Y Loss: 0.949796
T Loss: 11.591963
X Loss: -0.230723
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.059607
Epoch 99
Rec Loss: 2.044446
Epoch 149
Rec Loss: 2.055406
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.238897
Epoch 99
Rec Loss: 0.237138
Epoch 149
Rec Loss: 0.238307
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.490096
Insample Error 2.992207
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.203944
Rec Loss: 14.890814
KL Loss: 1.313130
Y Loss: 4.483962
T Loss: 12.648833
Epoch 99 
Overall Loss: 14.836522
Rec Loss: 13.455384
KL Loss: 1.381138
Y Loss: 2.338250
T Loss: 12.286259
Epoch 149 
Overall Loss: 14.213538
Rec Loss: 12.729751
KL Loss: 1.483787
Y Loss: 1.768377
T Loss: 11.845562
Epoch 199 
Overall Loss: 13.903454
Rec Loss: 12.352456
KL Loss: 1.550998
Y Loss: 1.454420
T Loss: 11.625246
Epoch 249 
Overall Loss: 13.779980
Rec Loss: 12.214031
KL Loss: 1.565950
Y Loss: 1.275660
T Loss: 11.576201
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.001283
Epoch 99
Rec Loss: 1.998143
Epoch 149
Rec Loss: 1.989317
Epoch 199
Rec Loss: 1.998572
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000002
Epoch 99
Rec Loss: 0.000001
Epoch 149
Rec Loss: 0.000000
Epoch 199
Rec Loss: 0.000000
Epoch 249
Rec Loss: 0.000000
Epoch 299
Rec Loss: 0.000000
Epoch 349
Rec Loss: 0.000000
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.606059
Insample Error: 2.548043
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.304787
Rec Loss: 16.152004
KL Loss: 1.152783
Y Loss: 6.225627
T Loss: 12.542466
X Loss: 0.496724
Epoch 99 
Overall Loss: 15.540022
Rec Loss: 14.141154
KL Loss: 1.398867
Y Loss: 2.715931
T Loss: 12.297974
X Loss: 0.485215
Epoch 149 
Overall Loss: 14.878594
Rec Loss: 13.295071
KL Loss: 1.583523
Y Loss: 2.012450
T Loss: 11.896658
X Loss: 0.392187
Epoch 199 
Overall Loss: 14.482545
Rec Loss: 12.700379
KL Loss: 1.782166
Y Loss: 1.566622
T Loss: 11.636505
X Loss: 0.280563
Epoch 249 
Overall Loss: 14.290560
Rec Loss: 12.504468
KL Loss: 1.786092
Y Loss: 1.302447
T Loss: 11.558133
X Loss: 0.295111
Epoch 299 
Overall Loss: 14.222933
Rec Loss: 12.473085
KL Loss: 1.749848
Y Loss: 1.199307
T Loss: 11.553807
X Loss: 0.319625
Epoch 349 
Overall Loss: 14.161920
Rec Loss: 12.447547
KL Loss: 1.714373
Y Loss: 1.102476
T Loss: 11.553453
X Loss: 0.342856
Epoch 399 
Overall Loss: 14.120134
Rec Loss: 12.425550
KL Loss: 1.694584
Y Loss: 1.036650
T Loss: 11.550052
X Loss: 0.357173
Epoch 449 
Overall Loss: 14.056824
Rec Loss: 12.428576
KL Loss: 1.628248
Y Loss: 1.035664
T Loss: 11.543514
X Loss: 0.367230
Epoch 499 
Overall Loss: 13.998605
Rec Loss: 12.432436
KL Loss: 1.566168
Y Loss: 0.964979
T Loss: 11.560780
X Loss: 0.389166
Epoch 549 
Overall Loss: 13.946241
Rec Loss: 12.425993
KL Loss: 1.520248
Y Loss: 0.951950
T Loss: 11.562404
X Loss: 0.387613
Epoch 599 
Overall Loss: 13.902267
Rec Loss: 12.407190
KL Loss: 1.495077
Y Loss: 0.927646
T Loss: 11.548237
X Loss: 0.395130
Epoch 649 
Overall Loss: 13.902127
Rec Loss: 12.430814
KL Loss: 1.471313
Y Loss: 0.909567
T Loss: 11.560828
X Loss: 0.415203
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.942681
Epoch 99
Rec Loss: 1.928339
Epoch 149
Rec Loss: 1.933271
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.822572
Epoch 99
Rec Loss: 0.843773
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.672346
Insample Error 2.305883
Ours, Train RMSE
0.6815, 
0.6335, 
0.6480, 
0.6698, 
0.5048, 
0.6668, 
0.6745, 
0.6294, 
0.6611, 
0.6061, 
Ours, Insample RMSE
2.3213, 
2.0495, 
2.3231, 
2.1756, 
2.5734, 
2.2984, 
2.1941, 
2.1955, 
2.0938, 
2.5480, 
CEVAE, Insample RMSE
2.5246, 
2.3703, 
2.3461, 
2.2302, 
2.2519, 
2.1736, 
2.7064, 
2.2208, 
2.9922, 
2.3059, 
Train, RMSE mean 0.6375 std 0.0496
Ours, RMSE mean 2.2773 std 0.1658, reconstruct confounder 1.9161 (0.0435) noise 0.0000 (0.0000)
CEVAE, RMSE mean 2.4122 std 0.2461, reconstruct confounder 1.9598 (0.0521) noise 0.5994 (0.3717)
Experiment Start!
Namespace(decay=0.0, l=5e-05, latdim=2, mask=0, nlayer=50, obsm=0, ycof=0.5, ylayer=50)
Y Mean 1.514292, Std 3.653528 
Observe confounder 0, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.668608
Rec Loss: 15.739897
KL Loss: 0.928711
Y Loss: 6.554993
T Loss: 12.462401
Epoch 99 
Overall Loss: 14.299058
Rec Loss: 13.029196
KL Loss: 1.269862
Y Loss: 1.526338
T Loss: 12.266026
Epoch 149 
Overall Loss: 13.966965
Rec Loss: 12.663335
KL Loss: 1.303630
Y Loss: 1.056972
T Loss: 12.134849
Epoch 199 
Overall Loss: 13.755093
Rec Loss: 12.416800
KL Loss: 1.338292
Y Loss: 0.950936
T Loss: 11.941333
Epoch 249 
Overall Loss: 13.604029
Rec Loss: 12.238704
KL Loss: 1.365326
Y Loss: 0.906552
T Loss: 11.785427
Epoch 299 
Overall Loss: 13.525874
Rec Loss: 12.149105
KL Loss: 1.376769
Y Loss: 0.928775
T Loss: 11.684718
Epoch 349 
Overall Loss: 13.453367
Rec Loss: 12.064985
KL Loss: 1.388382
Y Loss: 0.894373
T Loss: 11.617798
Epoch 399 
Overall Loss: 13.418661
Rec Loss: 12.023443
KL Loss: 1.395218
Y Loss: 0.892276
T Loss: 11.577305
Epoch 449 
Overall Loss: 13.379027
Rec Loss: 11.987063
KL Loss: 1.391964
Y Loss: 0.902772
T Loss: 11.535677
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.897569
Epoch 99
Rec Loss: 1.899151
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.018019
Epoch 99
Rec Loss: 10.014899
Epoch 149
Rec Loss: 10.015421
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.653789
Insample Error: 2.429567
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.470213
Rec Loss: 21.689722
KL Loss: 0.780491
Y Loss: 8.148269
T Loss: 12.603378
X Loss: 5.012210
Epoch 99 
Overall Loss: 19.946175
Rec Loss: 18.687424
KL Loss: 1.258750
Y Loss: 3.050350
T Loss: 12.170327
X Loss: 4.991922
Epoch 149 
Overall Loss: 19.067675
Rec Loss: 17.452331
KL Loss: 1.615344
Y Loss: 1.849521
T Loss: 11.998613
X Loss: 4.528958
Epoch 199 
Overall Loss: 18.751833
Rec Loss: 16.926199
KL Loss: 1.825634
Y Loss: 1.454337
T Loss: 11.844707
X Loss: 4.354324
Epoch 249 
Overall Loss: 18.601131
Rec Loss: 16.674954
KL Loss: 1.926178
Y Loss: 1.254696
T Loss: 11.759455
X Loss: 4.288151
Epoch 299 
Overall Loss: 18.512736
Rec Loss: 16.499393
KL Loss: 2.013343
Y Loss: 1.154758
T Loss: 11.683027
X Loss: 4.238987
Epoch 349 
Overall Loss: 18.462703
Rec Loss: 16.432629
KL Loss: 2.030073
Y Loss: 1.106101
T Loss: 11.667499
X Loss: 4.212080
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.931322
Epoch 99
Rec Loss: 1.934995
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 8.776220
Epoch 99
Rec Loss: 8.774951
Epoch 149
Rec Loss: 8.772960
Epoch 199
Rec Loss: 8.763351
Epoch 249
Rec Loss: 8.792983
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.686837
Insample Error 2.191488
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.932267
Rec Loss: 15.870476
KL Loss: 1.061790
Y Loss: 7.029470
T Loss: 12.355742
Epoch 99 
Overall Loss: 14.212573
Rec Loss: 12.854197
KL Loss: 1.358376
Y Loss: 1.376991
T Loss: 12.165702
Epoch 149 
Overall Loss: 13.904464
Rec Loss: 12.532949
KL Loss: 1.371515
Y Loss: 0.992765
T Loss: 12.036567
Epoch 199 
Overall Loss: 13.714738
Rec Loss: 12.338936
KL Loss: 1.375803
Y Loss: 0.946859
T Loss: 11.865506
Epoch 249 
Overall Loss: 13.610630
Rec Loss: 12.227280
KL Loss: 1.383349
Y Loss: 0.907265
T Loss: 11.773648
Epoch 299 
Overall Loss: 13.513741
Rec Loss: 12.124269
KL Loss: 1.389472
Y Loss: 0.896294
T Loss: 11.676122
Epoch 349 
Overall Loss: 13.451375
Rec Loss: 12.058404
KL Loss: 1.392971
Y Loss: 0.909628
T Loss: 11.603590
Epoch 399 
Overall Loss: 13.428730
Rec Loss: 12.022592
KL Loss: 1.406139
Y Loss: 0.918856
T Loss: 11.563164
Epoch 449 
Overall Loss: 13.391281
Rec Loss: 12.004917
KL Loss: 1.386363
Y Loss: 0.939474
T Loss: 11.535180
Epoch 499 
Overall Loss: 13.369904
Rec Loss: 11.972233
KL Loss: 1.397671
Y Loss: 0.912617
T Loss: 11.515925
Epoch 549 
Overall Loss: 13.338393
Rec Loss: 11.941795
KL Loss: 1.396597
Y Loss: 0.897820
T Loss: 11.492886
Epoch 599 
Overall Loss: 13.330293
Rec Loss: 11.943979
KL Loss: 1.386314
Y Loss: 0.895748
T Loss: 11.496106
Epoch 649 
Overall Loss: 13.309207
Rec Loss: 11.915166
KL Loss: 1.394041
Y Loss: 0.845566
T Loss: 11.492383
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.870876
Epoch 99
Rec Loss: 1.880165
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.020816
Epoch 99
Rec Loss: 10.019433
Epoch 149
Rec Loss: 10.012351
Epoch 199
Rec Loss: 10.018452
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.632828
Insample Error: 2.334987
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.236984
Rec Loss: 21.178821
KL Loss: 1.058163
Y Loss: 7.352541
T Loss: 12.551840
X Loss: 4.950710
Epoch 99 
Overall Loss: 19.546272
Rec Loss: 17.718390
KL Loss: 1.827882
Y Loss: 2.358534
T Loss: 12.204192
X Loss: 4.334931
Epoch 149 
Overall Loss: 18.922328
Rec Loss: 16.983653
KL Loss: 1.938675
Y Loss: 1.613983
T Loss: 12.034138
X Loss: 4.142524
Epoch 199 
Overall Loss: 18.719715
Rec Loss: 16.688783
KL Loss: 2.030932
Y Loss: 1.454485
T Loss: 11.908472
X Loss: 4.053068
Epoch 249 
Overall Loss: 18.597511
Rec Loss: 16.522114
KL Loss: 2.075397
Y Loss: 1.387023
T Loss: 11.818891
X Loss: 4.009712
Epoch 299 
Overall Loss: 18.539347
Rec Loss: 16.436939
KL Loss: 2.102408
Y Loss: 1.322384
T Loss: 11.780722
X Loss: 3.995025
Epoch 349 
Overall Loss: 18.452660
Rec Loss: 16.342444
KL Loss: 2.110216
Y Loss: 1.236618
T Loss: 11.740293
X Loss: 3.983842
Epoch 399 
Overall Loss: 18.325587
Rec Loss: 16.109926
KL Loss: 2.215660
Y Loss: 1.170991
T Loss: 11.673834
X Loss: 3.850597
Epoch 449 
Overall Loss: 18.248777
Rec Loss: 15.893977
KL Loss: 2.354800
Y Loss: 1.095019
T Loss: 11.638113
X Loss: 3.708354
Epoch 499 
Overall Loss: 18.198273
Rec Loss: 15.724091
KL Loss: 2.474182
Y Loss: 1.042574
T Loss: 11.584434
X Loss: 3.618370
Epoch 549 
Overall Loss: 18.158043
Rec Loss: 15.650678
KL Loss: 2.507366
Y Loss: 1.033199
T Loss: 11.568926
X Loss: 3.565153
Epoch 599 
Overall Loss: 18.132243
Rec Loss: 15.596280
KL Loss: 2.535963
Y Loss: 0.999372
T Loss: 11.549953
X Loss: 3.546641
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.905805
Epoch 99
Rec Loss: 1.900711
Epoch 149
Rec Loss: 1.902529
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 8.628852
Epoch 99
Rec Loss: 8.625245
Epoch 149
Rec Loss: 8.621602
Epoch 199
Rec Loss: 8.624922
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.713635
Insample Error 2.305583
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.547412
Rec Loss: 15.471869
KL Loss: 1.075542
Y Loss: 6.020704
T Loss: 12.461517
Epoch 99 
Overall Loss: 14.306817
Rec Loss: 13.018530
KL Loss: 1.288287
Y Loss: 1.502386
T Loss: 12.267337
Epoch 149 
Overall Loss: 13.999588
Rec Loss: 12.677799
KL Loss: 1.321788
Y Loss: 1.086680
T Loss: 12.134459
Epoch 199 
Overall Loss: 13.770837
Rec Loss: 12.426501
KL Loss: 1.344336
Y Loss: 0.951070
T Loss: 11.950966
Epoch 249 
Overall Loss: 13.610937
Rec Loss: 12.244637
KL Loss: 1.366300
Y Loss: 0.896497
T Loss: 11.796389
Epoch 299 
Overall Loss: 13.530648
Rec Loss: 12.155004
KL Loss: 1.375644
Y Loss: 0.918237
T Loss: 11.695885
Epoch 349 
Overall Loss: 13.460295
Rec Loss: 12.068639
KL Loss: 1.391655
Y Loss: 0.893037
T Loss: 11.622121
Epoch 399 
Overall Loss: 13.458914
Rec Loss: 12.070710
KL Loss: 1.388205
Y Loss: 0.956294
T Loss: 11.592563
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.924711
Epoch 99
Rec Loss: 1.916393
Epoch 149
Rec Loss: 1.914695
Epoch 199
Rec Loss: 1.915629
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.008006
Epoch 99
Rec Loss: 10.007924
Epoch 149
Rec Loss: 10.006261
Epoch 199
Rec Loss: 10.004283
Epoch 249
Rec Loss: 10.009308
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.669181
Insample Error: 2.523347
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.112847
Rec Loss: 21.099119
KL Loss: 1.013727
Y Loss: 6.989796
T Loss: 12.696257
X Loss: 4.907964
Epoch 99 
Overall Loss: 19.561174
Rec Loss: 17.784338
KL Loss: 1.776836
Y Loss: 2.418719
T Loss: 12.257171
X Loss: 4.317807
Epoch 149 
Overall Loss: 18.992036
Rec Loss: 17.068572
KL Loss: 1.923463
Y Loss: 1.705680
T Loss: 12.082655
X Loss: 4.133078
Epoch 199 
Overall Loss: 18.744719
Rec Loss: 16.657609
KL Loss: 2.087110
Y Loss: 1.482189
T Loss: 11.925154
X Loss: 3.991360
Epoch 249 
Overall Loss: 18.556167
Rec Loss: 16.303945
KL Loss: 2.252222
Y Loss: 1.338587
T Loss: 11.809491
X Loss: 3.825161
Epoch 299 
Overall Loss: 18.452786
Rec Loss: 16.022338
KL Loss: 2.430449
Y Loss: 1.190840
T Loss: 11.744672
X Loss: 3.682246
Epoch 349 
Overall Loss: 18.354865
Rec Loss: 15.841758
KL Loss: 2.513107
Y Loss: 1.116305
T Loss: 11.683033
X Loss: 3.600573
Epoch 399 
Overall Loss: 18.305382
Rec Loss: 15.752472
KL Loss: 2.552910
Y Loss: 1.075489
T Loss: 11.648776
X Loss: 3.565952
Epoch 449 
Overall Loss: 18.223765
Rec Loss: 15.669174
KL Loss: 2.554592
Y Loss: 1.044827
T Loss: 11.605107
X Loss: 3.541653
Epoch 499 
Overall Loss: 18.169005
Rec Loss: 15.584524
KL Loss: 2.584481
Y Loss: 0.990475
T Loss: 11.581773
X Loss: 3.507513
Epoch 549 
Overall Loss: 18.136357
Rec Loss: 15.524015
KL Loss: 2.612342
Y Loss: 0.960996
T Loss: 11.558402
X Loss: 3.485115
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.901404
Epoch 99
Rec Loss: 1.886954
Epoch 149
Rec Loss: 1.890515
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 8.583308
Epoch 99
Rec Loss: 8.574487
Epoch 149
Rec Loss: 8.580362
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.684235
Insample Error 2.232133
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.968003
Rec Loss: 14.809993
KL Loss: 1.158010
Y Loss: 4.840896
T Loss: 12.389545
Epoch 99 
Overall Loss: 14.142561
Rec Loss: 12.830365
KL Loss: 1.312197
Y Loss: 1.206388
T Loss: 12.227170
Epoch 149 
Overall Loss: 13.899626
Rec Loss: 12.542391
KL Loss: 1.357236
Y Loss: 0.984662
T Loss: 12.050060
Epoch 199 
Overall Loss: 13.727698
Rec Loss: 12.346558
KL Loss: 1.381139
Y Loss: 0.928930
T Loss: 11.882094
Epoch 249 
Overall Loss: 13.612672
Rec Loss: 12.211701
KL Loss: 1.400972
Y Loss: 0.918270
T Loss: 11.752565
Epoch 299 
Overall Loss: 13.556432
Rec Loss: 12.153336
KL Loss: 1.403097
Y Loss: 0.949099
T Loss: 11.678786
Epoch 349 
Overall Loss: 13.473903
Rec Loss: 12.063136
KL Loss: 1.410767
Y Loss: 0.895712
T Loss: 11.615280
Epoch 399 
Overall Loss: 13.440175
Rec Loss: 12.026058
KL Loss: 1.414116
Y Loss: 0.895928
T Loss: 11.578095
Epoch 449 
Overall Loss: 13.406323
Rec Loss: 12.002184
KL Loss: 1.404140
Y Loss: 0.896149
T Loss: 11.554109
Epoch 499 
Overall Loss: 13.383026
Rec Loss: 11.990884
KL Loss: 1.392142
Y Loss: 0.913928
T Loss: 11.533920
Epoch 549 
Overall Loss: 13.366703
Rec Loss: 11.965996
KL Loss: 1.400708
Y Loss: 0.891260
T Loss: 11.520365
Epoch 599 
Overall Loss: 13.344819
Rec Loss: 11.950769
KL Loss: 1.394049
Y Loss: 0.885861
T Loss: 11.507839
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.884552
Epoch 99
Rec Loss: 1.880043
Epoch 149
Rec Loss: 1.877604
Epoch 199
Rec Loss: 1.881777
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.019596
Epoch 99
Rec Loss: 10.019542
Epoch 149
Rec Loss: 10.017791
Epoch 199
Rec Loss: 10.020009
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.644474
Insample Error: 2.411448
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.599528
Rec Loss: 20.456555
KL Loss: 1.142973
Y Loss: 5.798335
T Loss: 12.557531
X Loss: 4.999857
Epoch 99 
Overall Loss: 19.455242
Rec Loss: 17.680121
KL Loss: 1.775121
Y Loss: 2.207666
T Loss: 12.248876
X Loss: 4.327411
Epoch 149 
Overall Loss: 18.966764
Rec Loss: 17.038263
KL Loss: 1.928501
Y Loss: 1.664501
T Loss: 12.090073
X Loss: 4.115939
Epoch 199 
Overall Loss: 18.742187
Rec Loss: 16.722592
KL Loss: 2.019595
Y Loss: 1.476454
T Loss: 11.949935
X Loss: 4.034431
Epoch 249 
Overall Loss: 18.624910
Rec Loss: 16.543445
KL Loss: 2.081465
Y Loss: 1.376679
T Loss: 11.855374
X Loss: 3.999731
Epoch 299 
Overall Loss: 18.546035
Rec Loss: 16.438053
KL Loss: 2.107983
Y Loss: 1.319214
T Loss: 11.792880
X Loss: 3.985566
Epoch 349 
Overall Loss: 18.453663
Rec Loss: 16.352181
KL Loss: 2.101482
Y Loss: 1.225326
T Loss: 11.747534
X Loss: 3.991984
Epoch 399 
Overall Loss: 18.398299
Rec Loss: 16.283399
KL Loss: 2.114899
Y Loss: 1.175976
T Loss: 11.711051
X Loss: 3.984361
Epoch 449 
Overall Loss: 18.309884
Rec Loss: 16.161899
KL Loss: 2.147985
Y Loss: 1.124929
T Loss: 11.659139
X Loss: 3.940296
Epoch 499 
Overall Loss: 18.224008
Rec Loss: 15.953272
KL Loss: 2.270735
Y Loss: 1.106122
T Loss: 11.610488
X Loss: 3.789724
Epoch 549 
Overall Loss: 18.174289
Rec Loss: 15.754570
KL Loss: 2.419719
Y Loss: 1.046911
T Loss: 11.579010
X Loss: 3.652105
Epoch 599 
Overall Loss: 18.127751
Rec Loss: 15.650348
KL Loss: 2.477403
Y Loss: 1.003499
T Loss: 11.555875
X Loss: 3.592724
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.899963
Epoch 99
Rec Loss: 1.894640
Epoch 149
Rec Loss: 1.900445
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 8.587655
Epoch 99
Rec Loss: 8.588491
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.716755
Insample Error 2.233338
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.240034
Rec Loss: 14.991778
KL Loss: 1.248256
Y Loss: 5.276649
T Loss: 12.353453
Epoch 99 
Overall Loss: 14.349399
Rec Loss: 12.996755
KL Loss: 1.352645
Y Loss: 1.681592
T Loss: 12.155959
Epoch 149 
Overall Loss: 13.935312
Rec Loss: 12.524320
KL Loss: 1.410991
Y Loss: 1.126495
T Loss: 11.961073
Epoch 199 
Overall Loss: 13.693036
Rec Loss: 12.259447
KL Loss: 1.433589
Y Loss: 0.972061
T Loss: 11.773416
Epoch 249 
Overall Loss: 13.586546
Rec Loss: 12.147392
KL Loss: 1.439154
Y Loss: 0.947289
T Loss: 11.673748
Epoch 299 
Overall Loss: 13.521317
Rec Loss: 12.101849
KL Loss: 1.419468
Y Loss: 0.934158
T Loss: 11.634770
Epoch 349 
Overall Loss: 13.465442
Rec Loss: 12.057640
KL Loss: 1.407802
Y Loss: 0.924122
T Loss: 11.595579
Epoch 399 
Overall Loss: 13.430872
Rec Loss: 12.023291
KL Loss: 1.407582
Y Loss: 0.924834
T Loss: 11.560874
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.915816
Epoch 99
Rec Loss: 1.912487
Epoch 149
Rec Loss: 1.912626
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.021873
Epoch 99
Rec Loss: 10.019378
Epoch 149
Rec Loss: 10.018589
Epoch 199
Rec Loss: 10.016410
Epoch 249
Rec Loss: 10.019073
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.669560
Insample Error: 2.516144
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.978431
Rec Loss: 20.967301
KL Loss: 1.011130
Y Loss: 6.626184
T Loss: 12.657879
X Loss: 4.996329
Epoch 99 
Overall Loss: 19.593616
Rec Loss: 17.908115
KL Loss: 1.685502
Y Loss: 2.294771
T Loss: 12.281520
X Loss: 4.479209
Epoch 149 
Overall Loss: 18.990076
Rec Loss: 17.210105
KL Loss: 1.779970
Y Loss: 1.639900
T Loss: 12.070742
X Loss: 4.319414
Epoch 199 
Overall Loss: 18.739299
Rec Loss: 16.850191
KL Loss: 1.889109
Y Loss: 1.454968
T Loss: 11.914017
X Loss: 4.208690
Epoch 249 
Overall Loss: 18.575437
Rec Loss: 16.611384
KL Loss: 1.964053
Y Loss: 1.341627
T Loss: 11.791493
X Loss: 4.149078
Epoch 299 
Overall Loss: 18.466582
Rec Loss: 16.441428
KL Loss: 2.025155
Y Loss: 1.215736
T Loss: 11.716840
X Loss: 4.116719
Epoch 349 
Overall Loss: 18.393460
Rec Loss: 16.338630
KL Loss: 2.054830
Y Loss: 1.123097
T Loss: 11.691485
X Loss: 4.085597
Epoch 399 
Overall Loss: 18.309174
Rec Loss: 16.216123
KL Loss: 2.093051
Y Loss: 1.053907
T Loss: 11.651945
X Loss: 4.037224
Epoch 449 
Overall Loss: 18.232986
Rec Loss: 16.105594
KL Loss: 2.127391
Y Loss: 0.989063
T Loss: 11.621336
X Loss: 3.989727
Epoch 499 
Overall Loss: 18.179349
Rec Loss: 16.028910
KL Loss: 2.150439
Y Loss: 0.948959
T Loss: 11.585120
X Loss: 3.969311
Epoch 549 
Overall Loss: 18.133326
Rec Loss: 15.976857
KL Loss: 2.156470
Y Loss: 0.910638
T Loss: 11.581648
X Loss: 3.939890
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.909140
Epoch 99
Rec Loss: 1.896139
Epoch 149
Rec Loss: 1.901524
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 8.670570
Epoch 99
Rec Loss: 8.673900
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.667006
Insample Error 2.125911
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.927195
Rec Loss: 14.672322
KL Loss: 1.254873
Y Loss: 4.549356
T Loss: 12.397644
Epoch 99 
Overall Loss: 14.303943
Rec Loss: 12.995024
KL Loss: 1.308920
Y Loss: 1.560257
T Loss: 12.214895
Epoch 149 
Overall Loss: 13.900278
Rec Loss: 12.557516
KL Loss: 1.342761
Y Loss: 1.039848
T Loss: 12.037592
Epoch 199 
Overall Loss: 13.709444
Rec Loss: 12.329261
KL Loss: 1.380182
Y Loss: 0.924144
T Loss: 11.867189
Epoch 249 
Overall Loss: 13.596921
Rec Loss: 12.214650
KL Loss: 1.382271
Y Loss: 0.923958
T Loss: 11.752671
Epoch 299 
Overall Loss: 13.520530
Rec Loss: 12.124376
KL Loss: 1.396154
Y Loss: 0.918584
T Loss: 11.665084
Epoch 349 
Overall Loss: 13.478206
Rec Loss: 12.080755
KL Loss: 1.397451
Y Loss: 0.919357
T Loss: 11.621077
Epoch 399 
Overall Loss: 13.429844
Rec Loss: 12.032378
KL Loss: 1.397466
Y Loss: 0.910369
T Loss: 11.577194
Epoch 449 
Overall Loss: 13.402985
Rec Loss: 12.000056
KL Loss: 1.402929
Y Loss: 0.911930
T Loss: 11.544091
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.895670
Epoch 99
Rec Loss: 1.897957
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.017743
Epoch 99
Rec Loss: 10.011162
Epoch 149
Rec Loss: 10.011268
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.668019
Insample Error: 2.540891
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.158772
Rec Loss: 21.260354
KL Loss: 0.898418
Y Loss: 6.833739
T Loss: 12.869598
X Loss: 4.973885
Epoch 99 
Overall Loss: 19.586195
Rec Loss: 17.854840
KL Loss: 1.731354
Y Loss: 2.237907
T Loss: 12.345567
X Loss: 4.390319
Epoch 149 
Overall Loss: 18.992193
Rec Loss: 17.117312
KL Loss: 1.874881
Y Loss: 1.649136
T Loss: 12.128941
X Loss: 4.163803
Epoch 199 
Overall Loss: 18.722193
Rec Loss: 16.697231
KL Loss: 2.024961
Y Loss: 1.502007
T Loss: 11.942403
X Loss: 4.003825
Epoch 249 
Overall Loss: 18.567815
Rec Loss: 16.364053
KL Loss: 2.203762
Y Loss: 1.341775
T Loss: 11.836348
X Loss: 3.856817
Epoch 299 
Overall Loss: 18.481273
Rec Loss: 16.088951
KL Loss: 2.392322
Y Loss: 1.246072
T Loss: 11.757379
X Loss: 3.708535
Epoch 349 
Overall Loss: 18.386627
Rec Loss: 15.908663
KL Loss: 2.477964
Y Loss: 1.196924
T Loss: 11.688664
X Loss: 3.621537
Epoch 399 
Overall Loss: 18.312071
Rec Loss: 15.778154
KL Loss: 2.533916
Y Loss: 1.089242
T Loss: 11.657218
X Loss: 3.576315
Epoch 449 
Overall Loss: 18.244352
Rec Loss: 15.700871
KL Loss: 2.543481
Y Loss: 1.050399
T Loss: 11.622405
X Loss: 3.553266
Epoch 499 
Overall Loss: 18.215280
Rec Loss: 15.641228
KL Loss: 2.574052
Y Loss: 1.029387
T Loss: 11.596621
X Loss: 3.529914
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.915662
Epoch 99
Rec Loss: 1.921575
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 8.592570
Epoch 99
Rec Loss: 8.576141
Epoch 149
Rec Loss: 8.579885
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.732842
Insample Error 2.316915
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.760409
Rec Loss: 14.540132
KL Loss: 1.220277
Y Loss: 4.356468
T Loss: 12.361899
Epoch 99 
Overall Loss: 14.192224
Rec Loss: 12.856215
KL Loss: 1.336009
Y Loss: 1.258564
T Loss: 12.226933
Epoch 149 
Overall Loss: 13.931361
Rec Loss: 12.589027
KL Loss: 1.342334
Y Loss: 0.989138
T Loss: 12.094459
Epoch 199 
Overall Loss: 13.732804
Rec Loss: 12.376856
KL Loss: 1.355947
Y Loss: 0.905450
T Loss: 11.924132
Epoch 249 
Overall Loss: 13.615421
Rec Loss: 12.231009
KL Loss: 1.384413
Y Loss: 0.862877
T Loss: 11.799570
Epoch 299 
Overall Loss: 13.543839
Rec Loss: 12.152282
KL Loss: 1.391557
Y Loss: 0.888167
T Loss: 11.708198
Epoch 349 
Overall Loss: 13.477257
Rec Loss: 12.092670
KL Loss: 1.384588
Y Loss: 0.906225
T Loss: 11.639557
Epoch 399 
Overall Loss: 13.446947
Rec Loss: 12.054326
KL Loss: 1.392621
Y Loss: 0.915344
T Loss: 11.596654
Epoch 449 
Overall Loss: 13.400302
Rec Loss: 12.008474
KL Loss: 1.391829
Y Loss: 0.894436
T Loss: 11.561256
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.900526
Epoch 99
Rec Loss: 1.895081
Epoch 149
Rec Loss: 1.891116
Epoch 199
Rec Loss: 1.895473
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.024115
Epoch 99
Rec Loss: 10.019994
Epoch 149
Rec Loss: 10.019694
Epoch 199
Rec Loss: 10.017296
Epoch 249
Rec Loss: 10.014628
Epoch 299
Rec Loss: 10.016031
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.642556
Insample Error: 2.476878
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.446643
Rec Loss: 21.541183
KL Loss: 0.905459
Y Loss: 7.812900
T Loss: 12.633113
X Loss: 5.001620
Epoch 99 
Overall Loss: 19.866812
Rec Loss: 18.152875
KL Loss: 1.713937
Y Loss: 2.925545
T Loss: 12.283908
X Loss: 4.406195
Epoch 149 
Overall Loss: 19.136236
Rec Loss: 17.282039
KL Loss: 1.854197
Y Loss: 1.881273
T Loss: 12.151398
X Loss: 4.190005
Epoch 199 
Overall Loss: 18.830760
Rec Loss: 16.802648
KL Loss: 2.028112
Y Loss: 1.560701
T Loss: 11.981342
X Loss: 4.040955
Epoch 249 
Overall Loss: 18.663642
Rec Loss: 16.463984
KL Loss: 2.199658
Y Loss: 1.392753
T Loss: 11.856143
X Loss: 3.911465
Epoch 299 
Overall Loss: 18.523116
Rec Loss: 16.191028
KL Loss: 2.332087
Y Loss: 1.284661
T Loss: 11.772136
X Loss: 3.776561
Epoch 349 
Overall Loss: 18.423532
Rec Loss: 15.986923
KL Loss: 2.436609
Y Loss: 1.156671
T Loss: 11.709903
X Loss: 3.698685
Epoch 399 
Overall Loss: 18.338998
Rec Loss: 15.841852
KL Loss: 2.497147
Y Loss: 1.089368
T Loss: 11.661051
X Loss: 3.636117
Epoch 449 
Overall Loss: 18.233257
Rec Loss: 15.718667
KL Loss: 2.514590
Y Loss: 1.006539
T Loss: 11.625964
X Loss: 3.589433
Epoch 499 
Overall Loss: 18.181296
Rec Loss: 15.661973
KL Loss: 2.519323
Y Loss: 1.017151
T Loss: 11.590946
X Loss: 3.562451
Epoch 549 
Overall Loss: 18.154318
Rec Loss: 15.585936
KL Loss: 2.568381
Y Loss: 0.980109
T Loss: 11.559583
X Loss: 3.536299
Epoch 599 
Overall Loss: 18.119009
Rec Loss: 15.509465
KL Loss: 2.609544
Y Loss: 0.951030
T Loss: 11.545142
X Loss: 3.488807
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.908922
Epoch 99
Rec Loss: 1.906710
Epoch 149
Rec Loss: 1.903728
Epoch 199
Rec Loss: 1.899103
Epoch 249
Rec Loss: 1.906168
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 8.600513
Epoch 99
Rec Loss: 8.599005
Epoch 149
Rec Loss: 8.598810
Epoch 199
Rec Loss: 8.598978
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.684521
Insample Error 2.261037
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.692889
Rec Loss: 15.613089
KL Loss: 1.079800
Y Loss: 6.182060
T Loss: 12.522059
Epoch 99 
Overall Loss: 14.378008
Rec Loss: 13.063857
KL Loss: 1.314151
Y Loss: 1.630460
T Loss: 12.248627
Epoch 149 
Overall Loss: 13.944473
Rec Loss: 12.610443
KL Loss: 1.334030
Y Loss: 1.122730
T Loss: 12.049078
Epoch 199 
Overall Loss: 13.749278
Rec Loss: 12.383338
KL Loss: 1.365940
Y Loss: 0.955175
T Loss: 11.905750
Epoch 249 
Overall Loss: 13.613670
Rec Loss: 12.239053
KL Loss: 1.374617
Y Loss: 0.923642
T Loss: 11.777232
Epoch 299 
Overall Loss: 13.525368
Rec Loss: 12.134485
KL Loss: 1.390883
Y Loss: 0.880240
T Loss: 11.694365
Epoch 349 
Overall Loss: 13.461341
Rec Loss: 12.074215
KL Loss: 1.387125
Y Loss: 0.884642
T Loss: 11.631894
Epoch 399 
Overall Loss: 13.425328
Rec Loss: 12.031620
KL Loss: 1.393708
Y Loss: 0.903727
T Loss: 11.579756
Epoch 449 
Overall Loss: 13.396964
Rec Loss: 11.995805
KL Loss: 1.401159
Y Loss: 0.898228
T Loss: 11.546691
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.895458
Epoch 99
Rec Loss: 1.897851
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.011143
Epoch 99
Rec Loss: 10.010808
Epoch 149
Rec Loss: 10.012412
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.648680
Insample Error: 2.386735
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.465827
Rec Loss: 20.257759
KL Loss: 1.208068
Y Loss: 5.568144
T Loss: 12.511351
X Loss: 4.962337
Epoch 99 
Overall Loss: 19.439668
Rec Loss: 17.723983
KL Loss: 1.715686
Y Loss: 2.123989
T Loss: 12.261651
X Loss: 4.400337
Epoch 149 
Overall Loss: 18.896998
Rec Loss: 17.078250
KL Loss: 1.818747
Y Loss: 1.565051
T Loss: 12.028021
X Loss: 4.267704
Epoch 199 
Overall Loss: 18.675500
Rec Loss: 16.783322
KL Loss: 1.892178
Y Loss: 1.380172
T Loss: 11.851400
X Loss: 4.241835
Epoch 249 
Overall Loss: 18.521094
Rec Loss: 16.575607
KL Loss: 1.945488
Y Loss: 1.203203
T Loss: 11.752590
X Loss: 4.221415
Epoch 299 
Overall Loss: 18.429262
Rec Loss: 16.477034
KL Loss: 1.952228
Y Loss: 1.145633
T Loss: 11.688777
X Loss: 4.215441
Epoch 349 
Overall Loss: 18.380111
Rec Loss: 16.419081
KL Loss: 1.961030
Y Loss: 1.091009
T Loss: 11.663471
X Loss: 4.210106
Epoch 399 
Overall Loss: 18.331400
Rec Loss: 16.364284
KL Loss: 1.967116
Y Loss: 1.051682
T Loss: 11.633734
X Loss: 4.204709
Epoch 449 
Overall Loss: 18.260283
Rec Loss: 16.293759
KL Loss: 1.966524
Y Loss: 0.946417
T Loss: 11.621619
X Loss: 4.198931
Epoch 499 
Overall Loss: 18.221545
Rec Loss: 16.249411
KL Loss: 1.972134
Y Loss: 0.962995
T Loss: 11.592981
X Loss: 4.174932
Epoch 549 
Overall Loss: 18.168133
Rec Loss: 16.167454
KL Loss: 2.000680
Y Loss: 0.954859
T Loss: 11.562512
X Loss: 4.127512
Epoch 599 
Overall Loss: 18.142630
Rec Loss: 16.093782
KL Loss: 2.048848
Y Loss: 0.923314
T Loss: 11.544672
X Loss: 4.087453
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.905453
Epoch 99
Rec Loss: 1.912832
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 8.730210
Epoch 99
Rec Loss: 8.719899
Epoch 149
Rec Loss: 8.727416
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.683063
Insample Error 2.339811
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.709043
Rec Loss: 15.633244
KL Loss: 1.075799
Y Loss: 6.241260
T Loss: 12.512614
Epoch 99 
Overall Loss: 14.453598
Rec Loss: 13.162616
KL Loss: 1.290982
Y Loss: 1.714658
T Loss: 12.305287
Epoch 149 
Overall Loss: 13.995266
Rec Loss: 12.674281
KL Loss: 1.320985
Y Loss: 1.083381
T Loss: 12.132590
Epoch 199 
Overall Loss: 13.749558
Rec Loss: 12.399112
KL Loss: 1.350446
Y Loss: 0.903724
T Loss: 11.947250
Epoch 249 
Overall Loss: 13.583204
Rec Loss: 12.204319
KL Loss: 1.378884
Y Loss: 0.866793
T Loss: 11.770923
Epoch 299 
Overall Loss: 13.499580
Rec Loss: 12.104180
KL Loss: 1.395400
Y Loss: 0.864817
T Loss: 11.671771
Epoch 349 
Overall Loss: 13.457499
Rec Loss: 12.058301
KL Loss: 1.399198
Y Loss: 0.880471
T Loss: 11.618066
Epoch 399 
Overall Loss: 13.432525
Rec Loss: 12.032028
KL Loss: 1.400497
Y Loss: 0.905529
T Loss: 11.579263
Epoch 449 
Overall Loss: 13.404208
Rec Loss: 12.000407
KL Loss: 1.403801
Y Loss: 0.895769
T Loss: 11.552523
Epoch 499 
Overall Loss: 13.359948
Rec Loss: 11.965770
KL Loss: 1.394178
Y Loss: 0.883902
T Loss: 11.523819
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.907151
Epoch 99
Rec Loss: 1.900923
Epoch 149
Rec Loss: 1.883404
Epoch 199
Rec Loss: 1.888078
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.004692
Epoch 99
Rec Loss: 10.005325
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.645153
Insample Error: 2.391184
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.987586
Rec Loss: 20.920632
KL Loss: 1.066954
Y Loss: 6.769117
T Loss: 12.561194
X Loss: 4.974880
Epoch 99 
Overall Loss: 19.687440
Rec Loss: 17.928664
KL Loss: 1.758777
Y Loss: 2.660432
T Loss: 12.262577
X Loss: 4.335872
Epoch 149 
Overall Loss: 19.073907
Rec Loss: 17.140357
KL Loss: 1.933550
Y Loss: 1.773832
T Loss: 12.133259
X Loss: 4.120183
Epoch 199 
Overall Loss: 18.806304
Rec Loss: 16.744193
KL Loss: 2.062112
Y Loss: 1.531966
T Loss: 11.959875
X Loss: 4.018335
Epoch 249 
Overall Loss: 18.627048
Rec Loss: 16.420031
KL Loss: 2.207017
Y Loss: 1.373449
T Loss: 11.839601
X Loss: 3.893705
Epoch 299 
Overall Loss: 18.503308
Rec Loss: 16.087408
KL Loss: 2.415900
Y Loss: 1.224257
T Loss: 11.767006
X Loss: 3.708274
Epoch 349 
Overall Loss: 18.391404
Rec Loss: 15.867917
KL Loss: 2.523487
Y Loss: 1.121989
T Loss: 11.700956
X Loss: 3.605966
Epoch 399 
Overall Loss: 18.320758
Rec Loss: 15.769479
KL Loss: 2.551279
Y Loss: 1.067538
T Loss: 11.651676
X Loss: 3.584033
Epoch 449 
Overall Loss: 18.214890
Rec Loss: 15.648594
KL Loss: 2.566296
Y Loss: 1.029568
T Loss: 11.599135
X Loss: 3.534675
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.928062
Epoch 99
Rec Loss: 1.925973
Epoch 149
Rec Loss: 1.918712
Epoch 199
Rec Loss: 1.926032
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 8.612390
Epoch 99
Rec Loss: 8.606674
Epoch 149
Rec Loss: 8.608163
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.722596
Insample Error 2.278068
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.963991
Rec Loss: 16.005019
KL Loss: 0.958972
Y Loss: 6.968666
T Loss: 12.520686
Epoch 99 
Overall Loss: 14.393278
Rec Loss: 13.091601
KL Loss: 1.301676
Y Loss: 1.730041
T Loss: 12.226581
Epoch 149 
Overall Loss: 13.965180
Rec Loss: 12.613240
KL Loss: 1.351940
Y Loss: 1.090220
T Loss: 12.068130
Epoch 199 
Overall Loss: 13.715604
Rec Loss: 12.347686
KL Loss: 1.367918
Y Loss: 0.911811
T Loss: 11.891781
Epoch 249 
Overall Loss: 13.590205
Rec Loss: 12.215530
KL Loss: 1.374674
Y Loss: 0.903338
T Loss: 11.763861
Epoch 299 
Overall Loss: 13.501077
Rec Loss: 12.112566
KL Loss: 1.388511
Y Loss: 0.887742
T Loss: 11.668695
Epoch 349 
Overall Loss: 13.466163
Rec Loss: 12.081401
KL Loss: 1.384762
Y Loss: 0.910485
T Loss: 11.626159
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.942002
Epoch 99
Rec Loss: 1.934052
Epoch 149
Rec Loss: 1.944049
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.007230
Epoch 99
Rec Loss: 10.006165
Epoch 149
Rec Loss: 10.011928
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.656240
Insample Error: 2.445725
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.097824
Rec Loss: 21.103684
KL Loss: 0.994139
Y Loss: 7.626964
T Loss: 12.523339
X Loss: 4.766863
Epoch 99 
Overall Loss: 19.511269
Rec Loss: 17.793331
KL Loss: 1.717938
Y Loss: 2.387992
T Loss: 12.213948
X Loss: 4.385388
Epoch 149 
Overall Loss: 18.921500
Rec Loss: 17.091881
KL Loss: 1.829619
Y Loss: 1.620617
T Loss: 12.032348
X Loss: 4.249225
Epoch 199 
Overall Loss: 18.700544
Rec Loss: 16.773839
KL Loss: 1.926705
Y Loss: 1.459025
T Loss: 11.875785
X Loss: 4.168541
Epoch 249 
Overall Loss: 18.587606
Rec Loss: 16.597082
KL Loss: 1.990524
Y Loss: 1.318762
T Loss: 11.774643
X Loss: 4.163058
Epoch 299 
Overall Loss: 18.486531
Rec Loss: 16.492769
KL Loss: 1.993762
Y Loss: 1.202835
T Loss: 11.717306
X Loss: 4.174045
Epoch 349 
Overall Loss: 18.441697
Rec Loss: 16.421058
KL Loss: 2.020640
Y Loss: 1.120325
T Loss: 11.689070
X Loss: 4.171825
Epoch 399 
Overall Loss: 18.371295
Rec Loss: 16.349561
KL Loss: 2.021735
Y Loss: 1.074644
T Loss: 11.651505
X Loss: 4.160734
Epoch 449 
Overall Loss: 18.327068
Rec Loss: 16.266012
KL Loss: 2.061056
Y Loss: 1.017626
T Loss: 11.634728
X Loss: 4.122471
Epoch 499 
Overall Loss: 18.276829
Rec Loss: 16.216952
KL Loss: 2.059876
Y Loss: 1.022546
T Loss: 11.619550
X Loss: 4.086129
Epoch 549 
Overall Loss: 18.247231
Rec Loss: 16.162839
KL Loss: 2.084392
Y Loss: 0.978615
T Loss: 11.610656
X Loss: 4.062876
Epoch 599 
Overall Loss: 18.194243
Rec Loss: 16.091898
KL Loss: 2.102344
Y Loss: 0.967210
T Loss: 11.578358
X Loss: 4.029935
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.924670
Epoch 99
Rec Loss: 1.921280
Epoch 149
Rec Loss: 1.919093
Epoch 199
Rec Loss: 1.920105
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 8.707043
Epoch 99
Rec Loss: 8.688125
Epoch 149
Rec Loss: 8.688100
Epoch 199
Rec Loss: 8.694698
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.699469
Insample Error 2.430842
Ours, Train RMSE
0.6538, 
0.6328, 
0.6692, 
0.6445, 
0.6696, 
0.6680, 
0.6426, 
0.6487, 
0.6452, 
0.6562, 
CEVAE, Train RMSE
0.6868, 
0.7136, 
0.6842, 
0.7168, 
0.6670, 
0.7328, 
0.6845, 
0.6831, 
0.7226, 
0.6995, 
Ours, Insample RMSE
2.4296, 
2.3350, 
2.5233, 
2.4114, 
2.5161, 
2.5409, 
2.4769, 
2.3867, 
2.3912, 
2.4457, 
CEVAE, Insample RMSE
2.1915, 
2.3056, 
2.2321, 
2.2333, 
2.1259, 
2.3169, 
2.2610, 
2.3398, 
2.2781, 
2.4308, 
Train, RMSE mean 0.6530 std 0.0120
CEVAE, RMSE mean 0.6991 std 0.0202
Ours, RMSE mean 2.4457 std 0.0642, reconstruct confounder 1.8973 (0.0179) noise 10.0113 (0.0046)
CEVAE, RMSE mean 2.2715 std 0.0800, reconstruct confounder 1.9068 (0.0131) noise 8.6407 (0.0625)
Experiment Start!
Namespace(decay=0.0, l=5e-05, latdim=1, mask=0, nlayer=50, obsm=0, ycof=0.5, ylayer=50)
Y Mean 1.514292, Std 3.653528 
Observe confounder 0, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.665189
Rec Loss: 14.539039
KL Loss: 1.126150
Y Loss: 4.496114
T Loss: 12.290982
Epoch 99 
Overall Loss: 14.118524
Rec Loss: 12.799688
KL Loss: 1.318836
Y Loss: 1.148126
T Loss: 12.225625
Epoch 149 
Overall Loss: 13.910512
Rec Loss: 12.582252
KL Loss: 1.328259
Y Loss: 0.959524
T Loss: 12.102491
Epoch 199 
Overall Loss: 13.724051
Rec Loss: 12.383697
KL Loss: 1.340353
Y Loss: 0.899855
T Loss: 11.933770
Epoch 249 
Overall Loss: 13.622223
Rec Loss: 12.246643
KL Loss: 1.375580
Y Loss: 0.890769
T Loss: 11.801258
Epoch 299 
Overall Loss: 13.545910
Rec Loss: 12.160806
KL Loss: 1.385104
Y Loss: 0.906393
T Loss: 11.707609
Epoch 349 
Overall Loss: 13.480511
Rec Loss: 12.084264
KL Loss: 1.396248
Y Loss: 0.896876
T Loss: 11.635826
Epoch 399 
Overall Loss: 13.446991
Rec Loss: 12.050216
KL Loss: 1.396775
Y Loss: 0.910657
T Loss: 11.594887
Epoch 449 
Overall Loss: 13.411250
Rec Loss: 12.012399
KL Loss: 1.398851
Y Loss: 0.911387
T Loss: 11.556705
Epoch 499 
Overall Loss: 13.367320
Rec Loss: 11.978783
KL Loss: 1.388538
Y Loss: 0.889699
T Loss: 11.533934
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.899687
Epoch 99
Rec Loss: 1.899028
Epoch 149
Rec Loss: 1.891999
Epoch 199
Rec Loss: 1.893738
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.024237
Epoch 99
Rec Loss: 10.023170
Epoch 149
Rec Loss: 10.022865
Epoch 199
Rec Loss: 10.022728
Epoch 249
Rec Loss: 10.023350
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.644762
Insample Error: 2.367814
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.920913
Rec Loss: 20.983614
KL Loss: 0.937299
Y Loss: 7.174050
T Loss: 12.387106
X Loss: 5.009483
Epoch 99 
Overall Loss: 19.852329
Rec Loss: 18.575014
KL Loss: 1.277314
Y Loss: 2.707650
T Loss: 12.210001
X Loss: 5.011188
Epoch 149 
Overall Loss: 19.127554
Rec Loss: 17.862942
KL Loss: 1.264613
Y Loss: 1.642560
T Loss: 12.031622
X Loss: 5.010039
Epoch 199 
Overall Loss: 18.888000
Rec Loss: 17.553285
KL Loss: 1.334716
Y Loss: 1.414530
T Loss: 11.835232
X Loss: 5.010788
Epoch 249 
Overall Loss: 18.790752
Rec Loss: 17.398971
KL Loss: 1.391781
Y Loss: 1.267132
T Loss: 11.754660
X Loss: 5.010745
Epoch 299 
Overall Loss: 18.730641
Rec Loss: 17.321481
KL Loss: 1.409160
Y Loss: 1.197836
T Loss: 11.712046
X Loss: 5.010517
Epoch 349 
Overall Loss: 18.675661
Rec Loss: 17.247114
KL Loss: 1.428547
Y Loss: 1.138443
T Loss: 11.667400
X Loss: 5.010492
Epoch 399 
Overall Loss: 18.634718
Rec Loss: 17.200275
KL Loss: 1.434442
Y Loss: 1.072684
T Loss: 11.653347
X Loss: 5.010587
Epoch 449 
Overall Loss: 18.579764
Rec Loss: 17.157239
KL Loss: 1.422525
Y Loss: 1.006522
T Loss: 11.643516
X Loss: 5.010462
Epoch 499 
Overall Loss: 18.527540
Rec Loss: 17.130264
KL Loss: 1.397277
Y Loss: 1.004247
T Loss: 11.617482
X Loss: 5.010658
Epoch 549 
Overall Loss: 18.476271
Rec Loss: 17.093057
KL Loss: 1.383215
Y Loss: 0.975630
T Loss: 11.595802
X Loss: 5.009440
Epoch 599 
Overall Loss: 18.435126
Rec Loss: 17.063318
KL Loss: 1.371809
Y Loss: 0.950357
T Loss: 11.578648
X Loss: 5.009491
Epoch 649 
Overall Loss: 18.397993
Rec Loss: 17.018989
KL Loss: 1.379003
Y Loss: 0.909290
T Loss: 11.554434
X Loss: 5.009910
Epoch 699 
Overall Loss: 18.378879
Rec Loss: 17.009752
KL Loss: 1.369127
Y Loss: 0.915506
T Loss: 11.542371
X Loss: 5.009628
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.900649
Epoch 99
Rec Loss: 1.893640
Epoch 149
Rec Loss: 1.894943
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.024182
Epoch 99
Rec Loss: 10.024064
Epoch 149
Rec Loss: 10.021523
Epoch 199
Rec Loss: 10.020681
Epoch 249
Rec Loss: 10.023645
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.676707
Insample Error 2.294286
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.956096
Rec Loss: 14.848558
KL Loss: 1.107537
Y Loss: 5.055932
T Loss: 12.320592
Epoch 99 
Overall Loss: 14.190366
Rec Loss: 12.888695
KL Loss: 1.301670
Y Loss: 1.273326
T Loss: 12.252032
Epoch 149 
Overall Loss: 13.944361
Rec Loss: 12.617552
KL Loss: 1.326809
Y Loss: 1.014669
T Loss: 12.110217
Epoch 199 
Overall Loss: 13.744078
Rec Loss: 12.387140
KL Loss: 1.356938
Y Loss: 0.889502
T Loss: 11.942389
Epoch 249 
Overall Loss: 13.615257
Rec Loss: 12.230354
KL Loss: 1.384903
Y Loss: 0.839649
T Loss: 11.810529
Epoch 299 
Overall Loss: 13.536295
Rec Loss: 12.148018
KL Loss: 1.388277
Y Loss: 0.860373
T Loss: 11.717832
Epoch 349 
Overall Loss: 13.482702
Rec Loss: 12.097231
KL Loss: 1.385471
Y Loss: 0.891988
T Loss: 11.651237
Epoch 399 
Overall Loss: 13.440005
Rec Loss: 12.044947
KL Loss: 1.395058
Y Loss: 0.887556
T Loss: 11.601169
Epoch 449 
Overall Loss: 13.401528
Rec Loss: 12.009708
KL Loss: 1.391820
Y Loss: 0.892750
T Loss: 11.563334
Epoch 499 
Overall Loss: 13.381662
Rec Loss: 11.989594
KL Loss: 1.392068
Y Loss: 0.917065
T Loss: 11.531061
Epoch 549 
Overall Loss: 13.361169
Rec Loss: 11.974106
KL Loss: 1.387063
Y Loss: 0.919508
T Loss: 11.514352
Epoch 599 
Overall Loss: 13.337895
Rec Loss: 11.957577
KL Loss: 1.380318
Y Loss: 0.924370
T Loss: 11.495392
Epoch 649 
Overall Loss: 13.326483
Rec Loss: 11.944127
KL Loss: 1.382356
Y Loss: 0.874862
T Loss: 11.506696
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.877900
Epoch 99
Rec Loss: 1.876748
Epoch 149
Rec Loss: 1.873153
Epoch 199
Rec Loss: 1.868322
Epoch 249
Rec Loss: 1.869259
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.023784
Epoch 99
Rec Loss: 10.020510
Epoch 149
Rec Loss: 10.021956
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.634402
Insample Error: 2.384390
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.503407
Rec Loss: 21.682542
KL Loss: 0.820865
Y Loss: 8.568640
T Loss: 12.388763
X Loss: 5.009458
Epoch 99 
Overall Loss: 20.049657
Rec Loss: 18.769670
KL Loss: 1.279987
Y Loss: 3.208923
T Loss: 12.155891
X Loss: 5.009318
Epoch 149 
Overall Loss: 19.190895
Rec Loss: 17.903097
KL Loss: 1.287799
Y Loss: 1.796507
T Loss: 11.994284
X Loss: 5.010559
Epoch 199 
Overall Loss: 18.926373
Rec Loss: 17.560375
KL Loss: 1.365999
Y Loss: 1.416600
T Loss: 11.841795
X Loss: 5.010280
Epoch 249 
Overall Loss: 18.800160
Rec Loss: 17.378941
KL Loss: 1.421219
Y Loss: 1.245047
T Loss: 11.746112
X Loss: 5.010305
Epoch 299 
Overall Loss: 18.740231
Rec Loss: 17.298618
KL Loss: 1.441613
Y Loss: 1.177475
T Loss: 11.699771
X Loss: 5.010110
Epoch 349 
Overall Loss: 18.669111
Rec Loss: 17.217898
KL Loss: 1.451214
Y Loss: 1.092652
T Loss: 11.661488
X Loss: 5.010083
Epoch 399 
Overall Loss: 18.633976
Rec Loss: 17.182560
KL Loss: 1.451416
Y Loss: 1.041904
T Loss: 11.650955
X Loss: 5.010653
Epoch 449 
Overall Loss: 18.573643
Rec Loss: 17.142360
KL Loss: 1.431284
Y Loss: 1.006887
T Loss: 11.628868
X Loss: 5.010048
Epoch 499 
Overall Loss: 18.524052
Rec Loss: 17.111032
KL Loss: 1.413020
Y Loss: 0.971404
T Loss: 11.615164
X Loss: 5.010166
Epoch 549 
Overall Loss: 18.459923
Rec Loss: 17.066671
KL Loss: 1.393251
Y Loss: 0.938923
T Loss: 11.586923
X Loss: 5.010288
Epoch 599 
Overall Loss: 18.428106
Rec Loss: 17.050513
KL Loss: 1.377592
Y Loss: 0.923486
T Loss: 11.578788
X Loss: 5.009983
Epoch 649 
Overall Loss: 18.386012
Rec Loss: 17.011335
KL Loss: 1.374677
Y Loss: 0.887353
T Loss: 11.557671
X Loss: 5.009988
Epoch 699 
Overall Loss: 18.370575
Rec Loss: 16.989042
KL Loss: 1.381533
Y Loss: 0.865039
T Loss: 11.546127
X Loss: 5.010396
Epoch 749 
Overall Loss: 18.340537
Rec Loss: 16.976954
KL Loss: 1.363583
Y Loss: 0.875729
T Loss: 11.528844
X Loss: 5.010246
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.876840
Epoch 99
Rec Loss: 1.881073
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.024394
Epoch 99
Rec Loss: 10.023893
Epoch 149
Rec Loss: 10.022983
Epoch 199
Rec Loss: 10.020017
Epoch 249
Rec Loss: 10.020843
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.626331
Insample Error 2.134344
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.492719
Rec Loss: 15.452613
KL Loss: 1.040107
Y Loss: 6.100354
T Loss: 12.402436
Epoch 99 
Overall Loss: 14.207599
Rec Loss: 12.941442
KL Loss: 1.266157
Y Loss: 1.276197
T Loss: 12.303344
Epoch 149 
Overall Loss: 13.932478
Rec Loss: 12.622661
KL Loss: 1.309817
Y Loss: 0.964045
T Loss: 12.140638
Epoch 199 
Overall Loss: 13.753758
Rec Loss: 12.428291
KL Loss: 1.325467
Y Loss: 0.898224
T Loss: 11.979179
Epoch 249 
Overall Loss: 13.629282
Rec Loss: 12.286784
KL Loss: 1.342498
Y Loss: 0.882971
T Loss: 11.845299
Epoch 299 
Overall Loss: 13.544280
Rec Loss: 12.179884
KL Loss: 1.364396
Y Loss: 0.891100
T Loss: 11.734335
Epoch 349 
Overall Loss: 13.469243
Rec Loss: 12.091762
KL Loss: 1.377482
Y Loss: 0.896955
T Loss: 11.643284
Epoch 399 
Overall Loss: 13.446300
Rec Loss: 12.053970
KL Loss: 1.392330
Y Loss: 0.887381
T Loss: 11.610279
Epoch 449 
Overall Loss: 13.406710
Rec Loss: 12.017027
KL Loss: 1.389683
Y Loss: 0.920715
T Loss: 11.556669
Epoch 499 
Overall Loss: 13.366620
Rec Loss: 11.991252
KL Loss: 1.375369
Y Loss: 0.916210
T Loss: 11.533147
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.889970
Epoch 99
Rec Loss: 1.902531
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.025469
Epoch 99
Rec Loss: 10.022121
Epoch 149
Rec Loss: 10.023192
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.657292
Insample Error: 2.494302
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.103243
Rec Loss: 21.201112
KL Loss: 0.902132
Y Loss: 7.296612
T Loss: 12.545278
X Loss: 5.007528
Epoch 99 
Overall Loss: 19.682707
Rec Loss: 18.370979
KL Loss: 1.311728
Y Loss: 2.232946
T Loss: 12.243308
X Loss: 5.011198
Epoch 149 
Overall Loss: 19.075749
Rec Loss: 17.779234
KL Loss: 1.296514
Y Loss: 1.484991
T Loss: 12.026943
X Loss: 5.009795
Epoch 199 
Overall Loss: 18.858676
Rec Loss: 17.517488
KL Loss: 1.341188
Y Loss: 1.375755
T Loss: 11.819470
X Loss: 5.010140
Epoch 249 
Overall Loss: 18.757457
Rec Loss: 17.384806
KL Loss: 1.372651
Y Loss: 1.259061
T Loss: 11.744394
X Loss: 5.010881
Epoch 299 
Overall Loss: 18.717950
Rec Loss: 17.313575
KL Loss: 1.404375
Y Loss: 1.193736
T Loss: 11.706075
X Loss: 5.010633
Epoch 349 
Overall Loss: 18.642905
Rec Loss: 17.224819
KL Loss: 1.418086
Y Loss: 1.095983
T Loss: 11.665946
X Loss: 5.010881
Epoch 399 
Overall Loss: 18.600244
Rec Loss: 17.181824
KL Loss: 1.418421
Y Loss: 1.041493
T Loss: 11.650572
X Loss: 5.010505
Epoch 449 
Overall Loss: 18.567465
Rec Loss: 17.156972
KL Loss: 1.410493
Y Loss: 1.015097
T Loss: 11.639027
X Loss: 5.010396
Epoch 499 
Overall Loss: 18.492120
Rec Loss: 17.105605
KL Loss: 1.386515
Y Loss: 0.970892
T Loss: 11.609545
X Loss: 5.010614
Epoch 549 
Overall Loss: 18.439682
Rec Loss: 17.078572
KL Loss: 1.361111
Y Loss: 0.948538
T Loss: 11.594098
X Loss: 5.010205
Epoch 599 
Overall Loss: 18.394616
Rec Loss: 17.037854
KL Loss: 1.356762
Y Loss: 0.907097
T Loss: 11.573799
X Loss: 5.010506
Epoch 649 
Overall Loss: 18.379565
Rec Loss: 17.021337
KL Loss: 1.358228
Y Loss: 0.896239
T Loss: 11.563775
X Loss: 5.009441
Epoch 699 
Overall Loss: 18.341935
Rec Loss: 16.989156
KL Loss: 1.352779
Y Loss: 0.870766
T Loss: 11.544216
X Loss: 5.009556
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.887613
Epoch 99
Rec Loss: 1.897240
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.023141
Epoch 99
Rec Loss: 10.022813
Epoch 149
Rec Loss: 10.022516
Epoch 199
Rec Loss: 10.020315
Epoch 249
Rec Loss: 10.019166
Epoch 299
Rec Loss: 10.019552
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.649734
Insample Error 2.173681
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.006676
Rec Loss: 14.846596
KL Loss: 1.160080
Y Loss: 5.148478
T Loss: 12.272357
Epoch 99 
Overall Loss: 14.197121
Rec Loss: 12.890335
KL Loss: 1.306787
Y Loss: 1.269477
T Loss: 12.255596
Epoch 149 
Overall Loss: 13.933098
Rec Loss: 12.592412
KL Loss: 1.340687
Y Loss: 0.956879
T Loss: 12.113972
Epoch 199 
Overall Loss: 13.736179
Rec Loss: 12.382842
KL Loss: 1.353337
Y Loss: 0.917707
T Loss: 11.923989
Epoch 249 
Overall Loss: 13.622676
Rec Loss: 12.245761
KL Loss: 1.376915
Y Loss: 0.896560
T Loss: 11.797481
Epoch 299 
Overall Loss: 13.553362
Rec Loss: 12.161869
KL Loss: 1.391493
Y Loss: 0.911145
T Loss: 11.706296
Epoch 349 
Overall Loss: 13.482359
Rec Loss: 12.092482
KL Loss: 1.389877
Y Loss: 0.908003
T Loss: 11.638480
Epoch 399 
Overall Loss: 13.442997
Rec Loss: 12.053198
KL Loss: 1.389798
Y Loss: 0.906826
T Loss: 11.599786
Epoch 449 
Overall Loss: 13.418048
Rec Loss: 12.030884
KL Loss: 1.387164
Y Loss: 0.921368
T Loss: 11.570200
Epoch 499 
Overall Loss: 13.384108
Rec Loss: 11.984337
KL Loss: 1.399772
Y Loss: 0.890596
T Loss: 11.539039
Epoch 549 
Overall Loss: 13.364590
Rec Loss: 11.970431
KL Loss: 1.394159
Y Loss: 0.906510
T Loss: 11.517177
Epoch 599 
Overall Loss: 13.350202
Rec Loss: 11.960466
KL Loss: 1.389736
Y Loss: 0.897600
T Loss: 11.511666
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.883744
Epoch 99
Rec Loss: 1.879594
Epoch 149
Rec Loss: 1.885484
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.023200
Epoch 99
Rec Loss: 10.021887
Epoch 149
Rec Loss: 10.022613
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.646363
Insample Error: 2.485133
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.429089
Rec Loss: 21.563517
KL Loss: 0.865572
Y Loss: 8.172751
T Loss: 12.461157
X Loss: 5.015984
Epoch 99 
Overall Loss: 19.824217
Rec Loss: 18.501244
KL Loss: 1.322972
Y Loss: 2.617739
T Loss: 12.180395
X Loss: 5.011980
Epoch 149 
Overall Loss: 19.099647
Rec Loss: 17.794215
KL Loss: 1.305432
Y Loss: 1.564376
T Loss: 12.001473
X Loss: 5.010555
Epoch 199 
Overall Loss: 18.866797
Rec Loss: 17.516318
KL Loss: 1.350479
Y Loss: 1.394561
T Loss: 11.808635
X Loss: 5.010402
Epoch 249 
Overall Loss: 18.789834
Rec Loss: 17.401480
KL Loss: 1.388354
Y Loss: 1.272979
T Loss: 11.754573
X Loss: 5.010418
Epoch 299 
Overall Loss: 18.715226
Rec Loss: 17.296687
KL Loss: 1.418539
Y Loss: 1.179767
T Loss: 11.696488
X Loss: 5.010315
Epoch 349 
Overall Loss: 18.654334
Rec Loss: 17.236360
KL Loss: 1.417973
Y Loss: 1.133425
T Loss: 11.659278
X Loss: 5.010369
Epoch 399 
Overall Loss: 18.619033
Rec Loss: 17.187194
KL Loss: 1.431839
Y Loss: 1.068846
T Loss: 11.642138
X Loss: 5.010633
Epoch 449 
Overall Loss: 18.564615
Rec Loss: 17.136660
KL Loss: 1.427955
Y Loss: 1.014516
T Loss: 11.619329
X Loss: 5.010073
Epoch 499 
Overall Loss: 18.498470
Rec Loss: 17.087758
KL Loss: 1.410712
Y Loss: 0.974071
T Loss: 11.591051
X Loss: 5.009671
Epoch 549 
Overall Loss: 18.453944
Rec Loss: 17.063910
KL Loss: 1.390034
Y Loss: 0.930125
T Loss: 11.588791
X Loss: 5.010057
Epoch 599 
Overall Loss: 18.390750
Rec Loss: 17.016607
KL Loss: 1.374143
Y Loss: 0.907537
T Loss: 11.553246
X Loss: 5.009593
Epoch 649 
Overall Loss: 18.368257
Rec Loss: 17.010146
KL Loss: 1.358111
Y Loss: 0.876953
T Loss: 11.561280
X Loss: 5.010390
Epoch 699 
Overall Loss: 18.343500
Rec Loss: 16.992384
KL Loss: 1.351117
Y Loss: 0.884716
T Loss: 11.540384
X Loss: 5.009642
Epoch 749 
Overall Loss: 18.325704
Rec Loss: 16.981313
KL Loss: 1.344391
Y Loss: 0.851165
T Loss: 11.546985
X Loss: 5.008745
Epoch 799 
Overall Loss: 18.311296
Rec Loss: 16.969590
KL Loss: 1.341705
Y Loss: 0.854811
T Loss: 11.533046
X Loss: 5.009139
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.873022
Epoch 99
Rec Loss: 1.870604
Epoch 149
Rec Loss: 1.873584
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.022389
Epoch 99
Rec Loss: 10.023156
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.631463
Insample Error 2.032879
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.403011
Rec Loss: 15.371443
KL Loss: 1.031567
Y Loss: 6.140121
T Loss: 12.301382
Epoch 99 
Overall Loss: 14.376364
Rec Loss: 13.056473
KL Loss: 1.319891
Y Loss: 1.644072
T Loss: 12.234437
Epoch 149 
Overall Loss: 14.004497
Rec Loss: 12.654379
KL Loss: 1.350119
Y Loss: 1.142712
T Loss: 12.083022
Epoch 199 
Overall Loss: 13.740872
Rec Loss: 12.352294
KL Loss: 1.388577
Y Loss: 0.945433
T Loss: 11.879578
Epoch 249 
Overall Loss: 13.600846
Rec Loss: 12.184655
KL Loss: 1.416191
Y Loss: 0.906359
T Loss: 11.731476
Epoch 299 
Overall Loss: 13.528051
Rec Loss: 12.111160
KL Loss: 1.416891
Y Loss: 0.922448
T Loss: 11.649936
Epoch 349 
Overall Loss: 13.466901
Rec Loss: 12.056162
KL Loss: 1.410739
Y Loss: 0.908383
T Loss: 11.601971
Epoch 399 
Overall Loss: 13.445453
Rec Loss: 12.037481
KL Loss: 1.407971
Y Loss: 0.940231
T Loss: 11.567366
Epoch 449 
Overall Loss: 13.407363
Rec Loss: 11.991927
KL Loss: 1.415436
Y Loss: 0.896765
T Loss: 11.543545
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.899158
Epoch 99
Rec Loss: 1.899224
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.023856
Epoch 99
Rec Loss: 10.024914
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.666745
Insample Error: 2.592738
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.885407
Rec Loss: 20.846631
KL Loss: 1.038777
Y Loss: 6.747520
T Loss: 12.457728
X Loss: 5.015142
Epoch 99 
Overall Loss: 19.709669
Rec Loss: 18.389505
KL Loss: 1.320163
Y Loss: 2.346028
T Loss: 12.205423
X Loss: 5.011068
Epoch 149 
Overall Loss: 19.094912
Rec Loss: 17.798840
KL Loss: 1.296073
Y Loss: 1.542404
T Loss: 12.017103
X Loss: 5.010534
Epoch 199 
Overall Loss: 18.886532
Rec Loss: 17.536494
KL Loss: 1.350038
Y Loss: 1.390755
T Loss: 11.830073
X Loss: 5.011044
Epoch 249 
Overall Loss: 18.757853
Rec Loss: 17.366949
KL Loss: 1.390904
Y Loss: 1.235109
T Loss: 11.738371
X Loss: 5.011023
Epoch 299 
Overall Loss: 18.696290
Rec Loss: 17.282125
KL Loss: 1.414165
Y Loss: 1.138178
T Loss: 11.702498
X Loss: 5.010537
Epoch 349 
Overall Loss: 18.648899
Rec Loss: 17.233031
KL Loss: 1.415867
Y Loss: 1.110477
T Loss: 11.667500
X Loss: 5.010293
Epoch 399 
Overall Loss: 18.589457
Rec Loss: 17.182021
KL Loss: 1.407435
Y Loss: 1.042996
T Loss: 11.650244
X Loss: 5.010280
Epoch 449 
Overall Loss: 18.521379
Rec Loss: 17.133563
KL Loss: 1.387816
Y Loss: 0.993778
T Loss: 11.625948
X Loss: 5.010726
Epoch 499 
Overall Loss: 18.470203
Rec Loss: 17.102956
KL Loss: 1.367247
Y Loss: 0.966599
T Loss: 11.609515
X Loss: 5.010142
Epoch 549 
Overall Loss: 18.424466
Rec Loss: 17.063196
KL Loss: 1.361270
Y Loss: 0.918990
T Loss: 11.593670
X Loss: 5.010031
Epoch 599 
Overall Loss: 18.377548
Rec Loss: 17.018574
KL Loss: 1.358974
Y Loss: 0.900426
T Loss: 11.558152
X Loss: 5.010209
Epoch 649 
Overall Loss: 18.359184
Rec Loss: 17.001439
KL Loss: 1.357745
Y Loss: 0.902058
T Loss: 11.540830
X Loss: 5.009580
Epoch 699 
Overall Loss: 18.342090
Rec Loss: 16.995014
KL Loss: 1.347077
Y Loss: 0.884552
T Loss: 11.543227
X Loss: 5.009511
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.891040
Epoch 99
Rec Loss: 1.893749
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.023192
Epoch 99
Rec Loss: 10.022638
Epoch 149
Rec Loss: 10.022098
Epoch 199
Rec Loss: 10.021103
Epoch 249
Rec Loss: 10.020659
Epoch 299
Rec Loss: 10.019427
Epoch 349
Rec Loss: 10.021482
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.651614
Insample Error 2.127070
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.763201
Rec Loss: 15.829987
KL Loss: 0.933214
Y Loss: 6.978508
T Loss: 12.340733
Epoch 99 
Overall Loss: 14.254945
Rec Loss: 12.952808
KL Loss: 1.302137
Y Loss: 1.394032
T Loss: 12.255792
Epoch 149 
Overall Loss: 13.949538
Rec Loss: 12.611773
KL Loss: 1.337765
Y Loss: 1.054202
T Loss: 12.084672
Epoch 199 
Overall Loss: 13.739094
Rec Loss: 12.365638
KL Loss: 1.373456
Y Loss: 0.973850
T Loss: 11.878712
Epoch 249 
Overall Loss: 13.610834
Rec Loss: 12.205549
KL Loss: 1.405285
Y Loss: 0.922790
T Loss: 11.744154
Epoch 299 
Overall Loss: 13.542343
Rec Loss: 12.127478
KL Loss: 1.414866
Y Loss: 0.946165
T Loss: 11.654394
Epoch 349 
Overall Loss: 13.485044
Rec Loss: 12.079697
KL Loss: 1.405348
Y Loss: 0.944569
T Loss: 11.607412
Epoch 399 
Overall Loss: 13.436742
Rec Loss: 12.032068
KL Loss: 1.404674
Y Loss: 0.911234
T Loss: 11.576451
Epoch 449 
Overall Loss: 13.412620
Rec Loss: 12.010128
KL Loss: 1.402492
Y Loss: 0.935931
T Loss: 11.542162
Epoch 499 
Overall Loss: 13.393236
Rec Loss: 12.003109
KL Loss: 1.390127
Y Loss: 0.939803
T Loss: 11.533207
Epoch 549 
Overall Loss: 13.356006
Rec Loss: 11.961260
KL Loss: 1.394745
Y Loss: 0.918254
T Loss: 11.502133
Epoch 599 
Overall Loss: 13.350144
Rec Loss: 11.954893
KL Loss: 1.395251
Y Loss: 0.896469
T Loss: 11.506658
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.884606
Epoch 99
Rec Loss: 1.884605
Epoch 149
Rec Loss: 1.886615
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.025666
Epoch 99
Rec Loss: 10.023179
Epoch 149
Rec Loss: 10.024831
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.653706
Insample Error: 2.529979
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.835402
Rec Loss: 20.774361
KL Loss: 1.061041
Y Loss: 6.778216
T Loss: 12.371981
X Loss: 5.013273
Epoch 99 
Overall Loss: 19.693667
Rec Loss: 18.392029
KL Loss: 1.301638
Y Loss: 2.363910
T Loss: 12.201134
X Loss: 5.008940
Epoch 149 
Overall Loss: 19.084086
Rec Loss: 17.774139
KL Loss: 1.309947
Y Loss: 1.561424
T Loss: 11.982456
X Loss: 5.010971
Epoch 199 
Overall Loss: 18.840604
Rec Loss: 17.466217
KL Loss: 1.374387
Y Loss: 1.329033
T Loss: 11.791206
X Loss: 5.010495
Epoch 249 
Overall Loss: 18.754090
Rec Loss: 17.357206
KL Loss: 1.396884
Y Loss: 1.234303
T Loss: 11.729767
X Loss: 5.010287
Epoch 299 
Overall Loss: 18.699808
Rec Loss: 17.262914
KL Loss: 1.436893
Y Loss: 1.160757
T Loss: 11.672163
X Loss: 5.010373
Epoch 349 
Overall Loss: 18.670884
Rec Loss: 17.224373
KL Loss: 1.446511
Y Loss: 1.097834
T Loss: 11.665054
X Loss: 5.010401
Epoch 399 
Overall Loss: 18.620975
Rec Loss: 17.179487
KL Loss: 1.441489
Y Loss: 1.048264
T Loss: 11.644942
X Loss: 5.010413
Epoch 449 
Overall Loss: 18.575871
Rec Loss: 17.150494
KL Loss: 1.425377
Y Loss: 1.023960
T Loss: 11.627994
X Loss: 5.010521
Epoch 499 
Overall Loss: 18.531301
Rec Loss: 17.116366
KL Loss: 1.414935
Y Loss: 0.989329
T Loss: 11.611271
X Loss: 5.010431
Epoch 549 
Overall Loss: 18.483477
Rec Loss: 17.100386
KL Loss: 1.383092
Y Loss: 0.972415
T Loss: 11.603878
X Loss: 5.010300
Epoch 599 
Overall Loss: 18.447205
Rec Loss: 17.070126
KL Loss: 1.377079
Y Loss: 0.962894
T Loss: 11.578931
X Loss: 5.009748
Epoch 649 
Overall Loss: 18.419399
Rec Loss: 17.038944
KL Loss: 1.380455
Y Loss: 0.948653
T Loss: 11.555037
X Loss: 5.009581
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.898664
Epoch 99
Rec Loss: 1.906763
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.024075
Epoch 99
Rec Loss: 10.024149
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.672823
Insample Error 2.386930
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.831954
Rec Loss: 14.645521
KL Loss: 1.186432
Y Loss: 4.699709
T Loss: 12.295667
Epoch 99 
Overall Loss: 14.298169
Rec Loss: 12.960311
KL Loss: 1.337858
Y Loss: 1.425890
T Loss: 12.247366
Epoch 149 
Overall Loss: 13.995683
Rec Loss: 12.631341
KL Loss: 1.364342
Y Loss: 1.050695
T Loss: 12.105993
Epoch 199 
Overall Loss: 13.746885
Rec Loss: 12.367705
KL Loss: 1.379180
Y Loss: 0.943220
T Loss: 11.896095
Epoch 249 
Overall Loss: 13.600841
Rec Loss: 12.197100
KL Loss: 1.403741
Y Loss: 0.888197
T Loss: 11.753002
Epoch 299 
Overall Loss: 13.537043
Rec Loss: 12.130127
KL Loss: 1.406917
Y Loss: 0.901439
T Loss: 11.679407
Epoch 349 
Overall Loss: 13.468180
Rec Loss: 12.072746
KL Loss: 1.395433
Y Loss: 0.919371
T Loss: 11.613061
Epoch 399 
Overall Loss: 13.430087
Rec Loss: 12.029074
KL Loss: 1.401012
Y Loss: 0.886913
T Loss: 11.585618
Epoch 449 
Overall Loss: 13.396548
Rec Loss: 11.996552
KL Loss: 1.399996
Y Loss: 0.879902
T Loss: 11.556601
Epoch 499 
Overall Loss: 13.383533
Rec Loss: 11.985010
KL Loss: 1.398523
Y Loss: 0.888840
T Loss: 11.540590
Epoch 549 
Overall Loss: 13.340359
Rec Loss: 11.951047
KL Loss: 1.389312
Y Loss: 0.864314
T Loss: 11.518889
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.881450
Epoch 99
Rec Loss: 1.873532
Epoch 149
Rec Loss: 1.889410
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.023502
Epoch 99
Rec Loss: 10.023629
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.627918
Insample Error: 2.301046
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.201925
Rec Loss: 21.279447
KL Loss: 0.922478
Y Loss: 7.706964
T Loss: 12.415500
X Loss: 5.010466
Epoch 99 
Overall Loss: 19.866216
Rec Loss: 18.603615
KL Loss: 1.262600
Y Loss: 2.895191
T Loss: 12.146127
X Loss: 5.009893
Epoch 149 
Overall Loss: 19.188669
Rec Loss: 17.888996
KL Loss: 1.299672
Y Loss: 1.744036
T Loss: 12.007955
X Loss: 5.009023
Epoch 199 
Overall Loss: 18.931477
Rec Loss: 17.559213
KL Loss: 1.372264
Y Loss: 1.424250
T Loss: 11.837389
X Loss: 5.009698
Epoch 249 
Overall Loss: 18.809422
Rec Loss: 17.403672
KL Loss: 1.405750
Y Loss: 1.289174
T Loss: 11.748775
X Loss: 5.010310
Epoch 299 
Overall Loss: 18.730499
Rec Loss: 17.303508
KL Loss: 1.426991
Y Loss: 1.193882
T Loss: 11.695303
X Loss: 5.011264
Epoch 349 
Overall Loss: 18.691649
Rec Loss: 17.249655
KL Loss: 1.441993
Y Loss: 1.111495
T Loss: 11.683522
X Loss: 5.010385
Epoch 399 
Overall Loss: 18.642887
Rec Loss: 17.180832
KL Loss: 1.462055
Y Loss: 1.047359
T Loss: 11.646683
X Loss: 5.010470
Epoch 449 
Overall Loss: 18.610988
Rec Loss: 17.159296
KL Loss: 1.451692
Y Loss: 1.018477
T Loss: 11.640040
X Loss: 5.010017
Epoch 499 
Overall Loss: 18.553292
Rec Loss: 17.130148
KL Loss: 1.423144
Y Loss: 0.998219
T Loss: 11.620665
X Loss: 5.010374
Epoch 549 
Overall Loss: 18.484196
Rec Loss: 17.087320
KL Loss: 1.396877
Y Loss: 0.946895
T Loss: 11.603095
X Loss: 5.010777
Epoch 599 
Overall Loss: 18.427928
Rec Loss: 17.036418
KL Loss: 1.391509
Y Loss: 0.915107
T Loss: 11.568560
X Loss: 5.010305
Epoch 649 
Overall Loss: 18.397603
Rec Loss: 17.023920
KL Loss: 1.373682
Y Loss: 0.883904
T Loss: 11.572302
X Loss: 5.009666
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.905384
Epoch 99
Rec Loss: 1.896485
Epoch 149
Rec Loss: 1.893638
Epoch 199
Rec Loss: 1.897472
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.023692
Epoch 99
Rec Loss: 10.023315
Epoch 149
Rec Loss: 10.021504
Epoch 199
Rec Loss: 10.022893
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.633935
Insample Error 2.137884
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.709491
Rec Loss: 14.599383
KL Loss: 1.110108
Y Loss: 4.675756
T Loss: 12.261505
Epoch 99 
Overall Loss: 14.189148
Rec Loss: 12.891384
KL Loss: 1.297765
Y Loss: 1.346552
T Loss: 12.218108
Epoch 149 
Overall Loss: 13.929029
Rec Loss: 12.607576
KL Loss: 1.321453
Y Loss: 1.018987
T Loss: 12.098082
Epoch 199 
Overall Loss: 13.744399
Rec Loss: 12.401094
KL Loss: 1.343305
Y Loss: 0.901698
T Loss: 11.950246
Epoch 249 
Overall Loss: 13.614991
Rec Loss: 12.229503
KL Loss: 1.385488
Y Loss: 0.876261
T Loss: 11.791372
Epoch 299 
Overall Loss: 13.537307
Rec Loss: 12.150977
KL Loss: 1.386329
Y Loss: 0.899554
T Loss: 11.701200
Epoch 349 
Overall Loss: 13.478794
Rec Loss: 12.075202
KL Loss: 1.403593
Y Loss: 0.891943
T Loss: 11.629230
Epoch 399 
Overall Loss: 13.447841
Rec Loss: 12.042585
KL Loss: 1.405256
Y Loss: 0.901409
T Loss: 11.591880
Epoch 449 
Overall Loss: 13.422760
Rec Loss: 12.030252
KL Loss: 1.392508
Y Loss: 0.920270
T Loss: 11.570117
Epoch 499 
Overall Loss: 13.392182
Rec Loss: 11.992623
KL Loss: 1.399559
Y Loss: 0.897100
T Loss: 11.544073
Epoch 549 
Overall Loss: 13.367117
Rec Loss: 11.966900
KL Loss: 1.400217
Y Loss: 0.889002
T Loss: 11.522399
Epoch 599 
Overall Loss: 13.338873
Rec Loss: 11.947763
KL Loss: 1.391110
Y Loss: 0.887626
T Loss: 11.503950
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.882057
Epoch 99
Rec Loss: 1.890365
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.026543
Epoch 99
Rec Loss: 10.023336
Epoch 149
Rec Loss: 10.021692
Epoch 199
Rec Loss: 10.022833
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.657527
Insample Error: 2.497035
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.646117
Rec Loss: 20.529394
KL Loss: 1.116722
Y Loss: 6.257119
T Loss: 12.387237
X Loss: 5.013599
Epoch 99 
Overall Loss: 19.706826
Rec Loss: 18.433476
KL Loss: 1.273351
Y Loss: 2.364313
T Loss: 12.238650
X Loss: 5.012669
Epoch 149 
Overall Loss: 19.118441
Rec Loss: 17.837412
KL Loss: 1.281029
Y Loss: 1.539494
T Loss: 12.056509
X Loss: 5.011156
Epoch 199 
Overall Loss: 18.872069
Rec Loss: 17.530593
KL Loss: 1.341476
Y Loss: 1.326095
T Loss: 11.856740
X Loss: 5.010805
Epoch 249 
Overall Loss: 18.776191
Rec Loss: 17.370104
KL Loss: 1.406086
Y Loss: 1.230375
T Loss: 11.744703
X Loss: 5.010213
Epoch 299 
Overall Loss: 18.720440
Rec Loss: 17.292626
KL Loss: 1.427814
Y Loss: 1.175960
T Loss: 11.693802
X Loss: 5.010843
Epoch 349 
Overall Loss: 18.664198
Rec Loss: 17.233606
KL Loss: 1.430592
Y Loss: 1.091671
T Loss: 11.677257
X Loss: 5.010513
Epoch 399 
Overall Loss: 18.617417
Rec Loss: 17.178038
KL Loss: 1.439379
Y Loss: 1.045727
T Loss: 11.644421
X Loss: 5.010753
Epoch 449 
Overall Loss: 18.559442
Rec Loss: 17.137147
KL Loss: 1.422295
Y Loss: 1.006153
T Loss: 11.623707
X Loss: 5.010364
Epoch 499 
Overall Loss: 18.498701
Rec Loss: 17.105859
KL Loss: 1.392843
Y Loss: 0.962822
T Loss: 11.614180
X Loss: 5.010267
Epoch 549 
Overall Loss: 18.447105
Rec Loss: 17.050381
KL Loss: 1.396724
Y Loss: 0.926275
T Loss: 11.577679
X Loss: 5.009565
Epoch 599 
Overall Loss: 18.414342
Rec Loss: 17.022425
KL Loss: 1.391917
Y Loss: 0.919855
T Loss: 11.552690
X Loss: 5.009807
Epoch 649 
Overall Loss: 18.381340
Rec Loss: 17.000749
KL Loss: 1.380590
Y Loss: 0.902555
T Loss: 11.540199
X Loss: 5.009273
Epoch 699 
Overall Loss: 18.350178
Rec Loss: 16.962589
KL Loss: 1.387589
Y Loss: 0.862287
T Loss: 11.522498
X Loss: 5.008947
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.887299
Epoch 99
Rec Loss: 1.883586
Epoch 149
Rec Loss: 1.877602
Epoch 199
Rec Loss: 1.880826
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.022108
Epoch 99
Rec Loss: 10.021069
Epoch 149
Rec Loss: 10.019240
Epoch 199
Rec Loss: 10.021393
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.634177
Insample Error 2.255546
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.748961
Rec Loss: 15.805711
KL Loss: 0.943250
Y Loss: 6.701971
T Loss: 12.454725
Epoch 99 
Overall Loss: 14.260112
Rec Loss: 12.971610
KL Loss: 1.288502
Y Loss: 1.406730
T Loss: 12.268245
Epoch 149 
Overall Loss: 13.982853
Rec Loss: 12.667771
KL Loss: 1.315082
Y Loss: 1.037851
T Loss: 12.148845
Epoch 199 
Overall Loss: 13.769225
Rec Loss: 12.434604
KL Loss: 1.334621
Y Loss: 0.912974
T Loss: 11.978117
Epoch 249 
Overall Loss: 13.627576
Rec Loss: 12.267477
KL Loss: 1.360099
Y Loss: 0.899096
T Loss: 11.817929
Epoch 299 
Overall Loss: 13.526311
Rec Loss: 12.148070
KL Loss: 1.378242
Y Loss: 0.906217
T Loss: 11.694961
Epoch 349 
Overall Loss: 13.460062
Rec Loss: 12.069980
KL Loss: 1.390082
Y Loss: 0.900180
T Loss: 11.619890
Epoch 399 
Overall Loss: 13.431316
Rec Loss: 12.030522
KL Loss: 1.400794
Y Loss: 0.898572
T Loss: 11.581236
Epoch 449 
Overall Loss: 13.396262
Rec Loss: 12.003119
KL Loss: 1.393142
Y Loss: 0.911026
T Loss: 11.547606
Epoch 499 
Overall Loss: 13.373803
Rec Loss: 11.992271
KL Loss: 1.381532
Y Loss: 0.911962
T Loss: 11.536291
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.883392
Epoch 99
Rec Loss: 1.884011
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.023450
Epoch 99
Rec Loss: 10.022334
Epoch 149
Rec Loss: 10.023299
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.641490
Insample Error: 2.441225
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 21.865825
Rec Loss: 20.884655
KL Loss: 0.981170
Y Loss: 6.859505
T Loss: 12.443078
X Loss: 5.011824
Epoch 99 
Overall Loss: 19.826102
Rec Loss: 18.557510
KL Loss: 1.268592
Y Loss: 2.603165
T Loss: 12.244642
X Loss: 5.011285
Epoch 149 
Overall Loss: 19.165716
Rec Loss: 17.890407
KL Loss: 1.275309
Y Loss: 1.587549
T Loss: 12.085755
X Loss: 5.010878
Epoch 199 
Overall Loss: 18.931085
Rec Loss: 17.611323
KL Loss: 1.319762
Y Loss: 1.409861
T Loss: 11.896538
X Loss: 5.009854
Epoch 249 
Overall Loss: 18.809305
Rec Loss: 17.402746
KL Loss: 1.406559
Y Loss: 1.227719
T Loss: 11.778573
X Loss: 5.010314
Epoch 299 
Overall Loss: 18.739013
Rec Loss: 17.292202
KL Loss: 1.446811
Y Loss: 1.146902
T Loss: 11.708058
X Loss: 5.010693
Epoch 349 
Overall Loss: 18.680571
Rec Loss: 17.218592
KL Loss: 1.461980
Y Loss: 1.053399
T Loss: 11.681097
X Loss: 5.010795
Epoch 399 
Overall Loss: 18.638689
Rec Loss: 17.181737
KL Loss: 1.456952
Y Loss: 1.039856
T Loss: 11.651052
X Loss: 5.010757
Epoch 449 
Overall Loss: 18.580078
Rec Loss: 17.119165
KL Loss: 1.460913
Y Loss: 0.974187
T Loss: 11.621513
X Loss: 5.010559
Epoch 499 
Overall Loss: 18.533556
Rec Loss: 17.090222
KL Loss: 1.443334
Y Loss: 0.945821
T Loss: 11.606404
X Loss: 5.010907
Epoch 549 
Overall Loss: 18.464292
Rec Loss: 17.064416
KL Loss: 1.399877
Y Loss: 0.935245
T Loss: 11.586320
X Loss: 5.010472
Epoch 599 
Overall Loss: 18.426970
Rec Loss: 17.046808
KL Loss: 1.380162
Y Loss: 0.939742
T Loss: 11.566867
X Loss: 5.010070
Epoch 649 
Overall Loss: 18.371774
Rec Loss: 17.002534
KL Loss: 1.369240
Y Loss: 0.873630
T Loss: 11.556154
X Loss: 5.009565
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.896999
Epoch 99
Rec Loss: 1.896942
Epoch 149
Rec Loss: 1.898709
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.024892
Epoch 99
Rec Loss: 10.024527
Epoch 149
Rec Loss: 10.023170
Epoch 199
Rec Loss: 10.022218
Epoch 249
Rec Loss: 10.021139
Epoch 299
Rec Loss: 10.022017
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.640420
Insample Error 2.168562
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.767225
Rec Loss: 15.783189
KL Loss: 0.984035
Y Loss: 6.894724
T Loss: 12.335828
Epoch 99 
Overall Loss: 14.329421
Rec Loss: 13.044491
KL Loss: 1.284930
Y Loss: 1.526141
T Loss: 12.281420
Epoch 149 
Overall Loss: 14.028085
Rec Loss: 12.711327
KL Loss: 1.316758
Y Loss: 1.109097
T Loss: 12.156778
Epoch 199 
Overall Loss: 13.794558
Rec Loss: 12.449686
KL Loss: 1.344872
Y Loss: 0.953859
T Loss: 11.972756
Epoch 249 
Overall Loss: 13.630556
Rec Loss: 12.257690
KL Loss: 1.372865
Y Loss: 0.893045
T Loss: 11.811168
Epoch 299 
Overall Loss: 13.541650
Rec Loss: 12.145515
KL Loss: 1.396135
Y Loss: 0.887009
T Loss: 11.702010
Epoch 349 
Overall Loss: 13.489887
Rec Loss: 12.089356
KL Loss: 1.400531
Y Loss: 0.898491
T Loss: 11.640111
Epoch 399 
Overall Loss: 13.438425
Rec Loss: 12.032938
KL Loss: 1.405486
Y Loss: 0.888248
T Loss: 11.588814
Epoch 449 
Overall Loss: 13.414230
Rec Loss: 12.020942
KL Loss: 1.393288
Y Loss: 0.898718
T Loss: 11.571582
Epoch 499 
Overall Loss: 13.378365
Rec Loss: 11.979453
KL Loss: 1.398912
Y Loss: 0.880005
T Loss: 11.539451
Epoch 549 
Overall Loss: 13.362098
Rec Loss: 11.962200
KL Loss: 1.399898
Y Loss: 0.892201
T Loss: 11.516099
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.891919
Epoch 99
Rec Loss: 1.887267
Epoch 149
Rec Loss: 1.889750
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.024583
Epoch 99
Rec Loss: 10.022865
Epoch 149
Rec Loss: 10.024202
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.642334
Insample Error: 2.373794
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 22.056368
Rec Loss: 21.066224
KL Loss: 0.990144
Y Loss: 7.306638
T Loss: 12.399710
X Loss: 5.013195
Epoch 99 
Overall Loss: 19.815285
Rec Loss: 18.526656
KL Loss: 1.288628
Y Loss: 2.612661
T Loss: 12.208907
X Loss: 5.011419
Epoch 149 
Overall Loss: 19.142095
Rec Loss: 17.836279
KL Loss: 1.305816
Y Loss: 1.603327
T Loss: 12.023721
X Loss: 5.010895
Epoch 199 
Overall Loss: 18.902132
Rec Loss: 17.542877
KL Loss: 1.359256
Y Loss: 1.412904
T Loss: 11.825490
X Loss: 5.010935
Epoch 249 
Overall Loss: 18.778349
Rec Loss: 17.387526
KL Loss: 1.390824
Y Loss: 1.287098
T Loss: 11.733246
X Loss: 5.010730
Epoch 299 
Overall Loss: 18.714332
Rec Loss: 17.298216
KL Loss: 1.416116
Y Loss: 1.179901
T Loss: 11.697322
X Loss: 5.010944
Epoch 349 
Overall Loss: 18.654961
Rec Loss: 17.234096
KL Loss: 1.420865
Y Loss: 1.113781
T Loss: 11.666456
X Loss: 5.010749
Epoch 399 
Overall Loss: 18.607589
Rec Loss: 17.184345
KL Loss: 1.423244
Y Loss: 1.058483
T Loss: 11.644267
X Loss: 5.010837
Epoch 449 
Overall Loss: 18.551373
Rec Loss: 17.145783
KL Loss: 1.405591
Y Loss: 1.013083
T Loss: 11.628867
X Loss: 5.010375
Epoch 499 
Overall Loss: 18.501020
Rec Loss: 17.107287
KL Loss: 1.393733
Y Loss: 0.981840
T Loss: 11.606292
X Loss: 5.010075
Epoch 549 
Overall Loss: 18.432658
Rec Loss: 17.050246
KL Loss: 1.382412
Y Loss: 0.926466
T Loss: 11.576988
X Loss: 5.010025
Epoch 599 
Overall Loss: 18.400521
Rec Loss: 17.032750
KL Loss: 1.367771
Y Loss: 0.929097
T Loss: 11.558508
X Loss: 5.009694
Epoch 649 
Overall Loss: 18.370521
Rec Loss: 16.992967
KL Loss: 1.377554
Y Loss: 0.894908
T Loss: 11.535389
X Loss: 5.010124
Epoch 699 
Overall Loss: 18.346405
Rec Loss: 16.968530
KL Loss: 1.377875
Y Loss: 0.872155
T Loss: 11.522354
X Loss: 5.010098
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.890025
Epoch 99
Rec Loss: 1.891759
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.024657
Epoch 99
Rec Loss: 10.022529
Epoch 149
Rec Loss: 10.021123
Epoch 199
Rec Loss: 10.021894
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.645021
Insample Error 2.227351
Ours, Train RMSE
0.6448, 
0.6344, 
0.6573, 
0.6464, 
0.6667, 
0.6537, 
0.6279, 
0.6575, 
0.6415, 
0.6423, 
CEVAE, Train RMSE
0.6767, 
0.6263, 
0.6497, 
0.6315, 
0.6516, 
0.6728, 
0.6339, 
0.6342, 
0.6404, 
0.6450, 
Ours, Insample RMSE
2.3678, 
2.3844, 
2.4943, 
2.4851, 
2.5927, 
2.5300, 
2.3010, 
2.4970, 
2.4412, 
2.3738, 
CEVAE, Insample RMSE
2.2943, 
2.1343, 
2.1737, 
2.0329, 
2.1271, 
2.3869, 
2.1379, 
2.2555, 
2.1686, 
2.2274, 
Train, RMSE mean 0.6473 std 0.0111
CEVAE, RMSE mean 0.6462 std 0.0162
Ours, RMSE mean 2.4467 std 0.0844, reconstruct confounder 1.8840 (0.0085) noise 10.0225 (0.0009)
CEVAE, RMSE mean 2.1939 std 0.0951, reconstruct confounder 1.8877 (0.0090) noise 10.0209 (0.0015)
Experiment Start!
Namespace(decay=0.0, l=5e-05, latdim=4, mask=5, nlayer=50, obsm=0, ycof=0.5, ylayer=50)
Y Mean 1.514292, Std 3.653528 
Observe confounder 0, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.678356
Rec Loss: 15.581261
KL Loss: 1.097096
Y Loss: 5.981866
T Loss: 12.590327
Epoch 99 
Overall Loss: 14.449794
Rec Loss: 13.158470
KL Loss: 1.291324
Y Loss: 1.745859
T Loss: 12.285540
Epoch 149 
Overall Loss: 14.013508
Rec Loss: 12.689384
KL Loss: 1.324124
Y Loss: 1.152217
T Loss: 12.113275
Epoch 199 
Overall Loss: 13.739523
Rec Loss: 12.377452
KL Loss: 1.362070
Y Loss: 0.923972
T Loss: 11.915467
Epoch 249 
Overall Loss: 13.606523
Rec Loss: 12.212648
KL Loss: 1.393875
Y Loss: 0.874282
T Loss: 11.775507
Epoch 299 
Overall Loss: 13.528032
Rec Loss: 12.117239
KL Loss: 1.410793
Y Loss: 0.901189
T Loss: 11.666644
Epoch 349 
Overall Loss: 13.482182
Rec Loss: 12.079716
KL Loss: 1.402466
Y Loss: 0.913046
T Loss: 11.623193
Epoch 399 
Overall Loss: 13.450940
Rec Loss: 12.053207
KL Loss: 1.397733
Y Loss: 0.931197
T Loss: 11.587608
Epoch 449 
Overall Loss: 13.403659
Rec Loss: 12.010890
KL Loss: 1.392770
Y Loss: 0.928111
T Loss: 11.546834
Epoch 499 
Overall Loss: 13.374827
Rec Loss: 11.977349
KL Loss: 1.397478
Y Loss: 0.888541
T Loss: 11.533079
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.901385
Epoch 99
Rec Loss: 1.896992
Epoch 149
Rec Loss: 1.895830
Epoch 199
Rec Loss: 1.893889
Epoch 249
Rec Loss: 1.908240
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.983263
Epoch 99
Rec Loss: 4.982476
Epoch 149
Rec Loss: 4.984223
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.657276
Insample Error: 2.501991
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 6.212070
Rec Loss: 0.706884
KL Loss: 5.505186
Y Loss: 8.189868
T Loss: 13.092588
X Loss: -16.480637
Epoch 99 
Overall Loss: -6.430235
Rec Loss: -13.871033
KL Loss: 7.440798
Y Loss: 4.570402
T Loss: 12.160342
X Loss: -28.316576
Epoch 149 
Overall Loss: -10.383887
Rec Loss: -18.748673
KL Loss: 8.364786
Y Loss: 2.315844
T Loss: 11.820218
X Loss: -31.726813
Epoch 199 
Overall Loss: -12.393629
Rec Loss: -20.798983
KL Loss: 8.405355
Y Loss: 1.936856
T Loss: 11.729742
X Loss: -33.497153
Epoch 249 
Overall Loss: -12.696762
Rec Loss: -21.451915
KL Loss: 8.755153
Y Loss: 1.820772
T Loss: 11.642307
X Loss: -34.004608
Epoch 299 
Overall Loss: -11.258058
Rec Loss: -20.011812
KL Loss: 8.753754
Y Loss: 1.570300
T Loss: 11.697570
X Loss: -32.494533
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.115271
Epoch 99
Rec Loss: 2.073415
Epoch 149
Rec Loss: 2.028162
Epoch 199
Rec Loss: 2.021121
Epoch 249
Rec Loss: 2.020780
Epoch 299
Rec Loss: 2.008356
Epoch 349
Rec Loss: 2.009651
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.996464
Epoch 99
Rec Loss: 4.998096
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 1.002932
Insample Error 2.751553
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.725694
Rec Loss: 15.608091
KL Loss: 1.117603
Y Loss: 6.203778
T Loss: 12.506202
Epoch 99 
Overall Loss: 14.704278
Rec Loss: 13.335822
KL Loss: 1.368456
Y Loss: 1.913220
T Loss: 12.379212
Epoch 149 
Overall Loss: 14.091726
Rec Loss: 12.815128
KL Loss: 1.276598
Y Loss: 1.267675
T Loss: 12.181291
Epoch 199 
Overall Loss: 13.786398
Rec Loss: 12.495974
KL Loss: 1.290424
Y Loss: 0.996750
T Loss: 11.997599
Epoch 249 
Overall Loss: 13.603973
Rec Loss: 12.281184
KL Loss: 1.322789
Y Loss: 0.897362
T Loss: 11.832503
Epoch 299 
Overall Loss: 13.490641
Rec Loss: 12.136000
KL Loss: 1.354640
Y Loss: 0.887535
T Loss: 11.692232
Epoch 349 
Overall Loss: 13.449537
Rec Loss: 12.078450
KL Loss: 1.371087
Y Loss: 0.914402
T Loss: 11.621249
Epoch 399 
Overall Loss: 13.405759
Rec Loss: 12.018824
KL Loss: 1.386935
Y Loss: 0.915010
T Loss: 11.561319
Epoch 449 
Overall Loss: 13.372700
Rec Loss: 11.985612
KL Loss: 1.387088
Y Loss: 0.910206
T Loss: 11.530509
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.893436
Epoch 99
Rec Loss: 1.903836
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.992220
Epoch 99
Rec Loss: 4.987021
Epoch 149
Rec Loss: 4.991956
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.667626
Insample Error: 2.520216
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 5.309939
Rec Loss: -0.062584
KL Loss: 5.372523
Y Loss: 8.825652
T Loss: 13.298582
X Loss: -17.773992
Epoch 99 
Overall Loss: -7.116829
Rec Loss: -14.019639
KL Loss: 6.902810
Y Loss: 4.254890
T Loss: 12.311128
X Loss: -28.458212
Epoch 149 
Overall Loss: -10.905901
Rec Loss: -18.588273
KL Loss: 7.682373
Y Loss: 2.539534
T Loss: 12.015643
X Loss: -31.873684
Epoch 199 
Overall Loss: -11.972939
Rec Loss: -19.890161
KL Loss: 7.917221
Y Loss: 2.140553
T Loss: 11.904188
X Loss: -32.864626
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.141861
Epoch 99
Rec Loss: 2.108326
Epoch 149
Rec Loss: 2.053498
Epoch 199
Rec Loss: 2.049495
Epoch 249
Rec Loss: 2.029539
Epoch 299
Rec Loss: 2.046652
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.991983
Epoch 99
Rec Loss: 4.986571
Epoch 149
Rec Loss: 4.985047
Epoch 199
Rec Loss: 4.984113
Epoch 249
Rec Loss: 4.979022
Epoch 299
Rec Loss: 4.980464
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 1.252925
Insample Error 3.285585
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.830879
Rec Loss: 17.205878
KL Loss: 0.625001
Y Loss: 8.684572
T Loss: 12.863593
Epoch 99 
Overall Loss: 14.395730
Rec Loss: 13.074721
KL Loss: 1.321009
Y Loss: 1.775093
T Loss: 12.187175
Epoch 149 
Overall Loss: 13.914564
Rec Loss: 12.553705
KL Loss: 1.360860
Y Loss: 1.103758
T Loss: 12.001825
Epoch 199 
Overall Loss: 13.696009
Rec Loss: 12.308417
KL Loss: 1.387592
Y Loss: 0.953734
T Loss: 11.831549
Epoch 249 
Overall Loss: 13.561864
Rec Loss: 12.174404
KL Loss: 1.387460
Y Loss: 0.907889
T Loss: 11.720460
Epoch 299 
Overall Loss: 13.483760
Rec Loss: 12.089003
KL Loss: 1.394757
Y Loss: 0.899945
T Loss: 11.639031
Epoch 349 
Overall Loss: 13.467805
Rec Loss: 12.080717
KL Loss: 1.387088
Y Loss: 0.926826
T Loss: 11.617303
Epoch 399 
Overall Loss: 13.398621
Rec Loss: 12.008211
KL Loss: 1.390409
Y Loss: 0.903590
T Loss: 11.556417
Epoch 449 
Overall Loss: 13.378958
Rec Loss: 11.995501
KL Loss: 1.383457
Y Loss: 0.906773
T Loss: 11.542115
Epoch 499 
Overall Loss: 13.355040
Rec Loss: 11.958416
KL Loss: 1.396624
Y Loss: 0.888827
T Loss: 11.514003
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.893140
Epoch 99
Rec Loss: 1.887849
Epoch 149
Rec Loss: 1.886748
Epoch 199
Rec Loss: 1.883823
Epoch 249
Rec Loss: 1.878081
Epoch 299
Rec Loss: 1.884324
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.988582
Epoch 99
Rec Loss: 4.989253
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.636394
Insample Error: 2.325684
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 8.515339
Rec Loss: 3.359502
KL Loss: 5.155837
Y Loss: 8.904112
T Loss: 13.030097
X Loss: -14.122651
Epoch 99 
Overall Loss: -6.734746
Rec Loss: -14.445279
KL Loss: 7.710534
Y Loss: 4.853148
T Loss: 12.079834
X Loss: -28.951688
Epoch 149 
Overall Loss: -10.047572
Rec Loss: -18.157479
KL Loss: 8.109907
Y Loss: 3.263303
T Loss: 11.818441
X Loss: -31.607571
Epoch 199 
Overall Loss: -12.497683
Rec Loss: -21.229336
KL Loss: 8.731653
Y Loss: 2.968888
T Loss: 11.701090
X Loss: -34.414870
Epoch 249 
Overall Loss: -13.301142
Rec Loss: -22.150661
KL Loss: 8.849520
Y Loss: 2.846580
T Loss: 11.600433
X Loss: -35.174385
Epoch 299 
Overall Loss: -14.280805
Rec Loss: -23.339857
KL Loss: 9.059052
Y Loss: 2.673257
T Loss: 11.546963
X Loss: -36.223449
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.092266
Epoch 99
Rec Loss: 2.059778
Epoch 149
Rec Loss: 2.027603
Epoch 199
Rec Loss: 2.018527
Epoch 249
Rec Loss: 2.005600
Epoch 299
Rec Loss: 2.011526
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.996740
Epoch 99
Rec Loss: 4.995188
Epoch 149
Rec Loss: 4.994993
Epoch 199
Rec Loss: 4.994993
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 1.564132
Insample Error 3.329780
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.410210
Rec Loss: 15.298408
KL Loss: 1.111802
Y Loss: 5.738533
T Loss: 12.429142
Epoch 99 
Overall Loss: 14.226103
Rec Loss: 12.930853
KL Loss: 1.295250
Y Loss: 1.441986
T Loss: 12.209860
Epoch 149 
Overall Loss: 13.933490
Rec Loss: 12.607306
KL Loss: 1.326185
Y Loss: 1.076498
T Loss: 12.069057
Epoch 199 
Overall Loss: 13.714585
Rec Loss: 12.344645
KL Loss: 1.369939
Y Loss: 0.915405
T Loss: 11.886942
Epoch 249 
Overall Loss: 13.593215
Rec Loss: 12.194015
KL Loss: 1.399200
Y Loss: 0.914720
T Loss: 11.736655
Epoch 299 
Overall Loss: 13.519779
Rec Loss: 12.109616
KL Loss: 1.410163
Y Loss: 0.924116
T Loss: 11.647558
Epoch 349 
Overall Loss: 13.489362
Rec Loss: 12.080393
KL Loss: 1.408970
Y Loss: 0.920385
T Loss: 11.620200
Epoch 399 
Overall Loss: 13.427427
Rec Loss: 12.015739
KL Loss: 1.411688
Y Loss: 0.885545
T Loss: 11.572967
Epoch 449 
Overall Loss: 13.412946
Rec Loss: 12.001604
KL Loss: 1.411342
Y Loss: 0.922028
T Loss: 11.540589
Epoch 499 
Overall Loss: 13.391851
Rec Loss: 11.984765
KL Loss: 1.407086
Y Loss: 0.914417
T Loss: 11.527556
Epoch 549 
Overall Loss: 13.391015
Rec Loss: 11.989768
KL Loss: 1.401246
Y Loss: 0.939844
T Loss: 11.519846
Epoch 599 
Overall Loss: 13.357134
Rec Loss: 11.954582
KL Loss: 1.402552
Y Loss: 0.891617
T Loss: 11.508774
Epoch 649 
Overall Loss: 13.328211
Rec Loss: 11.930212
KL Loss: 1.398000
Y Loss: 0.875143
T Loss: 11.492640
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.888080
Epoch 99
Rec Loss: 1.882164
Epoch 149
Rec Loss: 1.885464
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.967226
Epoch 99
Rec Loss: 4.964764
Epoch 149
Rec Loss: 4.965159
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.638821
Insample Error: 2.395883
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 9.763114
Rec Loss: 5.334236
KL Loss: 4.428878
Y Loss: 8.773954
T Loss: 13.247917
X Loss: -12.300658
Epoch 99 
Overall Loss: -7.491999
Rec Loss: -14.612899
KL Loss: 7.120900
Y Loss: 4.785939
T Loss: 12.243801
X Loss: -29.249669
Epoch 149 
Overall Loss: -12.422912
Rec Loss: -20.291795
KL Loss: 7.868883
Y Loss: 3.314697
T Loss: 11.891494
X Loss: -33.840639
Epoch 199 
Overall Loss: -14.250359
Rec Loss: -22.702343
KL Loss: 8.451983
Y Loss: 3.020667
T Loss: 11.748214
X Loss: -35.960891
Epoch 249 
Overall Loss: -15.318935
Rec Loss: -23.907615
KL Loss: 8.588680
Y Loss: 2.759100
T Loss: 11.689341
X Loss: -36.976507
Epoch 299 
Overall Loss: -15.620702
Rec Loss: -24.342070
KL Loss: 8.721367
Y Loss: 2.562098
T Loss: 11.658935
X Loss: -37.282053
Epoch 349 
Overall Loss: -17.192932
Rec Loss: -26.170624
KL Loss: 8.977693
Y Loss: 2.277893
T Loss: 11.637964
X Loss: -38.947535
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.150193
Epoch 99
Rec Loss: 2.104673
Epoch 149
Rec Loss: 2.065388
Epoch 199
Rec Loss: 2.038996
Epoch 249
Rec Loss: 2.048163
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.998283
Epoch 99
Rec Loss: 4.996435
Epoch 149
Rec Loss: 4.996799
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 1.407323
Insample Error 3.390624
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.866400
Rec Loss: 15.909839
KL Loss: 0.956561
Y Loss: 6.212670
T Loss: 12.803504
Epoch 99 
Overall Loss: 14.329283
Rec Loss: 13.000127
KL Loss: 1.329156
Y Loss: 1.528034
T Loss: 12.236110
Epoch 149 
Overall Loss: 13.918955
Rec Loss: 12.572736
KL Loss: 1.346218
Y Loss: 1.058435
T Loss: 12.043519
Epoch 199 
Overall Loss: 13.709657
Rec Loss: 12.332488
KL Loss: 1.377168
Y Loss: 0.913052
T Loss: 11.875962
Epoch 249 
Overall Loss: 13.584089
Rec Loss: 12.185704
KL Loss: 1.398384
Y Loss: 0.897464
T Loss: 11.736973
Epoch 299 
Overall Loss: 13.510649
Rec Loss: 12.114819
KL Loss: 1.395830
Y Loss: 0.889561
T Loss: 11.670038
Epoch 349 
Overall Loss: 13.471256
Rec Loss: 12.062215
KL Loss: 1.409041
Y Loss: 0.875612
T Loss: 11.624408
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.922990
Epoch 99
Rec Loss: 1.922471
Epoch 149
Rec Loss: 1.938989
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.994188
Epoch 99
Rec Loss: 4.985946
Epoch 149
Rec Loss: 4.988385
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.628591
Insample Error: 2.373359
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 11.055874
Rec Loss: 7.181860
KL Loss: 3.874014
Y Loss: 8.778307
T Loss: 13.178170
X Loss: -10.385463
Epoch 99 
Overall Loss: -6.703369
Rec Loss: -13.807434
KL Loss: 7.104065
Y Loss: 6.219137
T Loss: 12.310745
X Loss: -29.227747
Epoch 149 
Overall Loss: -11.406549
Rec Loss: -19.036842
KL Loss: 7.630292
Y Loss: 3.229090
T Loss: 11.957501
X Loss: -32.608889
Epoch 199 
Overall Loss: -14.062575
Rec Loss: -22.110063
KL Loss: 8.047488
Y Loss: 2.552033
T Loss: 11.856188
X Loss: -35.242269
Epoch 249 
Overall Loss: -14.793218
Rec Loss: -23.031989
KL Loss: 8.238772
Y Loss: 2.260655
T Loss: 11.792698
X Loss: -35.955015
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.126583
Epoch 99
Rec Loss: 2.073569
Epoch 149
Rec Loss: 2.098022
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.996480
Epoch 99
Rec Loss: 4.997003
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 1.408339
Insample Error 3.183502
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.061930
Rec Loss: 16.062884
KL Loss: 0.999046
Y Loss: 6.918606
T Loss: 12.603580
Epoch 99 
Overall Loss: 14.603503
Rec Loss: 13.302156
KL Loss: 1.301347
Y Loss: 2.106242
T Loss: 12.249035
Epoch 149 
Overall Loss: 13.978929
Rec Loss: 12.646044
KL Loss: 1.332886
Y Loss: 1.219421
T Loss: 12.036333
Epoch 199 
Overall Loss: 13.728418
Rec Loss: 12.384732
KL Loss: 1.343686
Y Loss: 1.002401
T Loss: 11.883531
Epoch 249 
Overall Loss: 13.578296
Rec Loss: 12.215456
KL Loss: 1.362840
Y Loss: 0.948425
T Loss: 11.741244
Epoch 299 
Overall Loss: 13.498938
Rec Loss: 12.117872
KL Loss: 1.381066
Y Loss: 0.923733
T Loss: 11.656006
Epoch 349 
Overall Loss: 13.439780
Rec Loss: 12.050809
KL Loss: 1.388971
Y Loss: 0.912892
T Loss: 11.594363
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.912652
Epoch 99
Rec Loss: 1.914304
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.992801
Epoch 99
Rec Loss: 4.992531
Epoch 149
Rec Loss: 4.995086
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.674563
Insample Error: 2.467507
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 8.343082
Rec Loss: 3.121309
KL Loss: 5.221773
Y Loss: 7.077112
T Loss: 12.804683
X Loss: -13.221930
Epoch 99 
Overall Loss: -8.510526
Rec Loss: -15.888707
KL Loss: 7.378181
Y Loss: 2.562728
T Loss: 12.130395
X Loss: -29.300466
Epoch 149 
Overall Loss: -12.119578
Rec Loss: -19.912580
KL Loss: 7.793003
Y Loss: 1.842500
T Loss: 11.953800
X Loss: -32.787630
Epoch 199 
Overall Loss: -13.502575
Rec Loss: -21.645850
KL Loss: 8.143275
Y Loss: 1.652564
T Loss: 11.843839
X Loss: -34.315971
Epoch 249 
Overall Loss: -13.983716
Rec Loss: -22.374891
KL Loss: 8.391175
Y Loss: 1.461590
T Loss: 11.701536
X Loss: -34.807221
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.045163
Epoch 99
Rec Loss: 2.035838
Epoch 149
Rec Loss: 2.008382
Epoch 199
Rec Loss: 1.980400
Epoch 249
Rec Loss: 1.996513
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.994280
Epoch 99
Rec Loss: 4.996327
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.915813
Insample Error 2.931256
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.852842
Rec Loss: 14.478611
KL Loss: 1.374231
Y Loss: 3.864529
T Loss: 12.546347
Epoch 99 
Overall Loss: 14.744162
Rec Loss: 13.308729
KL Loss: 1.435433
Y Loss: 1.982338
T Loss: 12.317560
Epoch 149 
Overall Loss: 14.017675
Rec Loss: 12.656810
KL Loss: 1.360866
Y Loss: 1.376871
T Loss: 11.968374
Epoch 199 
Overall Loss: 13.723505
Rec Loss: 12.356096
KL Loss: 1.367409
Y Loss: 1.066407
T Loss: 11.822893
Epoch 249 
Overall Loss: 13.592663
Rec Loss: 12.218896
KL Loss: 1.373766
Y Loss: 0.987616
T Loss: 11.725089
Epoch 299 
Overall Loss: 13.508444
Rec Loss: 12.120460
KL Loss: 1.387983
Y Loss: 0.947670
T Loss: 11.646625
Epoch 349 
Overall Loss: 13.462974
Rec Loss: 12.070584
KL Loss: 1.392390
Y Loss: 0.927691
T Loss: 11.606739
Epoch 399 
Overall Loss: 13.432280
Rec Loss: 12.042120
KL Loss: 1.390160
Y Loss: 0.941936
T Loss: 11.571152
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.911546
Epoch 99
Rec Loss: 1.904169
Epoch 149
Rec Loss: 1.905574
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.990407
Epoch 99
Rec Loss: 4.989276
Epoch 149
Rec Loss: 4.987384
Epoch 199
Rec Loss: 4.987700
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.672229
Insample Error: 2.451084
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 8.713379
Rec Loss: 3.749663
KL Loss: 4.963715
Y Loss: 7.690428
T Loss: 12.799688
X Loss: -12.895239
Epoch 99 
Overall Loss: -7.446378
Rec Loss: -14.682928
KL Loss: 7.236550
Y Loss: 3.825078
T Loss: 12.137510
X Loss: -28.732977
Epoch 149 
Overall Loss: -10.227774
Rec Loss: -18.010485
KL Loss: 7.782711
Y Loss: 2.715855
T Loss: 11.973456
X Loss: -31.341869
Epoch 199 
Overall Loss: -12.844283
Rec Loss: -20.714234
KL Loss: 7.869951
Y Loss: 2.343305
T Loss: 11.831784
X Loss: -33.717669
Epoch 249 
Overall Loss: -11.262824
Rec Loss: -19.260878
KL Loss: 7.998055
Y Loss: 2.067832
T Loss: 11.776720
X Loss: -32.071514
Epoch 299 
Overall Loss: -14.659217
Rec Loss: -22.922880
KL Loss: 8.263663
Y Loss: 1.820105
T Loss: 11.714682
X Loss: -35.547614
Epoch 349 
Overall Loss: -15.637730
Rec Loss: -23.829691
KL Loss: 8.191961
Y Loss: 1.626299
T Loss: 11.680735
X Loss: -36.323575
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.089622
Epoch 99
Rec Loss: 2.101840
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.989218
Epoch 99
Rec Loss: 4.994581
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 1.059425
Insample Error 3.075606
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.534214
Rec Loss: 15.343930
KL Loss: 1.190283
Y Loss: 5.761443
T Loss: 12.463209
Epoch 99 
Overall Loss: 14.350908
Rec Loss: 13.049166
KL Loss: 1.301742
Y Loss: 1.572153
T Loss: 12.263089
Epoch 149 
Overall Loss: 13.944789
Rec Loss: 12.615935
KL Loss: 1.328854
Y Loss: 1.080279
T Loss: 12.075796
Epoch 199 
Overall Loss: 13.722410
Rec Loss: 12.372890
KL Loss: 1.349519
Y Loss: 0.939002
T Loss: 11.903389
Epoch 249 
Overall Loss: 13.587729
Rec Loss: 12.223753
KL Loss: 1.363976
Y Loss: 0.901769
T Loss: 11.772868
Epoch 299 
Overall Loss: 13.499319
Rec Loss: 12.116091
KL Loss: 1.383228
Y Loss: 0.887456
T Loss: 11.672363
Epoch 349 
Overall Loss: 13.443432
Rec Loss: 12.059815
KL Loss: 1.383617
Y Loss: 0.917363
T Loss: 11.601134
Epoch 399 
Overall Loss: 13.422413
Rec Loss: 12.025236
KL Loss: 1.397177
Y Loss: 0.905040
T Loss: 11.572716
Epoch 449 
Overall Loss: 13.393846
Rec Loss: 11.996200
KL Loss: 1.397646
Y Loss: 0.907378
T Loss: 11.542511
Epoch 499 
Overall Loss: 13.369305
Rec Loss: 11.972903
KL Loss: 1.396403
Y Loss: 0.894388
T Loss: 11.525709
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.883466
Epoch 99
Rec Loss: 1.889859
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.990418
Epoch 99
Rec Loss: 4.993346
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.647009
Insample Error: 2.456207
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 8.440846
Rec Loss: 3.787078
KL Loss: 4.653768
Y Loss: 8.999180
T Loss: 13.242400
X Loss: -13.954913
Epoch 99 
Overall Loss: -4.291588
Rec Loss: -10.816130
KL Loss: 6.524541
Y Loss: 5.584655
T Loss: 12.453408
X Loss: -26.061866
Epoch 149 
Overall Loss: -9.148806
Rec Loss: -16.873649
KL Loss: 7.724843
Y Loss: 3.078476
T Loss: 12.120270
X Loss: -30.533157
Epoch 199 
Overall Loss: -11.528571
Rec Loss: -19.520591
KL Loss: 7.992020
Y Loss: 2.500811
T Loss: 11.907566
X Loss: -32.678562
Epoch 249 
Overall Loss: -13.034515
Rec Loss: -21.210242
KL Loss: 8.175727
Y Loss: 2.281317
T Loss: 11.742286
X Loss: -34.093187
Epoch 299 
Overall Loss: -13.512154
Rec Loss: -21.954800
KL Loss: 8.442646
Y Loss: 2.085266
T Loss: 11.649516
X Loss: -34.646950
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.117307
Epoch 99
Rec Loss: 2.078231
Epoch 149
Rec Loss: 2.070194
Epoch 199
Rec Loss: 2.057120
Epoch 249
Rec Loss: 2.021776
Epoch 299
Rec Loss: 2.024932
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.978149
Epoch 99
Rec Loss: 4.979847
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 1.262215
Insample Error 3.473707
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.636937
Rec Loss: 15.361380
KL Loss: 1.275556
Y Loss: 5.505664
T Loss: 12.608548
Epoch 99 
Overall Loss: 14.840287
Rec Loss: 13.378275
KL Loss: 1.462012
Y Loss: 1.995782
T Loss: 12.380384
Epoch 149 
Overall Loss: 14.190852
Rec Loss: 12.787774
KL Loss: 1.403078
Y Loss: 1.514358
T Loss: 12.030595
Epoch 199 
Overall Loss: 13.739930
Rec Loss: 12.375509
KL Loss: 1.364420
Y Loss: 1.119686
T Loss: 11.815667
Epoch 249 
Overall Loss: 13.568976
Rec Loss: 12.209660
KL Loss: 1.359316
Y Loss: 0.980078
T Loss: 11.719621
Epoch 299 
Overall Loss: 13.494150
Rec Loss: 12.128716
KL Loss: 1.365434
Y Loss: 0.942263
T Loss: 11.657585
Epoch 349 
Overall Loss: 13.426084
Rec Loss: 12.057301
KL Loss: 1.368783
Y Loss: 0.940939
T Loss: 11.586832
Epoch 399 
Overall Loss: 13.416271
Rec Loss: 12.040802
KL Loss: 1.375469
Y Loss: 0.959048
T Loss: 11.561278
Epoch 449 
Overall Loss: 13.401629
Rec Loss: 12.023002
KL Loss: 1.378627
Y Loss: 0.948795
T Loss: 11.548605
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.901706
Epoch 99
Rec Loss: 1.905263
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.991815
Epoch 99
Rec Loss: 4.987232
Epoch 149
Rec Loss: 4.986663
Epoch 199
Rec Loss: 4.991040
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.683320
Insample Error: 2.455718
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 9.413882
Rec Loss: 4.877550
KL Loss: 4.536332
Y Loss: 8.982856
T Loss: 13.193106
X Loss: -12.806985
Epoch 99 
Overall Loss: -7.167544
Rec Loss: -14.553622
KL Loss: 7.386077
Y Loss: 5.116859
T Loss: 12.263183
X Loss: -29.375234
Epoch 149 
Overall Loss: -11.458663
Rec Loss: -19.959473
KL Loss: 8.500810
Y Loss: 3.135712
T Loss: 11.994123
X Loss: -33.521451
Epoch 199 
Overall Loss: -13.260567
Rec Loss: -22.009122
KL Loss: 8.748556
Y Loss: 2.599037
T Loss: 11.877117
X Loss: -35.185758
Epoch 249 
Overall Loss: -14.726195
Rec Loss: -23.753712
KL Loss: 9.027518
Y Loss: 2.287923
T Loss: 11.772013
X Loss: -36.669687
Epoch 299 
Overall Loss: -15.284785
Rec Loss: -24.409774
KL Loss: 9.124989
Y Loss: 1.867500
T Loss: 11.687942
X Loss: -37.031467
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.018201
Epoch 99
Rec Loss: 1.997806
Epoch 149
Rec Loss: 2.001103
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.995509
Epoch 99
Rec Loss: 4.997890
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 1.008859
Insample Error 2.533484
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.285223
Rec Loss: 14.982202
KL Loss: 1.303022
Y Loss: 4.836671
T Loss: 12.563866
Epoch 99 
Overall Loss: 14.689870
Rec Loss: 13.266156
KL Loss: 1.423714
Y Loss: 1.748180
T Loss: 12.392066
Epoch 149 
Overall Loss: 14.151808
Rec Loss: 12.825982
KL Loss: 1.325826
Y Loss: 1.307905
T Loss: 12.172029
Epoch 199 
Overall Loss: 13.736193
Rec Loss: 12.427909
KL Loss: 1.308283
Y Loss: 0.950240
T Loss: 11.952789
Epoch 249 
Overall Loss: 13.587804
Rec Loss: 12.248533
KL Loss: 1.339271
Y Loss: 0.875357
T Loss: 11.810855
Epoch 299 
Overall Loss: 13.504261
Rec Loss: 12.144706
KL Loss: 1.359555
Y Loss: 0.866378
T Loss: 11.711517
Epoch 349 
Overall Loss: 13.449699
Rec Loss: 12.077234
KL Loss: 1.372465
Y Loss: 0.897784
T Loss: 11.628342
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.923705
Epoch 99
Rec Loss: 1.929882
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.994321
Epoch 99
Rec Loss: 4.996233
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.645846
Insample Error: 2.441910
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 8.394709
Rec Loss: 3.614757
KL Loss: 4.779952
Y Loss: 8.044767
T Loss: 12.977660
X Loss: -13.385286
Epoch 99 
Overall Loss: -7.104929
Rec Loss: -14.319796
KL Loss: 7.214867
Y Loss: 3.932449
T Loss: 12.140801
X Loss: -28.426820
Epoch 149 
Overall Loss: -11.528459
Rec Loss: -19.523138
KL Loss: 7.994679
Y Loss: 2.410521
T Loss: 11.930296
X Loss: -32.658695
Epoch 199 
Overall Loss: -11.189900
Rec Loss: -19.678530
KL Loss: 8.488629
Y Loss: 2.075912
T Loss: 11.766657
X Loss: -32.483143
Epoch 249 
Overall Loss: -14.211059
Rec Loss: -22.867793
KL Loss: 8.656734
Y Loss: 1.898335
T Loss: 11.681028
X Loss: -35.497988
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.061964
Epoch 99
Rec Loss: 2.061457
Epoch 149
Rec Loss: 2.016911
Epoch 199
Rec Loss: 1.988061
Epoch 249
Rec Loss: 1.977196
Epoch 299
Rec Loss: 1.987845
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 4.995370
Epoch 99
Rec Loss: 4.995963
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 1.123899
Insample Error 3.099189
Ours, Train RMSE
0.6573, 
0.6676, 
0.6364, 
0.6388, 
0.6286, 
0.6746, 
0.6722, 
0.6470, 
0.6833, 
0.6458, 
CEVAE, Train RMSE
1.0029, 
1.2529, 
1.5641, 
1.4073, 
1.4083, 
0.9158, 
1.0594, 
1.2622, 
1.0089, 
1.1239, 
Ours, Insample RMSE
2.5020, 
2.5202, 
2.3257, 
2.3959, 
2.3734, 
2.4675, 
2.4511, 
2.4562, 
2.4557, 
2.4419, 
CEVAE, Insample RMSE
2.7516, 
3.2856, 
3.3298, 
3.3906, 
3.1835, 
2.9313, 
3.0756, 
3.4737, 
2.5335, 
3.0992, 
Train, RMSE mean 0.6552 std 0.0176
CEVAE, RMSE mean 1.2006 std 0.2018
Ours, RMSE mean 2.4390 std 0.0558, reconstruct confounder 1.8996 (0.0155) noise 4.9860 (0.0078)
CEVAE, RMSE mean 3.1054 std 0.2810, reconstruct confounder 2.0223 (0.0352) noise 4.9916 (0.0068)
