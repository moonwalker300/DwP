Y Mean 1.192369, Std 4.040208 
Observe confounder 2, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 19.925428
Rec Loss: 18.006558
KL Loss: 1.918869
Y Loss: 2.396937
T Loss: 13.212685
Epoch 99 
Overall Loss: 16.845653
Rec Loss: 15.354621
KL Loss: 1.491032
Y Loss: 1.055853
T Loss: 13.242915
Epoch 149 
Overall Loss: 16.296759
Rec Loss: 14.961882
KL Loss: 1.334878
Y Loss: 0.862584
T Loss: 13.236713
Epoch 199 
Overall Loss: 15.865095
Rec Loss: 14.655123
KL Loss: 1.209972
Y Loss: 0.720436
T Loss: 13.214251
Epoch 249 
Overall Loss: 15.555632
Rec Loss: 14.405129
KL Loss: 1.150503
Y Loss: 0.611071
T Loss: 13.182988
Epoch 299 
Overall Loss: 15.245570
Rec Loss: 14.115770
KL Loss: 1.129799
Y Loss: 0.477445
T Loss: 13.160880
Epoch 349 
Overall Loss: 14.982347
Rec Loss: 13.861041
KL Loss: 1.121306
Y Loss: 0.362578
T Loss: 13.135886
Epoch 399 
Overall Loss: 14.854835
Rec Loss: 13.727134
KL Loss: 1.127702
Y Loss: 0.306158
T Loss: 13.114818
Epoch 449 
Overall Loss: 14.801479
Rec Loss: 13.665848
KL Loss: 1.135632
Y Loss: 0.288795
T Loss: 13.088258
Epoch 499 
Overall Loss: 14.771885
Rec Loss: 13.626215
KL Loss: 1.145669
Y Loss: 0.278187
T Loss: 13.069841
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.751741
Epoch 99
Rec Loss: 1.753474
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.040955
Epoch 99
Rec Loss: 10.041394
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.242206
Insample Error: 2.098868
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 28.181566
Rec Loss: 23.418433
KL Loss: 4.763133
Y Loss: 2.442866
T Loss: 13.241285
Epoch 99 
Overall Loss: 24.118641
Rec Loss: 20.693855
KL Loss: 3.424786
Y Loss: 1.141523
T Loss: 13.267216
Epoch 149 
Overall Loss: 23.094419
Rec Loss: 19.596249
KL Loss: 3.498170
Y Loss: 0.942416
T Loss: 13.244288
Epoch 199 
Overall Loss: 22.283035
Rec Loss: 18.699208
KL Loss: 3.583827
Y Loss: 0.771235
T Loss: 13.208095
Epoch 249 
Overall Loss: 21.493523
Rec Loss: 17.671678
KL Loss: 3.821845
Y Loss: 0.601884
T Loss: 13.205784
Epoch 299 
Overall Loss: 21.030378
Rec Loss: 17.151070
KL Loss: 3.879309
Y Loss: 0.477584
T Loss: 13.215605
Epoch 349 
Overall Loss: 20.796755
Rec Loss: 16.809878
KL Loss: 3.986877
Y Loss: 0.420570
T Loss: 13.199812
Epoch 399 
Overall Loss: 20.615002
Rec Loss: 16.316465
KL Loss: 4.298538
Y Loss: 0.384430
T Loss: 13.182116
Epoch 449 
Overall Loss: 20.445667
Rec Loss: 15.787584
KL Loss: 4.658083
Y Loss: 0.353163
T Loss: 13.173806
Epoch 499 
Overall Loss: 20.361049
Rec Loss: 15.551316
KL Loss: 4.809733
Y Loss: 0.344387
T Loss: 13.162207
Epoch 549 
Overall Loss: 20.268226
Rec Loss: 15.455468
KL Loss: 4.812759
Y Loss: 0.317559
T Loss: 13.155954
Epoch 599 
Overall Loss: 20.191072
Rec Loss: 15.444174
KL Loss: 4.746898
Y Loss: 0.300071
T Loss: 13.143323
Epoch 649 
Overall Loss: 20.142607
Rec Loss: 15.513936
KL Loss: 4.628670
Y Loss: 0.291711
T Loss: 13.128603
Epoch 699 
Overall Loss: 20.094555
Rec Loss: 15.528503
KL Loss: 4.566052
Y Loss: 0.284241
T Loss: 13.112550
Epoch 749 
Overall Loss: 20.062918
Rec Loss: 15.491987
KL Loss: 4.570932
Y Loss: 0.268685
T Loss: 13.099670
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.781950
Epoch 99
Rec Loss: 1.774084
Epoch 149
Rec Loss: 1.773380
Epoch 199
Rec Loss: 1.773006
Epoch 249
Rec Loss: 1.767567
Epoch 299
Rec Loss: 1.769457
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.201111
Epoch 99
Rec Loss: 6.185680
Epoch 149
Rec Loss: 6.183398
Epoch 199
Rec Loss: 6.182879
Epoch 249
Rec Loss: 6.180277
Epoch 299
Rec Loss: 6.188642
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.228766
Insample Error 2.063400
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 20.576756
Rec Loss: 18.838502
KL Loss: 1.738254
Y Loss: 2.822520
T Loss: 13.193462
Epoch 99 
Overall Loss: 16.958929
Rec Loss: 15.456918
KL Loss: 1.502010
Y Loss: 1.115358
T Loss: 13.226203
Epoch 149 
Overall Loss: 16.234439
Rec Loss: 14.903576
KL Loss: 1.330863
Y Loss: 0.841300
T Loss: 13.220976
Epoch 199 
Overall Loss: 15.691606
Rec Loss: 14.486341
KL Loss: 1.205265
Y Loss: 0.648775
T Loss: 13.188791
Epoch 249 
Overall Loss: 15.276754
Rec Loss: 14.123749
KL Loss: 1.153004
Y Loss: 0.483881
T Loss: 13.155988
Epoch 299 
Overall Loss: 15.037227
Rec Loss: 13.888962
KL Loss: 1.148266
Y Loss: 0.383328
T Loss: 13.122305
Epoch 349 
Overall Loss: 14.919332
Rec Loss: 13.761064
KL Loss: 1.158268
Y Loss: 0.334362
T Loss: 13.092341
Epoch 399 
Overall Loss: 14.848199
Rec Loss: 13.675560
KL Loss: 1.172639
Y Loss: 0.309846
T Loss: 13.055868
Epoch 449 
Overall Loss: 14.783603
Rec Loss: 13.603251
KL Loss: 1.180353
Y Loss: 0.289067
T Loss: 13.025117
Epoch 499 
Overall Loss: 14.750439
Rec Loss: 13.553146
KL Loss: 1.197293
Y Loss: 0.281539
T Loss: 12.990069
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.675147
Epoch 99
Rec Loss: 1.665107
Epoch 149
Rec Loss: 1.666350
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.056277
Epoch 99
Rec Loss: 10.050038
Epoch 149
Rec Loss: 10.059032
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.238926
Insample Error: 2.176958
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 32.096369
Rec Loss: 27.314707
KL Loss: 4.781663
Y Loss: 4.375711
T Loss: 13.265209
Epoch 99 
Overall Loss: 24.398696
Rec Loss: 20.872847
KL Loss: 3.525849
Y Loss: 1.198997
T Loss: 13.298180
Epoch 149 
Overall Loss: 22.756214
Rec Loss: 19.189382
KL Loss: 3.566832
Y Loss: 0.824135
T Loss: 13.264843
Epoch 199 
Overall Loss: 21.908908
Rec Loss: 18.139343
KL Loss: 3.769565
Y Loss: 0.644844
T Loss: 13.253633
Epoch 249 
Overall Loss: 21.486638
Rec Loss: 17.562883
KL Loss: 3.923755
Y Loss: 0.572308
T Loss: 13.246623
Epoch 299 
Overall Loss: 21.025284
Rec Loss: 16.754664
KL Loss: 4.270619
Y Loss: 0.509627
T Loss: 13.232934
Epoch 349 
Overall Loss: 20.703338
Rec Loss: 15.935488
KL Loss: 4.767851
Y Loss: 0.455347
T Loss: 13.218719
Epoch 399 
Overall Loss: 20.500341
Rec Loss: 15.462394
KL Loss: 5.037946
Y Loss: 0.411943
T Loss: 13.208669
Epoch 449 
Overall Loss: 20.377849
Rec Loss: 15.045233
KL Loss: 5.332616
Y Loss: 0.388244
T Loss: 13.189837
Epoch 499 
Overall Loss: 20.287279
Rec Loss: 14.735281
KL Loss: 5.551998
Y Loss: 0.371145
T Loss: 13.186063
Epoch 549 
Overall Loss: 20.202749
Rec Loss: 14.484279
KL Loss: 5.718470
Y Loss: 0.352579
T Loss: 13.172128
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.847844
Epoch 99
Rec Loss: 1.841429
Epoch 149
Rec Loss: 1.847965
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.911724
Epoch 99
Rec Loss: 5.911187
Epoch 149
Rec Loss: 5.909366
Epoch 199
Rec Loss: 5.903852
Epoch 249
Rec Loss: 5.895643
Epoch 299
Rec Loss: 5.910255
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.253115
Insample Error 2.071980
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 20.648364
Rec Loss: 18.516142
KL Loss: 2.132222
Y Loss: 2.656436
T Loss: 13.203270
Epoch 99 
Overall Loss: 16.998003
Rec Loss: 15.387638
KL Loss: 1.610365
Y Loss: 1.080367
T Loss: 13.226903
Epoch 149 
Overall Loss: 16.293016
Rec Loss: 14.887720
KL Loss: 1.405296
Y Loss: 0.832976
T Loss: 13.221768
Epoch 199 
Overall Loss: 15.765124
Rec Loss: 14.530522
KL Loss: 1.234602
Y Loss: 0.670862
T Loss: 13.188798
Epoch 249 
Overall Loss: 15.335431
Rec Loss: 14.165013
KL Loss: 1.170418
Y Loss: 0.503145
T Loss: 13.158723
Epoch 299 
Overall Loss: 15.050134
Rec Loss: 13.900494
KL Loss: 1.149640
Y Loss: 0.384148
T Loss: 13.132199
Epoch 349 
Overall Loss: 14.926742
Rec Loss: 13.774287
KL Loss: 1.152454
Y Loss: 0.336149
T Loss: 13.101989
Epoch 399 
Overall Loss: 14.833222
Rec Loss: 13.680169
KL Loss: 1.153053
Y Loss: 0.306064
T Loss: 13.068042
Epoch 449 
Overall Loss: 14.780639
Rec Loss: 13.607227
KL Loss: 1.173412
Y Loss: 0.283564
T Loss: 13.040099
Epoch 499 
Overall Loss: 14.765922
Rec Loss: 13.575737
KL Loss: 1.190184
Y Loss: 0.278922
T Loss: 13.017893
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.682753
Epoch 99
Rec Loss: 1.678065
Epoch 149
Rec Loss: 1.679793
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.045755
Epoch 99
Rec Loss: 10.047992
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.226843
Insample Error: 2.124656
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 31.014373
Rec Loss: 25.657488
KL Loss: 5.356885
Y Loss: 3.548985
T Loss: 13.247159
Epoch 99 
Overall Loss: 24.225018
Rec Loss: 20.567011
KL Loss: 3.658007
Y Loss: 1.116978
T Loss: 13.290680
Epoch 149 
Overall Loss: 22.823503
Rec Loss: 19.129743
KL Loss: 3.693759
Y Loss: 0.856647
T Loss: 13.259361
Epoch 199 
Overall Loss: 21.852964
Rec Loss: 17.707438
KL Loss: 4.145527
Y Loss: 0.684039
T Loss: 13.218176
Epoch 249 
Overall Loss: 21.128204
Rec Loss: 16.422704
KL Loss: 4.705500
Y Loss: 0.551940
T Loss: 13.228392
Epoch 299 
Overall Loss: 20.780538
Rec Loss: 15.883030
KL Loss: 4.897508
Y Loss: 0.478723
T Loss: 13.229567
Epoch 349 
Overall Loss: 20.577422
Rec Loss: 15.510245
KL Loss: 5.067178
Y Loss: 0.426431
T Loss: 13.226314
Epoch 399 
Overall Loss: 20.420329
Rec Loss: 15.206632
KL Loss: 5.213698
Y Loss: 0.377790
T Loss: 13.209552
Epoch 449 
Overall Loss: 20.290023
Rec Loss: 14.993157
KL Loss: 5.296866
Y Loss: 0.350324
T Loss: 13.192943
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.864480
Epoch 99
Rec Loss: 1.860214
Epoch 149
Rec Loss: 1.856761
Epoch 199
Rec Loss: 1.859132
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.874305
Epoch 99
Rec Loss: 5.881976
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.251979
Insample Error 2.064423
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 19.370211
Rec Loss: 17.734386
KL Loss: 1.635826
Y Loss: 2.250670
T Loss: 13.233045
Epoch 99 
Overall Loss: 16.449792
Rec Loss: 15.093463
KL Loss: 1.356330
Y Loss: 0.927636
T Loss: 13.238191
Epoch 149 
Overall Loss: 16.038906
Rec Loss: 14.788694
KL Loss: 1.250212
Y Loss: 0.779456
T Loss: 13.229781
Epoch 199 
Overall Loss: 15.705480
Rec Loss: 14.540716
KL Loss: 1.164763
Y Loss: 0.664457
T Loss: 13.211802
Epoch 249 
Overall Loss: 15.399402
Rec Loss: 14.271028
KL Loss: 1.128374
Y Loss: 0.543041
T Loss: 13.184946
Epoch 299 
Overall Loss: 15.124858
Rec Loss: 14.012773
KL Loss: 1.112084
Y Loss: 0.424908
T Loss: 13.162957
Epoch 349 
Overall Loss: 14.957395
Rec Loss: 13.840716
KL Loss: 1.116680
Y Loss: 0.350048
T Loss: 13.140620
Epoch 399 
Overall Loss: 14.869629
Rec Loss: 13.733170
KL Loss: 1.136459
Y Loss: 0.308191
T Loss: 13.116788
Epoch 449 
Overall Loss: 14.811094
Rec Loss: 13.665766
KL Loss: 1.145328
Y Loss: 0.287836
T Loss: 13.090094
Epoch 499 
Overall Loss: 14.770682
Rec Loss: 13.613616
KL Loss: 1.157067
Y Loss: 0.273965
T Loss: 13.065686
Epoch 549 
Overall Loss: 14.752889
Rec Loss: 13.582813
KL Loss: 1.170076
Y Loss: 0.269104
T Loss: 13.044605
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.726716
Epoch 99
Rec Loss: 1.723898
Epoch 149
Rec Loss: 1.726917
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.043006
Epoch 99
Rec Loss: 10.046893
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.232045
Insample Error: 2.121731
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 30.133536
Rec Loss: 25.289668
KL Loss: 4.843869
Y Loss: 3.349297
T Loss: 13.252896
Epoch 99 
Overall Loss: 24.352656
Rec Loss: 20.961617
KL Loss: 3.391039
Y Loss: 1.194428
T Loss: 13.292060
Epoch 149 
Overall Loss: 22.877741
Rec Loss: 19.592396
KL Loss: 3.285346
Y Loss: 0.846787
T Loss: 13.269845
Epoch 199 
Overall Loss: 21.828724
Rec Loss: 18.416369
KL Loss: 3.412355
Y Loss: 0.614100
T Loss: 13.241025
Epoch 249 
Overall Loss: 21.048625
Rec Loss: 17.569220
KL Loss: 3.479405
Y Loss: 0.422452
T Loss: 13.226652
Epoch 299 
Overall Loss: 20.639699
Rec Loss: 17.043586
KL Loss: 3.596113
Y Loss: 0.335943
T Loss: 13.217228
Epoch 349 
Overall Loss: 20.425515
Rec Loss: 16.676635
KL Loss: 3.748880
Y Loss: 0.300314
T Loss: 13.201469
Epoch 399 
Overall Loss: 20.318831
Rec Loss: 16.443914
KL Loss: 3.874918
Y Loss: 0.291643
T Loss: 13.179214
Epoch 449 
Overall Loss: 20.281600
Rec Loss: 16.307622
KL Loss: 3.973978
Y Loss: 0.290674
T Loss: 13.159152
Epoch 499 
Overall Loss: 20.203060
Rec Loss: 16.141704
KL Loss: 4.061356
Y Loss: 0.275242
T Loss: 13.141338
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.817269
Epoch 99
Rec Loss: 1.815794
Epoch 149
Rec Loss: 1.817355
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.216301
Epoch 99
Rec Loss: 6.226083
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.218077
Insample Error 2.077453
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 20.329291
Rec Loss: 18.285805
KL Loss: 2.043484
Y Loss: 2.534554
T Loss: 13.216698
Epoch 99 
Overall Loss: 16.651140
Rec Loss: 15.170936
KL Loss: 1.480205
Y Loss: 0.972569
T Loss: 13.225798
Epoch 149 
Overall Loss: 16.041755
Rec Loss: 14.737556
KL Loss: 1.304199
Y Loss: 0.759916
T Loss: 13.217725
Epoch 199 
Overall Loss: 15.679947
Rec Loss: 14.468233
KL Loss: 1.211714
Y Loss: 0.636883
T Loss: 13.194466
Epoch 249 
Overall Loss: 15.339461
Rec Loss: 14.188914
KL Loss: 1.150546
Y Loss: 0.508384
T Loss: 13.172145
Epoch 299 
Overall Loss: 15.088766
Rec Loss: 13.941899
KL Loss: 1.146868
Y Loss: 0.395622
T Loss: 13.150655
Epoch 349 
Overall Loss: 14.928552
Rec Loss: 13.776382
KL Loss: 1.152169
Y Loss: 0.323884
T Loss: 13.128615
Epoch 399 
Overall Loss: 14.866817
Rec Loss: 13.711335
KL Loss: 1.155481
Y Loss: 0.304414
T Loss: 13.102508
Epoch 449 
Overall Loss: 14.825217
Rec Loss: 13.665427
KL Loss: 1.159789
Y Loss: 0.294014
T Loss: 13.077400
Epoch 499 
Overall Loss: 14.792100
Rec Loss: 13.620441
KL Loss: 1.171659
Y Loss: 0.281568
T Loss: 13.057304
Epoch 549 
Overall Loss: 14.767409
Rec Loss: 13.591250
KL Loss: 1.176158
Y Loss: 0.275554
T Loss: 13.040143
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.740613
Epoch 99
Rec Loss: 1.739504
Epoch 149
Rec Loss: 1.735358
Epoch 199
Rec Loss: 1.741640
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.065522
Epoch 99
Rec Loss: 10.059149
Epoch 149
Rec Loss: 10.057635
Epoch 199
Rec Loss: 10.062148
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.230418
Insample Error: 2.124460
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 31.021369
Rec Loss: 26.638152
KL Loss: 4.383218
Y Loss: 4.016952
T Loss: 13.241655
Epoch 99 
Overall Loss: 24.142854
Rec Loss: 20.781450
KL Loss: 3.361404
Y Loss: 1.135221
T Loss: 13.280131
Epoch 149 
Overall Loss: 22.416498
Rec Loss: 19.171375
KL Loss: 3.245123
Y Loss: 0.710465
T Loss: 13.276128
Epoch 199 
Overall Loss: 21.476476
Rec Loss: 17.882364
KL Loss: 3.594112
Y Loss: 0.546840
T Loss: 13.260437
Epoch 249 
Overall Loss: 21.027692
Rec Loss: 17.241287
KL Loss: 3.786405
Y Loss: 0.448554
T Loss: 13.243671
Epoch 299 
Overall Loss: 20.769469
Rec Loss: 16.735625
KL Loss: 4.033845
Y Loss: 0.386339
T Loss: 13.219679
Epoch 349 
Overall Loss: 20.577268
Rec Loss: 16.264755
KL Loss: 4.312513
Y Loss: 0.350320
T Loss: 13.194718
Epoch 399 
Overall Loss: 20.431566
Rec Loss: 15.788086
KL Loss: 4.643480
Y Loss: 0.348468
T Loss: 13.170203
Epoch 449 
Overall Loss: 20.359685
Rec Loss: 15.587690
KL Loss: 4.771995
Y Loss: 0.323555
T Loss: 13.161923
Epoch 499 
Overall Loss: 20.280295
Rec Loss: 15.390746
KL Loss: 4.889550
Y Loss: 0.317968
T Loss: 13.149273
Epoch 549 
Overall Loss: 20.193682
Rec Loss: 15.175280
KL Loss: 5.018402
Y Loss: 0.307122
T Loss: 13.140971
Epoch 599 
Overall Loss: 20.158514
Rec Loss: 14.999534
KL Loss: 5.158981
Y Loss: 0.301578
T Loss: 13.129642
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.838356
Epoch 99
Rec Loss: 1.830432
Epoch 149
Rec Loss: 1.832487
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.087772
Epoch 99
Rec Loss: 6.052999
Epoch 149
Rec Loss: 6.081550
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.217047
Insample Error 2.091134
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 19.888776
Rec Loss: 17.642653
KL Loss: 2.246124
Y Loss: 2.214497
T Loss: 13.213658
Epoch 99 
Overall Loss: 16.743819
Rec Loss: 15.173846
KL Loss: 1.569973
Y Loss: 0.969071
T Loss: 13.235705
Epoch 149 
Overall Loss: 16.061739
Rec Loss: 14.706468
KL Loss: 1.355271
Y Loss: 0.744352
T Loss: 13.217764
Epoch 199 
Overall Loss: 15.519371
Rec Loss: 14.295631
KL Loss: 1.223740
Y Loss: 0.549190
T Loss: 13.197251
Epoch 249 
Overall Loss: 15.140606
Rec Loss: 13.964594
KL Loss: 1.176012
Y Loss: 0.396007
T Loss: 13.172580
Epoch 299 
Overall Loss: 14.978940
Rec Loss: 13.823895
KL Loss: 1.155046
Y Loss: 0.336186
T Loss: 13.151523
Epoch 349 
Overall Loss: 14.885912
Rec Loss: 13.744246
KL Loss: 1.141666
Y Loss: 0.306399
T Loss: 13.131449
Epoch 399 
Overall Loss: 14.841601
Rec Loss: 13.695351
KL Loss: 1.146251
Y Loss: 0.291126
T Loss: 13.113098
Epoch 449 
Overall Loss: 14.797846
Rec Loss: 13.653884
KL Loss: 1.143961
Y Loss: 0.280794
T Loss: 13.092296
Epoch 499 
Overall Loss: 14.777828
Rec Loss: 13.628222
KL Loss: 1.149606
Y Loss: 0.276393
T Loss: 13.075437
Epoch 549 
Overall Loss: 14.782179
Rec Loss: 13.623198
KL Loss: 1.158981
Y Loss: 0.282461
T Loss: 13.058277
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.758602
Epoch 99
Rec Loss: 1.757646
Epoch 149
Rec Loss: 1.754225
Epoch 199
Rec Loss: 1.751518
Epoch 249
Rec Loss: 1.752565
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.064685
Epoch 99
Rec Loss: 10.073574
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.223610
Insample Error: 2.098229
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 30.835294
Rec Loss: 25.869490
KL Loss: 4.965805
Y Loss: 3.667712
T Loss: 13.235978
Epoch 99 
Overall Loss: 24.520892
Rec Loss: 20.932013
KL Loss: 3.588880
Y Loss: 1.257407
T Loss: 13.294662
Epoch 149 
Overall Loss: 22.650543
Rec Loss: 18.640434
KL Loss: 4.010109
Y Loss: 0.836735
T Loss: 13.286176
Epoch 199 
Overall Loss: 21.582396
Rec Loss: 17.088051
KL Loss: 4.494346
Y Loss: 0.637586
T Loss: 13.273612
Epoch 249 
Overall Loss: 21.172431
Rec Loss: 16.461690
KL Loss: 4.710741
Y Loss: 0.558405
T Loss: 13.259923
Epoch 299 
Overall Loss: 20.933478
Rec Loss: 16.061465
KL Loss: 4.872014
Y Loss: 0.499897
T Loss: 13.248174
Epoch 349 
Overall Loss: 20.753586
Rec Loss: 15.693276
KL Loss: 5.060310
Y Loss: 0.462868
T Loss: 13.226801
Epoch 399 
Overall Loss: 20.563842
Rec Loss: 15.239023
KL Loss: 5.324819
Y Loss: 0.408203
T Loss: 13.215954
Epoch 449 
Overall Loss: 20.433829
Rec Loss: 14.883942
KL Loss: 5.549886
Y Loss: 0.376483
T Loss: 13.198602
Epoch 499 
Overall Loss: 20.353550
Rec Loss: 14.565707
KL Loss: 5.787843
Y Loss: 0.357056
T Loss: 13.187343
Epoch 549 
Overall Loss: 20.262001
Rec Loss: 14.345078
KL Loss: 5.916923
Y Loss: 0.344173
T Loss: 13.175574
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.851185
Epoch 99
Rec Loss: 1.849049
Epoch 149
Rec Loss: 1.848102
Epoch 199
Rec Loss: 1.845119
Epoch 249
Rec Loss: 1.848787
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.750019
Epoch 99
Rec Loss: 5.740039
Epoch 149
Rec Loss: 5.735654
Epoch 199
Rec Loss: 5.730503
Epoch 249
Rec Loss: 5.734707
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.246384
Insample Error 2.069461
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 21.064586
Rec Loss: 19.147386
KL Loss: 1.917200
Y Loss: 2.965427
T Loss: 13.216532
Epoch 99 
Overall Loss: 16.975235
Rec Loss: 15.458924
KL Loss: 1.516311
Y Loss: 1.106432
T Loss: 13.246060
Epoch 149 
Overall Loss: 16.210895
Rec Loss: 14.870109
KL Loss: 1.340787
Y Loss: 0.817465
T Loss: 13.235178
Epoch 199 
Overall Loss: 15.699354
Rec Loss: 14.482264
KL Loss: 1.217090
Y Loss: 0.637368
T Loss: 13.207527
Epoch 249 
Overall Loss: 15.310878
Rec Loss: 14.142230
KL Loss: 1.168648
Y Loss: 0.486447
T Loss: 13.169336
Epoch 299 
Overall Loss: 15.037181
Rec Loss: 13.872305
KL Loss: 1.164876
Y Loss: 0.363893
T Loss: 13.144519
Epoch 349 
Overall Loss: 14.925576
Rec Loss: 13.765492
KL Loss: 1.160084
Y Loss: 0.324003
T Loss: 13.117485
Epoch 399 
Overall Loss: 14.860786
Rec Loss: 13.691852
KL Loss: 1.168934
Y Loss: 0.302402
T Loss: 13.087049
Epoch 449 
Overall Loss: 14.810712
Rec Loss: 13.633737
KL Loss: 1.176976
Y Loss: 0.285225
T Loss: 13.063287
Epoch 499 
Overall Loss: 14.793973
Rec Loss: 13.601285
KL Loss: 1.192688
Y Loss: 0.279855
T Loss: 13.041575
Epoch 549 
Overall Loss: 14.753257
Rec Loss: 13.565010
KL Loss: 1.188247
Y Loss: 0.269130
T Loss: 13.026750
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.731688
Epoch 99
Rec Loss: 1.725397
Epoch 149
Rec Loss: 1.726347
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.067945
Epoch 99
Rec Loss: 10.065847
Epoch 149
Rec Loss: 10.069203
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.218873
Insample Error: 2.099930
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 29.709819
Rec Loss: 24.814074
KL Loss: 4.895745
Y Loss: 3.109581
T Loss: 13.262832
Epoch 99 
Overall Loss: 24.464992
Rec Loss: 21.063134
KL Loss: 3.401858
Y Loss: 1.283590
T Loss: 13.302388
Epoch 149 
Overall Loss: 22.844171
Rec Loss: 19.167640
KL Loss: 3.676531
Y Loss: 0.880489
T Loss: 13.280763
Epoch 199 
Overall Loss: 21.864494
Rec Loss: 17.905357
KL Loss: 3.959135
Y Loss: 0.671618
T Loss: 13.255491
Epoch 249 
Overall Loss: 21.167719
Rec Loss: 16.685632
KL Loss: 4.482087
Y Loss: 0.551571
T Loss: 13.246727
Epoch 299 
Overall Loss: 20.833800
Rec Loss: 16.079866
KL Loss: 4.753934
Y Loss: 0.480342
T Loss: 13.224288
Epoch 349 
Overall Loss: 20.619561
Rec Loss: 15.629555
KL Loss: 4.990006
Y Loss: 0.444915
T Loss: 13.214958
Epoch 399 
Overall Loss: 20.496752
Rec Loss: 15.308485
KL Loss: 5.188267
Y Loss: 0.402838
T Loss: 13.199715
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.896709
Epoch 99
Rec Loss: 1.888346
Epoch 149
Rec Loss: 1.888910
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.007771
Epoch 99
Rec Loss: 6.005907
Epoch 149
Rec Loss: 6.003385
Epoch 199
Rec Loss: 5.994913
Epoch 249
Rec Loss: 5.998054
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.261928
Insample Error 2.064148
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 19.827306
Rec Loss: 17.724289
KL Loss: 2.103018
Y Loss: 2.261836
T Loss: 13.200617
Epoch 99 
Overall Loss: 16.843922
Rec Loss: 15.226605
KL Loss: 1.617318
Y Loss: 0.996989
T Loss: 13.232626
Epoch 149 
Overall Loss: 16.197505
Rec Loss: 14.791898
KL Loss: 1.405608
Y Loss: 0.785413
T Loss: 13.221071
Epoch 199 
Overall Loss: 15.735646
Rec Loss: 14.477293
KL Loss: 1.258354
Y Loss: 0.641428
T Loss: 13.194437
Epoch 249 
Overall Loss: 15.365630
Rec Loss: 14.170462
KL Loss: 1.195168
Y Loss: 0.505113
T Loss: 13.160237
Epoch 299 
Overall Loss: 15.122968
Rec Loss: 13.951122
KL Loss: 1.171846
Y Loss: 0.408520
T Loss: 13.134082
Epoch 349 
Overall Loss: 14.936129
Rec Loss: 13.753386
KL Loss: 1.182744
Y Loss: 0.328573
T Loss: 13.096238
Epoch 399 
Overall Loss: 14.866340
Rec Loss: 13.679743
KL Loss: 1.186596
Y Loss: 0.307061
T Loss: 13.065622
Epoch 449 
Overall Loss: 14.797501
Rec Loss: 13.603223
KL Loss: 1.194278
Y Loss: 0.291012
T Loss: 13.021198
Epoch 499 
Overall Loss: 14.760414
Rec Loss: 13.557825
KL Loss: 1.202589
Y Loss: 0.274287
T Loss: 13.009251
Epoch 549 
Overall Loss: 14.749957
Rec Loss: 13.540626
KL Loss: 1.209331
Y Loss: 0.269959
T Loss: 13.000708
Epoch 599 
Overall Loss: 14.715359
Rec Loss: 13.506381
KL Loss: 1.208978
Y Loss: 0.261342
T Loss: 12.983697
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.671971
Epoch 99
Rec Loss: 1.663757
Epoch 149
Rec Loss: 1.667022
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.068776
Epoch 99
Rec Loss: 10.076692
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.211822
Insample Error: 2.109423
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 29.422743
Rec Loss: 24.438966
KL Loss: 4.983776
Y Loss: 2.943340
T Loss: 13.257184
Epoch 99 
Overall Loss: 24.251474
Rec Loss: 20.794877
KL Loss: 3.456597
Y Loss: 1.180945
T Loss: 13.275790
Epoch 149 
Overall Loss: 22.871039
Rec Loss: 19.298433
KL Loss: 3.572606
Y Loss: 0.874146
T Loss: 13.265225
Epoch 199 
Overall Loss: 21.815501
Rec Loss: 17.805724
KL Loss: 4.009777
Y Loss: 0.690982
T Loss: 13.244004
Epoch 249 
Overall Loss: 21.224352
Rec Loss: 16.765024
KL Loss: 4.459328
Y Loss: 0.597878
T Loss: 13.234975
Epoch 299 
Overall Loss: 20.886816
Rec Loss: 16.247034
KL Loss: 4.639783
Y Loss: 0.526438
T Loss: 13.223077
Epoch 349 
Overall Loss: 20.691028
Rec Loss: 15.781684
KL Loss: 4.909344
Y Loss: 0.466702
T Loss: 13.208846
Epoch 399 
Overall Loss: 20.505242
Rec Loss: 15.281926
KL Loss: 5.223316
Y Loss: 0.431918
T Loss: 13.194417
Epoch 449 
Overall Loss: 20.362410
Rec Loss: 14.851539
KL Loss: 5.510872
Y Loss: 0.392396
T Loss: 13.181519
Epoch 499 
Overall Loss: 20.318059
Rec Loss: 14.566492
KL Loss: 5.751566
Y Loss: 0.373195
T Loss: 13.174554
Epoch 549 
Overall Loss: 20.248220
Rec Loss: 14.370013
KL Loss: 5.878208
Y Loss: 0.354838
T Loss: 13.161834
Epoch 599 
Overall Loss: 20.220892
Rec Loss: 14.233426
KL Loss: 5.987465
Y Loss: 0.348420
T Loss: 13.152892
Epoch 649 
Overall Loss: 20.153862
Rec Loss: 14.140889
KL Loss: 6.012973
Y Loss: 0.341566
T Loss: 13.141233
Epoch 699 
Overall Loss: 20.119783
Rec Loss: 14.050611
KL Loss: 6.069172
Y Loss: 0.324925
T Loss: 13.128779
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.815130
Epoch 99
Rec Loss: 1.811005
Epoch 149
Rec Loss: 1.813941
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.752642
Epoch 99
Rec Loss: 5.735081
Epoch 149
Rec Loss: 5.737270
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.245093
Insample Error 2.028678
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 20.890536
Rec Loss: 19.174849
KL Loss: 1.715686
Y Loss: 2.966912
T Loss: 13.241026
Epoch 99 
Overall Loss: 16.864326
Rec Loss: 15.393230
KL Loss: 1.471096
Y Loss: 1.076984
T Loss: 13.239262
Epoch 149 
Overall Loss: 16.209702
Rec Loss: 14.910980
KL Loss: 1.298722
Y Loss: 0.841625
T Loss: 13.227730
Epoch 199 
Overall Loss: 15.811884
Rec Loss: 14.645773
KL Loss: 1.166111
Y Loss: 0.716729
T Loss: 13.212315
Epoch 249 
Overall Loss: 15.479041
Rec Loss: 14.355297
KL Loss: 1.123744
Y Loss: 0.586124
T Loss: 13.183050
Epoch 299 
Overall Loss: 15.167079
Rec Loss: 14.053199
KL Loss: 1.113879
Y Loss: 0.444130
T Loss: 13.164940
Epoch 349 
Overall Loss: 14.946273
Rec Loss: 13.819146
KL Loss: 1.127128
Y Loss: 0.341032
T Loss: 13.137081
Epoch 399 
Overall Loss: 14.863350
Rec Loss: 13.737944
KL Loss: 1.125406
Y Loss: 0.312365
T Loss: 13.113213
Epoch 449 
Overall Loss: 14.804016
Rec Loss: 13.667118
KL Loss: 1.136898
Y Loss: 0.291744
T Loss: 13.083629
Epoch 499 
Overall Loss: 14.777625
Rec Loss: 13.620145
KL Loss: 1.157480
Y Loss: 0.280502
T Loss: 13.059142
Epoch 549 
Overall Loss: 14.734963
Rec Loss: 13.564578
KL Loss: 1.170385
Y Loss: 0.265758
T Loss: 13.033063
Epoch 599 
Overall Loss: 14.730263
Rec Loss: 13.549780
KL Loss: 1.180483
Y Loss: 0.269630
T Loss: 13.010520
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.700416
Epoch 99
Rec Loss: 1.694611
Epoch 149
Rec Loss: 1.694499
Epoch 199
Rec Loss: 1.686728
Epoch 249
Rec Loss: 1.696870
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.056094
Epoch 99
Rec Loss: 10.053926
Epoch 149
Rec Loss: 10.058590
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.226667
Insample Error: 2.112495
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 29.127521
Rec Loss: 24.557420
KL Loss: 4.570100
Y Loss: 2.998986
T Loss: 13.224559
Epoch 99 
Overall Loss: 24.427192
Rec Loss: 21.131630
KL Loss: 3.295563
Y Loss: 1.271110
T Loss: 13.276343
Epoch 149 
Overall Loss: 23.396592
Rec Loss: 20.417764
KL Loss: 2.978827
Y Loss: 0.996981
T Loss: 13.248290
Epoch 199 
Overall Loss: 22.165220
Rec Loss: 19.149338
KL Loss: 3.015881
Y Loss: 0.715971
T Loss: 13.219107
Epoch 249 
Overall Loss: 20.987933
Rec Loss: 17.503471
KL Loss: 3.484462
Y Loss: 0.464182
T Loss: 13.203066
Epoch 299 
Overall Loss: 20.585960
Rec Loss: 16.869711
KL Loss: 3.716250
Y Loss: 0.367503
T Loss: 13.192405
Epoch 349 
Overall Loss: 20.404045
Rec Loss: 16.659893
KL Loss: 3.744153
Y Loss: 0.312736
T Loss: 13.184387
Epoch 399 
Overall Loss: 20.299502
Rec Loss: 16.475360
KL Loss: 3.824141
Y Loss: 0.295227
T Loss: 13.167800
Epoch 449 
Overall Loss: 20.216232
Rec Loss: 16.305914
KL Loss: 3.910318
Y Loss: 0.281632
T Loss: 13.145274
Epoch 499 
Overall Loss: 20.152618
Rec Loss: 16.157239
KL Loss: 3.995379
Y Loss: 0.276828
T Loss: 13.132570
Epoch 549 
Overall Loss: 20.133085
Rec Loss: 16.068930
KL Loss: 4.064156
Y Loss: 0.285577
T Loss: 13.117819
Epoch 599 
Overall Loss: 20.130420
Rec Loss: 15.970244
KL Loss: 4.160176
Y Loss: 0.278553
T Loss: 13.103146
Epoch 649 
Overall Loss: 20.095738
Rec Loss: 15.821601
KL Loss: 4.274137
Y Loss: 0.277808
T Loss: 13.092271
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.779482
Epoch 99
Rec Loss: 1.770056
Epoch 149
Rec Loss: 1.773562
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.178905
Epoch 99
Rec Loss: 6.166171
Epoch 149
Rec Loss: 6.181922
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.218406
Insample Error 2.059717
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 20.660213
Rec Loss: 19.065010
KL Loss: 1.595203
Y Loss: 2.930886
T Loss: 13.203238
Epoch 99 
Overall Loss: 16.541891
Rec Loss: 15.194524
KL Loss: 1.347368
Y Loss: 0.981044
T Loss: 13.232436
Epoch 149 
Overall Loss: 15.846361
Rec Loss: 14.603596
KL Loss: 1.242765
Y Loss: 0.685026
T Loss: 13.233544
Epoch 199 
Overall Loss: 15.373437
Rec Loss: 14.213657
KL Loss: 1.159780
Y Loss: 0.504345
T Loss: 13.204966
Epoch 249 
Overall Loss: 15.093676
Rec Loss: 13.980276
KL Loss: 1.113401
Y Loss: 0.403672
T Loss: 13.172932
Epoch 299 
Overall Loss: 14.948250
Rec Loss: 13.836816
KL Loss: 1.111434
Y Loss: 0.345013
T Loss: 13.146790
Epoch 349 
Overall Loss: 14.867996
Rec Loss: 13.748667
KL Loss: 1.119329
Y Loss: 0.314115
T Loss: 13.120437
Epoch 399 
Overall Loss: 14.824742
Rec Loss: 13.694321
KL Loss: 1.130422
Y Loss: 0.297960
T Loss: 13.098402
Epoch 449 
Overall Loss: 14.787014
Rec Loss: 13.645375
KL Loss: 1.141638
Y Loss: 0.284491
T Loss: 13.076394
Epoch 499 
Overall Loss: 14.774072
Rec Loss: 13.618356
KL Loss: 1.155716
Y Loss: 0.279159
T Loss: 13.060037
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.752119
Epoch 99
Rec Loss: 1.746503
Epoch 149
Rec Loss: 1.747697
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.068700
Epoch 99
Rec Loss: 10.068586
Epoch 149
Rec Loss: 10.060285
Epoch 199
Rec Loss: 10.059088
Epoch 249
Rec Loss: 10.063256
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.234204
Insample Error: 2.093298
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 29.757968
Rec Loss: 25.853290
KL Loss: 3.904677
Y Loss: 3.667511
T Loss: 13.221075
Epoch 99 
Overall Loss: 24.322645
Rec Loss: 21.051409
KL Loss: 3.271235
Y Loss: 1.274007
T Loss: 13.269785
Epoch 149 
Overall Loss: 22.906487
Rec Loss: 19.756122
KL Loss: 3.150365
Y Loss: 0.889865
T Loss: 13.257103
Epoch 199 
Overall Loss: 21.923892
Rec Loss: 18.788753
KL Loss: 3.135139
Y Loss: 0.648341
T Loss: 13.246555
Epoch 249 
Overall Loss: 21.096597
Rec Loss: 17.915151
KL Loss: 3.181447
Y Loss: 0.455528
T Loss: 13.224621
Epoch 299 
Overall Loss: 20.615600
Rec Loss: 17.075120
KL Loss: 3.540480
Y Loss: 0.357267
T Loss: 13.209885
Epoch 349 
Overall Loss: 20.413069
Rec Loss: 16.701316
KL Loss: 3.711753
Y Loss: 0.317363
T Loss: 13.184480
Epoch 399 
Overall Loss: 20.308367
Rec Loss: 16.511089
KL Loss: 3.797277
Y Loss: 0.297616
T Loss: 13.162883
Epoch 449 
Overall Loss: 20.202392
Rec Loss: 16.338235
KL Loss: 3.864156
Y Loss: 0.282531
T Loss: 13.142575
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.812779
Epoch 99
Rec Loss: 1.807339
Epoch 149
Rec Loss: 1.807294
Epoch 199
Rec Loss: 1.805189
Epoch 249
Rec Loss: 1.803881
Epoch 299
Rec Loss: 1.809182
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.330880
Epoch 99
Rec Loss: 6.321005
Epoch 149
Rec Loss: 6.303669
Epoch 199
Rec Loss: 6.323970
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.232532
Insample Error 2.040173
Ours, Train RMSE
0.2422, 
0.2389, 
0.2268, 
0.2320, 
0.2304, 
0.2236, 
0.2189, 
0.2118, 
0.2267, 
0.2342, 
2.0989, 
2.1770, 
2.1247, 
2.1217, 
2.1245, 
2.0982, 
2.0999, 
2.1094, 
2.1125, 
2.0933, 
2.0634, 
2.0720, 
2.0644, 
2.0775, 
2.0911, 
2.0695, 
2.0641, 
2.0287, 
2.0597, 
2.0402, 
Train, RMSE mean 0.2286 std 0.0086
Ours, RMSE mean 2.1160 std 0.0231, reconstruct confounder 1.7128 (0.0339) noise 10.0550 (0.0094)
CEVAE, RMSE mean 2.0631 std 0.0168, reconstruct confounder 1.8230 (0.0357) noise 6.0150 (0.1921)
Experiment Start!
Namespace(decay=0.0, l=5e-05, latdim=4, mask=0, nlayer=50, obsm=2, ycof=0.5, ylayer=50)
Y Mean 1.192369, Std 4.040208 
Observe confounder 2, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.943567
Rec Loss: 15.052507
KL Loss: 0.891060
Y Loss: 3.626393
T Loss: 13.239310
Epoch 99 
Overall Loss: 14.776605
Rec Loss: 14.130479
KL Loss: 0.646126
Y Loss: 1.824167
T Loss: 13.218395
Epoch 149 
Overall Loss: 14.433465
Rec Loss: 13.941183
KL Loss: 0.492282
Y Loss: 1.549542
T Loss: 13.166412
Epoch 199 
Overall Loss: 14.271055
Rec Loss: 13.830060
KL Loss: 0.440994
Y Loss: 1.404283
T Loss: 13.127919
Epoch 249 
Overall Loss: 14.199314
Rec Loss: 13.766668
KL Loss: 0.432645
Y Loss: 1.338511
T Loss: 13.097413
Epoch 299 
Overall Loss: 14.137760
Rec Loss: 13.694977
KL Loss: 0.442782
Y Loss: 1.225081
T Loss: 13.082437
Epoch 349 
Overall Loss: 14.072574
Rec Loss: 13.614246
KL Loss: 0.458328
Y Loss: 1.102451
T Loss: 13.063020
Epoch 399 
Overall Loss: 14.034236
Rec Loss: 13.558500
KL Loss: 0.475736
Y Loss: 1.012292
T Loss: 13.052354
Epoch 449 
Overall Loss: 14.017184
Rec Loss: 13.536316
KL Loss: 0.480868
Y Loss: 0.993476
T Loss: 13.039578
Epoch 499 
Overall Loss: 13.999493
Rec Loss: 13.513308
KL Loss: 0.486186
Y Loss: 0.955806
T Loss: 13.035405
Epoch 549 
Overall Loss: 13.978996
Rec Loss: 13.495549
KL Loss: 0.483447
Y Loss: 0.918529
T Loss: 13.036284
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.698601
Epoch 99
Rec Loss: 1.697932
Epoch 149
Rec Loss: 1.696234
Epoch 199
Rec Loss: 1.693319
Epoch 249
Rec Loss: 1.699283
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.058235
Epoch 99
Rec Loss: 10.056151
Epoch 149
Rec Loss: 10.052851
Epoch 199
Rec Loss: 10.055700
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.676506
Insample Error: 1.897998
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 23.906637
Rec Loss: 22.292506
KL Loss: 1.614131
Y Loss: 7.106126
T Loss: 13.323319
Epoch 99 
Overall Loss: 21.079750
Rec Loss: 18.962636
KL Loss: 2.117115
Y Loss: 2.271458
T Loss: 13.252601
Epoch 149 
Overall Loss: 20.267747
Rec Loss: 17.607694
KL Loss: 2.660053
Y Loss: 1.663595
T Loss: 13.213237
Epoch 199 
Overall Loss: 20.038024
Rec Loss: 17.169290
KL Loss: 2.868733
Y Loss: 1.493786
T Loss: 13.186007
Epoch 249 
Overall Loss: 19.816404
Rec Loss: 16.682253
KL Loss: 3.134151
Y Loss: 1.356912
T Loss: 13.161681
Epoch 299 
Overall Loss: 19.572558
Rec Loss: 15.902904
KL Loss: 3.669655
Y Loss: 1.207694
T Loss: 13.147641
Epoch 349 
Overall Loss: 19.479375
Rec Loss: 15.610368
KL Loss: 3.869007
Y Loss: 1.196108
T Loss: 13.126924
Epoch 399 
Overall Loss: 19.384331
Rec Loss: 15.331956
KL Loss: 4.052375
Y Loss: 1.137878
T Loss: 13.112920
Epoch 449 
Overall Loss: 19.377611
Rec Loss: 15.180440
KL Loss: 4.197171
Y Loss: 1.114815
T Loss: 13.107076
Epoch 499 
Overall Loss: 19.310457
Rec Loss: 15.008879
KL Loss: 4.301577
Y Loss: 1.081510
T Loss: 13.089863
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.837729
Epoch 99
Rec Loss: 1.836064
Epoch 149
Rec Loss: 1.832674
Epoch 199
Rec Loss: 1.829997
Epoch 249
Rec Loss: 1.834671
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.969329
Epoch 99
Rec Loss: 5.968447
Epoch 149
Rec Loss: 5.978902
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.639841
Insample Error 1.952206
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.324839
Rec Loss: 15.576477
KL Loss: 0.748361
Y Loss: 4.712213
T Loss: 13.220371
Epoch 99 
Overall Loss: 14.827848
Rec Loss: 14.232501
KL Loss: 0.595348
Y Loss: 2.047346
T Loss: 13.208827
Epoch 149 
Overall Loss: 14.452788
Rec Loss: 14.000222
KL Loss: 0.452567
Y Loss: 1.665520
T Loss: 13.167462
Epoch 199 
Overall Loss: 14.298223
Rec Loss: 13.876861
KL Loss: 0.421361
Y Loss: 1.500976
T Loss: 13.126374
Epoch 249 
Overall Loss: 14.218750
Rec Loss: 13.803097
KL Loss: 0.415653
Y Loss: 1.403263
T Loss: 13.101465
Epoch 299 
Overall Loss: 14.168948
Rec Loss: 13.738186
KL Loss: 0.430762
Y Loss: 1.301863
T Loss: 13.087254
Epoch 349 
Overall Loss: 14.100323
Rec Loss: 13.645543
KL Loss: 0.454780
Y Loss: 1.134680
T Loss: 13.078203
Epoch 399 
Overall Loss: 14.051091
Rec Loss: 13.573621
KL Loss: 0.477469
Y Loss: 1.024360
T Loss: 13.061441
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.718337
Epoch 99
Rec Loss: 1.720775
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.057180
Epoch 99
Rec Loss: 10.059632
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.685312
Insample Error: 2.021545
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 24.102036
Rec Loss: 22.560648
KL Loss: 1.541387
Y Loss: 7.725242
T Loss: 13.313845
Epoch 99 
Overall Loss: 21.152013
Rec Loss: 18.887408
KL Loss: 2.264605
Y Loss: 2.538987
T Loss: 13.258070
Epoch 149 
Overall Loss: 20.208444
Rec Loss: 16.996370
KL Loss: 3.212073
Y Loss: 1.798615
T Loss: 13.229053
Epoch 199 
Overall Loss: 19.939022
Rec Loss: 16.520410
KL Loss: 3.418611
Y Loss: 1.620797
T Loss: 13.200768
Epoch 249 
Overall Loss: 19.792513
Rec Loss: 16.224421
KL Loss: 3.568092
Y Loss: 1.483587
T Loss: 13.185120
Epoch 299 
Overall Loss: 19.581520
Rec Loss: 15.747946
KL Loss: 3.833574
Y Loss: 1.331984
T Loss: 13.151826
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.900616
Epoch 99
Rec Loss: 1.898073
Epoch 149
Rec Loss: 1.895155
Epoch 199
Rec Loss: 1.894103
Epoch 249
Rec Loss: 1.893275
Epoch 299
Rec Loss: 1.893362
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.968842
Epoch 99
Rec Loss: 5.969103
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.700247
Insample Error 1.904438
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.469547
Rec Loss: 15.535805
KL Loss: 0.933743
Y Loss: 4.582191
T Loss: 13.244710
Epoch 99 
Overall Loss: 14.819639
Rec Loss: 14.130244
KL Loss: 0.689395
Y Loss: 1.847320
T Loss: 13.206584
Epoch 149 
Overall Loss: 14.432059
Rec Loss: 13.879096
KL Loss: 0.552962
Y Loss: 1.452663
T Loss: 13.152765
Epoch 199 
Overall Loss: 14.231289
Rec Loss: 13.742687
KL Loss: 0.488601
Y Loss: 1.296972
T Loss: 13.094201
Epoch 249 
Overall Loss: 14.143511
Rec Loss: 13.658920
KL Loss: 0.484590
Y Loss: 1.173869
T Loss: 13.071986
Epoch 299 
Overall Loss: 14.074938
Rec Loss: 13.579376
KL Loss: 0.495561
Y Loss: 1.036520
T Loss: 13.061116
Epoch 349 
Overall Loss: 14.061833
Rec Loss: 13.556939
KL Loss: 0.504894
Y Loss: 0.997358
T Loss: 13.058260
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.669070
Epoch 99
Rec Loss: 1.665204
Epoch 149
Rec Loss: 1.657608
Epoch 199
Rec Loss: 1.669913
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.069598
Epoch 99
Rec Loss: 10.066887
Epoch 149
Rec Loss: 10.068170
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.675143
Insample Error: 2.038109
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 23.924318
Rec Loss: 22.339484
KL Loss: 1.584834
Y Loss: 7.219849
T Loss: 13.306116
Epoch 99 
Overall Loss: 21.396341
Rec Loss: 19.393430
KL Loss: 2.002911
Y Loss: 2.611533
T Loss: 13.277360
Epoch 149 
Overall Loss: 20.569513
Rec Loss: 17.993237
KL Loss: 2.576276
Y Loss: 1.973486
T Loss: 13.231543
Epoch 199 
Overall Loss: 19.947294
Rec Loss: 16.755816
KL Loss: 3.191478
Y Loss: 1.568725
T Loss: 13.193522
Epoch 249 
Overall Loss: 19.720758
Rec Loss: 16.228304
KL Loss: 3.492454
Y Loss: 1.419817
T Loss: 13.172501
Epoch 299 
Overall Loss: 19.591725
Rec Loss: 15.961046
KL Loss: 3.630679
Y Loss: 1.293838
T Loss: 13.152386
Epoch 349 
Overall Loss: 19.490370
Rec Loss: 15.715543
KL Loss: 3.774827
Y Loss: 1.197693
T Loss: 13.130228
Epoch 399 
Overall Loss: 19.443917
Rec Loss: 15.549027
KL Loss: 3.894891
Y Loss: 1.120458
T Loss: 13.117898
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.842358
Epoch 99
Rec Loss: 1.836695
Epoch 149
Rec Loss: 1.841955
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.030702
Epoch 99
Rec Loss: 6.019361
Epoch 149
Rec Loss: 6.007469
Epoch 199
Rec Loss: 6.008824
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.666230
Insample Error 1.939566
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.939376
Rec Loss: 15.137072
KL Loss: 0.802304
Y Loss: 3.756862
T Loss: 13.258641
Epoch 99 
Overall Loss: 14.631103
Rec Loss: 14.023495
KL Loss: 0.607608
Y Loss: 1.606684
T Loss: 13.220154
Epoch 149 
Overall Loss: 14.386970
Rec Loss: 13.911466
KL Loss: 0.475504
Y Loss: 1.472753
T Loss: 13.175090
Epoch 199 
Overall Loss: 14.242713
Rec Loss: 13.810069
KL Loss: 0.432644
Y Loss: 1.348018
T Loss: 13.136060
Epoch 249 
Overall Loss: 14.175819
Rec Loss: 13.742026
KL Loss: 0.433793
Y Loss: 1.266106
T Loss: 13.108973
Epoch 299 
Overall Loss: 14.110770
Rec Loss: 13.671779
KL Loss: 0.438991
Y Loss: 1.154430
T Loss: 13.094564
Epoch 349 
Overall Loss: 14.084242
Rec Loss: 13.631659
KL Loss: 0.452583
Y Loss: 1.107390
T Loss: 13.077964
Epoch 399 
Overall Loss: 14.046369
Rec Loss: 13.575688
KL Loss: 0.470680
Y Loss: 1.022874
T Loss: 13.064251
Epoch 449 
Overall Loss: 14.028919
Rec Loss: 13.555869
KL Loss: 0.473050
Y Loss: 0.987078
T Loss: 13.062331
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.758518
Epoch 99
Rec Loss: 1.736272
Epoch 149
Rec Loss: 1.737195
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.051725
Epoch 99
Rec Loss: 10.050449
Epoch 149
Rec Loss: 10.049217
Epoch 199
Rec Loss: 10.052352
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.691095
Insample Error: 2.021943
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 23.916417
Rec Loss: 22.366623
KL Loss: 1.549795
Y Loss: 7.176768
T Loss: 13.343307
Epoch 99 
Overall Loss: 21.328475
Rec Loss: 19.402602
KL Loss: 1.925874
Y Loss: 2.584888
T Loss: 13.278070
Epoch 149 
Overall Loss: 20.415148
Rec Loss: 17.837967
KL Loss: 2.577181
Y Loss: 1.778648
T Loss: 13.233348
Epoch 199 
Overall Loss: 19.972538
Rec Loss: 16.968389
KL Loss: 3.004149
Y Loss: 1.500073
T Loss: 13.189199
Epoch 249 
Overall Loss: 19.690035
Rec Loss: 16.189363
KL Loss: 3.500672
Y Loss: 1.386318
T Loss: 13.170097
Epoch 299 
Overall Loss: 19.555601
Rec Loss: 15.828852
KL Loss: 3.726749
Y Loss: 1.265111
T Loss: 13.155410
Epoch 349 
Overall Loss: 19.464644
Rec Loss: 15.585410
KL Loss: 3.879234
Y Loss: 1.197325
T Loss: 13.137669
Epoch 399 
Overall Loss: 19.411535
Rec Loss: 15.429048
KL Loss: 3.982487
Y Loss: 1.159378
T Loss: 13.118613
Epoch 449 
Overall Loss: 19.378183
Rec Loss: 15.309216
KL Loss: 4.068968
Y Loss: 1.158493
T Loss: 13.107498
Epoch 499 
Overall Loss: 19.356761
Rec Loss: 15.182742
KL Loss: 4.174019
Y Loss: 1.108736
T Loss: 13.088767
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.820218
Epoch 99
Rec Loss: 1.829250
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.975322
Epoch 99
Rec Loss: 5.974606
Epoch 149
Rec Loss: 5.974134
Epoch 199
Rec Loss: 5.981224
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.639219
Insample Error 1.963173
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.493268
Rec Loss: 15.578266
KL Loss: 0.915003
Y Loss: 4.636048
T Loss: 13.260242
Epoch 99 
Overall Loss: 14.682813
Rec Loss: 14.013230
KL Loss: 0.669583
Y Loss: 1.611912
T Loss: 13.207274
Epoch 149 
Overall Loss: 14.341073
Rec Loss: 13.830011
KL Loss: 0.511062
Y Loss: 1.360243
T Loss: 13.149890
Epoch 199 
Overall Loss: 14.205635
Rec Loss: 13.731395
KL Loss: 0.474240
Y Loss: 1.249902
T Loss: 13.106445
Epoch 249 
Overall Loss: 14.117232
Rec Loss: 13.644798
KL Loss: 0.472435
Y Loss: 1.123710
T Loss: 13.082943
Epoch 299 
Overall Loss: 14.081542
Rec Loss: 13.595257
KL Loss: 0.486285
Y Loss: 1.055413
T Loss: 13.067551
Epoch 349 
Overall Loss: 14.058837
Rec Loss: 13.563530
KL Loss: 0.495308
Y Loss: 1.001911
T Loss: 13.062574
Epoch 399 
Overall Loss: 14.040593
Rec Loss: 13.545015
KL Loss: 0.495578
Y Loss: 0.984816
T Loss: 13.052607
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.747066
Epoch 99
Rec Loss: 1.745813
Epoch 149
Rec Loss: 1.747548
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.074442
Epoch 99
Rec Loss: 10.072898
Epoch 149
Rec Loss: 10.071057
Epoch 199
Rec Loss: 10.068479
Epoch 249
Rec Loss: 10.072218
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.686648
Insample Error: 2.040579
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 23.676972
Rec Loss: 21.994114
KL Loss: 1.682858
Y Loss: 6.588142
T Loss: 13.321161
Epoch 99 
Overall Loss: 21.297526
Rec Loss: 19.244301
KL Loss: 2.053225
Y Loss: 2.429224
T Loss: 13.275951
Epoch 149 
Overall Loss: 20.633194
Rec Loss: 18.102202
KL Loss: 2.530992
Y Loss: 1.977937
T Loss: 13.211919
Epoch 199 
Overall Loss: 20.165555
Rec Loss: 17.300976
KL Loss: 2.864580
Y Loss: 1.647497
T Loss: 13.155948
Epoch 249 
Overall Loss: 19.795303
Rec Loss: 16.458433
KL Loss: 3.336870
Y Loss: 1.422847
T Loss: 13.152064
Epoch 299 
Overall Loss: 19.594901
Rec Loss: 15.908591
KL Loss: 3.686310
Y Loss: 1.281392
T Loss: 13.142309
Epoch 349 
Overall Loss: 19.503358
Rec Loss: 15.661226
KL Loss: 3.842132
Y Loss: 1.271938
T Loss: 13.128566
Epoch 399 
Overall Loss: 19.390341
Rec Loss: 15.371837
KL Loss: 4.018504
Y Loss: 1.139239
T Loss: 13.111900
Epoch 449 
Overall Loss: 19.347834
Rec Loss: 15.171627
KL Loss: 4.176207
Y Loss: 1.103960
T Loss: 13.096344
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.831349
Epoch 99
Rec Loss: 1.830934
Epoch 149
Rec Loss: 1.830355
Epoch 199
Rec Loss: 1.832537
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.010673
Epoch 99
Rec Loss: 5.997656
Epoch 149
Rec Loss: 6.006804
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.653434
Insample Error 1.932206
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.305827
Rec Loss: 15.359978
KL Loss: 0.945850
Y Loss: 4.198131
T Loss: 13.260912
Epoch 99 
Overall Loss: 14.738020
Rec Loss: 14.028667
KL Loss: 0.709353
Y Loss: 1.605936
T Loss: 13.225699
Epoch 149 
Overall Loss: 14.396880
Rec Loss: 13.831047
KL Loss: 0.565833
Y Loss: 1.314665
T Loss: 13.173715
Epoch 199 
Overall Loss: 14.199043
Rec Loss: 13.703402
KL Loss: 0.495640
Y Loss: 1.167125
T Loss: 13.119840
Epoch 249 
Overall Loss: 14.107353
Rec Loss: 13.610882
KL Loss: 0.496472
Y Loss: 1.062894
T Loss: 13.079435
Epoch 299 
Overall Loss: 14.073641
Rec Loss: 13.573041
KL Loss: 0.500601
Y Loss: 1.015925
T Loss: 13.065078
Epoch 349 
Overall Loss: 14.044487
Rec Loss: 13.544470
KL Loss: 0.500017
Y Loss: 0.976870
T Loss: 13.056035
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.751250
Epoch 99
Rec Loss: 1.753884
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.063166
Epoch 99
Rec Loss: 10.059027
Epoch 149
Rec Loss: 10.062054
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.685110
Insample Error: 2.018471
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 23.242845
Rec Loss: 21.519331
KL Loss: 1.723513
Y Loss: 5.587451
T Loss: 13.341680
Epoch 99 
Overall Loss: 21.299242
Rec Loss: 19.227775
KL Loss: 2.071467
Y Loss: 2.549650
T Loss: 13.259194
Epoch 149 
Overall Loss: 20.489971
Rec Loss: 17.764472
KL Loss: 2.725500
Y Loss: 1.944218
T Loss: 13.211625
Epoch 199 
Overall Loss: 19.920305
Rec Loss: 16.503548
KL Loss: 3.416757
Y Loss: 1.559540
T Loss: 13.204044
Epoch 249 
Overall Loss: 19.729133
Rec Loss: 16.079053
KL Loss: 3.650080
Y Loss: 1.450028
T Loss: 13.179243
Epoch 299 
Overall Loss: 19.615514
Rec Loss: 15.721702
KL Loss: 3.893812
Y Loss: 1.337465
T Loss: 13.155456
Epoch 349 
Overall Loss: 19.501305
Rec Loss: 15.367672
KL Loss: 4.133633
Y Loss: 1.257950
T Loss: 13.138261
Epoch 399 
Overall Loss: 19.443981
Rec Loss: 15.091854
KL Loss: 4.352127
Y Loss: 1.210302
T Loss: 13.128198
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.844804
Epoch 99
Rec Loss: 1.852038
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.817876
Epoch 99
Rec Loss: 5.804708
Epoch 149
Rec Loss: 5.814290
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.667295
Insample Error 1.931921
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.869407
Rec Loss: 16.147842
KL Loss: 0.721564
Y Loss: 5.786402
T Loss: 13.254641
Epoch 99 
Overall Loss: 14.791503
Rec Loss: 14.119231
KL Loss: 0.672273
Y Loss: 1.784061
T Loss: 13.227201
Epoch 149 
Overall Loss: 14.405193
Rec Loss: 13.841844
KL Loss: 0.563349
Y Loss: 1.334588
T Loss: 13.174550
Epoch 199 
Overall Loss: 14.197842
Rec Loss: 13.693756
KL Loss: 0.504086
Y Loss: 1.143805
T Loss: 13.121853
Epoch 249 
Overall Loss: 14.121349
Rec Loss: 13.622934
KL Loss: 0.498415
Y Loss: 1.077280
T Loss: 13.084294
Epoch 299 
Overall Loss: 14.077362
Rec Loss: 13.574438
KL Loss: 0.502924
Y Loss: 1.003956
T Loss: 13.072460
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.769330
Epoch 99
Rec Loss: 1.763037
Epoch 149
Rec Loss: 1.766324
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.059772
Epoch 99
Rec Loss: 10.064109
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.699246
Insample Error: 2.012886
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 23.621821
Rec Loss: 22.027145
KL Loss: 1.594676
Y Loss: 6.533159
T Loss: 13.329524
Epoch 99 
Overall Loss: 21.279388
Rec Loss: 19.447587
KL Loss: 1.831801
Y Loss: 2.516196
T Loss: 13.276228
Epoch 149 
Overall Loss: 20.277181
Rec Loss: 17.658919
KL Loss: 2.618261
Y Loss: 1.695810
T Loss: 13.226637
Epoch 199 
Overall Loss: 19.843196
Rec Loss: 16.601093
KL Loss: 3.242104
Y Loss: 1.481072
T Loss: 13.200545
Epoch 249 
Overall Loss: 19.666957
Rec Loss: 16.185180
KL Loss: 3.481777
Y Loss: 1.326464
T Loss: 13.183733
Epoch 299 
Overall Loss: 19.515956
Rec Loss: 15.839405
KL Loss: 3.676550
Y Loss: 1.210265
T Loss: 13.158955
Epoch 349 
Overall Loss: 19.417504
Rec Loss: 15.504098
KL Loss: 3.913406
Y Loss: 1.151249
T Loss: 13.133534
Epoch 399 
Overall Loss: 19.332939
Rec Loss: 15.216097
KL Loss: 4.116842
Y Loss: 1.067989
T Loss: 13.111485
Epoch 449 
Overall Loss: 19.303021
Rec Loss: 15.067830
KL Loss: 4.235190
Y Loss: 1.054859
T Loss: 13.098254
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.829252
Epoch 99
Rec Loss: 1.827190
Epoch 149
Rec Loss: 1.829962
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.982370
Epoch 99
Rec Loss: 5.992448
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.630398
Insample Error 1.915498
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.288688
Rec Loss: 15.355096
KL Loss: 0.933592
Y Loss: 4.251237
T Loss: 13.229477
Epoch 99 
Overall Loss: 14.815396
Rec Loss: 14.154573
KL Loss: 0.660823
Y Loss: 1.870017
T Loss: 13.219565
Epoch 149 
Overall Loss: 14.404916
Rec Loss: 13.924282
KL Loss: 0.480635
Y Loss: 1.528429
T Loss: 13.160067
Epoch 199 
Overall Loss: 14.268261
Rec Loss: 13.825881
KL Loss: 0.442380
Y Loss: 1.407075
T Loss: 13.122343
Epoch 249 
Overall Loss: 14.216985
Rec Loss: 13.791122
KL Loss: 0.425862
Y Loss: 1.369719
T Loss: 13.106263
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.799300
Epoch 99
Rec Loss: 1.800534
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.075251
Epoch 99
Rec Loss: 10.078327
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.855420
Insample Error: 2.051978
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 23.095694
Rec Loss: 21.361290
KL Loss: 1.734404
Y Loss: 5.258838
T Loss: 13.319627
Epoch 99 
Overall Loss: 21.187598
Rec Loss: 19.136965
KL Loss: 2.050633
Y Loss: 2.364365
T Loss: 13.282593
Epoch 149 
Overall Loss: 20.369965
Rec Loss: 17.672805
KL Loss: 2.697160
Y Loss: 1.824120
T Loss: 13.218781
Epoch 199 
Overall Loss: 19.953423
Rec Loss: 16.804625
KL Loss: 3.148798
Y Loss: 1.584982
T Loss: 13.188712
Epoch 249 
Overall Loss: 19.708757
Rec Loss: 16.147778
KL Loss: 3.560979
Y Loss: 1.448828
T Loss: 13.176430
Epoch 299 
Overall Loss: 19.559599
Rec Loss: 15.742313
KL Loss: 3.817287
Y Loss: 1.334711
T Loss: 13.152741
Epoch 349 
Overall Loss: 19.466127
Rec Loss: 15.437205
KL Loss: 4.028922
Y Loss: 1.258581
T Loss: 13.130493
Epoch 399 
Overall Loss: 19.348777
Rec Loss: 15.122262
KL Loss: 4.226515
Y Loss: 1.187838
T Loss: 13.118971
Epoch 449 
Overall Loss: 19.313260
Rec Loss: 14.906299
KL Loss: 4.406961
Y Loss: 1.142680
T Loss: 13.104666
Epoch 499 
Overall Loss: 19.299213
Rec Loss: 14.789788
KL Loss: 4.509425
Y Loss: 1.133356
T Loss: 13.091705
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.830739
Epoch 99
Rec Loss: 1.822111
Epoch 149
Rec Loss: 1.820160
Epoch 199
Rec Loss: 1.821145
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 6.122913
Epoch 99
Rec Loss: 6.116654
Epoch 149
Rec Loss: 6.108550
Epoch 199
Rec Loss: 6.122791
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.623301
Insample Error 1.882377
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.570223
Rec Loss: 15.843750
KL Loss: 0.726474
Y Loss: 5.102548
T Loss: 13.292476
Epoch 99 
Overall Loss: 14.800175
Rec Loss: 14.189447
KL Loss: 0.610728
Y Loss: 1.927771
T Loss: 13.225562
Epoch 149 
Overall Loss: 14.420906
Rec Loss: 13.955855
KL Loss: 0.465050
Y Loss: 1.555920
T Loss: 13.177896
Epoch 199 
Overall Loss: 14.279822
Rec Loss: 13.859484
KL Loss: 0.420338
Y Loss: 1.429052
T Loss: 13.144958
Epoch 249 
Overall Loss: 14.218593
Rec Loss: 13.811842
KL Loss: 0.406751
Y Loss: 1.385471
T Loss: 13.119107
Epoch 299 
Overall Loss: 14.193162
Rec Loss: 13.794173
KL Loss: 0.398989
Y Loss: 1.364651
T Loss: 13.111847
Epoch 349 
Overall Loss: 14.148173
Rec Loss: 13.743244
KL Loss: 0.404929
Y Loss: 1.281548
T Loss: 13.102470
Epoch 399 
Overall Loss: 14.106329
Rec Loss: 13.699855
KL Loss: 0.406474
Y Loss: 1.213615
T Loss: 13.093047
Epoch 449 
Overall Loss: 14.041893
Rec Loss: 13.612138
KL Loss: 0.429755
Y Loss: 1.072572
T Loss: 13.075852
Epoch 499 
Overall Loss: 14.008148
Rec Loss: 13.558142
KL Loss: 0.450006
Y Loss: 0.993062
T Loss: 13.061611
Epoch 549 
Overall Loss: 13.991358
Rec Loss: 13.532490
KL Loss: 0.458868
Y Loss: 0.950794
T Loss: 13.057092
Epoch 599 
Overall Loss: 13.979892
Rec Loss: 13.517886
KL Loss: 0.462006
Y Loss: 0.943379
T Loss: 13.046197
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.705542
Epoch 99
Rec Loss: 1.705804
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.073369
Epoch 99
Rec Loss: 10.066999
Epoch 149
Rec Loss: 10.069710
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.677204
Insample Error: 1.852578
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 23.839453
Rec Loss: 22.230242
KL Loss: 1.609210
Y Loss: 7.129955
T Loss: 13.309659
Epoch 99 
Overall Loss: 21.369636
Rec Loss: 19.244367
KL Loss: 2.125269
Y Loss: 2.758046
T Loss: 13.271293
Epoch 149 
Overall Loss: 20.323199
Rec Loss: 17.426075
KL Loss: 2.897123
Y Loss: 1.942668
T Loss: 13.217156
Epoch 199 
Overall Loss: 19.917144
Rec Loss: 16.517086
KL Loss: 3.400058
Y Loss: 1.627936
T Loss: 13.195062
Epoch 249 
Overall Loss: 19.746948
Rec Loss: 16.218876
KL Loss: 3.528072
Y Loss: 1.463619
T Loss: 13.169235
Epoch 299 
Overall Loss: 19.663882
Rec Loss: 16.048851
KL Loss: 3.615030
Y Loss: 1.383218
T Loss: 13.154432
Epoch 349 
Overall Loss: 19.586050
Rec Loss: 15.900960
KL Loss: 3.685090
Y Loss: 1.335031
T Loss: 13.141675
Epoch 399 
Overall Loss: 19.450700
Rec Loss: 15.544542
KL Loss: 3.906157
Y Loss: 1.206967
T Loss: 13.112869
Epoch 449 
Overall Loss: 19.412083
Rec Loss: 15.291700
KL Loss: 4.120383
Y Loss: 1.144184
T Loss: 13.097088
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.840906
Epoch 99
Rec Loss: 1.842476
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.925004
Epoch 99
Rec Loss: 5.905663
Epoch 149
Rec Loss: 5.904615
Epoch 199
Rec Loss: 5.891230
Epoch 249
Rec Loss: 5.903909
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.662067
Insample Error 1.935796
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.068622
Rec Loss: 15.271292
KL Loss: 0.797329
Y Loss: 4.087339
T Loss: 13.227623
Epoch 99 
Overall Loss: 14.668124
Rec Loss: 14.003202
KL Loss: 0.664922
Y Loss: 1.593693
T Loss: 13.206356
Epoch 149 
Overall Loss: 14.361561
Rec Loss: 13.782919
KL Loss: 0.578642
Y Loss: 1.260272
T Loss: 13.152783
Epoch 199 
Overall Loss: 14.144491
Rec Loss: 13.638266
KL Loss: 0.506225
Y Loss: 1.099636
T Loss: 13.088449
Epoch 249 
Overall Loss: 14.085628
Rec Loss: 13.587919
KL Loss: 0.497709
Y Loss: 1.041755
T Loss: 13.067042
Epoch 299 
Overall Loss: 14.066787
Rec Loss: 13.573545
KL Loss: 0.493243
Y Loss: 1.018899
T Loss: 13.064095
Epoch 349 
Overall Loss: 14.047314
Rec Loss: 13.559860
KL Loss: 0.487454
Y Loss: 1.002943
T Loss: 13.058389
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.758923
Epoch 99
Rec Loss: 1.749812
Epoch 149
Rec Loss: 1.754965
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.074061
Epoch 99
Rec Loss: 10.070250
Epoch 149
Rec Loss: 10.069274
Epoch 199
Rec Loss: 10.071388
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.706222
Insample Error: 2.022499
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 24.239369
Rec Loss: 22.813902
KL Loss: 1.425467
Y Loss: 8.002576
T Loss: 13.367749
Epoch 99 
Overall Loss: 21.375525
Rec Loss: 19.431181
KL Loss: 1.944344
Y Loss: 2.662772
T Loss: 13.295635
Epoch 149 
Overall Loss: 20.200589
Rec Loss: 17.094207
KL Loss: 3.106382
Y Loss: 1.799927
T Loss: 13.241953
Epoch 199 
Overall Loss: 19.873479
Rec Loss: 16.385556
KL Loss: 3.487922
Y Loss: 1.568503
T Loss: 13.206834
Epoch 249 
Overall Loss: 19.721866
Rec Loss: 15.956188
KL Loss: 3.765679
Y Loss: 1.459778
T Loss: 13.179900
Epoch 299 
Overall Loss: 19.615502
Rec Loss: 15.572873
KL Loss: 4.042630
Y Loss: 1.344845
T Loss: 13.163197
Epoch 349 
Overall Loss: 19.509103
Rec Loss: 15.226486
KL Loss: 4.282617
Y Loss: 1.317698
T Loss: 13.143650
Epoch 399 
Overall Loss: 19.473445
Rec Loss: 14.988075
KL Loss: 4.485369
Y Loss: 1.251578
T Loss: 13.128846
Epoch 449 
Overall Loss: 19.413817
Rec Loss: 14.780894
KL Loss: 4.632924
Y Loss: 1.203612
T Loss: 13.114062
Epoch 499 
Overall Loss: 19.383698
Rec Loss: 14.628239
KL Loss: 4.755459
Y Loss: 1.192200
T Loss: 13.100743
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.841729
Epoch 99
Rec Loss: 1.847037
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 5.789518
Epoch 99
Rec Loss: 5.779839
Epoch 149
Rec Loss: 5.783030
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.672177
Insample Error 1.960999
Ours, Train RMSE
0.6765, 
0.6853, 
0.6751, 
0.6911, 
0.6866, 
0.6851, 
0.6992, 
0.8554, 
0.6772, 
0.7062, 
Ours, Insample RMSE
1.8980, 
2.0215, 
2.0381, 
2.0219, 
2.0406, 
2.0185, 
2.0129, 
2.0520, 
1.8526, 
2.0225, 
CEVAE, Insample RMSE
1.9522, 
1.9044, 
1.9396, 
1.9632, 
1.9322, 
1.9319, 
1.9155, 
1.8824, 
1.9358, 
1.9610, 
Train, RMSE mean 0.7038 std 0.0514
Ours, RMSE mean 1.9979 std 0.0631, reconstruct confounder 1.7320 (0.0378) noise 10.0625 (0.0078)
CEVAE, RMSE mean 1.9318 std 0.0241, reconstruct confounder 1.8385 (0.0200) noise 5.9483 (0.0930)
Experiment Start!
Namespace(decay=0.0, l=5e-05, latdim=4, mask=10, nlayer=50, obsm=2, ycof=0.5, ylayer=50)
Y Mean 1.192369, Std 4.040208 
Observe confounder 2, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.667990
Rec Loss: 14.858137
KL Loss: 0.809853
Y Loss: 3.262372
T Loss: 13.226952
Epoch 99 
Overall Loss: 14.680265
Rec Loss: 14.087608
KL Loss: 0.592657
Y Loss: 1.752637
T Loss: 13.211289
Epoch 149 
Overall Loss: 14.376916
Rec Loss: 13.901593
KL Loss: 0.475323
Y Loss: 1.481078
T Loss: 13.161054
Epoch 199 
Overall Loss: 14.250508
Rec Loss: 13.804557
KL Loss: 0.445951
Y Loss: 1.357327
T Loss: 13.125893
Epoch 249 
Overall Loss: 14.180080
Rec Loss: 13.738328
KL Loss: 0.441752
Y Loss: 1.287191
T Loss: 13.094732
Epoch 299 
Overall Loss: 14.115942
Rec Loss: 13.658504
KL Loss: 0.457438
Y Loss: 1.162631
T Loss: 13.077189
Epoch 349 
Overall Loss: 14.060770
Rec Loss: 13.589434
KL Loss: 0.471336
Y Loss: 1.058723
T Loss: 13.060073
Epoch 399 
Overall Loss: 14.031597
Rec Loss: 13.547445
KL Loss: 0.484152
Y Loss: 0.991254
T Loss: 13.051818
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.724835
Epoch 99
Rec Loss: 1.723636
Epoch 149
Rec Loss: 1.719570
Epoch 199
Rec Loss: 1.723076
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000131
Epoch 99
Rec Loss: 0.000037
Epoch 149
Rec Loss: 0.000017
Epoch 199
Rec Loss: 0.000010
Epoch 249
Rec Loss: 0.000006
Epoch 299
Rec Loss: 0.000004
Epoch 349
Rec Loss: 0.000003
Epoch 399
Rec Loss: 0.000009
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.702599
Insample Error: 2.012372
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: -10.723885
Rec Loss: -18.892657
KL Loss: 8.168772
Y Loss: 9.734299
T Loss: 13.366356
X Loss: -37.126163
Epoch 99 
Overall Loss: -36.154857
Rec Loss: -47.994199
KL Loss: 11.839344
Y Loss: 8.525787
T Loss: 13.259434
X Loss: -65.516528
Epoch 149 
Overall Loss: -43.832277
Rec Loss: -56.585121
KL Loss: 12.752844
Y Loss: 5.519219
T Loss: 13.121816
X Loss: -72.466548
Epoch 199 
Overall Loss: -48.879930
Rec Loss: -62.147868
KL Loss: 13.267938
Y Loss: 5.129198
T Loss: 13.029164
X Loss: -77.741628
Epoch 249 
Overall Loss: -50.200388
Rec Loss: -63.011609
KL Loss: 12.811222
Y Loss: 5.107743
T Loss: 13.006900
X Loss: -78.572381
Epoch 299 
Overall Loss: -53.163607
Rec Loss: -66.284691
KL Loss: 13.121084
Y Loss: 5.329188
T Loss: 12.985980
X Loss: -81.935266
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.782775
Epoch 99
Rec Loss: 2.775644
Epoch 149
Rec Loss: 2.754816
Epoch 199
Rec Loss: 2.710349
Epoch 249
Rec Loss: 2.704845
Epoch 299
Rec Loss: 2.696266
Epoch 349
Rec Loss: 2.671305
Epoch 399
Rec Loss: 2.664025
Epoch 449
Rec Loss: 2.682542
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000005
Epoch 99
Rec Loss: 0.000002
Epoch 149
Rec Loss: 0.000002
Epoch 199
Rec Loss: 0.000004
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 2.290440
Insample Error 4.359286
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.984822
Rec Loss: 15.261650
KL Loss: 0.723171
Y Loss: 4.116950
T Loss: 13.203176
Epoch 99 
Overall Loss: 14.744535
Rec Loss: 14.200516
KL Loss: 0.544019
Y Loss: 1.997045
T Loss: 13.201994
Epoch 149 
Overall Loss: 14.415625
Rec Loss: 13.976261
KL Loss: 0.439363
Y Loss: 1.622703
T Loss: 13.164909
Epoch 199 
Overall Loss: 14.292278
Rec Loss: 13.871196
KL Loss: 0.421081
Y Loss: 1.487561
T Loss: 13.127416
Epoch 249 
Overall Loss: 14.215996
Rec Loss: 13.800833
KL Loss: 0.415163
Y Loss: 1.397943
T Loss: 13.101861
Epoch 299 
Overall Loss: 14.162857
Rec Loss: 13.730871
KL Loss: 0.431986
Y Loss: 1.289804
T Loss: 13.085969
Epoch 349 
Overall Loss: 14.094390
Rec Loss: 13.635634
KL Loss: 0.458756
Y Loss: 1.117664
T Loss: 13.076802
Epoch 399 
Overall Loss: 14.047958
Rec Loss: 13.567423
KL Loss: 0.480535
Y Loss: 1.013401
T Loss: 13.060722
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.715051
Epoch 99
Rec Loss: 1.715879
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000056
Epoch 99
Rec Loss: 0.000018
Epoch 149
Rec Loss: 0.000010
Epoch 199
Rec Loss: 0.000006
Epoch 249
Rec Loss: 0.000005
Epoch 299
Rec Loss: 0.000006
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.681809
Insample Error: 2.029863
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: -11.962464
Rec Loss: -21.554781
KL Loss: 9.592317
Y Loss: 10.541774
T Loss: 13.389704
X Loss: -40.215372
Epoch 99 
Overall Loss: -37.123240
Rec Loss: -49.433943
KL Loss: 12.310703
Y Loss: 6.825950
T Loss: 13.096743
X Loss: -65.943660
Epoch 149 
Overall Loss: -46.077831
Rec Loss: -59.380365
KL Loss: 13.302535
Y Loss: 4.433956
T Loss: 12.949786
X Loss: -74.547128
Epoch 199 
Overall Loss: -48.239347
Rec Loss: -61.450503
KL Loss: 13.211157
Y Loss: 4.375325
T Loss: 12.897612
X Loss: -76.535779
Epoch 249 
Overall Loss: -46.502405
Rec Loss: -59.654145
KL Loss: 13.151741
Y Loss: 4.334150
T Loss: 12.886387
X Loss: -74.707609
Epoch 299 
Overall Loss: -50.655212
Rec Loss: -63.756902
KL Loss: 13.101689
Y Loss: 4.216976
T Loss: 12.887847
X Loss: -78.753237
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.256626
Epoch 99
Rec Loss: 2.244293
Epoch 149
Rec Loss: 2.250733
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000008
Epoch 99
Rec Loss: 0.000003
Epoch 149
Rec Loss: 0.000002
Epoch 199
Rec Loss: 0.000001
Epoch 249
Rec Loss: 0.000004
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 1.956190
Insample Error 3.654542
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.050925
Rec Loss: 15.236275
KL Loss: 0.814650
Y Loss: 4.021491
T Loss: 13.225530
Epoch 99 
Overall Loss: 14.735048
Rec Loss: 14.129787
KL Loss: 0.605261
Y Loss: 1.860941
T Loss: 13.199316
Epoch 149 
Overall Loss: 14.381783
Rec Loss: 13.895518
KL Loss: 0.486265
Y Loss: 1.488748
T Loss: 13.151144
Epoch 199 
Overall Loss: 14.239885
Rec Loss: 13.799632
KL Loss: 0.440254
Y Loss: 1.385089
T Loss: 13.107087
Epoch 249 
Overall Loss: 14.180599
Rec Loss: 13.734478
KL Loss: 0.446121
Y Loss: 1.287956
T Loss: 13.090501
Epoch 299 
Overall Loss: 14.102616
Rec Loss: 13.639169
KL Loss: 0.463446
Y Loss: 1.121450
T Loss: 13.078445
Epoch 349 
Overall Loss: 14.071330
Rec Loss: 13.585223
KL Loss: 0.486108
Y Loss: 1.028687
T Loss: 13.070879
Epoch 399 
Overall Loss: 14.028668
Rec Loss: 13.543405
KL Loss: 0.485264
Y Loss: 0.972741
T Loss: 13.057034
Epoch 449 
Overall Loss: 14.017348
Rec Loss: 13.531519
KL Loss: 0.485829
Y Loss: 0.954204
T Loss: 13.054417
Epoch 499 
Overall Loss: 14.003218
Rec Loss: 13.517779
KL Loss: 0.485440
Y Loss: 0.936181
T Loss: 13.049689
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.663566
Epoch 99
Rec Loss: 1.657331
Epoch 149
Rec Loss: 1.659324
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000113
Epoch 99
Rec Loss: 0.000034
Epoch 149
Rec Loss: 0.000016
Epoch 199
Rec Loss: 0.000009
Epoch 249
Rec Loss: 0.000005
Epoch 299
Rec Loss: 0.000003
Epoch 349
Rec Loss: 0.000004
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.670885
Insample Error: 1.936574
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: -6.540682
Rec Loss: -15.430869
KL Loss: 8.890187
Y Loss: 13.754695
T Loss: 13.671834
X Loss: -35.980050
Epoch 99 
Overall Loss: -32.519700
Rec Loss: -44.158448
KL Loss: 11.638748
Y Loss: 12.583462
T Loss: 13.613429
X Loss: -64.063607
Epoch 149 
Overall Loss: -39.058400
Rec Loss: -50.536189
KL Loss: 11.477789
Y Loss: 7.022957
T Loss: 13.467370
X Loss: -67.515041
Epoch 199 
Overall Loss: -46.646975
Rec Loss: -58.879719
KL Loss: 12.232746
Y Loss: 5.244976
T Loss: 13.287525
X Loss: -74.789732
Epoch 249 
Overall Loss: -49.891631
Rec Loss: -62.049801
KL Loss: 12.158170
Y Loss: 5.071468
T Loss: 13.176792
X Loss: -77.762328
Epoch 299 
Overall Loss: -51.364569
Rec Loss: -63.786468
KL Loss: 12.421898
Y Loss: 4.984606
T Loss: 13.143451
X Loss: -79.422222
Epoch 349 
Overall Loss: -51.530198
Rec Loss: -63.597110
KL Loss: 12.066911
Y Loss: 4.805642
T Loss: 13.181652
X Loss: -79.181584
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.803284
Epoch 99
Rec Loss: 2.816262
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000020
Epoch 99
Rec Loss: 0.000003
Epoch 149
Rec Loss: 0.000001
Epoch 199
Rec Loss: 0.000001
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 2.156237
Insample Error 4.354096
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.698660
Rec Loss: 14.959829
KL Loss: 0.738831
Y Loss: 3.433179
T Loss: 13.243239
Epoch 99 
Overall Loss: 14.573286
Rec Loss: 14.019170
KL Loss: 0.554116
Y Loss: 1.616850
T Loss: 13.210745
Epoch 149 
Overall Loss: 14.351158
Rec Loss: 13.902030
KL Loss: 0.449128
Y Loss: 1.463939
T Loss: 13.170061
Epoch 199 
Overall Loss: 14.235293
Rec Loss: 13.807640
KL Loss: 0.427654
Y Loss: 1.345485
T Loss: 13.134897
Epoch 249 
Overall Loss: 14.178435
Rec Loss: 13.749965
KL Loss: 0.428471
Y Loss: 1.275793
T Loss: 13.112068
Epoch 299 
Overall Loss: 14.116740
Rec Loss: 13.685897
KL Loss: 0.430843
Y Loss: 1.171986
T Loss: 13.099904
Epoch 349 
Overall Loss: 14.091436
Rec Loss: 13.647880
KL Loss: 0.443556
Y Loss: 1.125159
T Loss: 13.085301
Epoch 399 
Overall Loss: 14.049962
Rec Loss: 13.586157
KL Loss: 0.463805
Y Loss: 1.030571
T Loss: 13.070872
Epoch 449 
Overall Loss: 14.033217
Rec Loss: 13.565231
KL Loss: 0.467987
Y Loss: 0.993391
T Loss: 13.068535
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.742825
Epoch 99
Rec Loss: 1.743887
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000029
Epoch 99
Rec Loss: 0.000009
Epoch 149
Rec Loss: 0.000005
Epoch 199
Rec Loss: 0.000003
Epoch 249
Rec Loss: 0.000002
Epoch 299
Rec Loss: 0.000002
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.699300
Insample Error: 2.018751
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: -10.999800
Rec Loss: -19.505653
KL Loss: 8.505853
Y Loss: 7.959079
T Loss: 13.316216
X Loss: -36.801408
Epoch 99 
Overall Loss: -39.756167
Rec Loss: -50.072290
KL Loss: 10.316123
Y Loss: 5.411136
T Loss: 13.204447
X Loss: -65.982304
Epoch 149 
Overall Loss: -47.794669
Rec Loss: -59.753210
KL Loss: 11.958541
Y Loss: 4.000470
T Loss: 13.070154
X Loss: -74.823597
Epoch 199 
Overall Loss: -49.188988
Rec Loss: -61.306986
KL Loss: 12.117998
Y Loss: 3.905706
T Loss: 12.992262
X Loss: -76.252101
Epoch 249 
Overall Loss: -53.318281
Rec Loss: -65.725677
KL Loss: 12.407397
Y Loss: 3.925595
T Loss: 12.959244
X Loss: -80.647719
Epoch 299 
Overall Loss: -52.722723
Rec Loss: -64.595560
KL Loss: 11.872836
Y Loss: 3.738043
T Loss: 12.941912
X Loss: -79.406494
Epoch 349 
Overall Loss: -55.587932
Rec Loss: -67.882325
KL Loss: 12.294393
Y Loss: 3.737623
T Loss: 12.948420
X Loss: -82.699557
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.540198
Epoch 99
Rec Loss: 2.524137
Epoch 149
Rec Loss: 2.515428
Epoch 199
Rec Loss: 2.481496
Epoch 249
Rec Loss: 2.472202
Epoch 299
Rec Loss: 2.478971
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000005
Epoch 99
Rec Loss: 0.000001
Epoch 149
Rec Loss: 0.000001
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 1.871462
Insample Error 4.087905
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.089005
Rec Loss: 15.287798
KL Loss: 0.801207
Y Loss: 4.095313
T Loss: 13.240140
Epoch 99 
Overall Loss: 14.615529
Rec Loss: 14.030989
KL Loss: 0.584540
Y Loss: 1.664988
T Loss: 13.198495
Epoch 149 
Overall Loss: 14.313132
Rec Loss: 13.847538
KL Loss: 0.465593
Y Loss: 1.399774
T Loss: 13.147652
Epoch 199 
Overall Loss: 14.215470
Rec Loss: 13.763129
KL Loss: 0.452342
Y Loss: 1.306092
T Loss: 13.110083
Epoch 249 
Overall Loss: 14.139597
Rec Loss: 13.689812
KL Loss: 0.449785
Y Loss: 1.197244
T Loss: 13.091190
Epoch 299 
Overall Loss: 14.093167
Rec Loss: 13.627099
KL Loss: 0.466068
Y Loss: 1.098072
T Loss: 13.078063
Epoch 349 
Overall Loss: 14.062108
Rec Loss: 13.582535
KL Loss: 0.479573
Y Loss: 1.023603
T Loss: 13.070733
Epoch 399 
Overall Loss: 14.039932
Rec Loss: 13.557883
KL Loss: 0.482049
Y Loss: 0.999576
T Loss: 13.058095
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.744949
Epoch 99
Rec Loss: 1.742189
Epoch 149
Rec Loss: 1.744286
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000093
Epoch 99
Rec Loss: 0.000027
Epoch 149
Rec Loss: 0.000013
Epoch 199
Rec Loss: 0.000008
Epoch 249
Rec Loss: 0.000005
Epoch 299
Rec Loss: 0.000017
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.705391
Insample Error: 2.027159
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: -12.090468
Rec Loss: -22.280343
KL Loss: 10.189874
Y Loss: 14.187616
T Loss: 13.728996
X Loss: -43.103146
Epoch 99 
Overall Loss: -35.107095
Rec Loss: -46.522811
KL Loss: 11.415716
Y Loss: 10.731423
T Loss: 13.712602
X Loss: -65.601127
Epoch 149 
Overall Loss: -43.219731
Rec Loss: -55.415507
KL Loss: 12.195775
Y Loss: 5.782971
T Loss: 13.608789
X Loss: -71.915782
Epoch 199 
Overall Loss: -46.230046
Rec Loss: -58.314729
KL Loss: 12.084683
Y Loss: 4.882670
T Loss: 13.484867
X Loss: -74.240933
Epoch 249 
Overall Loss: -50.282732
Rec Loss: -62.305704
KL Loss: 12.022973
Y Loss: 4.779411
T Loss: 13.336546
X Loss: -78.031954
Epoch 299 
Overall Loss: -49.469902
Rec Loss: -59.737229
KL Loss: 10.267327
Y Loss: 4.707923
T Loss: 13.310802
X Loss: -75.401992
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 3.527818
Epoch 99
Rec Loss: 3.479473
Epoch 149
Rec Loss: 3.393348
Epoch 199
Rec Loss: 3.425203
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000003
Epoch 99
Rec Loss: 0.000001
Epoch 149
Rec Loss: 0.000002
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 2.136445
Insample Error 4.833705
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.044057
Rec Loss: 15.216970
KL Loss: 0.827087
Y Loss: 3.937734
T Loss: 13.248103
Epoch 99 
Overall Loss: 14.650065
Rec Loss: 13.993102
KL Loss: 0.656962
Y Loss: 1.550162
T Loss: 13.218021
Epoch 149 
Overall Loss: 14.332720
Rec Loss: 13.795402
KL Loss: 0.537317
Y Loss: 1.262655
T Loss: 13.164075
Epoch 199 
Overall Loss: 14.173478
Rec Loss: 13.684482
KL Loss: 0.488996
Y Loss: 1.141964
T Loss: 13.113501
Epoch 249 
Overall Loss: 14.097961
Rec Loss: 13.604569
KL Loss: 0.493392
Y Loss: 1.051902
T Loss: 13.078617
Epoch 299 
Overall Loss: 14.071701
Rec Loss: 13.575327
KL Loss: 0.496374
Y Loss: 1.013444
T Loss: 13.068604
Epoch 349 
Overall Loss: 14.045552
Rec Loss: 13.552619
KL Loss: 0.492932
Y Loss: 0.982548
T Loss: 13.061345
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.763000
Epoch 99
Rec Loss: 1.758319
Epoch 149
Rec Loss: 1.758253
Epoch 199
Rec Loss: 1.756481
Epoch 249
Rec Loss: 1.766063
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000091
Epoch 99
Rec Loss: 0.000031
Epoch 149
Rec Loss: 0.000015
Epoch 199
Rec Loss: 0.000008
Epoch 249
Rec Loss: 0.000005
Epoch 299
Rec Loss: 0.000004
Epoch 349
Rec Loss: 0.000007
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.695577
Insample Error: 2.014146
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: -8.790373
Rec Loss: -18.547716
KL Loss: 9.757343
Y Loss: 13.345871
T Loss: 13.597343
X Loss: -38.817995
Epoch 99 
Overall Loss: -35.911725
Rec Loss: -48.175112
KL Loss: 12.263385
Y Loss: 9.289254
T Loss: 13.556353
X Loss: -66.376092
Epoch 149 
Overall Loss: -43.002062
Rec Loss: -53.310438
KL Loss: 10.308377
Y Loss: 5.022834
T Loss: 13.343680
X Loss: -69.165538
Epoch 199 
Overall Loss: -47.612670
Rec Loss: -59.625414
KL Loss: 12.012745
Y Loss: 4.379615
T Loss: 13.175924
X Loss: -74.991148
Epoch 249 
Overall Loss: -42.140764
Rec Loss: -52.860862
KL Loss: 10.720099
Y Loss: 3.997075
T Loss: 13.144282
X Loss: -68.003682
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.732855
Epoch 99
Rec Loss: 2.739293
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000009
Epoch 99
Rec Loss: 0.000005
Epoch 149
Rec Loss: 0.000014
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 1.915741
Insample Error 4.640978
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.498545
Rec Loss: 15.835135
KL Loss: 0.663411
Y Loss: 5.186995
T Loss: 13.241637
Epoch 99 
Overall Loss: 14.736938
Rec Loss: 14.131247
KL Loss: 0.605691
Y Loss: 1.810334
T Loss: 13.226080
Epoch 149 
Overall Loss: 14.370735
Rec Loss: 13.860730
KL Loss: 0.510005
Y Loss: 1.373919
T Loss: 13.173771
Epoch 199 
Overall Loss: 14.208963
Rec Loss: 13.729941
KL Loss: 0.479022
Y Loss: 1.202683
T Loss: 13.128600
Epoch 249 
Overall Loss: 14.134429
Rec Loss: 13.653491
KL Loss: 0.480939
Y Loss: 1.123164
T Loss: 13.091909
Epoch 299 
Overall Loss: 14.087307
Rec Loss: 13.594052
KL Loss: 0.493256
Y Loss: 1.031761
T Loss: 13.078171
Epoch 349 
Overall Loss: 14.067871
Rec Loss: 13.573843
KL Loss: 0.494029
Y Loss: 1.018608
T Loss: 13.064539
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.755553
Epoch 99
Rec Loss: 1.754244
Epoch 149
Rec Loss: 1.748172
Epoch 199
Rec Loss: 1.757841
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000090
Epoch 99
Rec Loss: 0.000027
Epoch 149
Rec Loss: 0.000014
Epoch 199
Rec Loss: 0.000008
Epoch 249
Rec Loss: 0.000005
Epoch 299
Rec Loss: 0.000004
Epoch 349
Rec Loss: 0.000004
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.686764
Insample Error: 1.993232
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: -9.953134
Rec Loss: -18.482633
KL Loss: 8.529500
Y Loss: 11.122770
T Loss: 13.388467
X Loss: -37.432485
Epoch 99 
Overall Loss: -36.299979
Rec Loss: -48.656878
KL Loss: 12.356899
Y Loss: 10.191292
T Loss: 13.265961
X Loss: -67.018487
Epoch 149 
Overall Loss: -42.109819
Rec Loss: -53.594498
KL Loss: 11.484681
Y Loss: 5.931434
T Loss: 13.192748
X Loss: -69.752964
Epoch 199 
Overall Loss: -49.594183
Rec Loss: -62.068543
KL Loss: 12.474360
Y Loss: 5.227744
T Loss: 13.095222
X Loss: -77.777639
Epoch 249 
Overall Loss: -52.980547
Rec Loss: -65.487151
KL Loss: 12.506603
Y Loss: 5.232224
T Loss: 13.024603
X Loss: -81.127865
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.734388
Epoch 99
Rec Loss: 2.711623
Epoch 149
Rec Loss: 2.702391
Epoch 199
Rec Loss: 2.672850
Epoch 249
Rec Loss: 2.654024
Epoch 299
Rec Loss: 2.650440
Epoch 349
Rec Loss: 2.663075
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000006
Epoch 99
Rec Loss: 0.000002
Epoch 149
Rec Loss: 0.000002
Epoch 199
Rec Loss: 0.000002
Epoch 249
Rec Loss: 0.000001
Epoch 299
Rec Loss: 0.000001
Epoch 349
Rec Loss: 0.000004
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 2.259512
Insample Error 4.434273
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.910386
Rec Loss: 15.004123
KL Loss: 0.906262
Y Loss: 3.573354
T Loss: 13.217446
Epoch 99 
Overall Loss: 14.714540
Rec Loss: 14.102904
KL Loss: 0.611636
Y Loss: 1.788167
T Loss: 13.208820
Epoch 149 
Overall Loss: 14.353482
Rec Loss: 13.890853
KL Loss: 0.462630
Y Loss: 1.489328
T Loss: 13.146189
Epoch 199 
Overall Loss: 14.256294
Rec Loss: 13.813505
KL Loss: 0.442789
Y Loss: 1.393323
T Loss: 13.116844
Epoch 249 
Overall Loss: 14.200079
Rec Loss: 13.774324
KL Loss: 0.425755
Y Loss: 1.341953
T Loss: 13.103348
Epoch 299 
Overall Loss: 14.174337
Rec Loss: 13.762864
KL Loss: 0.411473
Y Loss: 1.330125
T Loss: 13.097801
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.777586
Epoch 99
Rec Loss: 1.770016
Epoch 149
Rec Loss: 1.773339
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000084
Epoch 99
Rec Loss: 0.000031
Epoch 149
Rec Loss: 0.000016
Epoch 199
Rec Loss: 0.000010
Epoch 249
Rec Loss: 0.000006
Epoch 299
Rec Loss: 0.000004
Epoch 349
Rec Loss: 0.000003
Epoch 399
Rec Loss: 0.000002
Epoch 449
Rec Loss: 0.000004
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.847397
Insample Error: 2.066187
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: -11.069570
Rec Loss: -19.296702
KL Loss: 8.227132
Y Loss: 12.959480
T Loss: 13.587070
X Loss: -39.363512
Epoch 99 
Overall Loss: -37.945638
Rec Loss: -50.114940
KL Loss: 12.169302
Y Loss: 9.060847
T Loss: 13.357409
X Loss: -68.002773
Epoch 149 
Overall Loss: -45.177932
Rec Loss: -57.788602
KL Loss: 12.610669
Y Loss: 5.246455
T Loss: 13.187736
X Loss: -73.599567
Epoch 199 
Overall Loss: -49.173947
Rec Loss: -61.756099
KL Loss: 12.582151
Y Loss: 4.667784
T Loss: 13.125516
X Loss: -77.215506
Epoch 249 
Overall Loss: -51.048911
Rec Loss: -63.988722
KL Loss: 12.939813
Y Loss: 4.324612
T Loss: 13.098220
X Loss: -79.249249
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.571630
Epoch 99
Rec Loss: 2.537155
Epoch 149
Rec Loss: 2.543667
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000008
Epoch 99
Rec Loss: 0.000003
Epoch 149
Rec Loss: 0.000004
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 1.989832
Insample Error 4.151085
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.168427
Rec Loss: 15.497737
KL Loss: 0.670691
Y Loss: 4.469625
T Loss: 13.262924
Epoch 99 
Overall Loss: 14.708141
Rec Loss: 14.156032
KL Loss: 0.552110
Y Loss: 1.885095
T Loss: 13.213484
Epoch 149 
Overall Loss: 14.361747
Rec Loss: 13.916980
KL Loss: 0.444767
Y Loss: 1.499486
T Loss: 13.167237
Epoch 199 
Overall Loss: 14.259262
Rec Loss: 13.837937
KL Loss: 0.421325
Y Loss: 1.402126
T Loss: 13.136874
Epoch 249 
Overall Loss: 14.204576
Rec Loss: 13.797537
KL Loss: 0.407039
Y Loss: 1.367760
T Loss: 13.113657
Epoch 299 
Overall Loss: 14.179151
Rec Loss: 13.780058
KL Loss: 0.399093
Y Loss: 1.343734
T Loss: 13.108191
Epoch 349 
Overall Loss: 14.133019
Rec Loss: 13.726209
KL Loss: 0.406810
Y Loss: 1.256256
T Loss: 13.098081
Epoch 399 
Overall Loss: 14.086630
Rec Loss: 13.672278
KL Loss: 0.414352
Y Loss: 1.170738
T Loss: 13.086909
Epoch 449 
Overall Loss: 14.030722
Rec Loss: 13.592223
KL Loss: 0.438499
Y Loss: 1.044211
T Loss: 13.070118
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.737465
Epoch 99
Rec Loss: 1.736154
Epoch 149
Rec Loss: 1.734786
Epoch 199
Rec Loss: 1.723835
Epoch 249
Rec Loss: 1.731095
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000080
Epoch 99
Rec Loss: 0.000026
Epoch 149
Rec Loss: 0.000014
Epoch 199
Rec Loss: 0.000008
Epoch 249
Rec Loss: 0.000005
Epoch 299
Rec Loss: 0.000004
Epoch 349
Rec Loss: 0.000003
Epoch 399
Rec Loss: 0.000003
Epoch 449
Rec Loss: 0.000010
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.750868
Insample Error: 1.997168
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: -9.790393
Rec Loss: -17.260435
KL Loss: 7.470042
Y Loss: 11.870075
T Loss: 13.616317
X Loss: -36.811790
Epoch 99 
Overall Loss: -36.446033
Rec Loss: -47.863658
KL Loss: 11.417625
Y Loss: 12.309084
T Loss: 13.592542
X Loss: -67.610741
Epoch 149 
Overall Loss: -43.957776
Rec Loss: -55.714554
KL Loss: 11.756779
Y Loss: 7.568680
T Loss: 13.412634
X Loss: -72.911527
Epoch 199 
Overall Loss: -47.453976
Rec Loss: -59.692900
KL Loss: 12.238924
Y Loss: 5.865813
T Loss: 13.211547
X Loss: -75.837352
Epoch 249 
Overall Loss: -47.644773
Rec Loss: -59.817410
KL Loss: 12.172638
Y Loss: 5.618122
T Loss: 13.086526
X Loss: -75.712996
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 3.059617
Epoch 99
Rec Loss: 3.006165
Epoch 149
Rec Loss: 3.017934
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000004
Epoch 99
Rec Loss: 0.000012
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 2.336937
Insample Error 4.476604
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 15.887712
Rec Loss: 15.155057
KL Loss: 0.732655
Y Loss: 3.871263
T Loss: 13.219425
Epoch 99 
Overall Loss: 14.602884
Rec Loss: 14.007380
KL Loss: 0.595504
Y Loss: 1.609375
T Loss: 13.202693
Epoch 149 
Overall Loss: 14.310152
Rec Loss: 13.773524
KL Loss: 0.536627
Y Loss: 1.252470
T Loss: 13.147290
Epoch 199 
Overall Loss: 14.131248
Rec Loss: 13.638593
KL Loss: 0.492655
Y Loss: 1.098435
T Loss: 13.089376
Epoch 249 
Overall Loss: 14.084308
Rec Loss: 13.594222
KL Loss: 0.490086
Y Loss: 1.046458
T Loss: 13.070993
Epoch 299 
Overall Loss: 14.068428
Rec Loss: 13.580986
KL Loss: 0.487442
Y Loss: 1.024117
T Loss: 13.068928
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.758293
Epoch 99
Rec Loss: 1.754625
Epoch 149
Rec Loss: 1.765607
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000130
Epoch 99
Rec Loss: 0.000044
Epoch 149
Rec Loss: 0.000021
Epoch 199
Rec Loss: 0.000012
Epoch 249
Rec Loss: 0.000008
Epoch 299
Rec Loss: 0.000005
Epoch 349
Rec Loss: 0.000004
Epoch 399
Rec Loss: 0.000004
Epoch 449
Rec Loss: 0.000009
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.727656
Insample Error: 2.025600
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: -6.943079
Rec Loss: -16.738592
KL Loss: 9.795514
Y Loss: 9.871059
T Loss: 13.349759
X Loss: -35.023881
Epoch 99 
Overall Loss: -36.881746
Rec Loss: -48.365191
KL Loss: 11.483445
Y Loss: 5.232891
T Loss: 13.200006
X Loss: -64.181641
Epoch 149 
Overall Loss: -46.696499
Rec Loss: -58.137839
KL Loss: 11.441339
Y Loss: 3.610427
T Loss: 13.136595
X Loss: -73.079647
Epoch 199 
Overall Loss: -48.268302
Rec Loss: -59.794143
KL Loss: 11.525840
Y Loss: 3.260981
T Loss: 13.105865
X Loss: -74.530500
Epoch 249 
Overall Loss: -52.928724
Rec Loss: -64.635633
KL Loss: 11.706910
Y Loss: 2.900651
T Loss: 13.082606
X Loss: -79.168567
Epoch 299 
Overall Loss: -22.579843
Rec Loss: -34.141055
KL Loss: 11.561211
Y Loss: 2.391460
T Loss: 13.134636
X Loss: -48.471420
Epoch 349 
Overall Loss: -55.257721
Rec Loss: -66.814634
KL Loss: 11.556916
Y Loss: 1.945050
T Loss: 13.089042
X Loss: -80.876205
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.221983
Epoch 99
Rec Loss: 2.205575
Epoch 149
Rec Loss: 2.198146
Epoch 199
Rec Loss: 2.225156
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.000005
Epoch 99
Rec Loss: 0.000002
Epoch 149
Rec Loss: 0.000002
Epoch 199
Rec Loss: 0.000001
Epoch 249
Rec Loss: 0.000001
Epoch 299
Rec Loss: 0.000001
Epoch 349
Rec Loss: 0.000001
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 1.095097
Insample Error 2.933313
Ours, Train RMSE
0.7026, 
0.6818, 
0.6709, 
0.6993, 
0.7054, 
0.6956, 
0.6868, 
0.8474, 
0.7509, 
0.7277, 
CEVAE, Train RMSE
2.2904, 
1.9562, 
2.1562, 
1.8715, 
2.1364, 
1.9157, 
2.2595, 
1.9898, 
2.3369, 
1.0951, 
Ours, Insample RMSE
2.0124, 
2.0299, 
1.9366, 
2.0188, 
2.0272, 
2.0141, 
1.9932, 
2.0662, 
1.9972, 
2.0256, 
CEVAE, Insample RMSE
4.3593, 
3.6545, 
4.3541, 
4.0879, 
4.8337, 
4.6410, 
4.4343, 
4.1511, 
4.4766, 
2.9333, 
Train, RMSE mean 0.7168 std 0.0486
CEVAE, RMSE mean 2.0008 std 0.3395
Ours, RMSE mean 2.0121 std 0.0316, reconstruct confounder 1.7330 (0.0302) noise 0.0000 (0.0000)
CEVAE, RMSE mean 4.1926 std 0.5189, reconstruct confounder 2.6702 (0.3345) noise 0.0000 (0.0000)
