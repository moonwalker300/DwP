Experiment Start!
Namespace(decay=0.0, l=5e-05, latdim=4, mask=0, nlayer=50, obsm=1, ycof=0.5, ylayer=50)
Y Mean -0.063601, Std 1.481582 
Observe confounder 1, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 13.991982
Rec Loss: 13.762839
KL Loss: 0.229143
Y Loss: 1.103529
T Loss: 13.211075
Epoch 99 
Overall Loss: 13.584737
Rec Loss: 13.384046
KL Loss: 0.200692
Y Loss: 1.060678
T Loss: 12.853707
Epoch 149 
Overall Loss: 13.217178
Rec Loss: 12.618159
KL Loss: 0.599019
Y Loss: 1.001615
T Loss: 12.117351
Epoch 199 
Overall Loss: 13.107708
Rec Loss: 12.457012
KL Loss: 0.650696
Y Loss: 0.947572
T Loss: 11.983226
Epoch 249 
Overall Loss: 13.033534
Rec Loss: 12.334996
KL Loss: 0.698539
Y Loss: 0.909329
T Loss: 11.880331
Epoch 299 
Overall Loss: 12.779823
Rec Loss: 11.763023
KL Loss: 1.016801
Y Loss: 0.835490
T Loss: 11.345278
Epoch 349 
Overall Loss: 12.536954
Rec Loss: 11.088497
KL Loss: 1.448458
Y Loss: 0.785571
T Loss: 10.695711
Epoch 399 
Overall Loss: 12.474772
Rec Loss: 10.912992
KL Loss: 1.561780
Y Loss: 0.759042
T Loss: 10.533471
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.837715
Epoch 99
Rec Loss: 1.830871
Epoch 149
Rec Loss: 1.832671
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.142574
Epoch 99
Rec Loss: 10.134375
Epoch 149
Rec Loss: 10.132757
Epoch 199
Rec Loss: 10.128112
Epoch 249
Rec Loss: 10.127701
Epoch 299
Rec Loss: 10.129235
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.822816
Insample Error: 1.382689
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 12.687089
Rec Loss: 9.250996
KL Loss: 3.436093
Y Loss: 1.311014
T Loss: 13.790479
X Loss: -5.194990
Epoch 99 
Overall Loss: -5.313329
Rec Loss: -13.904251
KL Loss: 8.590922
Y Loss: 1.187946
T Loss: 13.774621
X Loss: -28.272845
Epoch 149 
Overall Loss: -9.299189
Rec Loss: -18.659492
KL Loss: 9.360302
Y Loss: 1.158001
T Loss: 13.728110
X Loss: -32.966601
Epoch 199 
Overall Loss: -11.456567
Rec Loss: -21.520921
KL Loss: 10.064354
Y Loss: 1.137247
T Loss: 13.704872
X Loss: -35.794417
Epoch 249 
Overall Loss: -12.866170
Rec Loss: -23.474681
KL Loss: 10.608510
Y Loss: 1.103174
T Loss: 13.640859
X Loss: -37.667127
Epoch 299 
Overall Loss: -13.672001
Rec Loss: -24.540597
KL Loss: 10.868595
Y Loss: 1.053534
T Loss: 13.575824
X Loss: -38.643187
Epoch 349 
Overall Loss: -14.744818
Rec Loss: -26.045344
KL Loss: 11.300526
Y Loss: 0.993347
T Loss: 13.482453
X Loss: -40.024470
Epoch 399 
Overall Loss: -15.757669
Rec Loss: -27.417058
KL Loss: 11.659390
Y Loss: 0.937463
T Loss: 13.365195
X Loss: -41.250984
Epoch 449 
Overall Loss: -16.287156
Rec Loss: -28.169121
KL Loss: 11.881965
Y Loss: 0.892546
T Loss: 13.270385
X Loss: -41.885780
Epoch 499 
Overall Loss: -17.190260
Rec Loss: -29.317935
KL Loss: 12.127675
Y Loss: 0.839865
T Loss: 13.128267
X Loss: -42.866135
Epoch 549 
Overall Loss: -17.620129
Rec Loss: -29.933339
KL Loss: 12.313210
Y Loss: 0.788253
T Loss: 12.995929
X Loss: -43.323394
Epoch 599 
Overall Loss: -18.360805
Rec Loss: -30.848784
KL Loss: 12.487979
Y Loss: 0.757492
T Loss: 12.892268
X Loss: -44.119798
Epoch 649 
Overall Loss: -18.702654
Rec Loss: -31.335019
KL Loss: 12.632364
Y Loss: 0.723790
T Loss: 12.782204
X Loss: -44.479118
Epoch 699 
Overall Loss: -19.074818
Rec Loss: -31.958041
KL Loss: 12.883224
Y Loss: 0.682824
T Loss: 12.689906
X Loss: -44.989359
Epoch 749 
Overall Loss: -19.448181
Rec Loss: -32.347555
KL Loss: 12.899375
Y Loss: 0.680387
T Loss: 12.636334
X Loss: -45.324084
Epoch 799 
Overall Loss: -19.784061
Rec Loss: -32.926588
KL Loss: 13.142527
Y Loss: 0.661706
T Loss: 12.536453
X Loss: -45.793894
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 3.327257
Epoch 99
Rec Loss: 3.327968
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.032578
Epoch 99
Rec Loss: 0.005676
Epoch 149
Rec Loss: 0.007483
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.760980
Insample Error 1.445765
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.235883
Rec Loss: 14.075313
KL Loss: 0.160570
Y Loss: 1.185037
T Loss: 13.482794
Epoch 99 
Overall Loss: 13.338557
Rec Loss: 12.796323
KL Loss: 0.542234
Y Loss: 1.022277
T Loss: 12.285184
Epoch 149 
Overall Loss: 13.167208
Rec Loss: 12.434884
KL Loss: 0.732324
Y Loss: 0.960002
T Loss: 11.954884
Epoch 199 
Overall Loss: 12.939241
Rec Loss: 11.921933
KL Loss: 1.017308
Y Loss: 0.897151
T Loss: 11.473357
Epoch 249 
Overall Loss: 12.798101
Rec Loss: 11.619916
KL Loss: 1.178185
Y Loss: 0.855437
T Loss: 11.192197
Epoch 299 
Overall Loss: 12.580423
Rec Loss: 11.106223
KL Loss: 1.474200
Y Loss: 0.802767
T Loss: 10.704839
Epoch 349 
Overall Loss: 12.469783
Rec Loss: 10.825995
KL Loss: 1.643788
Y Loss: 0.759217
T Loss: 10.446386
Epoch 399 
Overall Loss: 12.423881
Rec Loss: 10.784699
KL Loss: 1.639182
Y Loss: 0.734516
T Loss: 10.417440
Epoch 449 
Overall Loss: 12.379816
Rec Loss: 10.731152
KL Loss: 1.648664
Y Loss: 0.695780
T Loss: 10.383262
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.765383
Epoch 99
Rec Loss: 1.738654
Epoch 149
Rec Loss: 1.750722
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.148559
Epoch 99
Rec Loss: 10.137649
Epoch 149
Rec Loss: 10.135019
Epoch 199
Rec Loss: 10.142552
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.796552
Insample Error: 1.278359
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 13.660487
Rec Loss: 10.821758
KL Loss: 2.838729
Y Loss: 1.245820
T Loss: 13.759866
X Loss: -3.561018
Epoch 99 
Overall Loss: -5.460305
Rec Loss: -14.277323
KL Loss: 8.817018
Y Loss: 0.905598
T Loss: 13.288626
X Loss: -28.018748
Epoch 149 
Overall Loss: -10.135528
Rec Loss: -19.891436
KL Loss: 9.755908
Y Loss: 0.813078
T Loss: 13.176165
X Loss: -33.474140
Epoch 199 
Overall Loss: -12.399335
Rec Loss: -22.947500
KL Loss: 10.548164
Y Loss: 0.734810
T Loss: 13.120702
X Loss: -36.435607
Epoch 249 
Overall Loss: -13.828501
Rec Loss: -25.010887
KL Loss: 11.182386
Y Loss: 0.683195
T Loss: 13.057101
X Loss: -38.409586
Epoch 299 
Overall Loss: -15.026303
Rec Loss: -26.593627
KL Loss: 11.567323
Y Loss: 0.669597
T Loss: 13.017617
X Loss: -39.946042
Epoch 349 
Overall Loss: -15.275004
Rec Loss: -27.163241
KL Loss: 11.888236
Y Loss: 0.630588
T Loss: 12.999973
X Loss: -40.478508
Epoch 399 
Overall Loss: -16.641380
Rec Loss: -28.736631
KL Loss: 12.095251
Y Loss: 0.640743
T Loss: 12.945828
X Loss: -42.002829
Epoch 449 
Overall Loss: -17.317878
Rec Loss: -29.598210
KL Loss: 12.280331
Y Loss: 0.625422
T Loss: 12.919134
X Loss: -42.830055
Epoch 499 
Overall Loss: -17.813199
Rec Loss: -30.159348
KL Loss: 12.346150
Y Loss: 0.633496
T Loss: 12.894753
X Loss: -43.370849
Epoch 549 
Overall Loss: -18.082630
Rec Loss: -30.534985
KL Loss: 12.452356
Y Loss: 0.612651
T Loss: 12.845814
X Loss: -43.687125
Epoch 599 
Overall Loss: -18.873018
Rec Loss: -31.464707
KL Loss: 12.591689
Y Loss: 0.596394
T Loss: 12.811634
X Loss: -44.574537
Epoch 649 
Overall Loss: -19.020776
Rec Loss: -31.706982
KL Loss: 12.686207
Y Loss: 0.593270
T Loss: 12.776381
X Loss: -44.779998
Epoch 699 
Overall Loss: -19.799459
Rec Loss: -32.543032
KL Loss: 12.743574
Y Loss: 0.577010
T Loss: 12.716448
X Loss: -45.547986
Epoch 749 
Overall Loss: -20.269692
Rec Loss: -33.086690
KL Loss: 12.816998
Y Loss: 0.583015
T Loss: 12.690872
X Loss: -46.069071
Epoch 799 
Overall Loss: -20.493793
Rec Loss: -33.385308
KL Loss: 12.891515
Y Loss: 0.577701
T Loss: 12.654121
X Loss: -46.328279
Epoch 849 
Overall Loss: -20.640089
Rec Loss: -33.641074
KL Loss: 13.000985
Y Loss: 0.572242
T Loss: 12.619436
X Loss: -46.546631
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 3.307293
Epoch 99
Rec Loss: 3.301862
Epoch 149
Rec Loss: 3.303238
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.017219
Epoch 99
Rec Loss: 0.007160
Epoch 149
Rec Loss: 0.015453
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.634528
Insample Error 1.227057
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 13.985523
Rec Loss: 13.827527
KL Loss: 0.157996
Y Loss: 1.146078
T Loss: 13.254488
Epoch 99 
Overall Loss: 13.580160
Rec Loss: 13.368711
KL Loss: 0.211449
Y Loss: 1.059302
T Loss: 12.839060
Epoch 149 
Overall Loss: 13.192817
Rec Loss: 12.581480
KL Loss: 0.611337
Y Loss: 1.008665
T Loss: 12.077148
Epoch 199 
Overall Loss: 12.901912
Rec Loss: 11.893687
KL Loss: 1.008225
Y Loss: 0.957585
T Loss: 11.414895
Epoch 249 
Overall Loss: 12.792605
Rec Loss: 11.704230
KL Loss: 1.088375
Y Loss: 0.910999
T Loss: 11.248731
Epoch 299 
Overall Loss: 12.684364
Rec Loss: 11.517376
KL Loss: 1.166988
Y Loss: 0.844922
T Loss: 11.094914
Epoch 349 
Overall Loss: 12.612055
Rec Loss: 11.363826
KL Loss: 1.248229
Y Loss: 0.798476
T Loss: 10.964588
Epoch 399 
Overall Loss: 12.451274
Rec Loss: 10.922173
KL Loss: 1.529100
Y Loss: 0.756768
T Loss: 10.543789
Epoch 449 
Overall Loss: 12.422150
Rec Loss: 10.801858
KL Loss: 1.620292
Y Loss: 0.728601
T Loss: 10.437557
Epoch 499 
Overall Loss: 12.399041
Rec Loss: 10.777099
KL Loss: 1.621942
Y Loss: 0.709055
T Loss: 10.422572
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.752196
Epoch 99
Rec Loss: 1.757850
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.149796
Epoch 99
Rec Loss: 10.140476
Epoch 149
Rec Loss: 10.147953
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.801522
Insample Error: 1.348947
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 10.315481
Rec Loss: 5.425077
KL Loss: 4.890403
Y Loss: 1.367650
T Loss: 13.836823
X Loss: -9.095571
Epoch 99 
Overall Loss: -3.655013
Rec Loss: -11.877836
KL Loss: 8.222823
Y Loss: 1.210567
T Loss: 13.807586
X Loss: -26.290706
Epoch 149 
Overall Loss: -7.975043
Rec Loss: -17.154214
KL Loss: 9.179171
Y Loss: 1.183880
T Loss: 13.781547
X Loss: -31.527700
Epoch 199 
Overall Loss: -10.902277
Rec Loss: -20.985033
KL Loss: 10.082756
Y Loss: 1.158666
T Loss: 13.751174
X Loss: -35.315540
Epoch 249 
Overall Loss: -12.651219
Rec Loss: -23.411156
KL Loss: 10.759938
Y Loss: 1.106316
T Loss: 13.720593
X Loss: -37.684907
Epoch 299 
Overall Loss: -13.822384
Rec Loss: -25.008861
KL Loss: 11.186476
Y Loss: 1.050243
T Loss: 13.663062
X Loss: -39.197044
Epoch 349 
Overall Loss: -14.875988
Rec Loss: -26.481573
KL Loss: 11.605585
Y Loss: 0.986991
T Loss: 13.586136
X Loss: -40.561206
Epoch 399 
Overall Loss: -15.683951
Rec Loss: -27.565370
KL Loss: 11.881419
Y Loss: 0.925793
T Loss: 13.483958
X Loss: -41.512225
Epoch 449 
Overall Loss: -16.548019
Rec Loss: -28.672927
KL Loss: 12.124908
Y Loss: 0.874746
T Loss: 13.391599
X Loss: -42.501899
Epoch 499 
Overall Loss: -17.225506
Rec Loss: -29.477011
KL Loss: 12.251505
Y Loss: 0.822609
T Loss: 13.269951
X Loss: -43.158268
Epoch 549 
Overall Loss: -17.594969
Rec Loss: -30.139470
KL Loss: 12.544501
Y Loss: 0.766785
T Loss: 13.168006
X Loss: -43.690869
Epoch 599 
Overall Loss: -18.338293
Rec Loss: -31.065381
KL Loss: 12.727089
Y Loss: 0.745398
T Loss: 13.089980
X Loss: -44.528061
Epoch 649 
Overall Loss: -18.861677
Rec Loss: -31.763008
KL Loss: 12.901332
Y Loss: 0.704287
T Loss: 13.009436
X Loss: -45.124587
Epoch 699 
Overall Loss: -19.234813
Rec Loss: -32.271782
KL Loss: 13.036969
Y Loss: 0.689481
T Loss: 12.933163
X Loss: -45.549686
Epoch 749 
Overall Loss: -19.549138
Rec Loss: -32.591977
KL Loss: 13.042839
Y Loss: 0.677092
T Loss: 12.894144
X Loss: -45.824667
Epoch 799 
Overall Loss: -20.133990
Rec Loss: -33.384895
KL Loss: 13.250906
Y Loss: 0.673899
T Loss: 12.821476
X Loss: -46.543321
Epoch 849 
Overall Loss: -20.200486
Rec Loss: -33.556673
KL Loss: 13.356187
Y Loss: 0.657983
T Loss: 12.798866
X Loss: -46.684532
Epoch 899 
Overall Loss: -20.658453
Rec Loss: -34.110856
KL Loss: 13.452402
Y Loss: 0.652021
T Loss: 12.720958
X Loss: -47.157823
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 3.393115
Epoch 99
Rec Loss: 3.384065
Epoch 149
Rec Loss: 3.387532
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.007263
Epoch 99
Rec Loss: 0.003586
Epoch 149
Rec Loss: 0.005561
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.742535
Insample Error 1.485609
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.050022
Rec Loss: 13.828707
KL Loss: 0.221315
Y Loss: 1.067158
T Loss: 13.295127
Epoch 99 
Overall Loss: 13.374725
Rec Loss: 12.863056
KL Loss: 0.511669
Y Loss: 1.025536
T Loss: 12.350288
Epoch 149 
Overall Loss: 13.187943
Rec Loss: 12.544525
KL Loss: 0.643418
Y Loss: 1.013034
T Loss: 12.038008
Epoch 199 
Overall Loss: 13.057668
Rec Loss: 12.322296
KL Loss: 0.735373
Y Loss: 0.977557
T Loss: 11.833517
Epoch 249 
Overall Loss: 12.804428
Rec Loss: 11.700473
KL Loss: 1.103955
Y Loss: 0.896586
T Loss: 11.252180
Epoch 299 
Overall Loss: 12.707791
Rec Loss: 11.544015
KL Loss: 1.163777
Y Loss: 0.837463
T Loss: 11.125283
Epoch 349 
Overall Loss: 12.655247
Rec Loss: 11.482056
KL Loss: 1.173191
Y Loss: 0.800572
T Loss: 11.081770
Epoch 399 
Overall Loss: 12.625778
Rec Loss: 11.458424
KL Loss: 1.167353
Y Loss: 0.770013
T Loss: 11.073418
Epoch 449 
Overall Loss: 12.590958
Rec Loss: 11.420291
KL Loss: 1.170666
Y Loss: 0.743705
T Loss: 11.048439
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.123031
Epoch 99
Rec Loss: 2.106115
Epoch 149
Rec Loss: 2.116486
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.093640
Epoch 99
Rec Loss: 10.105468
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.814910
Insample Error: 1.297150
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 11.377169
Rec Loss: 8.009304
KL Loss: 3.367864
Y Loss: 1.366324
T Loss: 13.780582
X Loss: -6.454440
Epoch 99 
Overall Loss: -4.023356
Rec Loss: -12.696585
KL Loss: 8.673229
Y Loss: 1.120765
T Loss: 13.512816
X Loss: -26.769784
Epoch 149 
Overall Loss: -7.827998
Rec Loss: -17.590184
KL Loss: 9.762186
Y Loss: 1.022637
T Loss: 13.173916
X Loss: -31.275418
Epoch 199 
Overall Loss: -10.016563
Rec Loss: -20.484929
KL Loss: 10.468366
Y Loss: 0.926413
T Loss: 12.897581
X Loss: -33.845715
Epoch 249 
Overall Loss: -11.720220
Rec Loss: -22.796843
KL Loss: 11.076623
Y Loss: 0.820013
T Loss: 12.694359
X Loss: -35.901208
Epoch 299 
Overall Loss: -12.792791
Rec Loss: -24.346719
KL Loss: 11.553928
Y Loss: 0.736848
T Loss: 12.524510
X Loss: -37.239653
Epoch 349 
Overall Loss: -14.006254
Rec Loss: -25.919906
KL Loss: 11.913652
Y Loss: 0.652326
T Loss: 12.384016
X Loss: -38.630085
Epoch 399 
Overall Loss: -14.966046
Rec Loss: -27.216627
KL Loss: 12.250580
Y Loss: 0.603255
T Loss: 12.275115
X Loss: -39.793368
Epoch 449 
Overall Loss: -15.800985
Rec Loss: -28.399287
KL Loss: 12.598303
Y Loss: 0.553588
T Loss: 12.189567
X Loss: -40.865649
Epoch 499 
Overall Loss: -16.557707
Rec Loss: -29.447980
KL Loss: 12.890272
Y Loss: 0.526396
T Loss: 12.094862
X Loss: -41.806040
Epoch 549 
Overall Loss: -17.361479
Rec Loss: -30.424297
KL Loss: 13.062817
Y Loss: 0.525006
T Loss: 12.020908
X Loss: -42.707709
Epoch 599 
Overall Loss: -17.874532
Rec Loss: -31.200764
KL Loss: 13.326231
Y Loss: 0.491714
T Loss: 11.953213
X Loss: -43.399833
Epoch 649 
Overall Loss: -18.504677
Rec Loss: -32.015320
KL Loss: 13.510644
Y Loss: 0.484264
T Loss: 11.884653
X Loss: -44.142105
Epoch 699 
Overall Loss: -19.263369
Rec Loss: -32.870391
KL Loss: 13.607022
Y Loss: 0.474743
T Loss: 11.820873
X Loss: -44.928635
Epoch 749 
Overall Loss: -19.485959
Rec Loss: -33.251270
KL Loss: 13.765312
Y Loss: 0.481258
T Loss: 11.768619
X Loss: -45.260518
Epoch 799 
Overall Loss: -20.052892
Rec Loss: -33.909021
KL Loss: 13.856129
Y Loss: 0.464917
T Loss: 11.708865
X Loss: -45.850344
Epoch 849 
Overall Loss: -20.511540
Rec Loss: -34.572497
KL Loss: 14.060958
Y Loss: 0.462812
T Loss: 11.638005
X Loss: -46.441907
Epoch 899 
Overall Loss: -20.984878
Rec Loss: -35.181941
KL Loss: 14.197063
Y Loss: 0.458212
T Loss: 11.570612
X Loss: -46.981659
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.751639
Epoch 99
Rec Loss: 2.731879
Epoch 149
Rec Loss: 2.745284
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.006026
Epoch 99
Rec Loss: 0.004969
Epoch 149
Rec Loss: 0.005093
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.538658
Insample Error 1.326380
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.003045
Rec Loss: 13.736811
KL Loss: 0.266234
Y Loss: 1.085628
T Loss: 13.193998
Epoch 99 
Overall Loss: 13.351913
Rec Loss: 12.840116
KL Loss: 0.511798
Y Loss: 1.046297
T Loss: 12.316967
Epoch 149 
Overall Loss: 13.104390
Rec Loss: 12.385377
KL Loss: 0.719013
Y Loss: 0.973276
T Loss: 11.898739
Epoch 199 
Overall Loss: 12.875636
Rec Loss: 11.857016
KL Loss: 1.018620
Y Loss: 0.925118
T Loss: 11.394457
Epoch 249 
Overall Loss: 12.741070
Rec Loss: 11.571336
KL Loss: 1.169734
Y Loss: 0.885168
T Loss: 11.128752
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.121403
Epoch 99
Rec Loss: 2.115781
Epoch 149
Rec Loss: 2.129592
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.037847
Epoch 99
Rec Loss: 10.046331
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.885741
Insample Error: 1.282984
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 12.833386
Rec Loss: 9.267338
KL Loss: 3.566048
Y Loss: 1.345961
T Loss: 13.835205
X Loss: -5.240848
Epoch 99 
Overall Loss: -1.252584
Rec Loss: -11.297454
KL Loss: 10.044869
Y Loss: 1.197224
T Loss: 13.688823
X Loss: -25.584889
Epoch 149 
Overall Loss: -5.138918
Rec Loss: -16.274341
KL Loss: 11.135423
Y Loss: 1.144040
T Loss: 13.350275
X Loss: -30.196635
Epoch 199 
Overall Loss: -7.971454
Rec Loss: -20.236976
KL Loss: 12.265522
Y Loss: 1.084800
T Loss: 12.987510
X Loss: -33.766887
Epoch 249 
Overall Loss: -9.688451
Rec Loss: -23.043184
KL Loss: 13.354733
Y Loss: 1.019634
T Loss: 12.822774
X Loss: -36.375774
Epoch 299 
Overall Loss: -11.500932
Rec Loss: -25.636706
KL Loss: 14.135774
Y Loss: 0.944161
T Loss: 12.746386
X Loss: -38.855173
Epoch 349 
Overall Loss: -12.653659
Rec Loss: -27.306192
KL Loss: 14.652532
Y Loss: 0.868712
T Loss: 12.696028
X Loss: -40.436575
Epoch 399 
Overall Loss: -13.701297
Rec Loss: -28.719363
KL Loss: 15.018066
Y Loss: 0.801301
T Loss: 12.642731
X Loss: -41.762745
Epoch 449 
Overall Loss: -14.397626
Rec Loss: -29.713778
KL Loss: 15.316152
Y Loss: 0.749441
T Loss: 12.615471
X Loss: -42.703969
Epoch 499 
Overall Loss: -15.181690
Rec Loss: -30.690500
KL Loss: 15.508810
Y Loss: 0.708873
T Loss: 12.574988
X Loss: -43.619925
Epoch 549 
Overall Loss: -15.876018
Rec Loss: -31.681722
KL Loss: 15.805704
Y Loss: 0.669667
T Loss: 12.521379
X Loss: -44.537934
Epoch 599 
Overall Loss: -16.094021
Rec Loss: -32.093441
KL Loss: 15.999422
Y Loss: 0.643321
T Loss: 12.454475
X Loss: -44.869577
Epoch 649 
Overall Loss: -16.713074
Rec Loss: -32.906628
KL Loss: 16.193555
Y Loss: 0.626407
T Loss: 12.399753
X Loss: -45.619585
Epoch 699 
Overall Loss: -17.203665
Rec Loss: -33.617943
KL Loss: 16.414278
Y Loss: 0.585524
T Loss: 12.328610
X Loss: -46.239315
Epoch 749 
Overall Loss: -17.648509
Rec Loss: -34.207953
KL Loss: 16.559443
Y Loss: 0.563880
T Loss: 12.239087
X Loss: -46.728979
Epoch 799 
Overall Loss: -17.641490
Rec Loss: -34.323666
KL Loss: 16.682174
Y Loss: 0.550092
T Loss: 12.154962
X Loss: -46.753673
Epoch 849 
Overall Loss: -18.599549
Rec Loss: -35.495244
KL Loss: 16.895695
Y Loss: 0.521526
T Loss: 12.055624
X Loss: -47.811632
Epoch 899 
Overall Loss: -18.813951
Rec Loss: -35.857651
KL Loss: 17.043699
Y Loss: 0.497244
T Loss: 11.969083
X Loss: -48.075355
Epoch 949 
Overall Loss: -19.196767
Rec Loss: -36.385199
KL Loss: 17.188433
Y Loss: 0.477546
T Loss: 11.887526
X Loss: -48.511497
Epoch 999 
Overall Loss: -19.308156
Rec Loss: -36.505444
KL Loss: 17.197287
Y Loss: 0.465596
T Loss: 11.825037
X Loss: -48.563280
Epoch 1049 
Overall Loss: -19.865873
Rec Loss: -37.233308
KL Loss: 17.367434
Y Loss: 0.441522
T Loss: 11.774209
X Loss: -49.228277
Epoch 1099 
Overall Loss: -20.081685
Rec Loss: -37.562643
KL Loss: 17.480958
Y Loss: 0.429069
T Loss: 11.699217
X Loss: -49.476395
Epoch 1149 
Overall Loss: -20.093596
Rec Loss: -37.596094
KL Loss: 17.502499
Y Loss: 0.409000
T Loss: 11.656257
X Loss: -49.456852
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.921109
Epoch 99
Rec Loss: 2.896464
Epoch 149
Rec Loss: 2.868045
Epoch 199
Rec Loss: 2.874714
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.004842
Epoch 99
Rec Loss: 0.002053
Epoch 149
Rec Loss: 0.001427
Epoch 199
Rec Loss: 0.001192
Epoch 249
Rec Loss: 0.001263
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.554576
Insample Error 2.335872
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 13.978336
Rec Loss: 13.752961
KL Loss: 0.225375
Y Loss: 1.137676
T Loss: 13.184123
Epoch 99 
Overall Loss: 13.358013
Rec Loss: 12.839181
KL Loss: 0.518833
Y Loss: 1.037585
T Loss: 12.320388
Epoch 149 
Overall Loss: 13.054981
Rec Loss: 12.283455
KL Loss: 0.771527
Y Loss: 0.984135
T Loss: 11.791387
Epoch 199 
Overall Loss: 12.784872
Rec Loss: 11.645275
KL Loss: 1.139597
Y Loss: 0.945769
T Loss: 11.172391
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.161995
Epoch 99
Rec Loss: 2.150776
Epoch 149
Rec Loss: 2.153686
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.043224
Epoch 99
Rec Loss: 10.003651
Epoch 149
Rec Loss: 9.998442
Epoch 199
Rec Loss: 9.975976
Epoch 249
Rec Loss: 9.988711
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.920687
Insample Error: 1.328037
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 14.453532
Rec Loss: 12.143332
KL Loss: 2.310200
Y Loss: 1.288525
T Loss: 13.778922
X Loss: -2.279852
Epoch 99 
Overall Loss: -4.018759
Rec Loss: -12.438576
KL Loss: 8.419817
Y Loss: 1.121507
T Loss: 13.502273
X Loss: -26.501602
Epoch 149 
Overall Loss: -8.294040
Rec Loss: -17.453035
KL Loss: 9.158995
Y Loss: 1.081998
T Loss: 13.389481
X Loss: -31.383514
Epoch 199 
Overall Loss: -10.840086
Rec Loss: -20.953048
KL Loss: 10.112962
Y Loss: 1.034319
T Loss: 13.287585
X Loss: -34.757792
Epoch 249 
Overall Loss: -12.767361
Rec Loss: -23.640694
KL Loss: 10.873333
Y Loss: 0.962694
T Loss: 13.163107
X Loss: -37.285148
Epoch 299 
Overall Loss: -14.014150
Rec Loss: -25.474209
KL Loss: 11.460060
Y Loss: 0.891848
T Loss: 13.036424
X Loss: -38.956556
Epoch 349 
Overall Loss: -15.132303
Rec Loss: -27.046723
KL Loss: 11.914420
Y Loss: 0.828526
T Loss: 12.919659
X Loss: -40.380644
Epoch 399 
Overall Loss: -16.099792
Rec Loss: -28.322894
KL Loss: 12.223102
Y Loss: 0.767501
T Loss: 12.826787
X Loss: -41.533431
Epoch 449 
Overall Loss: -17.093601
Rec Loss: -29.591366
KL Loss: 12.497764
Y Loss: 0.728190
T Loss: 12.747346
X Loss: -42.702807
Epoch 499 
Overall Loss: -17.643913
Rec Loss: -30.343117
KL Loss: 12.699204
Y Loss: 0.701078
T Loss: 12.658166
X Loss: -43.351822
Epoch 549 
Overall Loss: -18.294410
Rec Loss: -31.274748
KL Loss: 12.980338
Y Loss: 0.670546
T Loss: 12.509386
X Loss: -44.119407
Epoch 599 
Overall Loss: -18.773715
Rec Loss: -31.891821
KL Loss: 13.118105
Y Loss: 0.667974
T Loss: 12.337570
X Loss: -44.563378
Epoch 649 
Overall Loss: -19.582739
Rec Loss: -32.905351
KL Loss: 13.322613
Y Loss: 0.660085
T Loss: 12.142997
X Loss: -45.378391
Epoch 699 
Overall Loss: -20.139715
Rec Loss: -33.635760
KL Loss: 13.496046
Y Loss: 0.641590
T Loss: 11.970084
X Loss: -45.926640
Epoch 749 
Overall Loss: -20.521645
Rec Loss: -34.125837
KL Loss: 13.604192
Y Loss: 0.635914
T Loss: 11.828717
X Loss: -46.272511
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.839519
Epoch 99
Rec Loss: 2.839669
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.003777
Epoch 99
Rec Loss: 0.005504
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.716937
Insample Error 1.290108
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.120764
Rec Loss: 13.885015
KL Loss: 0.235750
Y Loss: 1.081705
T Loss: 13.344162
Epoch 99 
Overall Loss: 13.542577
Rec Loss: 13.244385
KL Loss: 0.298193
Y Loss: 1.041757
T Loss: 12.723506
Epoch 149 
Overall Loss: 13.152853
Rec Loss: 12.445580
KL Loss: 0.707273
Y Loss: 0.954166
T Loss: 11.968497
Epoch 199 
Overall Loss: 12.738206
Rec Loss: 11.446202
KL Loss: 1.292004
Y Loss: 0.833383
T Loss: 11.029510
Epoch 249 
Overall Loss: 12.582203
Rec Loss: 10.982554
KL Loss: 1.599649
Y Loss: 0.827694
T Loss: 10.568707
Epoch 299 
Overall Loss: 12.560676
Rec Loss: 10.890652
KL Loss: 1.670023
Y Loss: 0.801109
T Loss: 10.490098
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.758556
Epoch 99
Rec Loss: 1.734428
Epoch 149
Rec Loss: 1.748844
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.150471
Epoch 99
Rec Loss: 10.142264
Epoch 149
Rec Loss: 10.139130
Epoch 199
Rec Loss: 10.139788
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.822431
Insample Error: 1.145982
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 14.722323
Rec Loss: 12.785051
KL Loss: 1.937272
Y Loss: 1.318800
T Loss: 13.780030
X Loss: -1.654379
Epoch 99 
Overall Loss: -4.165612
Rec Loss: -12.373653
KL Loss: 8.208041
Y Loss: 1.014075
T Loss: 13.371450
X Loss: -26.252140
Epoch 149 
Overall Loss: -9.505653
Rec Loss: -18.810410
KL Loss: 9.304757
Y Loss: 0.929768
T Loss: 13.169337
X Loss: -32.444630
Epoch 199 
Overall Loss: -12.216511
Rec Loss: -22.400213
KL Loss: 10.183701
Y Loss: 0.879154
T Loss: 13.058214
X Loss: -35.898004
Epoch 249 
Overall Loss: -13.858337
Rec Loss: -24.602390
KL Loss: 10.744053
Y Loss: 0.840412
T Loss: 12.972517
X Loss: -37.995113
Epoch 299 
Overall Loss: -14.656067
Rec Loss: -25.751331
KL Loss: 11.095264
Y Loss: 0.795394
T Loss: 12.898162
X Loss: -39.047190
Epoch 349 
Overall Loss: -15.879296
Rec Loss: -27.306948
KL Loss: 11.427652
Y Loss: 0.769440
T Loss: 12.841081
X Loss: -40.532749
Epoch 399 
Overall Loss: -16.765436
Rec Loss: -28.437552
KL Loss: 11.672117
Y Loss: 0.734672
T Loss: 12.758632
X Loss: -41.563520
Epoch 449 
Overall Loss: -17.309317
Rec Loss: -29.144983
KL Loss: 11.835665
Y Loss: 0.712770
T Loss: 12.683096
X Loss: -42.184463
Epoch 499 
Overall Loss: -17.954115
Rec Loss: -30.031811
KL Loss: 12.077697
Y Loss: 0.684706
T Loss: 12.629727
X Loss: -43.003891
Epoch 549 
Overall Loss: -18.633673
Rec Loss: -30.912139
KL Loss: 12.278466
Y Loss: 0.658812
T Loss: 12.509714
X Loss: -43.751259
Epoch 599 
Overall Loss: -19.170883
Rec Loss: -31.616450
KL Loss: 12.445568
Y Loss: 0.630214
T Loss: 12.412385
X Loss: -44.343941
Epoch 649 
Overall Loss: -19.630118
Rec Loss: -32.188983
KL Loss: 12.558865
Y Loss: 0.625491
T Loss: 12.313685
X Loss: -44.815413
Epoch 699 
Overall Loss: -20.116407
Rec Loss: -32.913479
KL Loss: 12.797071
Y Loss: 0.611000
T Loss: 12.189185
X Loss: -45.408163
Epoch 749 
Overall Loss: -20.508723
Rec Loss: -33.433164
KL Loss: 12.924441
Y Loss: 0.603660
T Loss: 12.057965
X Loss: -45.792960
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.966106
Epoch 99
Rec Loss: 2.955135
Epoch 149
Rec Loss: 2.937540
Epoch 199
Rec Loss: 2.933745
Epoch 249
Rec Loss: 2.930003
Epoch 299
Rec Loss: 2.939373
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.008146
Epoch 99
Rec Loss: 0.005733
Epoch 149
Rec Loss: 0.005257
Epoch 199
Rec Loss: 0.004547
Epoch 249
Rec Loss: 0.012949
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.681302
Insample Error 1.250043
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 13.904029
Rec Loss: 13.706109
KL Loss: 0.197920
Y Loss: 1.165792
T Loss: 13.123213
Epoch 99 
Overall Loss: 13.556312
Rec Loss: 13.343228
KL Loss: 0.213084
Y Loss: 1.053722
T Loss: 12.816367
Epoch 149 
Overall Loss: 13.296177
Rec Loss: 12.783943
KL Loss: 0.512234
Y Loss: 0.985767
T Loss: 12.291060
Epoch 199 
Overall Loss: 13.144965
Rec Loss: 12.486930
KL Loss: 0.658035
Y Loss: 0.911529
T Loss: 12.031166
Epoch 249 
Overall Loss: 12.915254
Rec Loss: 11.898338
KL Loss: 1.016916
Y Loss: 0.864361
T Loss: 11.466157
Epoch 299 
Overall Loss: 12.776746
Rec Loss: 11.633305
KL Loss: 1.143441
Y Loss: 0.827924
T Loss: 11.219344
Epoch 349 
Overall Loss: 12.663851
Rec Loss: 11.466151
KL Loss: 1.197699
Y Loss: 0.791891
T Loss: 11.070206
Epoch 399 
Overall Loss: 12.466725
Rec Loss: 11.028680
KL Loss: 1.438045
Y Loss: 0.752468
T Loss: 10.652446
Epoch 449 
Overall Loss: 12.414705
Rec Loss: 10.815612
KL Loss: 1.599093
Y Loss: 0.731644
T Loss: 10.449790
Epoch 499 
Overall Loss: 12.396434
Rec Loss: 10.792360
KL Loss: 1.604074
Y Loss: 0.695854
T Loss: 10.444433
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.738734
Epoch 99
Rec Loss: 1.764129
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.149912
Epoch 99
Rec Loss: 10.145812
Epoch 149
Rec Loss: 10.149345
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.803193
Insample Error: 1.324715
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 11.706314
Rec Loss: 7.584831
KL Loss: 4.121483
Y Loss: 1.407929
T Loss: 13.837040
X Loss: -6.956173
Epoch 99 
Overall Loss: -3.559608
Rec Loss: -12.476552
KL Loss: 8.916945
Y Loss: 1.209826
T Loss: 13.793507
X Loss: -26.874973
Epoch 149 
Overall Loss: -7.563208
Rec Loss: -17.502274
KL Loss: 9.939067
Y Loss: 1.171407
T Loss: 13.682234
X Loss: -31.770211
Epoch 199 
Overall Loss: -10.146554
Rec Loss: -21.030087
KL Loss: 10.883533
Y Loss: 1.113515
T Loss: 13.515647
X Loss: -35.102492
Epoch 249 
Overall Loss: -11.840067
Rec Loss: -23.432754
KL Loss: 11.592687
Y Loss: 1.025919
T Loss: 13.293211
X Loss: -37.238924
Epoch 299 
Overall Loss: -13.289192
Rec Loss: -25.337413
KL Loss: 12.048220
Y Loss: 0.925647
T Loss: 13.141186
X Loss: -38.941423
Epoch 349 
Overall Loss: -14.281237
Rec Loss: -26.648999
KL Loss: 12.367762
Y Loss: 0.802002
T Loss: 13.005089
X Loss: -40.055089
Epoch 399 
Overall Loss: -14.921834
Rec Loss: -27.469293
KL Loss: 12.547458
Y Loss: 0.719852
T Loss: 12.920296
X Loss: -40.749515
Epoch 449 
Overall Loss: -15.660372
Rec Loss: -28.439533
KL Loss: 12.779162
Y Loss: 0.666577
T Loss: 12.849727
X Loss: -41.622549
Epoch 499 
Overall Loss: -16.426177
Rec Loss: -29.423608
KL Loss: 12.997431
Y Loss: 0.630678
T Loss: 12.777585
X Loss: -42.516532
Epoch 549 
Overall Loss: -16.874111
Rec Loss: -30.045228
KL Loss: 13.171117
Y Loss: 0.601658
T Loss: 12.718746
X Loss: -43.064803
Epoch 599 
Overall Loss: -17.437721
Rec Loss: -30.715573
KL Loss: 13.277852
Y Loss: 0.589617
T Loss: 12.665860
X Loss: -43.676241
Epoch 649 
Overall Loss: -17.984882
Rec Loss: -31.377303
KL Loss: 13.392420
Y Loss: 0.577029
T Loss: 12.625342
X Loss: -44.291160
Epoch 699 
Overall Loss: -18.398322
Rec Loss: -31.914959
KL Loss: 13.516636
Y Loss: 0.586167
T Loss: 12.588538
X Loss: -44.796580
Epoch 749 
Overall Loss: -18.721286
Rec Loss: -32.311007
KL Loss: 13.589721
Y Loss: 0.566587
T Loss: 12.532843
X Loss: -45.127144
Epoch 799 
Overall Loss: -19.438204
Rec Loss: -33.196506
KL Loss: 13.758301
Y Loss: 0.565289
T Loss: 12.474473
X Loss: -45.953623
Epoch 849 
Overall Loss: -19.630916
Rec Loss: -33.457435
KL Loss: 13.826519
Y Loss: 0.555409
T Loss: 12.425013
X Loss: -46.160152
Epoch 899 
Overall Loss: -19.900689
Rec Loss: -33.834802
KL Loss: 13.934113
Y Loss: 0.561099
T Loss: 12.373459
X Loss: -46.488810
Epoch 949 
Overall Loss: -20.396751
Rec Loss: -34.289906
KL Loss: 13.893154
Y Loss: 0.557160
T Loss: 12.320076
X Loss: -46.888561
Epoch 999 
Overall Loss: -20.721221
Rec Loss: -34.868534
KL Loss: 14.147313
Y Loss: 0.552358
T Loss: 12.273663
X Loss: -47.418375
Epoch 1049 
Overall Loss: -20.973852
Rec Loss: -35.229202
KL Loss: 14.255349
Y Loss: 0.558759
T Loss: 12.213713
X Loss: -47.722293
Epoch 1099 
Overall Loss: -21.219169
Rec Loss: -35.467779
KL Loss: 14.248611
Y Loss: 0.542742
T Loss: 12.172645
X Loss: -47.911796
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.916376
Epoch 99
Rec Loss: 2.896090
Epoch 149
Rec Loss: 2.885443
Epoch 199
Rec Loss: 2.895599
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.006722
Epoch 99
Rec Loss: 0.002790
Epoch 149
Rec Loss: 0.002585
Epoch 199
Rec Loss: 0.002330
Epoch 249
Rec Loss: 0.002486
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.630428
Insample Error 1.426230
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.134908
Rec Loss: 13.866065
KL Loss: 0.268842
Y Loss: 1.111152
T Loss: 13.310489
Epoch 99 
Overall Loss: 13.530512
Rec Loss: 13.176820
KL Loss: 0.353692
Y Loss: 1.017633
T Loss: 12.668004
Epoch 149 
Overall Loss: 13.003819
Rec Loss: 12.025329
KL Loss: 0.978490
Y Loss: 0.934101
T Loss: 11.558278
Epoch 199 
Overall Loss: 12.830201
Rec Loss: 11.673783
KL Loss: 1.156418
Y Loss: 0.898891
T Loss: 11.224338
Epoch 249 
Overall Loss: 12.745543
Rec Loss: 11.491841
KL Loss: 1.253701
Y Loss: 0.838581
T Loss: 11.072550
Epoch 299 
Overall Loss: 12.599469
Rec Loss: 11.145517
KL Loss: 1.453952
Y Loss: 0.805084
T Loss: 10.742975
Epoch 349 
Overall Loss: 12.512677
Rec Loss: 10.909007
KL Loss: 1.603671
Y Loss: 0.778694
T Loss: 10.519660
Epoch 399 
Overall Loss: 12.487985
Rec Loss: 10.872581
KL Loss: 1.615405
Y Loss: 0.768098
T Loss: 10.488532
Epoch 449 
Overall Loss: 12.457356
Rec Loss: 10.830760
KL Loss: 1.626596
Y Loss: 0.733785
T Loss: 10.463867
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.857444
Epoch 99
Rec Loss: 1.842712
Epoch 149
Rec Loss: 1.835289
Epoch 199
Rec Loss: 1.826259
Epoch 249
Rec Loss: 1.840490
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.149104
Epoch 99
Rec Loss: 10.146513
Epoch 149
Rec Loss: 10.144199
Epoch 199
Rec Loss: 10.139733
Epoch 249
Rec Loss: 10.134129
Epoch 299
Rec Loss: 10.137223
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.817771
Insample Error: 1.401763
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 13.090646
Rec Loss: 10.092937
KL Loss: 2.997708
Y Loss: 1.401627
T Loss: 13.840455
X Loss: -4.448331
Epoch 99 
Overall Loss: -3.232230
Rec Loss: -12.305608
KL Loss: 9.073378
Y Loss: 1.183470
T Loss: 13.780296
X Loss: -26.677639
Epoch 149 
Overall Loss: -7.446661
Rec Loss: -17.588046
KL Loss: 10.141385
Y Loss: 1.120004
T Loss: 13.694653
X Loss: -31.842701
Epoch 199 
Overall Loss: -9.896510
Rec Loss: -20.588984
KL Loss: 10.692473
Y Loss: 1.057307
T Loss: 13.617619
X Loss: -34.735255
Epoch 249 
Overall Loss: -12.073837
Rec Loss: -23.222524
KL Loss: 11.148688
Y Loss: 1.016417
T Loss: 13.542269
X Loss: -37.273003
Epoch 299 
Overall Loss: -13.477606
Rec Loss: -25.010025
KL Loss: 11.532419
Y Loss: 0.949573
T Loss: 13.468740
X Loss: -38.953552
Epoch 349 
Overall Loss: -14.630593
Rec Loss: -26.529762
KL Loss: 11.899169
Y Loss: 0.881495
T Loss: 13.339590
X Loss: -40.310099
Epoch 399 
Overall Loss: -15.532753
Rec Loss: -27.791585
KL Loss: 12.258832
Y Loss: 0.814071
T Loss: 13.213557
X Loss: -41.412179
Epoch 449 
Overall Loss: -16.283511
Rec Loss: -28.842110
KL Loss: 12.558598
Y Loss: 0.764239
T Loss: 13.064318
X Loss: -42.288547
Epoch 499 
Overall Loss: -17.018480
Rec Loss: -29.831224
KL Loss: 12.812745
Y Loss: 0.703833
T Loss: 12.929016
X Loss: -43.112156
Epoch 549 
Overall Loss: -17.531418
Rec Loss: -30.553721
KL Loss: 13.022303
Y Loss: 0.658359
T Loss: 12.786686
X Loss: -43.669585
Epoch 599 
Overall Loss: -18.122039
Rec Loss: -31.292711
KL Loss: 13.170672
Y Loss: 0.623259
T Loss: 12.668069
X Loss: -44.272410
Epoch 649 
Overall Loss: -18.732839
Rec Loss: -32.101736
KL Loss: 13.368898
Y Loss: 0.600898
T Loss: 12.578819
X Loss: -44.981003
Epoch 699 
Overall Loss: -19.150582
Rec Loss: -32.642955
KL Loss: 13.492372
Y Loss: 0.578385
T Loss: 12.477009
X Loss: -45.409155
Epoch 749 
Overall Loss: -19.563445
Rec Loss: -33.226834
KL Loss: 13.663389
Y Loss: 0.575457
T Loss: 12.411517
X Loss: -45.926079
Epoch 799 
Overall Loss: -19.972274
Rec Loss: -33.738637
KL Loss: 13.766362
Y Loss: 0.550751
T Loss: 12.304964
X Loss: -46.318975
Epoch 849 
Overall Loss: -20.265745
Rec Loss: -34.253762
KL Loss: 13.988017
Y Loss: 0.538644
T Loss: 12.220634
X Loss: -46.743717
Epoch 899 
Overall Loss: -20.331403
Rec Loss: -34.391855
KL Loss: 14.060452
Y Loss: 0.548503
T Loss: 12.101247
X Loss: -46.767354
Epoch 949 
Overall Loss: -20.807970
Rec Loss: -35.028116
KL Loss: 14.220146
Y Loss: 0.532826
T Loss: 12.033293
X Loss: -47.327822
Epoch 999 
Overall Loss: -21.102977
Rec Loss: -35.407808
KL Loss: 14.304830
Y Loss: 0.534915
T Loss: 11.987814
X Loss: -47.663080
Epoch 1049 
Overall Loss: -21.448890
Rec Loss: -35.896319
KL Loss: 14.447430
Y Loss: 0.531047
T Loss: 11.903094
X Loss: -48.064939
Epoch 1099 
Overall Loss: -21.590977
Rec Loss: -36.044067
KL Loss: 14.453091
Y Loss: 0.519445
T Loss: 11.852285
X Loss: -48.156075
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.974574
Epoch 99
Rec Loss: 2.964004
Epoch 149
Rec Loss: 2.961814
Epoch 199
Rec Loss: 2.942755
Epoch 249
Rec Loss: 2.949708
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.004157
Epoch 99
Rec Loss: 0.002972
Epoch 149
Rec Loss: 0.002495
Epoch 199
Rec Loss: 0.002875
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.614953
Insample Error 1.360114
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.127936
Rec Loss: 13.961511
KL Loss: 0.166426
Y Loss: 1.123944
T Loss: 13.399539
Epoch 99 
Overall Loss: 13.532011
Rec Loss: 13.281992
KL Loss: 0.250020
Y Loss: 1.051481
T Loss: 12.756251
Epoch 149 
Overall Loss: 13.171076
Rec Loss: 12.522714
KL Loss: 0.648362
Y Loss: 0.994198
T Loss: 12.025615
Epoch 199 
Overall Loss: 12.971819
Rec Loss: 12.141204
KL Loss: 0.830615
Y Loss: 0.945778
T Loss: 11.668315
Epoch 249 
Overall Loss: 12.762808
Rec Loss: 11.640720
KL Loss: 1.122087
Y Loss: 0.918167
T Loss: 11.181637
Epoch 299 
Overall Loss: 12.683234
Rec Loss: 11.533675
KL Loss: 1.149559
Y Loss: 0.858440
T Loss: 11.104455
Epoch 349 
Overall Loss: 12.660725
Rec Loss: 11.506411
KL Loss: 1.154313
Y Loss: 0.804567
T Loss: 11.104128
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.145905
Epoch 99
Rec Loss: 2.130464
Epoch 149
Rec Loss: 2.144754
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 10.095687
Epoch 99
Rec Loss: 10.130746
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.871566
Insample Error: 1.334236
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 12.771659
Rec Loss: 9.394354
KL Loss: 3.377305
Y Loss: 1.340485
T Loss: 13.803219
X Loss: -5.079107
Epoch 99 
Overall Loss: -1.937702
Rec Loss: -11.781451
KL Loss: 9.843749
Y Loss: 1.050655
T Loss: 13.364032
X Loss: -25.670810
Epoch 149 
Overall Loss: -5.222972
Rec Loss: -15.865740
KL Loss: 10.642769
Y Loss: 0.908825
T Loss: 12.986043
X Loss: -29.306196
Epoch 199 
Overall Loss: -6.670452
Rec Loss: -18.002145
KL Loss: 11.331694
Y Loss: 0.780901
T Loss: 12.920825
X Loss: -31.313421
Epoch 249 
Overall Loss: -8.114072
Rec Loss: -20.132668
KL Loss: 12.018597
Y Loss: 0.683886
T Loss: 12.872220
X Loss: -33.346831
Epoch 299 
Overall Loss: -9.546747
Rec Loss: -22.336405
KL Loss: 12.789658
Y Loss: 0.604912
T Loss: 12.827180
X Loss: -35.466041
Epoch 349 
Overall Loss: -10.658847
Rec Loss: -24.167458
KL Loss: 13.508610
Y Loss: 0.539657
T Loss: 12.780167
X Loss: -37.217452
Epoch 399 
Overall Loss: -11.735251
Rec Loss: -25.755219
KL Loss: 14.019968
Y Loss: 0.495284
T Loss: 12.753059
X Loss: -38.755919
Epoch 449 
Overall Loss: -12.507106
Rec Loss: -26.869012
KL Loss: 14.361906
Y Loss: 0.460433
T Loss: 12.706490
X Loss: -39.805717
Epoch 499 
Overall Loss: -13.251830
Rec Loss: -27.944763
KL Loss: 14.692933
Y Loss: 0.446500
T Loss: 12.651899
X Loss: -40.819912
Epoch 549 
Overall Loss: -13.722905
Rec Loss: -28.645497
KL Loss: 14.922592
Y Loss: 0.425685
T Loss: 12.594233
X Loss: -41.452571
Epoch 599 
Overall Loss: -14.502303
Rec Loss: -29.584235
KL Loss: 15.081932
Y Loss: 0.413841
T Loss: 12.515527
X Loss: -42.306681
Epoch 649 
Overall Loss: -15.020233
Rec Loss: -30.265210
KL Loss: 15.244977
Y Loss: 0.407287
T Loss: 12.450703
X Loss: -42.919555
Epoch 699 
Overall Loss: -15.463529
Rec Loss: -30.839329
KL Loss: 15.375800
Y Loss: 0.405444
T Loss: 12.391346
X Loss: -43.433397
Epoch 749 
Overall Loss: -15.902225
Rec Loss: -31.393092
KL Loss: 15.490867
Y Loss: 0.397675
T Loss: 12.349698
X Loss: -43.941627
Epoch 799 
Overall Loss: -16.428604
Rec Loss: -32.019517
KL Loss: 15.590912
Y Loss: 0.405119
T Loss: 12.304801
X Loss: -44.526877
Epoch 849 
Overall Loss: -16.749148
Rec Loss: -32.381540
KL Loss: 15.632391
Y Loss: 0.404816
T Loss: 12.273738
X Loss: -44.857685
Epoch 899 
Overall Loss: -17.257729
Rec Loss: -33.056842
KL Loss: 15.799113
Y Loss: 0.397404
T Loss: 12.260218
X Loss: -45.515762
Epoch 949 
Overall Loss: -17.214822
Rec Loss: -33.093921
KL Loss: 15.879099
Y Loss: 0.407589
T Loss: 12.234580
X Loss: -45.532296
Epoch 999 
Overall Loss: -16.711313
Rec Loss: -32.602159
KL Loss: 15.890846
Y Loss: 0.420654
T Loss: 12.223984
X Loss: -45.036471
Epoch 1049 
Overall Loss: -18.095333
Rec Loss: -34.096632
KL Loss: 16.001298
Y Loss: 0.418593
T Loss: 12.192948
X Loss: -46.498876
Epoch 1099 
Overall Loss: -18.302933
Rec Loss: -34.419065
KL Loss: 16.116132
Y Loss: 0.406047
T Loss: 12.158669
X Loss: -46.780759
Epoch 1149 
Overall Loss: -18.500993
Rec Loss: -34.691863
KL Loss: 16.190871
Y Loss: 0.425371
T Loss: 12.133362
X Loss: -47.037911
Epoch 1199 
Overall Loss: -18.843965
Rec Loss: -35.052937
KL Loss: 16.208972
Y Loss: 0.429945
T Loss: 12.095681
X Loss: -47.363589
Epoch 1249 
Overall Loss: -19.370337
Rec Loss: -35.631922
KL Loss: 16.261584
Y Loss: 0.444388
T Loss: 12.073448
X Loss: -47.927564
Epoch 1299 
Overall Loss: -19.666405
Rec Loss: -36.091728
KL Loss: 16.425323
Y Loss: 0.437301
T Loss: 12.037787
X Loss: -48.348165
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.981711
Epoch 99
Rec Loss: 2.982974
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.005069
Epoch 99
Rec Loss: 0.004140
Epoch 149
Rec Loss: 0.002580
Epoch 199
Rec Loss: 0.003480
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.594681
Insample Error 1.557882
Ours, Train RMSE
0.8228, 
0.7966, 
0.8015, 
0.8149, 
0.8857, 
0.9207, 
0.8224, 
0.8032, 
0.8178, 
0.8716, 
CEVAE, Train RMSE
0.7610, 
0.6345, 
0.7425, 
0.5387, 
0.5546, 
0.7169, 
0.6813, 
0.6304, 
0.6150, 
0.5947, 
Ours, Insample RMSE
1.3827, 
1.2784, 
1.3489, 
1.2972, 
1.2830, 
1.3280, 
1.1460, 
1.3247, 
1.4018, 
1.3342, 
CEVAE, Insample RMSE
1.4458, 
1.2271, 
1.4856, 
1.3264, 
2.3359, 
1.2901, 
1.2500, 
1.4262, 
1.3601, 
1.5579, 
Train, RMSE mean 0.8357 std 0.0398
CEVAE, RMSE mean 0.6470 std 0.0726
Ours, RMSE mean 1.3125 std 0.0671, reconstruct confounder 1.9124 (0.1775) noise 10.1025 (0.0526)
CEVAE, RMSE mean 1.4705 std 0.3054, reconstruct confounder 3.0193 (0.2188) noise 0.0038 (0.0017)
Experiment Start!
Namespace(cevaelr=5e-05, decay=0.0, l=0.001, latdim=4, mask=0, nlayer=50, obsm=1, stop=2000, ycof=0.5, ylayer=50)
Y Mean 1.037543, Std 4.233836 
Test Y Mean 0.042888, Std 4.254001 
Observe confounder 1, Noise 10 dimension
Learning Rate 0.001000
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.534511
Rec Loss: 12.681716
KL Loss: 1.852795
Y Loss: 1.037174
T Loss: 12.163129
Epoch 99 
Overall Loss: 14.448771
Rec Loss: 12.344576
KL Loss: 2.104195
Y Loss: 1.007340
T Loss: 11.840906
Epoch 149 
Overall Loss: 14.442494
Rec Loss: 12.304048
KL Loss: 2.138445
Y Loss: 0.986471
T Loss: 11.810812
Epoch 199 
Overall Loss: 14.421421
Rec Loss: 12.287194
KL Loss: 2.134227
Y Loss: 1.011610
T Loss: 11.781389
Epoch 249 
Overall Loss: 14.396443
Rec Loss: 12.304426
KL Loss: 2.092017
Y Loss: 1.019024
T Loss: 11.794914
Epoch 299 
Overall Loss: 14.387541
Rec Loss: 12.263606
KL Loss: 2.123935
Y Loss: 1.011703
T Loss: 11.757755
Epoch 349 
Overall Loss: 14.372232
Rec Loss: 12.282251
KL Loss: 2.089981
Y Loss: 1.000340
T Loss: 11.782081
Epoch 399 
Overall Loss: 14.395706
Rec Loss: 12.277981
KL Loss: 2.117725
Y Loss: 0.990631
T Loss: 11.782666
Epoch 449 
Overall Loss: 14.385628
Rec Loss: 12.291949
KL Loss: 2.093678
Y Loss: 1.001834
T Loss: 11.791032
Epoch 499 
Overall Loss: 14.376976
Rec Loss: 12.274269
KL Loss: 2.102707
Y Loss: 0.999027
T Loss: 11.774755
Epoch 549 
Overall Loss: 14.372322
Rec Loss: 12.272310
KL Loss: 2.100012
Y Loss: 0.982809
T Loss: 11.780905
Epoch 599 
Overall Loss: 14.386466
Rec Loss: 12.312884
KL Loss: 2.073582
Y Loss: 1.028191
T Loss: 11.798788
Epoch 649 
Overall Loss: 14.377955
Rec Loss: 12.277620
KL Loss: 2.100336
Y Loss: 0.992983
T Loss: 11.781128
Epoch 699 
Overall Loss: 14.369499
Rec Loss: 12.271183
KL Loss: 2.098317
Y Loss: 0.992277
T Loss: 11.775044
Epoch 749 
Overall Loss: 14.356299
Rec Loss: 12.292994
KL Loss: 2.063305
Y Loss: 1.012200
T Loss: 11.786894
Epoch 799 
Overall Loss: 14.349614
Rec Loss: 12.268177
KL Loss: 2.081437
Y Loss: 1.017089
T Loss: 11.759632
Epoch 849 
Overall Loss: 14.356029
Rec Loss: 12.291110
KL Loss: 2.064919
Y Loss: 1.035025
T Loss: 11.773598
Epoch 899 
Overall Loss: 14.334698
Rec Loss: 12.246158
KL Loss: 2.088540
Y Loss: 0.973922
T Loss: 11.759197
Epoch 949 
Overall Loss: 14.354571
Rec Loss: 12.257280
KL Loss: 2.097291
Y Loss: 0.986048
T Loss: 11.764256
Epoch 999 
Overall Loss: 14.346997
Rec Loss: 12.263092
KL Loss: 2.083905
Y Loss: 1.023064
T Loss: 11.751560
Epoch 1049 
Overall Loss: 14.330992
Rec Loss: 12.243774
KL Loss: 2.087218
Y Loss: 1.011257
T Loss: 11.738145
Epoch 1099 
Overall Loss: 14.357141
Rec Loss: 12.288089
KL Loss: 2.069052
Y Loss: 1.054255
T Loss: 11.760961
Epoch 1149 
Overall Loss: 14.359645
Rec Loss: 12.252738
KL Loss: 2.106907
Y Loss: 0.978570
T Loss: 11.763453
Epoch 1199 
Overall Loss: 14.340855
Rec Loss: 12.268383
KL Loss: 2.072472
Y Loss: 1.014868
T Loss: 11.760949
Epoch 1249 
Overall Loss: 14.326253
Rec Loss: 12.241599
KL Loss: 2.084654
Y Loss: 0.998522
T Loss: 11.742338
Epoch 1299 
Overall Loss: 14.331236
Rec Loss: 12.274352
KL Loss: 2.056884
Y Loss: 1.030893
T Loss: 11.758905
Epoch 1349 
Overall Loss: 14.350169
Rec Loss: 12.263005
KL Loss: 2.087164
Y Loss: 0.995177
T Loss: 11.765416
Epoch 1399 
Overall Loss: 14.343584
Rec Loss: 12.276120
KL Loss: 2.067465
Y Loss: 1.030230
T Loss: 11.761004
Epoch 1449 
Overall Loss: 14.335470
Rec Loss: 12.243692
KL Loss: 2.091778
Y Loss: 0.988198
T Loss: 11.749592
Epoch 1499 
Overall Loss: 14.306700
Rec Loss: 12.223328
KL Loss: 2.083371
Y Loss: 0.995701
T Loss: 11.725478
Epoch 1549 
Overall Loss: 14.343260
Rec Loss: 12.257389
KL Loss: 2.085871
Y Loss: 1.019458
T Loss: 11.747660
Epoch 1599 
Overall Loss: 14.338821
Rec Loss: 12.281600
KL Loss: 2.057221
Y Loss: 1.045759
T Loss: 11.758720
Epoch 1649 
Overall Loss: 14.331533
Rec Loss: 12.241057
KL Loss: 2.090476
Y Loss: 0.988971
T Loss: 11.746572
Epoch 1699 
Overall Loss: 14.316230
Rec Loss: 12.234632
KL Loss: 2.081598
Y Loss: 1.005107
T Loss: 11.732079
Epoch 1749 
Overall Loss: 14.314872
Rec Loss: 12.252916
KL Loss: 2.061956
Y Loss: 1.016177
T Loss: 11.744827
Epoch 1799 
Overall Loss: 14.358413
Rec Loss: 12.239800
KL Loss: 2.118613
Y Loss: 0.993838
T Loss: 11.742881
Epoch 1849 
Overall Loss: 14.327393
Rec Loss: 12.232595
KL Loss: 2.094798
Y Loss: 0.983459
T Loss: 11.740865
Epoch 1899 
Overall Loss: 14.347941
Rec Loss: 12.251075
KL Loss: 2.096866
Y Loss: 1.027518
T Loss: 11.737316
Epoch 1949 
Overall Loss: 14.324344
Rec Loss: 12.234892
KL Loss: 2.089452
Y Loss: 0.984008
T Loss: 11.742889
Epoch 1999 
Overall Loss: 14.316900
Rec Loss: 12.249488
KL Loss: 2.067412
Y Loss: 1.006585
T Loss: 11.746196
Epoch 2049 
Overall Loss: 14.341512
Rec Loss: 12.241400
KL Loss: 2.100112
Y Loss: 0.998478
T Loss: 11.742161
Epoch 2099 
Overall Loss: 14.329889
Rec Loss: 12.230543
KL Loss: 2.099346
Y Loss: 0.998963
T Loss: 11.731062
Epoch 2149 
Overall Loss: 14.330318
Rec Loss: 12.234274
KL Loss: 2.096044
Y Loss: 1.008227
T Loss: 11.730160
Epoch 2199 
Overall Loss: 14.325224
Rec Loss: 12.238477
KL Loss: 2.086747
Y Loss: 1.019423
T Loss: 11.728765
Epoch 2249 
Overall Loss: 14.330391
Rec Loss: 12.245374
KL Loss: 2.085017
Y Loss: 0.992766
T Loss: 11.748991
Epoch 2299 
Overall Loss: 14.327971
Rec Loss: 12.233949
KL Loss: 2.094022
Y Loss: 0.995135
T Loss: 11.736381
Epoch 2349 
Overall Loss: 14.300967
Rec Loss: 12.233488
KL Loss: 2.067479
Y Loss: 1.007170
T Loss: 11.729903
Epoch 2399 
Overall Loss: 14.312660
Rec Loss: 12.237934
KL Loss: 2.074726
Y Loss: 1.019795
T Loss: 11.728037
Epoch 2449 
Overall Loss: 14.302750
Rec Loss: 12.228607
KL Loss: 2.074143
Y Loss: 1.001207
T Loss: 11.728003
Epoch 2499 
Overall Loss: 14.316153
Rec Loss: 12.229278
KL Loss: 2.086875
Y Loss: 1.003549
T Loss: 11.727504
Epoch 2549 
Overall Loss: 14.321923
Rec Loss: 12.225936
KL Loss: 2.095987
Y Loss: 0.992267
T Loss: 11.729802
Epoch 2599 
Overall Loss: 14.318633
Rec Loss: 12.248826
KL Loss: 2.069806
Y Loss: 1.015817
T Loss: 11.740918
Epoch 2649 
Overall Loss: 14.328447
Rec Loss: 12.244410
KL Loss: 2.084037
Y Loss: 1.004248
T Loss: 11.742285
Epoch 2699 
Overall Loss: 14.339860
Rec Loss: 12.233405
KL Loss: 2.106455
Y Loss: 0.997589
T Loss: 11.734611
Epoch 2749 
Overall Loss: 14.294683
Rec Loss: 12.217341
KL Loss: 2.077342
Y Loss: 0.982768
T Loss: 11.725956
Epoch 2799 
Overall Loss: 14.312043
Rec Loss: 12.229047
KL Loss: 2.082996
Y Loss: 0.980041
T Loss: 11.739027
Epoch 2849 
Overall Loss: 14.348458
Rec Loss: 12.231792
KL Loss: 2.116666
Y Loss: 1.000015
T Loss: 11.731784
Epoch 2899 
Overall Loss: 14.325077
Rec Loss: 12.224642
KL Loss: 2.100435
Y Loss: 1.010043
T Loss: 11.719620
Epoch 2949 
Overall Loss: 14.325044
Rec Loss: 12.247148
KL Loss: 2.077897
Y Loss: 1.008508
T Loss: 11.742893
Epoch 2999 
Overall Loss: 14.312632
Rec Loss: 12.232125
KL Loss: 2.080507
Y Loss: 1.003175
T Loss: 11.730538
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.548938
Epoch 99
Rec Loss: 1.546044
Epoch 149
Rec Loss: 1.539282
Epoch 199
Rec Loss: 1.523445
Epoch 249
Rec Loss: 1.515011
Epoch 299
Rec Loss: 1.529342
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.879833
Epoch 99
Rec Loss: 9.852183
Epoch 149
Rec Loss: 9.844676
Epoch 199
Rec Loss: 9.854878
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.525808
Insample Error: 1.389853
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 18.243015
Rec Loss: 14.657701
KL Loss: 3.585314
Y Loss: 5.832297
T Loss: 13.398631
X Loss: -1.657078
Epoch 99 
Overall Loss: -0.384040
Rec Loss: -8.579098
KL Loss: 8.195058
Y Loss: 2.229916
T Loss: 13.325769
X Loss: -23.019826
Epoch 149 
Overall Loss: -6.603381
Rec Loss: -15.894958
KL Loss: 9.291577
Y Loss: 1.454522
T Loss: 13.325467
X Loss: -29.947686
Epoch 199 
Overall Loss: -9.879597
Rec Loss: -20.329235
KL Loss: 10.449638
Y Loss: 0.918879
T Loss: 13.306981
X Loss: -34.095656
Epoch 249 
Overall Loss: -11.941722
Rec Loss: -23.193793
KL Loss: 11.252071
Y Loss: 0.747580
T Loss: 13.294745
X Loss: -36.862329
Epoch 299 
Overall Loss: -13.263567
Rec Loss: -24.977620
KL Loss: 11.714053
Y Loss: 0.694542
T Loss: 13.278612
X Loss: -38.603504
Epoch 349 
Overall Loss: -14.145537
Rec Loss: -26.211792
KL Loss: 12.066255
Y Loss: 0.667191
T Loss: 13.262747
X Loss: -39.808136
Epoch 399 
Overall Loss: -14.904506
Rec Loss: -27.232496
KL Loss: 12.327990
Y Loss: 0.692075
T Loss: 13.239871
X Loss: -40.818405
Epoch 449 
Overall Loss: -15.577438
Rec Loss: -28.167114
KL Loss: 12.589677
Y Loss: 0.686871
T Loss: 13.209482
X Loss: -41.720032
Epoch 499 
Overall Loss: -16.251088
Rec Loss: -29.005793
KL Loss: 12.754705
Y Loss: 0.736837
T Loss: 13.176007
X Loss: -42.550220
Epoch 549 
Overall Loss: -16.841351
Rec Loss: -29.797577
KL Loss: 12.956226
Y Loss: 0.715328
T Loss: 13.139663
X Loss: -43.294904
Epoch 599 
Overall Loss: -17.432578
Rec Loss: -30.482221
KL Loss: 13.049643
Y Loss: 0.756020
T Loss: 13.092270
X Loss: -43.952501
Epoch 649 
Overall Loss: -17.879097
Rec Loss: -31.197496
KL Loss: 13.318399
Y Loss: 0.748987
T Loss: 13.035942
X Loss: -44.607931
Epoch 699 
Overall Loss: -18.433193
Rec Loss: -31.880560
KL Loss: 13.447367
Y Loss: 0.754544
T Loss: 12.989954
X Loss: -45.247786
Epoch 749 
Overall Loss: -18.855681
Rec Loss: -32.382587
KL Loss: 13.526907
Y Loss: 0.760588
T Loss: 12.943017
X Loss: -45.705899
Epoch 799 
Overall Loss: -19.175772
Rec Loss: -32.866993
KL Loss: 13.691220
Y Loss: 0.758098
T Loss: 12.910034
X Loss: -46.156075
Epoch 849 
Overall Loss: -19.432612
Rec Loss: -33.101958
KL Loss: 13.669345
Y Loss: 0.794568
T Loss: 12.889831
X Loss: -46.389074
Epoch 899 
Overall Loss: -19.907568
Rec Loss: -33.746251
KL Loss: 13.838683
Y Loss: 0.772905
T Loss: 12.866352
X Loss: -46.999057
Epoch 949 
Overall Loss: -20.141130
Rec Loss: -34.067273
KL Loss: 13.926143
Y Loss: 0.763622
T Loss: 12.847178
X Loss: -47.296262
Epoch 999 
Overall Loss: -20.418683
Rec Loss: -34.427052
KL Loss: 14.008369
Y Loss: 0.766126
T Loss: 12.844771
X Loss: -47.654887
Epoch 1049 
Overall Loss: -20.620945
Rec Loss: -34.734776
KL Loss: 14.113831
Y Loss: 0.790992
T Loss: 12.830732
X Loss: -47.961004
Epoch 1099 
Overall Loss: -20.730397
Rec Loss: -34.905680
KL Loss: 14.175284
Y Loss: 0.769388
T Loss: 12.822746
X Loss: -48.113121
Epoch 1149 
Overall Loss: -20.896358
Rec Loss: -35.078896
KL Loss: 14.182538
Y Loss: 0.773838
T Loss: 12.816541
X Loss: -48.282355
Epoch 1199 
Overall Loss: -21.440643
Rec Loss: -35.748130
KL Loss: 14.307486
Y Loss: 0.790248
T Loss: 12.807567
X Loss: -48.950820
Epoch 1249 
Overall Loss: -21.642899
Rec Loss: -36.009183
KL Loss: 14.366283
Y Loss: 0.754535
T Loss: 12.800366
X Loss: -49.186816
Epoch 1299 
Overall Loss: -21.691094
Rec Loss: -36.096538
KL Loss: 14.405444
Y Loss: 0.766817
T Loss: 12.796236
X Loss: -49.276184
Epoch 1349 
Overall Loss: -22.048174
Rec Loss: -36.462731
KL Loss: 14.414557
Y Loss: 0.801555
T Loss: 12.787467
X Loss: -49.650975
Epoch 1399 
Overall Loss: -21.770780
Rec Loss: -36.245113
KL Loss: 14.474333
Y Loss: 0.780970
T Loss: 12.785273
X Loss: -49.420871
Epoch 1449 
Overall Loss: -22.441118
Rec Loss: -36.999780
KL Loss: 14.558662
Y Loss: 0.775320
T Loss: 12.779217
X Loss: -50.166658
Epoch 1499 
Overall Loss: -22.584177
Rec Loss: -37.186585
KL Loss: 14.602406
Y Loss: 0.752875
T Loss: 12.767316
X Loss: -50.330338
Epoch 1549 
Overall Loss: -22.707522
Rec Loss: -37.296698
KL Loss: 14.589176
Y Loss: 0.772151
T Loss: 12.772558
X Loss: -50.455332
Epoch 1599 
Overall Loss: -22.735086
Rec Loss: -37.309352
KL Loss: 14.574267
Y Loss: 0.793278
T Loss: 12.771647
X Loss: -50.477639
Epoch 1649 
Overall Loss: -22.986489
Rec Loss: -37.590155
KL Loss: 14.603667
Y Loss: 0.779956
T Loss: 12.770936
X Loss: -50.751070
Epoch 1699 
Overall Loss: -23.299045
Rec Loss: -38.046173
KL Loss: 14.747129
Y Loss: 0.761418
T Loss: 12.760021
X Loss: -51.186905
Epoch 1749 
Overall Loss: -23.037646
Rec Loss: -37.697595
KL Loss: 14.659949
Y Loss: 0.769535
T Loss: 12.748972
X Loss: -50.831332
Epoch 1799 
Overall Loss: -23.347488
Rec Loss: -38.084726
KL Loss: 14.737237
Y Loss: 0.768273
T Loss: 12.740722
X Loss: -51.209583
Epoch 1849 
Overall Loss: -23.609285
Rec Loss: -38.294556
KL Loss: 14.685271
Y Loss: 0.794801
T Loss: 12.746880
X Loss: -51.438836
Epoch 1899 
Overall Loss: -23.356359
Rec Loss: -38.241405
KL Loss: 14.885046
Y Loss: 0.767783
T Loss: 12.740854
X Loss: -51.366150
Epoch 1949 
Overall Loss: -23.797464
Rec Loss: -38.672649
KL Loss: 14.875186
Y Loss: 0.788080
T Loss: 12.741495
X Loss: -51.808184
Epoch 1999 
Overall Loss: -24.023456
Rec Loss: -38.923563
KL Loss: 14.900107
Y Loss: 0.769192
T Loss: 12.732720
X Loss: -52.040878
Epoch 2049 
Overall Loss: -22.917596
Rec Loss: -37.780474
KL Loss: 14.862878
Y Loss: 0.790411
T Loss: 12.718499
X Loss: -50.894178
Epoch 2099 
Overall Loss: -24.230437
Rec Loss: -39.275253
KL Loss: 15.044816
Y Loss: 0.758347
T Loss: 12.717375
X Loss: -52.371802
Epoch 2149 
Overall Loss: -24.308974
Rec Loss: -39.422882
KL Loss: 15.113907
Y Loss: 0.761748
T Loss: 12.715840
X Loss: -52.519595
Epoch 2199 
Overall Loss: -24.444054
Rec Loss: -39.464018
KL Loss: 15.019965
Y Loss: 0.785991
T Loss: 12.723727
X Loss: -52.580741
Epoch 2249 
Overall Loss: -23.963319
Rec Loss: -38.991385
KL Loss: 15.028066
Y Loss: 0.754280
T Loss: 12.719160
X Loss: -52.087685
Epoch 2299 
Overall Loss: -24.412943
Rec Loss: -39.368513
KL Loss: 14.955571
Y Loss: 0.775513
T Loss: 12.710054
X Loss: -52.466324
Epoch 2349 
Overall Loss: -24.579643
Rec Loss: -39.606126
KL Loss: 15.026483
Y Loss: 0.796922
T Loss: 12.704711
X Loss: -52.709299
Epoch 2399 
Overall Loss: -24.653011
Rec Loss: -39.666673
KL Loss: 15.013662
Y Loss: 0.792711
T Loss: 12.708883
X Loss: -52.771912
Epoch 2449 
Overall Loss: -25.074005
Rec Loss: -40.254487
KL Loss: 15.180482
Y Loss: 0.745772
T Loss: 12.704053
X Loss: -53.331425
Epoch 2499 
Overall Loss: -25.139617
Rec Loss: -40.173449
KL Loss: 15.033832
Y Loss: 0.792208
T Loss: 12.698070
X Loss: -53.267623
Epoch 2549 
Overall Loss: -25.067168
Rec Loss: -40.300830
KL Loss: 15.233662
Y Loss: 0.769247
T Loss: 12.694830
X Loss: -53.380283
Epoch 2599 
Overall Loss: -25.121059
Rec Loss: -40.207499
KL Loss: 15.086440
Y Loss: 0.756648
T Loss: 12.680238
X Loss: -53.266061
Epoch 2649 
Overall Loss: -25.382891
Rec Loss: -40.669171
KL Loss: 15.286280
Y Loss: 0.762629
T Loss: 12.683958
X Loss: -53.734444
Epoch 2699 
Overall Loss: -24.983272
Rec Loss: -40.134786
KL Loss: 15.151513
Y Loss: 0.778536
T Loss: 12.695737
X Loss: -53.219791
Epoch 2749 
Overall Loss: -25.114181
Rec Loss: -40.112740
KL Loss: 14.998558
Y Loss: 0.778066
T Loss: 12.687591
X Loss: -53.189361
Epoch 2799 
Overall Loss: -25.510194
Rec Loss: -40.718159
KL Loss: 15.207964
Y Loss: 0.785576
T Loss: 12.678031
X Loss: -53.788977
Epoch 2849 
Overall Loss: -24.772633
Rec Loss: -39.816760
KL Loss: 15.044127
Y Loss: 0.774337
T Loss: 12.684835
X Loss: -52.888764
Epoch 2899 
Overall Loss: -25.001237
Rec Loss: -40.419187
KL Loss: 15.417949
Y Loss: 0.758512
T Loss: 12.667506
X Loss: -53.465949
Epoch 2949 
Overall Loss: -25.885292
Rec Loss: -41.125105
KL Loss: 15.239812
Y Loss: 0.784419
T Loss: 12.668943
X Loss: -54.186258
Epoch 2999 
Overall Loss: -25.963079
Rec Loss: -41.254831
KL Loss: 15.291751
Y Loss: 0.742987
T Loss: 12.664739
X Loss: -54.291063
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.806223
Epoch 99
Rec Loss: 2.797786
Epoch 149
Rec Loss: 2.797527
Epoch 199
Rec Loss: 2.787835
Epoch 249
Rec Loss: 2.791542
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.003311
Epoch 99
Rec Loss: 0.002026
Epoch 149
Rec Loss: 0.002208
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.378100
Insample Error 2.186920
[34m== Direct Regression: Training all ==[0m
Epoch 49 
Prediction Loss: 7.173071
Epoch 99 
Prediction Loss: 6.819553
Epoch 149 
Prediction Loss: 6.581262
Epoch 199 
Prediction Loss: 6.454806
Epoch 249 
Prediction Loss: 6.402800
Epoch 299 
Prediction Loss: 6.324995
Epoch 349 
Prediction Loss: 6.274848
Epoch 399 
Prediction Loss: 6.291612
Epoch 449 
Prediction Loss: 6.190923
Epoch 499 
Prediction Loss: 6.134678
Epoch 549 
Prediction Loss: 6.117543
Epoch 599 
Prediction Loss: 6.021643
Epoch 649 
Prediction Loss: 5.994863
Epoch 699 
Prediction Loss: 5.991081
Epoch 749 
Prediction Loss: 5.884805
Epoch 799 
Prediction Loss: 5.810490
Epoch 849 
Prediction Loss: 5.746401
Epoch 899 
Prediction Loss: 5.702848
Epoch 949 
Prediction Loss: 5.620504
Epoch 999 
Prediction Loss: 5.627114
Epoch 1049 
Prediction Loss: 5.548723
Epoch 1099 
Prediction Loss: 5.470579
Epoch 1149 
Prediction Loss: 5.439828
Epoch 1199 
Prediction Loss: 5.381542
Epoch 1249 
Prediction Loss: 5.309562
Epoch 1299 
Prediction Loss: 5.293407
Epoch 1349 
Prediction Loss: 5.279220
Epoch 1399 
Prediction Loss: 5.192157
Epoch 1449 
Prediction Loss: 5.166945
Epoch 1499 
Prediction Loss: 5.093450
Epoch 1549 
Prediction Loss: 5.088797
Epoch 1599 
Prediction Loss: 5.090855
Epoch 1649 
Prediction Loss: 4.985687
Epoch 1699 
Prediction Loss: 4.957817
Epoch 1749 
Prediction Loss: 4.966060
Epoch 1799 
Prediction Loss: 4.862872
Epoch 1849 
Prediction Loss: 4.830193
Epoch 1899 
Prediction Loss: 4.823598
Epoch 1949 
Prediction Loss: 4.752612
Epoch 1999 
Prediction Loss: 4.803753
Epoch 2049 
Prediction Loss: 4.707579
Epoch 2099 
Prediction Loss: 4.675197
Epoch 2149 
Prediction Loss: 4.616603
Epoch 2199 
Prediction Loss: 4.669123
Epoch 2249 
Prediction Loss: 4.549367
Epoch 2299 
Prediction Loss: 4.564434
Epoch 2349 
Prediction Loss: 4.529178
Epoch 2399 
Prediction Loss: 4.577488
Epoch 2449 
Prediction Loss: 4.429766
Epoch 2499 
Prediction Loss: 4.431786
Epoch 2549 
Prediction Loss: 4.470638
Epoch 2599 
Prediction Loss: 4.386273
Epoch 2649 
Prediction Loss: 4.365572
Epoch 2699 
Prediction Loss: 4.322411
Epoch 2749 
Prediction Loss: 4.370962
Epoch 2799 
Prediction Loss: 4.294316
Epoch 2849 
Prediction Loss: 4.287537
Epoch 2899 
Prediction Loss: 4.237175
Epoch 2949 
Prediction Loss: 4.225527
Epoch 2999 
Prediction Loss: 4.194258
Epoch 3049 
Prediction Loss: 4.166031
Epoch 3099 
Prediction Loss: 4.163525
Epoch 3149 
Prediction Loss: 4.134309
Epoch 3199 
Prediction Loss: 4.135230
Epoch 3249 
Prediction Loss: 4.094936
Epoch 3299 
Prediction Loss: 4.070662
Epoch 3349 
Prediction Loss: 4.076541
Epoch 3399 
Prediction Loss: 4.042630
Epoch 3449 
Prediction Loss: 4.081693
Epoch 3499 
Prediction Loss: 3.992892
Epoch 3549 
Prediction Loss: 4.003998
Epoch 3599 
Prediction Loss: 3.965263
Epoch 3649 
Prediction Loss: 3.948089
Epoch 3699 
Prediction Loss: 3.932170
Epoch 3749 
Prediction Loss: 3.887393
Epoch 3799 
Prediction Loss: 3.889431
Epoch 3849 
Prediction Loss: 3.888041
Epoch 3899 
Prediction Loss: 3.893399
Epoch 3949 
Prediction Loss: 3.839520
Epoch 3999 
Prediction Loss: 3.822076
Epoch 4049 
Prediction Loss: 3.811330
Epoch 4099 
Prediction Loss: 3.804014
Epoch 4149 
Prediction Loss: 3.799895
Epoch 4199 
Prediction Loss: 3.743374
Epoch 4249 
Prediction Loss: 3.734570
Epoch 4299 
Prediction Loss: 3.750297
Epoch 4349 
Prediction Loss: 3.720935
Epoch 4399 
Prediction Loss: 3.681748
Epoch 4449 
Prediction Loss: 3.678648
Epoch 4499 
Prediction Loss: 3.649647
Epoch 4549 
Prediction Loss: 3.653787
Epoch 4599 
Prediction Loss: 3.616484
Epoch 4649 
Prediction Loss: 3.650034
Epoch 4699 
Prediction Loss: 3.608211
Epoch 4749 
Prediction Loss: 3.626851
Epoch 4799 
Prediction Loss: 3.620623
Epoch 4849 
Prediction Loss: 3.599251
Epoch 4899 
Prediction Loss: 3.586884
Epoch 4949 
Prediction Loss: 3.552571
Epoch 4999 
Prediction Loss: 3.545511
Epoch 5049 
Prediction Loss: 3.506998
Epoch 5099 
Prediction Loss: 3.489683
Epoch 5149 
Prediction Loss: 3.463764
Epoch 5199 
Prediction Loss: 3.494272
Epoch 5249 
Prediction Loss: 3.488798
Epoch 5299 
Prediction Loss: 3.444447
Epoch 5349 
Prediction Loss: 3.451964
Epoch 5399 
Prediction Loss: 3.448568
Epoch 5449 
Prediction Loss: 3.422686
Epoch 5499 
Prediction Loss: 3.437253
Epoch 5549 
Prediction Loss: 3.409984
Epoch 5599 
Prediction Loss: 3.403383
Epoch 5649 
Prediction Loss: 3.374147
Epoch 5699 
Prediction Loss: 3.390354
Epoch 5749 
Prediction Loss: 3.345746
Epoch 5799 
Prediction Loss: 3.335107
Epoch 5849 
Prediction Loss: 3.341357
Epoch 5899 
Prediction Loss: 3.310963
Epoch 5949 
Prediction Loss: 3.350083
Epoch 5999 
Prediction Loss: 3.292118
[34m== Direct Regression: Testing in sample performance ==[0m
Train Error 1.811490
Insample Error 4.829388
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.537117
Rec Loss: 12.666187
KL Loss: 1.870930
Y Loss: 1.044239
T Loss: 12.144068
Epoch 99 
Overall Loss: 14.442634
Rec Loss: 12.348254
KL Loss: 2.094380
Y Loss: 0.997540
T Loss: 11.849484
Epoch 149 
Overall Loss: 14.424905
Rec Loss: 12.324653
KL Loss: 2.100252
Y Loss: 0.997154
T Loss: 11.826077
Epoch 199 
Overall Loss: 14.390134
Rec Loss: 12.310584
KL Loss: 2.079550
Y Loss: 1.016573
T Loss: 11.802297
Epoch 249 
Overall Loss: 14.405030
Rec Loss: 12.311337
KL Loss: 2.093693
Y Loss: 1.011670
T Loss: 11.805503
Epoch 299 
Overall Loss: 14.394245
Rec Loss: 12.304500
KL Loss: 2.089744
Y Loss: 1.003903
T Loss: 11.802549
Epoch 349 
Overall Loss: 14.388206
Rec Loss: 12.284216
KL Loss: 2.103990
Y Loss: 0.983284
T Loss: 11.792574
Epoch 399 
Overall Loss: 14.364904
Rec Loss: 12.294533
KL Loss: 2.070371
Y Loss: 1.011474
T Loss: 11.788796
Epoch 449 
Overall Loss: 14.384208
Rec Loss: 12.278960
KL Loss: 2.105248
Y Loss: 1.010449
T Loss: 11.773736
Epoch 499 
Overall Loss: 14.373379
Rec Loss: 12.288522
KL Loss: 2.084856
Y Loss: 0.974426
T Loss: 11.801309
Epoch 549 
Overall Loss: 14.360974
Rec Loss: 12.277318
KL Loss: 2.083656
Y Loss: 1.005546
T Loss: 11.774545
Epoch 599 
Overall Loss: 14.389427
Rec Loss: 12.294228
KL Loss: 2.095199
Y Loss: 1.014017
T Loss: 11.787219
Epoch 649 
Overall Loss: 14.375430
Rec Loss: 12.303723
KL Loss: 2.071707
Y Loss: 1.015850
T Loss: 11.795799
Epoch 699 
Overall Loss: 14.370075
Rec Loss: 12.292161
KL Loss: 2.077914
Y Loss: 1.003284
T Loss: 11.790519
Epoch 749 
Overall Loss: 14.342464
Rec Loss: 12.273177
KL Loss: 2.069287
Y Loss: 1.009167
T Loss: 11.768594
Epoch 799 
Overall Loss: 14.358963
Rec Loss: 12.283644
KL Loss: 2.075319
Y Loss: 1.010425
T Loss: 11.778432
Epoch 849 
Overall Loss: 14.359398
Rec Loss: 12.281580
KL Loss: 2.077818
Y Loss: 1.027087
T Loss: 11.768036
Epoch 899 
Overall Loss: 14.357722
Rec Loss: 12.268897
KL Loss: 2.088825
Y Loss: 1.011485
T Loss: 11.763154
Epoch 949 
Overall Loss: 14.366697
Rec Loss: 12.244610
KL Loss: 2.122088
Y Loss: 0.971665
T Loss: 11.758777
Epoch 999 
Overall Loss: 14.375303
Rec Loss: 12.276190
KL Loss: 2.099114
Y Loss: 1.007128
T Loss: 11.772626
Epoch 1049 
Overall Loss: 14.341792
Rec Loss: 12.261338
KL Loss: 2.080454
Y Loss: 1.004819
T Loss: 11.758929
Epoch 1099 
Overall Loss: 14.332375
Rec Loss: 12.265514
KL Loss: 2.066862
Y Loss: 1.015508
T Loss: 11.757759
Epoch 1149 
Overall Loss: 14.333155
Rec Loss: 12.253232
KL Loss: 2.079923
Y Loss: 0.992500
T Loss: 11.756982
Epoch 1199 
Overall Loss: 14.353355
Rec Loss: 12.275724
KL Loss: 2.077631
Y Loss: 1.037080
T Loss: 11.757184
Epoch 1249 
Overall Loss: 14.352446
Rec Loss: 12.255831
KL Loss: 2.096615
Y Loss: 1.009514
T Loss: 11.751074
Epoch 1299 
Overall Loss: 14.365267
Rec Loss: 12.269405
KL Loss: 2.095862
Y Loss: 0.985411
T Loss: 11.776699
Epoch 1349 
Overall Loss: 14.362184
Rec Loss: 12.262302
KL Loss: 2.099881
Y Loss: 1.023886
T Loss: 11.750359
Epoch 1399 
Overall Loss: 14.330957
Rec Loss: 12.244641
KL Loss: 2.086316
Y Loss: 1.002842
T Loss: 11.743220
Epoch 1449 
Overall Loss: 14.339143
Rec Loss: 12.248781
KL Loss: 2.090363
Y Loss: 0.999338
T Loss: 11.749112
Epoch 1499 
Overall Loss: 14.338592
Rec Loss: 12.225958
KL Loss: 2.112634
Y Loss: 1.004001
T Loss: 11.723958
Epoch 1549 
Overall Loss: 14.358830
Rec Loss: 12.265719
KL Loss: 2.093111
Y Loss: 1.014442
T Loss: 11.758498
Epoch 1599 
Overall Loss: 14.351487
Rec Loss: 12.266008
KL Loss: 2.085480
Y Loss: 1.029338
T Loss: 11.751339
Epoch 1649 
Overall Loss: 14.320947
Rec Loss: 12.243997
KL Loss: 2.076950
Y Loss: 1.020338
T Loss: 11.733828
Epoch 1699 
Overall Loss: 14.362730
Rec Loss: 12.237369
KL Loss: 2.125360
Y Loss: 0.991257
T Loss: 11.741741
Epoch 1749 
Overall Loss: 14.333342
Rec Loss: 12.232099
KL Loss: 2.101243
Y Loss: 1.008169
T Loss: 11.728015
Epoch 1799 
Overall Loss: 14.340137
Rec Loss: 12.251079
KL Loss: 2.089058
Y Loss: 1.011721
T Loss: 11.745218
Epoch 1849 
Overall Loss: 14.327919
Rec Loss: 12.245507
KL Loss: 2.082412
Y Loss: 0.995729
T Loss: 11.747642
Epoch 1899 
Overall Loss: 14.308766
Rec Loss: 12.234271
KL Loss: 2.074495
Y Loss: 0.991106
T Loss: 11.738718
Epoch 1949 
Overall Loss: 14.337824
Rec Loss: 12.251778
KL Loss: 2.086046
Y Loss: 1.022619
T Loss: 11.740469
Epoch 1999 
Overall Loss: 14.322894
Rec Loss: 12.227884
KL Loss: 2.095010
Y Loss: 1.006277
T Loss: 11.724745
Epoch 2049 
Overall Loss: 14.321092
Rec Loss: 12.228904
KL Loss: 2.092188
Y Loss: 0.972322
T Loss: 11.742744
Epoch 2099 
Overall Loss: 14.337866
Rec Loss: 12.242699
KL Loss: 2.095167
Y Loss: 1.027594
T Loss: 11.728902
Epoch 2149 
Overall Loss: 14.343439
Rec Loss: 12.258277
KL Loss: 2.085162
Y Loss: 1.013781
T Loss: 11.751387
Epoch 2199 
Overall Loss: 14.330588
Rec Loss: 12.256055
KL Loss: 2.074533
Y Loss: 1.015677
T Loss: 11.748217
Epoch 2249 
Overall Loss: 14.333692
Rec Loss: 12.230934
KL Loss: 2.102758
Y Loss: 1.005837
T Loss: 11.728015
Epoch 2299 
Overall Loss: 14.334587
Rec Loss: 12.251312
KL Loss: 2.083275
Y Loss: 1.022965
T Loss: 11.739829
Epoch 2349 
Overall Loss: 14.324655
Rec Loss: 12.232567
KL Loss: 2.092088
Y Loss: 1.022088
T Loss: 11.721523
Epoch 2399 
Overall Loss: 14.313694
Rec Loss: 12.229732
KL Loss: 2.083962
Y Loss: 0.979419
T Loss: 11.740022
Epoch 2449 
Overall Loss: 14.332813
Rec Loss: 12.220062
KL Loss: 2.112751
Y Loss: 0.987787
T Loss: 11.726169
Epoch 2499 
Overall Loss: 14.316151
Rec Loss: 12.236186
KL Loss: 2.079964
Y Loss: 1.014042
T Loss: 11.729165
Epoch 2549 
Overall Loss: 14.323973
Rec Loss: 12.232996
KL Loss: 2.090977
Y Loss: 1.029415
T Loss: 11.718289
Epoch 2599 
Overall Loss: 14.350639
Rec Loss: 12.258380
KL Loss: 2.092260
Y Loss: 1.025224
T Loss: 11.745767
Epoch 2649 
Overall Loss: 14.339229
Rec Loss: 12.247247
KL Loss: 2.091982
Y Loss: 1.029443
T Loss: 11.732525
Epoch 2699 
Overall Loss: 14.322710
Rec Loss: 12.223175
KL Loss: 2.099534
Y Loss: 0.974537
T Loss: 11.735907
Epoch 2749 
Overall Loss: 14.314699
Rec Loss: 12.240027
KL Loss: 2.074672
Y Loss: 1.015525
T Loss: 11.732265
Epoch 2799 
Overall Loss: 14.321778
Rec Loss: 12.234227
KL Loss: 2.087550
Y Loss: 0.984868
T Loss: 11.741793
Epoch 2849 
Overall Loss: 14.315859
Rec Loss: 12.233009
KL Loss: 2.082849
Y Loss: 1.027310
T Loss: 11.719355
Epoch 2899 
Overall Loss: 14.295353
Rec Loss: 12.212374
KL Loss: 2.082979
Y Loss: 0.998339
T Loss: 11.713204
Epoch 2949 
Overall Loss: 14.316575
Rec Loss: 12.221421
KL Loss: 2.095154
Y Loss: 1.023364
T Loss: 11.709738
Epoch 2999 
Overall Loss: 14.306115
Rec Loss: 12.226297
KL Loss: 2.079819
Y Loss: 1.006059
T Loss: 11.723267
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.532629
Epoch 99
Rec Loss: 1.522720
Epoch 149
Rec Loss: 1.516385
Epoch 199
Rec Loss: 1.518714
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.906062
Epoch 99
Rec Loss: 9.884921
Epoch 149
Rec Loss: 9.870793
Epoch 199
Rec Loss: 9.856139
Epoch 249
Rec Loss: 9.883527
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.459100
Insample Error: 1.347913
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 18.006209
Rec Loss: 14.188592
KL Loss: 3.817617
Y Loss: 5.635245
T Loss: 13.391635
X Loss: -2.020666
Epoch 99 
Overall Loss: -0.239701
Rec Loss: -9.137392
KL Loss: 8.897691
Y Loss: 2.225719
T Loss: 13.304558
X Loss: -23.554809
Epoch 149 
Overall Loss: -6.822168
Rec Loss: -16.918165
KL Loss: 10.095996
Y Loss: 1.333698
T Loss: 13.303514
X Loss: -30.888527
Epoch 199 
Overall Loss: -10.001423
Rec Loss: -21.114654
KL Loss: 11.113232
Y Loss: 0.743023
T Loss: 13.298454
X Loss: -34.784622
Epoch 249 
Overall Loss: -11.560243
Rec Loss: -23.065202
KL Loss: 11.504959
Y Loss: 0.539537
T Loss: 13.292209
X Loss: -36.627180
Epoch 299 
Overall Loss: -12.752957
Rec Loss: -24.673979
KL Loss: 11.921023
Y Loss: 0.458865
T Loss: 13.269269
X Loss: -38.172681
Epoch 349 
Overall Loss: -13.784609
Rec Loss: -25.967435
KL Loss: 12.182825
Y Loss: 0.439167
T Loss: 13.245969
X Loss: -39.432987
Epoch 399 
Overall Loss: -14.487943
Rec Loss: -26.933084
KL Loss: 12.445141
Y Loss: 0.437610
T Loss: 13.212361
X Loss: -40.364250
Epoch 449 
Overall Loss: -15.048842
Rec Loss: -27.644070
KL Loss: 12.595227
Y Loss: 0.393379
T Loss: 13.174811
X Loss: -41.015571
Epoch 499 
Overall Loss: -15.604460
Rec Loss: -28.444078
KL Loss: 12.839618
Y Loss: 0.385604
T Loss: 13.136633
X Loss: -41.773514
Epoch 549 
Overall Loss: -16.116382
Rec Loss: -29.038222
KL Loss: 12.921838
Y Loss: 0.378178
T Loss: 13.092494
X Loss: -42.319804
Epoch 599 
Overall Loss: -16.876274
Rec Loss: -30.088799
KL Loss: 13.212525
Y Loss: 0.353914
T Loss: 13.047989
X Loss: -43.313745
Epoch 649 
Overall Loss: -17.109563
Rec Loss: -30.463110
KL Loss: 13.353545
Y Loss: 0.335473
T Loss: 13.003384
X Loss: -43.634229
Epoch 699 
Overall Loss: -17.569146
Rec Loss: -31.017970
KL Loss: 13.448825
Y Loss: 0.324911
T Loss: 12.966227
X Loss: -44.146652
Epoch 749 
Overall Loss: -18.022966
Rec Loss: -31.701394
KL Loss: 13.678428
Y Loss: 0.293695
T Loss: 12.936283
X Loss: -44.784525
Epoch 799 
Overall Loss: -18.267325
Rec Loss: -31.953015
KL Loss: 13.685690
Y Loss: 0.292108
T Loss: 12.908917
X Loss: -45.007987
Epoch 849 
Overall Loss: -18.592722
Rec Loss: -32.345808
KL Loss: 13.753087
Y Loss: 0.283072
T Loss: 12.891686
X Loss: -45.379029
Epoch 899 
Overall Loss: -18.894580
Rec Loss: -32.856244
KL Loss: 13.961664
Y Loss: 0.260814
T Loss: 12.866958
X Loss: -45.853609
Epoch 949 
Overall Loss: -19.126060
Rec Loss: -33.231930
KL Loss: 14.105869
Y Loss: 0.248630
T Loss: 12.853869
X Loss: -46.210112
Epoch 999 
Overall Loss: -19.324412
Rec Loss: -33.459049
KL Loss: 14.134637
Y Loss: 0.238975
T Loss: 12.838933
X Loss: -46.417471
Epoch 1049 
Overall Loss: -19.720478
Rec Loss: -33.885290
KL Loss: 14.164812
Y Loss: 0.236442
T Loss: 12.825488
X Loss: -46.828998
Epoch 1099 
Overall Loss: -19.715025
Rec Loss: -33.913138
KL Loss: 14.198114
Y Loss: 0.236472
T Loss: 12.816225
X Loss: -46.847600
Epoch 1149 
Overall Loss: -20.099805
Rec Loss: -34.314209
KL Loss: 14.214403
Y Loss: 0.235595
T Loss: 12.803489
X Loss: -47.235495
Epoch 1199 
Overall Loss: -20.390186
Rec Loss: -34.869370
KL Loss: 14.479184
Y Loss: 0.214515
T Loss: 12.794518
X Loss: -47.771147
Epoch 1249 
Overall Loss: -20.720354
Rec Loss: -35.200546
KL Loss: 14.480191
Y Loss: 0.224410
T Loss: 12.786345
X Loss: -48.099095
Epoch 1299 
Overall Loss: -20.704227
Rec Loss: -35.217751
KL Loss: 14.513524
Y Loss: 0.221967
T Loss: 12.777832
X Loss: -48.106567
Epoch 1349 
Overall Loss: -20.888032
Rec Loss: -35.539684
KL Loss: 14.651653
Y Loss: 0.210530
T Loss: 12.767734
X Loss: -48.412682
Epoch 1399 
Overall Loss: -20.016701
Rec Loss: -34.688542
KL Loss: 14.671841
Y Loss: 0.207320
T Loss: 12.759200
X Loss: -47.551402
Epoch 1449 
Overall Loss: -21.195571
Rec Loss: -35.924631
KL Loss: 14.729060
Y Loss: 0.209229
T Loss: 12.752330
X Loss: -48.781576
Epoch 1499 
Overall Loss: -20.887931
Rec Loss: -35.575000
KL Loss: 14.687070
Y Loss: 0.218464
T Loss: 12.743681
X Loss: -48.427914
Epoch 1549 
Overall Loss: -20.908512
Rec Loss: -35.655092
KL Loss: 14.746581
Y Loss: 0.232162
T Loss: 12.745952
X Loss: -48.517125
Epoch 1599 
Overall Loss: -21.856952
Rec Loss: -36.643869
KL Loss: 14.786916
Y Loss: 0.214516
T Loss: 12.727690
X Loss: -49.478817
Epoch 1649 
Overall Loss: -22.023678
Rec Loss: -36.686408
KL Loss: 14.662731
Y Loss: 0.231622
T Loss: 12.725893
X Loss: -49.528114
Epoch 1699 
Overall Loss: -21.985345
Rec Loss: -36.755020
KL Loss: 14.769675
Y Loss: 0.235246
T Loss: 12.716054
X Loss: -49.588696
Epoch 1749 
Overall Loss: -22.296070
Rec Loss: -37.261681
KL Loss: 14.965611
Y Loss: 0.211785
T Loss: 12.695836
X Loss: -50.063410
Epoch 1799 
Overall Loss: -22.413074
Rec Loss: -37.369613
KL Loss: 14.956539
Y Loss: 0.218194
T Loss: 12.696560
X Loss: -50.175269
Epoch 1849 
Overall Loss: -22.522952
Rec Loss: -37.506604
KL Loss: 14.983651
Y Loss: 0.226114
T Loss: 12.683337
X Loss: -50.302997
Epoch 1899 
Overall Loss: -22.174471
Rec Loss: -37.175621
KL Loss: 15.001150
Y Loss: 0.224319
T Loss: 12.680263
X Loss: -49.968045
Epoch 1949 
Overall Loss: -22.896732
Rec Loss: -37.906247
KL Loss: 15.009515
Y Loss: 0.237483
T Loss: 12.672903
X Loss: -50.697891
Epoch 1999 
Overall Loss: -22.189111
Rec Loss: -37.206121
KL Loss: 15.017010
Y Loss: 0.235779
T Loss: 12.656443
X Loss: -49.980453
Epoch 2049 
Overall Loss: -23.074460
Rec Loss: -38.208718
KL Loss: 15.134259
Y Loss: 0.227442
T Loss: 12.647689
X Loss: -50.970129
Epoch 2099 
Overall Loss: -23.187296
Rec Loss: -38.304669
KL Loss: 15.117373
Y Loss: 0.230123
T Loss: 12.638035
X Loss: -51.057766
Epoch 2149 
Overall Loss: -22.953983
Rec Loss: -38.134093
KL Loss: 15.180111
Y Loss: 0.239708
T Loss: 12.631399
X Loss: -50.885347
Epoch 2199 
Overall Loss: -23.419366
Rec Loss: -38.632266
KL Loss: 15.212900
Y Loss: 0.236469
T Loss: 12.621504
X Loss: -51.372005
Epoch 2249 
Overall Loss: -23.709692
Rec Loss: -38.876952
KL Loss: 15.167261
Y Loss: 0.243342
T Loss: 12.611247
X Loss: -51.609871
Epoch 2299 
Overall Loss: -23.574277
Rec Loss: -38.796625
KL Loss: 15.222348
Y Loss: 0.246481
T Loss: 12.603065
X Loss: -51.522929
Epoch 2349 
Overall Loss: -23.795341
Rec Loss: -39.087818
KL Loss: 15.292476
Y Loss: 0.242401
T Loss: 12.590264
X Loss: -51.799282
Epoch 2399 
Overall Loss: -23.402241
Rec Loss: -38.753929
KL Loss: 15.351687
Y Loss: 0.235198
T Loss: 12.571621
X Loss: -51.443150
Epoch 2449 
Overall Loss: -23.940812
Rec Loss: -39.318298
KL Loss: 15.377486
Y Loss: 0.244448
T Loss: 12.566792
X Loss: -52.007315
Epoch 2499 
Overall Loss: -24.100802
Rec Loss: -39.410533
KL Loss: 15.309732
Y Loss: 0.243039
T Loss: 12.550286
X Loss: -52.082339
Epoch 2549 
Overall Loss: -23.795741
Rec Loss: -39.255634
KL Loss: 15.459893
Y Loss: 0.241335
T Loss: 12.530509
X Loss: -51.906810
Epoch 2599 
Overall Loss: -24.489731
Rec Loss: -39.859734
KL Loss: 15.370002
Y Loss: 0.249999
T Loss: 12.526986
X Loss: -52.511718
Epoch 2649 
Overall Loss: -24.431397
Rec Loss: -39.997524
KL Loss: 15.566127
Y Loss: 0.228612
T Loss: 12.495786
X Loss: -52.607614
Epoch 2699 
Overall Loss: -24.487538
Rec Loss: -39.956792
KL Loss: 15.469255
Y Loss: 0.254688
T Loss: 12.492942
X Loss: -52.577078
Epoch 2749 
Overall Loss: -24.555791
Rec Loss: -40.085293
KL Loss: 15.529503
Y Loss: 0.250106
T Loss: 12.464524
X Loss: -52.674870
Epoch 2799 
Overall Loss: -24.762925
Rec Loss: -40.294845
KL Loss: 15.531919
Y Loss: 0.251534
T Loss: 12.445468
X Loss: -52.866079
Epoch 2849 
Overall Loss: -24.888816
Rec Loss: -40.452628
KL Loss: 15.563812
Y Loss: 0.252477
T Loss: 12.461225
X Loss: -53.040092
Epoch 2899 
Overall Loss: -24.701425
Rec Loss: -40.131352
KL Loss: 15.429927
Y Loss: 0.266471
T Loss: 12.438370
X Loss: -52.702957
Epoch 2949 
Overall Loss: -25.005986
Rec Loss: -40.661804
KL Loss: 15.655818
Y Loss: 0.256254
T Loss: 12.404929
X Loss: -53.194860
Epoch 2999 
Overall Loss: -24.968057
Rec Loss: -40.744821
KL Loss: 15.776764
Y Loss: 0.233459
T Loss: 12.392139
X Loss: -53.253690
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.700749
Epoch 99
Rec Loss: 2.686978
Epoch 149
Rec Loss: 2.680933
Epoch 199
Rec Loss: 2.669421
Epoch 249
Rec Loss: 2.670086
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.004666
Epoch 99
Rec Loss: 0.001903
Epoch 149
Rec Loss: 0.001531
Epoch 199
Rec Loss: 0.001049
Epoch 249
Rec Loss: 0.001247
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.208134
Insample Error 2.255642
[34m== Direct Regression: Training all ==[0m
Epoch 49 
Prediction Loss: 7.151070
Epoch 99 
Prediction Loss: 6.841324
Epoch 149 
Prediction Loss: 6.597011
Epoch 199 
Prediction Loss: 6.489216
Epoch 249 
Prediction Loss: 6.440514
Epoch 299 
Prediction Loss: 6.390168
Epoch 349 
Prediction Loss: 6.346802
Epoch 399 
Prediction Loss: 6.279311
Epoch 449 
Prediction Loss: 6.258662
Epoch 499 
Prediction Loss: 6.216937
Epoch 549 
Prediction Loss: 6.168254
Epoch 599 
Prediction Loss: 6.132376
Epoch 649 
Prediction Loss: 6.076140
Epoch 699 
Prediction Loss: 6.059641
Epoch 749 
Prediction Loss: 5.994640
Epoch 799 
Prediction Loss: 5.952976
Epoch 849 
Prediction Loss: 5.927396
Epoch 899 
Prediction Loss: 5.929637
Epoch 949 
Prediction Loss: 5.822328
Epoch 999 
Prediction Loss: 5.805983
Epoch 1049 
Prediction Loss: 5.755166
Epoch 1099 
Prediction Loss: 5.705903
Epoch 1149 
Prediction Loss: 5.726878
Epoch 1199 
Prediction Loss: 5.655304
Epoch 1249 
Prediction Loss: 5.620881
Epoch 1299 
Prediction Loss: 5.546094
Epoch 1349 
Prediction Loss: 5.566135
Epoch 1399 
Prediction Loss: 5.492575
Epoch 1449 
Prediction Loss: 5.442949
Epoch 1499 
Prediction Loss: 5.397781
Epoch 1549 
Prediction Loss: 5.361320
Epoch 1599 
Prediction Loss: 5.348206
Epoch 1649 
Prediction Loss: 5.292973
Epoch 1699 
Prediction Loss: 5.282472
Epoch 1749 
Prediction Loss: 5.203550
Epoch 1799 
Prediction Loss: 5.216655
Epoch 1849 
Prediction Loss: 5.185407
Epoch 1899 
Prediction Loss: 5.204110
Epoch 1949 
Prediction Loss: 5.088329
Epoch 1999 
Prediction Loss: 5.073686
Epoch 2049 
Prediction Loss: 5.014651
Epoch 2099 
Prediction Loss: 4.996758
Epoch 2149 
Prediction Loss: 4.976157
Epoch 2199 
Prediction Loss: 4.931621
Epoch 2249 
Prediction Loss: 4.923139
Epoch 2299 
Prediction Loss: 4.882736
Epoch 2349 
Prediction Loss: 4.849904
Epoch 2399 
Prediction Loss: 4.815395
Epoch 2449 
Prediction Loss: 4.884840
Epoch 2499 
Prediction Loss: 4.795430
Epoch 2549 
Prediction Loss: 4.765904
Epoch 2599 
Prediction Loss: 4.752671
Epoch 2649 
Prediction Loss: 4.735409
Epoch 2699 
Prediction Loss: 4.729771
Epoch 2749 
Prediction Loss: 4.708487
Epoch 2799 
Prediction Loss: 4.642504
Epoch 2849 
Prediction Loss: 4.631502
Epoch 2899 
Prediction Loss: 4.601215
Epoch 2949 
Prediction Loss: 4.638629
Epoch 2999 
Prediction Loss: 4.584073
Epoch 3049 
Prediction Loss: 4.578087
Epoch 3099 
Prediction Loss: 4.614385
Epoch 3149 
Prediction Loss: 4.523212
Epoch 3199 
Prediction Loss: 4.525084
Epoch 3249 
Prediction Loss: 4.507820
Epoch 3299 
Prediction Loss: 4.500915
Epoch 3349 
Prediction Loss: 4.455071
Epoch 3399 
Prediction Loss: 4.434732
Epoch 3449 
Prediction Loss: 4.448345
Epoch 3499 
Prediction Loss: 4.423562
Epoch 3549 
Prediction Loss: 4.374547
Epoch 3599 
Prediction Loss: 4.358673
Epoch 3649 
Prediction Loss: 4.336624
Epoch 3699 
Prediction Loss: 4.340189
Epoch 3749 
Prediction Loss: 4.361293
Epoch 3799 
Prediction Loss: 4.339445
Epoch 3849 
Prediction Loss: 4.282725
Epoch 3899 
Prediction Loss: 4.269763
Epoch 3949 
Prediction Loss: 4.252839
Epoch 3999 
Prediction Loss: 4.303962
Epoch 4049 
Prediction Loss: 4.259334
Epoch 4099 
Prediction Loss: 4.241780
Epoch 4149 
Prediction Loss: 4.164639
Epoch 4199 
Prediction Loss: 4.169078
Epoch 4249 
Prediction Loss: 4.145960
Epoch 4299 
Prediction Loss: 4.138441
Epoch 4349 
Prediction Loss: 4.119188
Epoch 4399 
Prediction Loss: 4.124164
Epoch 4449 
Prediction Loss: 4.095781
Epoch 4499 
Prediction Loss: 4.068301
Epoch 4549 
Prediction Loss: 4.103520
Epoch 4599 
Prediction Loss: 4.065745
Epoch 4649 
Prediction Loss: 4.109570
Epoch 4699 
Prediction Loss: 4.020476
Epoch 4749 
Prediction Loss: 3.998292
Epoch 4799 
Prediction Loss: 4.053556
Epoch 4849 
Prediction Loss: 3.988685
Epoch 4899 
Prediction Loss: 3.991517
Epoch 4949 
Prediction Loss: 3.964517
Epoch 4999 
Prediction Loss: 3.951634
Epoch 5049 
Prediction Loss: 3.941477
Epoch 5099 
Prediction Loss: 3.906328
Epoch 5149 
Prediction Loss: 3.965253
Epoch 5199 
Prediction Loss: 3.901999
Epoch 5249 
Prediction Loss: 3.891184
Epoch 5299 
Prediction Loss: 3.914990
Epoch 5349 
Prediction Loss: 3.856318
Epoch 5399 
Prediction Loss: 3.861291
Epoch 5449 
Prediction Loss: 3.854128
Epoch 5499 
Prediction Loss: 3.818127
Epoch 5549 
Prediction Loss: 3.832559
Epoch 5599 
Prediction Loss: 3.820951
Epoch 5649 
Prediction Loss: 3.778772
Epoch 5699 
Prediction Loss: 3.767630
Epoch 5749 
Prediction Loss: 3.765712
Epoch 5799 
Prediction Loss: 3.766300
Epoch 5849 
Prediction Loss: 3.762835
Epoch 5899 
Prediction Loss: 3.771238
Epoch 5949 
Prediction Loss: 3.713990
Epoch 5999 
Prediction Loss: 3.714353
[34m== Direct Regression: Testing in sample performance ==[0m
Train Error 1.927654
Insample Error 4.760807
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.522606
Rec Loss: 12.545287
KL Loss: 1.977319
Y Loss: 1.038710
T Loss: 12.025932
Epoch 99 
Overall Loss: 14.452843
Rec Loss: 12.333150
KL Loss: 2.119693
Y Loss: 1.003153
T Loss: 11.831574
Epoch 149 
Overall Loss: 14.464842
Rec Loss: 12.323154
KL Loss: 2.141688
Y Loss: 1.010183
T Loss: 11.818062
Epoch 199 
Overall Loss: 14.434514
Rec Loss: 12.288912
KL Loss: 2.145602
Y Loss: 0.987587
T Loss: 11.795119
Epoch 249 
Overall Loss: 14.428275
Rec Loss: 12.303838
KL Loss: 2.124437
Y Loss: 1.002843
T Loss: 11.802417
Epoch 299 
Overall Loss: 14.400654
Rec Loss: 12.266469
KL Loss: 2.134185
Y Loss: 0.975843
T Loss: 11.778548
Epoch 349 
Overall Loss: 14.412759
Rec Loss: 12.290877
KL Loss: 2.121882
Y Loss: 1.015621
T Loss: 11.783066
Epoch 399 
Overall Loss: 14.381829
Rec Loss: 12.274750
KL Loss: 2.107078
Y Loss: 1.009893
T Loss: 11.769804
Epoch 449 
Overall Loss: 14.407521
Rec Loss: 12.301075
KL Loss: 2.106446
Y Loss: 1.052574
T Loss: 11.774788
Epoch 499 
Overall Loss: 14.378125
Rec Loss: 12.267282
KL Loss: 2.110843
Y Loss: 0.976987
T Loss: 11.778788
Epoch 549 
Overall Loss: 14.383169
Rec Loss: 12.254293
KL Loss: 2.128876
Y Loss: 1.010946
T Loss: 11.748821
Epoch 599 
Overall Loss: 14.363690
Rec Loss: 12.269160
KL Loss: 2.094530
Y Loss: 1.002418
T Loss: 11.767951
Epoch 649 
Overall Loss: 14.372722
Rec Loss: 12.288236
KL Loss: 2.084487
Y Loss: 1.024407
T Loss: 11.776032
Epoch 699 
Overall Loss: 14.363403
Rec Loss: 12.261594
KL Loss: 2.101809
Y Loss: 0.995622
T Loss: 11.763783
Epoch 749 
Overall Loss: 14.346742
Rec Loss: 12.265796
KL Loss: 2.080946
Y Loss: 1.016113
T Loss: 11.757739
Epoch 799 
Overall Loss: 14.331682
Rec Loss: 12.254565
KL Loss: 2.077117
Y Loss: 0.981258
T Loss: 11.763936
Epoch 849 
Overall Loss: 14.355054
Rec Loss: 12.270995
KL Loss: 2.084058
Y Loss: 1.023853
T Loss: 11.759069
Epoch 899 
Overall Loss: 14.355177
Rec Loss: 12.266040
KL Loss: 2.089137
Y Loss: 0.989359
T Loss: 11.771361
Epoch 949 
Overall Loss: 14.348826
Rec Loss: 12.273011
KL Loss: 2.075815
Y Loss: 1.031170
T Loss: 11.757426
Epoch 999 
Overall Loss: 14.362813
Rec Loss: 12.289068
KL Loss: 2.073744
Y Loss: 1.043780
T Loss: 11.767178
Epoch 1049 
Overall Loss: 14.361983
Rec Loss: 12.275561
KL Loss: 2.086422
Y Loss: 1.020387
T Loss: 11.765368
Epoch 1099 
Overall Loss: 14.334352
Rec Loss: 12.256815
KL Loss: 2.077537
Y Loss: 1.009941
T Loss: 11.751845
Epoch 1149 
Overall Loss: 14.342360
Rec Loss: 12.270114
KL Loss: 2.072246
Y Loss: 1.046352
T Loss: 11.746938
Epoch 1199 
Overall Loss: 14.342023
Rec Loss: 12.284487
KL Loss: 2.057536
Y Loss: 1.019617
T Loss: 11.774678
Epoch 1249 
Overall Loss: 14.342244
Rec Loss: 12.249293
KL Loss: 2.092951
Y Loss: 0.998357
T Loss: 11.750114
Epoch 1299 
Overall Loss: 14.335027
Rec Loss: 12.250673
KL Loss: 2.084354
Y Loss: 1.005787
T Loss: 11.747780
Epoch 1349 
Overall Loss: 14.335465
Rec Loss: 12.248426
KL Loss: 2.087039
Y Loss: 1.012641
T Loss: 11.742106
Epoch 1399 
Overall Loss: 14.331352
Rec Loss: 12.250108
KL Loss: 2.081244
Y Loss: 0.978353
T Loss: 11.760931
Epoch 1449 
Overall Loss: 14.340296
Rec Loss: 12.270487
KL Loss: 2.069810
Y Loss: 1.030340
T Loss: 11.755316
Epoch 1499 
Overall Loss: 14.345274
Rec Loss: 12.254973
KL Loss: 2.090300
Y Loss: 0.983787
T Loss: 11.763080
Epoch 1549 
Overall Loss: 14.344427
Rec Loss: 12.256146
KL Loss: 2.088281
Y Loss: 1.004184
T Loss: 11.754054
Epoch 1599 
Overall Loss: 14.333274
Rec Loss: 12.254187
KL Loss: 2.079087
Y Loss: 0.986626
T Loss: 11.760875
Epoch 1649 
Overall Loss: 14.316795
Rec Loss: 12.249219
KL Loss: 2.067577
Y Loss: 1.008104
T Loss: 11.745167
Epoch 1699 
Overall Loss: 14.341606
Rec Loss: 12.255669
KL Loss: 2.085938
Y Loss: 1.020210
T Loss: 11.745564
Epoch 1749 
Overall Loss: 14.359279
Rec Loss: 12.263446
KL Loss: 2.095834
Y Loss: 1.019071
T Loss: 11.753910
Epoch 1799 
Overall Loss: 14.347644
Rec Loss: 12.286904
KL Loss: 2.060740
Y Loss: 1.022183
T Loss: 11.775812
Epoch 1849 
Overall Loss: 14.334072
Rec Loss: 12.245839
KL Loss: 2.088233
Y Loss: 1.017960
T Loss: 11.736859
Epoch 1899 
Overall Loss: 14.324478
Rec Loss: 12.243700
KL Loss: 2.080777
Y Loss: 0.987360
T Loss: 11.750020
Epoch 1949 
Overall Loss: 14.341137
Rec Loss: 12.232969
KL Loss: 2.108168
Y Loss: 0.998856
T Loss: 11.733541
Epoch 1999 
Overall Loss: 14.309875
Rec Loss: 12.248489
KL Loss: 2.061386
Y Loss: 1.008588
T Loss: 11.744195
Epoch 2049 
Overall Loss: 14.347110
Rec Loss: 12.249998
KL Loss: 2.097112
Y Loss: 1.008271
T Loss: 11.745863
Epoch 2099 
Overall Loss: 14.337190
Rec Loss: 12.241583
KL Loss: 2.095607
Y Loss: 1.026678
T Loss: 11.728244
Epoch 2149 
Overall Loss: 14.316742
Rec Loss: 12.234456
KL Loss: 2.082286
Y Loss: 1.013499
T Loss: 11.727706
Epoch 2199 
Overall Loss: 14.327613
Rec Loss: 12.246321
KL Loss: 2.081292
Y Loss: 1.007276
T Loss: 11.742683
Epoch 2249 
Overall Loss: 14.346409
Rec Loss: 12.257077
KL Loss: 2.089332
Y Loss: 1.007967
T Loss: 11.753094
Epoch 2299 
Overall Loss: 14.333600
Rec Loss: 12.251799
KL Loss: 2.081801
Y Loss: 1.008043
T Loss: 11.747777
Epoch 2349 
Overall Loss: 14.344478
Rec Loss: 12.253261
KL Loss: 2.091217
Y Loss: 1.001379
T Loss: 11.752572
Epoch 2399 
Overall Loss: 14.309725
Rec Loss: 12.226790
KL Loss: 2.082935
Y Loss: 0.985224
T Loss: 11.734178
Epoch 2449 
Overall Loss: 14.331333
Rec Loss: 12.261921
KL Loss: 2.069413
Y Loss: 1.039897
T Loss: 11.741972
Epoch 2499 
Overall Loss: 14.299658
Rec Loss: 12.234658
KL Loss: 2.065000
Y Loss: 0.977224
T Loss: 11.746045
Epoch 2549 
Overall Loss: 14.324485
Rec Loss: 12.205613
KL Loss: 2.118872
Y Loss: 0.983367
T Loss: 11.713930
Epoch 2599 
Overall Loss: 14.317063
Rec Loss: 12.227658
KL Loss: 2.089405
Y Loss: 0.976518
T Loss: 11.739400
Epoch 2649 
Overall Loss: 14.311205
Rec Loss: 12.224138
KL Loss: 2.087067
Y Loss: 1.005534
T Loss: 11.721371
Epoch 2699 
Overall Loss: 14.291609
Rec Loss: 12.206814
KL Loss: 2.084795
Y Loss: 0.982329
T Loss: 11.715649
Epoch 2749 
Overall Loss: 14.325792
Rec Loss: 12.242969
KL Loss: 2.082823
Y Loss: 1.030975
T Loss: 11.727481
Epoch 2799 
Overall Loss: 14.302349
Rec Loss: 12.221305
KL Loss: 2.081044
Y Loss: 1.014549
T Loss: 11.714031
Epoch 2849 
Overall Loss: 14.302240
Rec Loss: 12.239609
KL Loss: 2.062631
Y Loss: 1.005523
T Loss: 11.736848
Epoch 2899 
Overall Loss: 14.321081
Rec Loss: 12.244511
KL Loss: 2.076570
Y Loss: 1.024454
T Loss: 11.732284
Epoch 2949 
Overall Loss: 14.322246
Rec Loss: 12.229172
KL Loss: 2.093074
Y Loss: 1.010423
T Loss: 11.723960
Epoch 2999 
Overall Loss: 14.314916
Rec Loss: 12.209809
KL Loss: 2.105107
Y Loss: 0.966450
T Loss: 11.726584
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.537730
Epoch 99
Rec Loss: 1.550855
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.861434
Epoch 99
Rec Loss: 9.847007
Epoch 149
Rec Loss: 9.856983
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.469480
Insample Error: 1.378492
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 18.979058
Rec Loss: 15.386272
KL Loss: 3.592786
Y Loss: 8.109521
T Loss: 13.451003
X Loss: -2.119492
Epoch 99 
Overall Loss: 1.991735
Rec Loss: -7.642374
KL Loss: 9.634108
Y Loss: 3.086674
T Loss: 13.305164
X Loss: -22.490874
Epoch 149 
Overall Loss: -3.214276
Rec Loss: -13.992430
KL Loss: 10.778155
Y Loss: 1.921619
T Loss: 13.301194
X Loss: -28.254433
Epoch 199 
Overall Loss: -6.874051
Rec Loss: -18.718480
KL Loss: 11.844429
Y Loss: 1.001549
T Loss: 13.299025
X Loss: -32.518281
Epoch 249 
Overall Loss: -9.344022
Rec Loss: -21.924543
KL Loss: 12.580521
Y Loss: 0.570510
T Loss: 13.289659
X Loss: -35.499457
Epoch 299 
Overall Loss: -10.986557
Rec Loss: -24.107199
KL Loss: 13.120642
Y Loss: 0.431901
T Loss: 13.274715
X Loss: -37.597865
Epoch 349 
Overall Loss: -12.071122
Rec Loss: -25.549014
KL Loss: 13.477893
Y Loss: 0.372339
T Loss: 13.256910
X Loss: -38.992094
Epoch 399 
Overall Loss: -12.941160
Rec Loss: -26.722909
KL Loss: 13.781749
Y Loss: 0.351221
T Loss: 13.243997
X Loss: -40.142517
Epoch 449 
Overall Loss: -13.782397
Rec Loss: -27.794552
KL Loss: 14.012155
Y Loss: 0.342680
T Loss: 13.219568
X Loss: -41.185462
Epoch 499 
Overall Loss: -14.478526
Rec Loss: -28.679658
KL Loss: 14.201133
Y Loss: 0.344588
T Loss: 13.194604
X Loss: -42.046557
Epoch 549 
Overall Loss: -14.945004
Rec Loss: -29.280223
KL Loss: 14.335218
Y Loss: 0.328744
T Loss: 13.168939
X Loss: -42.613533
Epoch 599 
Overall Loss: -15.552094
Rec Loss: -29.993406
KL Loss: 14.441312
Y Loss: 0.326012
T Loss: 13.128112
X Loss: -43.284525
Epoch 649 
Overall Loss: -15.546447
Rec Loss: -30.244382
KL Loss: 14.697936
Y Loss: 0.312275
T Loss: 13.098517
X Loss: -43.499037
Epoch 699 
Overall Loss: -16.372674
Rec Loss: -31.138149
KL Loss: 14.765476
Y Loss: 0.312607
T Loss: 13.057408
X Loss: -44.351862
Epoch 749 
Overall Loss: -16.778251
Rec Loss: -31.663795
KL Loss: 14.885545
Y Loss: 0.299025
T Loss: 13.017164
X Loss: -44.830472
Epoch 799 
Overall Loss: -17.169665
Rec Loss: -31.952425
KL Loss: 14.782759
Y Loss: 0.296873
T Loss: 12.990145
X Loss: -45.091007
Epoch 849 
Overall Loss: -17.525641
Rec Loss: -32.569641
KL Loss: 15.044000
Y Loss: 0.281053
T Loss: 12.955072
X Loss: -45.665240
Epoch 899 
Overall Loss: -17.540802
Rec Loss: -32.476585
KL Loss: 14.935783
Y Loss: 0.272270
T Loss: 12.932970
X Loss: -45.545690
Epoch 949 
Overall Loss: -17.900754
Rec Loss: -32.981205
KL Loss: 15.080452
Y Loss: 0.264380
T Loss: 12.911217
X Loss: -46.024611
Epoch 999 
Overall Loss: -18.017303
Rec Loss: -33.229404
KL Loss: 15.212101
Y Loss: 0.253643
T Loss: 12.887680
X Loss: -46.243907
Epoch 1049 
Overall Loss: -18.176374
Rec Loss: -33.171512
KL Loss: 14.995137
Y Loss: 0.270898
T Loss: 12.880582
X Loss: -46.187543
Epoch 1099 
Overall Loss: -18.871153
Rec Loss: -34.085208
KL Loss: 15.214055
Y Loss: 0.249977
T Loss: 12.864620
X Loss: -47.074816
Epoch 1149 
Overall Loss: -19.192724
Rec Loss: -34.460206
KL Loss: 15.267481
Y Loss: 0.235912
T Loss: 12.850715
X Loss: -47.428876
Epoch 1199 
Overall Loss: -19.207934
Rec Loss: -34.256651
KL Loss: 15.048717
Y Loss: 0.238073
T Loss: 12.846699
X Loss: -47.222386
Epoch 1249 
Overall Loss: -18.803236
Rec Loss: -33.997890
KL Loss: 15.194654
Y Loss: 0.236325
T Loss: 12.834967
X Loss: -46.951019
Epoch 1299 
Overall Loss: -20.033839
Rec Loss: -35.216444
KL Loss: 15.182605
Y Loss: 0.229300
T Loss: 12.827525
X Loss: -48.158619
Epoch 1349 
Overall Loss: -19.768025
Rec Loss: -34.910264
KL Loss: 15.142238
Y Loss: 0.237589
T Loss: 12.818298
X Loss: -47.847355
Epoch 1399 
Overall Loss: -20.424390
Rec Loss: -35.566978
KL Loss: 15.142589
Y Loss: 0.238841
T Loss: 12.816741
X Loss: -48.503140
Epoch 1449 
Overall Loss: -20.581903
Rec Loss: -35.748441
KL Loss: 15.166539
Y Loss: 0.230963
T Loss: 12.810426
X Loss: -48.674349
Epoch 1499 
Overall Loss: -20.824558
Rec Loss: -35.900080
KL Loss: 15.075522
Y Loss: 0.233128
T Loss: 12.800242
X Loss: -48.816886
Epoch 1549 
Overall Loss: -20.913574
Rec Loss: -35.964557
KL Loss: 15.050983
Y Loss: 0.231873
T Loss: 12.792982
X Loss: -48.873475
Epoch 1599 
Overall Loss: -21.182823
Rec Loss: -36.355902
KL Loss: 15.173078
Y Loss: 0.214744
T Loss: 12.779029
X Loss: -49.242302
Epoch 1649 
Overall Loss: -21.342349
Rec Loss: -36.500340
KL Loss: 15.157991
Y Loss: 0.208377
T Loss: 12.765330
X Loss: -49.369858
Epoch 1699 
Overall Loss: -21.181076
Rec Loss: -36.413658
KL Loss: 15.232582
Y Loss: 0.202591
T Loss: 12.747401
X Loss: -49.262354
Epoch 1749 
Overall Loss: -21.691431
Rec Loss: -36.879838
KL Loss: 15.188408
Y Loss: 0.200097
T Loss: 12.744991
X Loss: -49.724878
Epoch 1799 
Overall Loss: -21.903822
Rec Loss: -37.158016
KL Loss: 15.254195
Y Loss: 0.200805
T Loss: 12.729654
X Loss: -49.988071
Epoch 1849 
Overall Loss: -21.943775
Rec Loss: -37.181037
KL Loss: 15.237263
Y Loss: 0.204557
T Loss: 12.719379
X Loss: -50.002695
Epoch 1899 
Overall Loss: -22.032569
Rec Loss: -37.314166
KL Loss: 15.281596
Y Loss: 0.184838
T Loss: 12.709571
X Loss: -50.116154
Epoch 1949 
Overall Loss: -22.427084
Rec Loss: -37.767049
KL Loss: 15.339965
Y Loss: 0.191738
T Loss: 12.695515
X Loss: -50.558435
Epoch 1999 
Overall Loss: -22.541335
Rec Loss: -37.924188
KL Loss: 15.382852
Y Loss: 0.190602
T Loss: 12.677747
X Loss: -50.697234
Epoch 2049 
Overall Loss: -22.304734
Rec Loss: -37.680901
KL Loss: 15.376168
Y Loss: 0.187227
T Loss: 12.668144
X Loss: -50.442660
Epoch 2099 
Overall Loss: -22.871523
Rec Loss: -38.133853
KL Loss: 15.262329
Y Loss: 0.198805
T Loss: 12.665277
X Loss: -50.898532
Epoch 2149 
Overall Loss: -22.470064
Rec Loss: -37.808388
KL Loss: 15.338324
Y Loss: 0.183137
T Loss: 12.649664
X Loss: -50.549620
Epoch 2199 
Overall Loss: -23.046305
Rec Loss: -38.580073
KL Loss: 15.533768
Y Loss: 0.179273
T Loss: 12.633147
X Loss: -51.302855
Epoch 2249 
Overall Loss: -22.557406
Rec Loss: -38.106217
KL Loss: 15.548811
Y Loss: 0.187409
T Loss: 12.626219
X Loss: -50.826142
Epoch 2299 
Overall Loss: -22.728462
Rec Loss: -37.988630
KL Loss: 15.260167
Y Loss: 0.205181
T Loss: 12.620700
X Loss: -50.711921
Epoch 2349 
Overall Loss: -23.538932
Rec Loss: -39.000348
KL Loss: 15.461416
Y Loss: 0.195506
T Loss: 12.610218
X Loss: -51.708319
Epoch 2399 
Overall Loss: -23.574371
Rec Loss: -39.074928
KL Loss: 15.500556
Y Loss: 0.192337
T Loss: 12.584513
X Loss: -51.755609
Epoch 2449 
Overall Loss: -22.552892
Rec Loss: -37.993597
KL Loss: 15.440706
Y Loss: 0.203398
T Loss: 12.585096
X Loss: -50.680394
Epoch 2499 
Overall Loss: -23.816023
Rec Loss: -39.452478
KL Loss: 15.636456
Y Loss: 0.185338
T Loss: 12.566822
X Loss: -52.111969
Epoch 2549 
Overall Loss: -23.213831
Rec Loss: -38.799633
KL Loss: 15.585802
Y Loss: 0.190038
T Loss: 12.556143
X Loss: -51.450795
Epoch 2599 
Overall Loss: -23.713863
Rec Loss: -39.399338
KL Loss: 15.685476
Y Loss: 0.179808
T Loss: 12.552755
X Loss: -52.041998
Epoch 2649 
Overall Loss: -23.793034
Rec Loss: -39.465108
KL Loss: 15.672075
Y Loss: 0.194404
T Loss: 12.534439
X Loss: -52.096749
Epoch 2699 
Overall Loss: -23.774310
Rec Loss: -39.321503
KL Loss: 15.547193
Y Loss: 0.204984
T Loss: 12.531719
X Loss: -51.955715
Epoch 2749 
Overall Loss: -23.771570
Rec Loss: -39.366475
KL Loss: 15.594906
Y Loss: 0.198185
T Loss: 12.515718
X Loss: -51.981287
Epoch 2799 
Overall Loss: -24.326475
Rec Loss: -40.077674
KL Loss: 15.751199
Y Loss: 0.179070
T Loss: 12.500034
X Loss: -52.667243
Epoch 2849 
Overall Loss: -24.377068
Rec Loss: -40.126529
KL Loss: 15.749461
Y Loss: 0.194591
T Loss: 12.502328
X Loss: -52.726152
Epoch 2899 
Overall Loss: -23.992595
Rec Loss: -39.603037
KL Loss: 15.610442
Y Loss: 0.198086
T Loss: 12.500524
X Loss: -52.202603
Epoch 2949 
Overall Loss: -24.733538
Rec Loss: -40.465977
KL Loss: 15.732439
Y Loss: 0.189549
T Loss: 12.479459
X Loss: -53.040210
Epoch 2999 
Overall Loss: -24.536283
Rec Loss: -40.217703
KL Loss: 15.681420
Y Loss: 0.200761
T Loss: 12.467672
X Loss: -52.785754
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.779635
Epoch 99
Rec Loss: 2.781713
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.005034
Epoch 99
Rec Loss: 0.002743
Epoch 149
Rec Loss: 0.001653
Epoch 199
Rec Loss: 0.001466
Epoch 249
Rec Loss: 0.001048
Epoch 299
Rec Loss: 0.001399
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.176977
Insample Error 2.679532
[34m== Direct Regression: Training all ==[0m
Epoch 49 
Prediction Loss: 7.167573
Epoch 99 
Prediction Loss: 6.773479
Epoch 149 
Prediction Loss: 6.540634
Epoch 199 
Prediction Loss: 6.457028
Epoch 249 
Prediction Loss: 6.410731
Epoch 299 
Prediction Loss: 6.366221
Epoch 349 
Prediction Loss: 6.373254
Epoch 399 
Prediction Loss: 6.310026
Epoch 449 
Prediction Loss: 6.296378
Epoch 499 
Prediction Loss: 6.266641
Epoch 549 
Prediction Loss: 6.207280
Epoch 599 
Prediction Loss: 6.166007
Epoch 649 
Prediction Loss: 6.141173
Epoch 699 
Prediction Loss: 6.161799
Epoch 749 
Prediction Loss: 6.076563
Epoch 799 
Prediction Loss: 6.116957
Epoch 849 
Prediction Loss: 6.011691
Epoch 899 
Prediction Loss: 5.967093
Epoch 949 
Prediction Loss: 5.959236
Epoch 999 
Prediction Loss: 5.889102
Epoch 1049 
Prediction Loss: 5.860138
Epoch 1099 
Prediction Loss: 5.834510
Epoch 1149 
Prediction Loss: 5.852683
Epoch 1199 
Prediction Loss: 5.804781
Epoch 1249 
Prediction Loss: 5.712014
Epoch 1299 
Prediction Loss: 5.707400
Epoch 1349 
Prediction Loss: 5.697216
Epoch 1399 
Prediction Loss: 5.639028
Epoch 1449 
Prediction Loss: 5.572224
Epoch 1499 
Prediction Loss: 5.571267
Epoch 1549 
Prediction Loss: 5.527283
Epoch 1599 
Prediction Loss: 5.506007
Epoch 1649 
Prediction Loss: 5.476263
Epoch 1699 
Prediction Loss: 5.480685
Epoch 1749 
Prediction Loss: 5.417266
Epoch 1799 
Prediction Loss: 5.368411
Epoch 1849 
Prediction Loss: 5.398432
Epoch 1899 
Prediction Loss: 5.343488
Epoch 1949 
Prediction Loss: 5.249566
Epoch 1999 
Prediction Loss: 5.262726
Epoch 2049 
Prediction Loss: 5.281786
Epoch 2099 
Prediction Loss: 5.213744
Epoch 2149 
Prediction Loss: 5.171298
Epoch 2199 
Prediction Loss: 5.160595
Epoch 2249 
Prediction Loss: 5.105187
Epoch 2299 
Prediction Loss: 5.188770
Epoch 2349 
Prediction Loss: 5.092360
Epoch 2399 
Prediction Loss: 5.016606
Epoch 2449 
Prediction Loss: 5.156731
Epoch 2499 
Prediction Loss: 4.992966
Epoch 2549 
Prediction Loss: 5.016580
Epoch 2599 
Prediction Loss: 4.968129
Epoch 2649 
Prediction Loss: 4.981690
Epoch 2699 
Prediction Loss: 4.908061
Epoch 2749 
Prediction Loss: 4.866807
Epoch 2799 
Prediction Loss: 4.947801
Epoch 2849 
Prediction Loss: 4.875409
Epoch 2899 
Prediction Loss: 4.902881
Epoch 2949 
Prediction Loss: 4.820721
Epoch 2999 
Prediction Loss: 4.784491
Epoch 3049 
Prediction Loss: 4.810385
Epoch 3099 
Prediction Loss: 4.774915
Epoch 3149 
Prediction Loss: 4.760082
Epoch 3199 
Prediction Loss: 4.742545
Epoch 3249 
Prediction Loss: 4.716512
Epoch 3299 
Prediction Loss: 4.667749
Epoch 3349 
Prediction Loss: 4.677577
Epoch 3399 
Prediction Loss: 4.669555
Epoch 3449 
Prediction Loss: 4.614027
Epoch 3499 
Prediction Loss: 4.598269
Epoch 3549 
Prediction Loss: 4.613908
Epoch 3599 
Prediction Loss: 4.559964
Epoch 3649 
Prediction Loss: 4.527488
Epoch 3699 
Prediction Loss: 4.604715
Epoch 3749 
Prediction Loss: 4.519260
Epoch 3799 
Prediction Loss: 4.515187
Epoch 3849 
Prediction Loss: 4.477398
Epoch 3899 
Prediction Loss: 4.465323
Epoch 3949 
Prediction Loss: 4.455664
Epoch 3999 
Prediction Loss: 4.413267
Epoch 4049 
Prediction Loss: 4.421848
Epoch 4099 
Prediction Loss: 4.424943
Epoch 4149 
Prediction Loss: 4.402997
Epoch 4199 
Prediction Loss: 4.359754
Epoch 4249 
Prediction Loss: 4.353263
Epoch 4299 
Prediction Loss: 4.374915
Epoch 4349 
Prediction Loss: 4.319246
Epoch 4399 
Prediction Loss: 4.340804
Epoch 4449 
Prediction Loss: 4.294975
Epoch 4499 
Prediction Loss: 4.277929
Epoch 4549 
Prediction Loss: 4.276786
Epoch 4599 
Prediction Loss: 4.253506
Epoch 4649 
Prediction Loss: 4.259842
Epoch 4699 
Prediction Loss: 4.264723
Epoch 4749 
Prediction Loss: 4.199558
Epoch 4799 
Prediction Loss: 4.234066
Epoch 4849 
Prediction Loss: 4.193782
Epoch 4899 
Prediction Loss: 4.156006
Epoch 4949 
Prediction Loss: 4.219037
Epoch 4999 
Prediction Loss: 4.141331
Epoch 5049 
Prediction Loss: 4.183971
Epoch 5099 
Prediction Loss: 4.164777
Epoch 5149 
Prediction Loss: 4.165559
Epoch 5199 
Prediction Loss: 4.108420
Epoch 5249 
Prediction Loss: 4.152327
Epoch 5299 
Prediction Loss: 4.075559
Epoch 5349 
Prediction Loss: 4.133353
Epoch 5399 
Prediction Loss: 4.058655
Epoch 5449 
Prediction Loss: 4.017670
Epoch 5499 
Prediction Loss: 4.008967
Epoch 5549 
Prediction Loss: 4.001133
Epoch 5599 
Prediction Loss: 4.021260
Epoch 5649 
Prediction Loss: 4.072001
Epoch 5699 
Prediction Loss: 3.960182
Epoch 5749 
Prediction Loss: 3.999650
Epoch 5799 
Prediction Loss: 3.950509
Epoch 5849 
Prediction Loss: 3.954163
Epoch 5899 
Prediction Loss: 3.933964
Epoch 5949 
Prediction Loss: 3.903190
Epoch 5999 
Prediction Loss: 3.895644
[34m== Direct Regression: Testing in sample performance ==[0m
Train Error 1.970660
Insample Error 4.686182
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.562740
Rec Loss: 12.673549
KL Loss: 1.889190
Y Loss: 1.056925
T Loss: 12.145087
Epoch 99 
Overall Loss: 14.465976
Rec Loss: 12.313348
KL Loss: 2.152628
Y Loss: 0.988124
T Loss: 11.819286
Epoch 149 
Overall Loss: 14.433470
Rec Loss: 12.310260
KL Loss: 2.123210
Y Loss: 0.992202
T Loss: 11.814159
Epoch 199 
Overall Loss: 14.441535
Rec Loss: 12.302334
KL Loss: 2.139200
Y Loss: 1.017386
T Loss: 11.793641
Epoch 249 
Overall Loss: 14.413633
Rec Loss: 12.309860
KL Loss: 2.103773
Y Loss: 1.000088
T Loss: 11.809816
Epoch 299 
Overall Loss: 14.385600
Rec Loss: 12.261140
KL Loss: 2.124460
Y Loss: 0.978844
T Loss: 11.771718
Epoch 349 
Overall Loss: 14.387624
Rec Loss: 12.292731
KL Loss: 2.094894
Y Loss: 1.026978
T Loss: 11.779242
Epoch 399 
Overall Loss: 14.384221
Rec Loss: 12.292249
KL Loss: 2.091972
Y Loss: 0.997815
T Loss: 11.793341
Epoch 449 
Overall Loss: 14.374144
Rec Loss: 12.265658
KL Loss: 2.108486
Y Loss: 1.009155
T Loss: 11.761080
Epoch 499 
Overall Loss: 14.387415
Rec Loss: 12.285189
KL Loss: 2.102226
Y Loss: 1.020050
T Loss: 11.775164
Epoch 549 
Overall Loss: 14.389444
Rec Loss: 12.274900
KL Loss: 2.114544
Y Loss: 1.022398
T Loss: 11.763701
Epoch 599 
Overall Loss: 14.367666
Rec Loss: 12.279728
KL Loss: 2.087938
Y Loss: 1.010726
T Loss: 11.774365
Epoch 649 
Overall Loss: 14.366946
Rec Loss: 12.273096
KL Loss: 2.093850
Y Loss: 1.022633
T Loss: 11.761780
Epoch 699 
Overall Loss: 14.364981
Rec Loss: 12.277831
KL Loss: 2.087149
Y Loss: 1.027265
T Loss: 11.764199
Epoch 749 
Overall Loss: 14.364560
Rec Loss: 12.274661
KL Loss: 2.089899
Y Loss: 1.027974
T Loss: 11.760674
Epoch 799 
Overall Loss: 14.363525
Rec Loss: 12.263387
KL Loss: 2.100137
Y Loss: 1.011252
T Loss: 11.757762
Epoch 849 
Overall Loss: 14.387202
Rec Loss: 12.291076
KL Loss: 2.096126
Y Loss: 1.036239
T Loss: 11.772957
Epoch 899 
Overall Loss: 14.345945
Rec Loss: 12.244377
KL Loss: 2.101567
Y Loss: 0.987052
T Loss: 11.750851
Epoch 949 
Overall Loss: 14.358505
Rec Loss: 12.255005
KL Loss: 2.103500
Y Loss: 0.998535
T Loss: 11.755737
Epoch 999 
Overall Loss: 14.353146
Rec Loss: 12.282636
KL Loss: 2.070510
Y Loss: 1.026140
T Loss: 11.769566
Epoch 1049 
Overall Loss: 14.368628
Rec Loss: 12.242426
KL Loss: 2.126203
Y Loss: 0.997857
T Loss: 11.743498
Epoch 1099 
Overall Loss: 14.363665
Rec Loss: 12.279594
KL Loss: 2.084071
Y Loss: 1.037564
T Loss: 11.760812
Epoch 1149 
Overall Loss: 14.371903
Rec Loss: 12.246261
KL Loss: 2.125642
Y Loss: 0.993361
T Loss: 11.749580
Epoch 1199 
Overall Loss: 14.333386
Rec Loss: 12.253193
KL Loss: 2.080193
Y Loss: 0.986339
T Loss: 11.760023
Epoch 1249 
Overall Loss: 14.354756
Rec Loss: 12.285306
KL Loss: 2.069450
Y Loss: 1.032467
T Loss: 11.769073
Epoch 1299 
Overall Loss: 14.353797
Rec Loss: 12.265536
KL Loss: 2.088262
Y Loss: 0.982333
T Loss: 11.774370
Epoch 1349 
Overall Loss: 14.347273
Rec Loss: 12.258234
KL Loss: 2.089039
Y Loss: 1.027483
T Loss: 11.744492
Epoch 1399 
Overall Loss: 14.352139
Rec Loss: 12.269559
KL Loss: 2.082580
Y Loss: 1.015456
T Loss: 11.761831
Epoch 1449 
Overall Loss: 14.322254
Rec Loss: 12.248520
KL Loss: 2.073734
Y Loss: 1.007849
T Loss: 11.744596
Epoch 1499 
Overall Loss: 14.347110
Rec Loss: 12.242717
KL Loss: 2.104393
Y Loss: 0.980156
T Loss: 11.752639
Epoch 1549 
Overall Loss: 14.344948
Rec Loss: 12.234603
KL Loss: 2.110344
Y Loss: 0.983564
T Loss: 11.742821
Epoch 1599 
Overall Loss: 14.343879
Rec Loss: 12.267335
KL Loss: 2.076543
Y Loss: 1.043327
T Loss: 11.745672
Epoch 1649 
Overall Loss: 14.333598
Rec Loss: 12.244078
KL Loss: 2.089520
Y Loss: 0.989510
T Loss: 11.749323
Epoch 1699 
Overall Loss: 14.339069
Rec Loss: 12.249195
KL Loss: 2.089874
Y Loss: 1.017772
T Loss: 11.740309
Epoch 1749 
Overall Loss: 14.336339
Rec Loss: 12.257514
KL Loss: 2.078826
Y Loss: 1.000207
T Loss: 11.757410
Epoch 1799 
Overall Loss: 14.338894
Rec Loss: 12.232012
KL Loss: 2.106881
Y Loss: 0.996351
T Loss: 11.733837
Epoch 1849 
Overall Loss: 14.334930
Rec Loss: 12.225755
KL Loss: 2.109174
Y Loss: 0.968736
T Loss: 11.741387
Epoch 1899 
Overall Loss: 14.350949
Rec Loss: 12.251592
KL Loss: 2.099356
Y Loss: 0.993990
T Loss: 11.754597
Epoch 1949 
Overall Loss: 14.336770
Rec Loss: 12.264548
KL Loss: 2.072222
Y Loss: 1.000720
T Loss: 11.764188
Epoch 1999 
Overall Loss: 14.338921
Rec Loss: 12.236718
KL Loss: 2.102203
Y Loss: 1.001218
T Loss: 11.736109
Epoch 2049 
Overall Loss: 14.348979
Rec Loss: 12.245983
KL Loss: 2.102996
Y Loss: 1.016016
T Loss: 11.737975
Epoch 2099 
Overall Loss: 14.305067
Rec Loss: 12.224837
KL Loss: 2.080229
Y Loss: 0.984323
T Loss: 11.732675
Epoch 2149 
Overall Loss: 14.335760
Rec Loss: 12.247187
KL Loss: 2.088573
Y Loss: 1.011951
T Loss: 11.741212
Epoch 2199 
Overall Loss: 14.333043
Rec Loss: 12.251152
KL Loss: 2.081891
Y Loss: 1.018003
T Loss: 11.742150
Epoch 2249 
Overall Loss: 14.340200
Rec Loss: 12.247793
KL Loss: 2.092406
Y Loss: 1.005335
T Loss: 11.745126
Epoch 2299 
Overall Loss: 14.322435
Rec Loss: 12.241881
KL Loss: 2.080554
Y Loss: 1.013051
T Loss: 11.735355
Epoch 2349 
Overall Loss: 14.334204
Rec Loss: 12.228676
KL Loss: 2.105528
Y Loss: 0.997192
T Loss: 11.730080
Epoch 2399 
Overall Loss: 14.314551
Rec Loss: 12.226390
KL Loss: 2.088161
Y Loss: 1.006620
T Loss: 11.723080
Epoch 2449 
Overall Loss: 14.327839
Rec Loss: 12.245136
KL Loss: 2.082703
Y Loss: 0.980975
T Loss: 11.754649
Epoch 2499 
Overall Loss: 14.331072
Rec Loss: 12.228059
KL Loss: 2.103013
Y Loss: 0.980937
T Loss: 11.737591
Epoch 2549 
Overall Loss: 14.315175
Rec Loss: 12.212416
KL Loss: 2.102759
Y Loss: 0.970531
T Loss: 11.727150
Epoch 2599 
Overall Loss: 14.296059
Rec Loss: 12.231925
KL Loss: 2.064134
Y Loss: 1.006582
T Loss: 11.728634
Epoch 2649 
Overall Loss: 14.317874
Rec Loss: 12.213499
KL Loss: 2.104376
Y Loss: 1.015032
T Loss: 11.705983
Epoch 2699 
Overall Loss: 14.332277
Rec Loss: 12.235212
KL Loss: 2.097064
Y Loss: 1.014755
T Loss: 11.727835
Epoch 2749 
Overall Loss: 14.337910
Rec Loss: 12.245961
KL Loss: 2.091949
Y Loss: 1.016658
T Loss: 11.737631
Epoch 2799 
Overall Loss: 14.328363
Rec Loss: 12.225771
KL Loss: 2.102593
Y Loss: 1.011071
T Loss: 11.720236
Epoch 2849 
Overall Loss: 14.285670
Rec Loss: 12.199769
KL Loss: 2.085901
Y Loss: 0.988222
T Loss: 11.705659
Epoch 2899 
Overall Loss: 14.317005
Rec Loss: 12.212171
KL Loss: 2.104834
Y Loss: 0.995496
T Loss: 11.714423
Epoch 2949 
Overall Loss: 14.331434
Rec Loss: 12.225831
KL Loss: 2.105604
Y Loss: 1.003759
T Loss: 11.723951
Epoch 2999 
Overall Loss: 14.322708
Rec Loss: 12.222698
KL Loss: 2.100011
Y Loss: 1.017415
T Loss: 11.713990
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.548535
Epoch 99
Rec Loss: 1.520523
Epoch 149
Rec Loss: 1.531281
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.862782
Epoch 99
Rec Loss: 9.864100
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.560217
Insample Error: 1.244190
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.310868
Rec Loss: 13.580267
KL Loss: 3.730600
Y Loss: 6.122562
T Loss: 13.423326
X Loss: -2.904339
Epoch 99 
Overall Loss: -1.150247
Rec Loss: -9.461071
KL Loss: 8.310825
Y Loss: 2.857159
T Loss: 13.375849
X Loss: -24.265500
Epoch 149 
Overall Loss: -6.732049
Rec Loss: -16.068693
KL Loss: 9.336644
Y Loss: 2.240201
T Loss: 13.366547
X Loss: -30.555341
Epoch 199 
Overall Loss: -10.195291
Rec Loss: -20.658578
KL Loss: 10.463287
Y Loss: 1.722862
T Loss: 13.340556
X Loss: -34.860565
Epoch 249 
Overall Loss: -12.085638
Rec Loss: -23.296544
KL Loss: 11.210906
Y Loss: 1.415278
T Loss: 13.321861
X Loss: -37.326044
Epoch 299 
Overall Loss: -13.600123
Rec Loss: -25.305418
KL Loss: 11.705294
Y Loss: 1.195960
T Loss: 13.289656
X Loss: -39.193054
Epoch 349 
Overall Loss: -14.742107
Rec Loss: -26.890596
KL Loss: 12.148489
Y Loss: 1.051076
T Loss: 13.263573
X Loss: -40.679707
Epoch 399 
Overall Loss: -15.820560
Rec Loss: -28.249977
KL Loss: 12.429417
Y Loss: 1.004600
T Loss: 13.229345
X Loss: -41.981621
Epoch 449 
Overall Loss: -16.302718
Rec Loss: -28.973644
KL Loss: 12.670925
Y Loss: 0.994760
T Loss: 13.184113
X Loss: -42.655136
Epoch 499 
Overall Loss: -17.087003
Rec Loss: -29.902076
KL Loss: 12.815073
Y Loss: 1.000549
T Loss: 13.143634
X Loss: -43.545984
Epoch 549 
Overall Loss: -17.701788
Rec Loss: -30.670113
KL Loss: 12.968325
Y Loss: 0.965674
T Loss: 13.088950
X Loss: -44.241900
Epoch 599 
Overall Loss: -18.263844
Rec Loss: -31.377520
KL Loss: 13.113675
Y Loss: 0.936044
T Loss: 13.042070
X Loss: -44.887613
Epoch 649 
Overall Loss: -18.791030
Rec Loss: -31.949961
KL Loss: 13.158931
Y Loss: 0.935680
T Loss: 12.993477
X Loss: -45.411278
Epoch 699 
Overall Loss: -19.277564
Rec Loss: -32.566098
KL Loss: 13.288533
Y Loss: 0.932703
T Loss: 12.956818
X Loss: -45.989266
Epoch 749 
Overall Loss: -19.538677
Rec Loss: -32.967590
KL Loss: 13.428914
Y Loss: 0.908932
T Loss: 12.938812
X Loss: -46.360868
Epoch 799 
Overall Loss: -19.896002
Rec Loss: -33.446226
KL Loss: 13.550224
Y Loss: 0.883130
T Loss: 12.918517
X Loss: -46.806309
Epoch 849 
Overall Loss: -20.401145
Rec Loss: -34.036972
KL Loss: 13.635827
Y Loss: 0.876039
T Loss: 12.912684
X Loss: -47.387675
Epoch 899 
Overall Loss: -20.545724
Rec Loss: -34.227529
KL Loss: 13.681805
Y Loss: 0.871939
T Loss: 12.906608
X Loss: -47.570106
Epoch 949 
Overall Loss: -20.525222
Rec Loss: -34.278986
KL Loss: 13.753765
Y Loss: 0.863208
T Loss: 12.903610
X Loss: -47.614200
Epoch 999 
Overall Loss: -21.188154
Rec Loss: -34.967988
KL Loss: 13.779835
Y Loss: 0.870668
T Loss: 12.904906
X Loss: -48.308228
Epoch 1049 
Overall Loss: -21.305406
Rec Loss: -35.211291
KL Loss: 13.905886
Y Loss: 0.837560
T Loss: 12.899534
X Loss: -48.529605
Epoch 1099 
Overall Loss: -21.738101
Rec Loss: -35.710032
KL Loss: 13.971932
Y Loss: 0.848256
T Loss: 12.893687
X Loss: -49.027848
Epoch 1149 
Overall Loss: -21.799881
Rec Loss: -35.802003
KL Loss: 14.002122
Y Loss: 0.844214
T Loss: 12.892437
X Loss: -49.116547
Epoch 1199 
Overall Loss: -22.148679
Rec Loss: -36.232208
KL Loss: 14.083530
Y Loss: 0.820227
T Loss: 12.885873
X Loss: -49.528196
Epoch 1249 
Overall Loss: -22.140329
Rec Loss: -36.207317
KL Loss: 14.066988
Y Loss: 0.833315
T Loss: 12.890691
X Loss: -49.514666
Epoch 1299 
Overall Loss: -22.307746
Rec Loss: -36.408823
KL Loss: 14.101076
Y Loss: 0.832597
T Loss: 12.876223
X Loss: -49.701344
Epoch 1349 
Overall Loss: -22.783583
Rec Loss: -36.982156
KL Loss: 14.198573
Y Loss: 0.812525
T Loss: 12.882874
X Loss: -50.271293
Epoch 1399 
Overall Loss: -22.368423
Rec Loss: -36.499252
KL Loss: 14.130830
Y Loss: 0.819394
T Loss: 12.880948
X Loss: -49.789897
Epoch 1449 
Overall Loss: -22.965911
Rec Loss: -37.090882
KL Loss: 14.124972
Y Loss: 0.815020
T Loss: 12.881057
X Loss: -50.379450
Epoch 1499 
Overall Loss: -23.066719
Rec Loss: -37.427945
KL Loss: 14.361226
Y Loss: 0.816731
T Loss: 12.872455
X Loss: -50.708766
Epoch 1549 
Overall Loss: -23.209385
Rec Loss: -37.489372
KL Loss: 14.279986
Y Loss: 0.829922
T Loss: 12.876319
X Loss: -50.780650
Epoch 1599 
Overall Loss: -23.462470
Rec Loss: -37.903853
KL Loss: 14.441383
Y Loss: 0.822330
T Loss: 12.872176
X Loss: -51.187194
Epoch 1649 
Overall Loss: -23.643628
Rec Loss: -38.119587
KL Loss: 14.475959
Y Loss: 0.811001
T Loss: 12.864699
X Loss: -51.389787
Epoch 1699 
Overall Loss: -23.743016
Rec Loss: -38.118959
KL Loss: 14.375944
Y Loss: 0.825665
T Loss: 12.870414
X Loss: -51.402207
Epoch 1749 
Overall Loss: -23.515683
Rec Loss: -38.022777
KL Loss: 14.507092
Y Loss: 0.810461
T Loss: 12.862072
X Loss: -51.290077
Epoch 1799 
Overall Loss: -24.002104
Rec Loss: -38.523177
KL Loss: 14.521073
Y Loss: 0.818280
T Loss: 12.856723
X Loss: -51.789040
Epoch 1849 
Overall Loss: -23.921990
Rec Loss: -38.485479
KL Loss: 14.563488
Y Loss: 0.798297
T Loss: 12.854292
X Loss: -51.738920
Epoch 1899 
Overall Loss: -24.376216
Rec Loss: -38.902106
KL Loss: 14.525889
Y Loss: 0.800213
T Loss: 12.866957
X Loss: -52.169168
Epoch 1949 
Overall Loss: -24.052701
Rec Loss: -38.622977
KL Loss: 14.570276
Y Loss: 0.795856
T Loss: 12.854647
X Loss: -51.875553
Epoch 1999 
Overall Loss: -24.683467
Rec Loss: -39.364118
KL Loss: 14.680651
Y Loss: 0.783936
T Loss: 12.854925
X Loss: -52.611011
Epoch 2049 
Overall Loss: -24.504616
Rec Loss: -39.156990
KL Loss: 14.652374
Y Loss: 0.809377
T Loss: 12.853540
X Loss: -52.415219
Epoch 2099 
Overall Loss: -24.749058
Rec Loss: -39.250127
KL Loss: 14.501069
Y Loss: 0.804853
T Loss: 12.853375
X Loss: -52.505928
Epoch 2149 
Overall Loss: -24.637899
Rec Loss: -39.355316
KL Loss: 14.717417
Y Loss: 0.791067
T Loss: 12.852131
X Loss: -52.602980
Epoch 2199 
Overall Loss: -24.828989
Rec Loss: -39.543026
KL Loss: 14.714036
Y Loss: 0.807000
T Loss: 12.849231
X Loss: -52.795757
Epoch 2249 
Overall Loss: -24.967098
Rec Loss: -39.671588
KL Loss: 14.704490
Y Loss: 0.788007
T Loss: 12.847530
X Loss: -52.913122
Epoch 2299 
Overall Loss: -25.133640
Rec Loss: -39.938760
KL Loss: 14.805120
Y Loss: 0.798732
T Loss: 12.845515
X Loss: -53.183640
Epoch 2349 
Overall Loss: -25.175295
Rec Loss: -39.928601
KL Loss: 14.753305
Y Loss: 0.805255
T Loss: 12.849206
X Loss: -53.180435
Epoch 2399 
Overall Loss: -25.500680
Rec Loss: -40.311808
KL Loss: 14.811127
Y Loss: 0.811576
T Loss: 12.849350
X Loss: -53.566945
Epoch 2449 
Overall Loss: -25.510495
Rec Loss: -40.367275
KL Loss: 14.856780
Y Loss: 0.800455
T Loss: 12.842911
X Loss: -53.610413
Epoch 2499 
Overall Loss: -25.603756
Rec Loss: -40.390584
KL Loss: 14.786828
Y Loss: 0.804330
T Loss: 12.841549
X Loss: -53.634299
Epoch 2549 
Overall Loss: -25.676517
Rec Loss: -40.645744
KL Loss: 14.969225
Y Loss: 0.777980
T Loss: 12.838927
X Loss: -53.873659
Epoch 2599 
Overall Loss: -25.894780
Rec Loss: -40.858158
KL Loss: 14.963377
Y Loss: 0.777580
T Loss: 12.837050
X Loss: -54.083998
Epoch 2649 
Overall Loss: -25.947825
Rec Loss: -40.808160
KL Loss: 14.860336
Y Loss: 0.811637
T Loss: 12.838904
X Loss: -54.052883
Epoch 2699 
Overall Loss: -25.460670
Rec Loss: -40.276168
KL Loss: 14.815499
Y Loss: 0.807621
T Loss: 12.838031
X Loss: -53.518009
Epoch 2749 
Overall Loss: -26.083425
Rec Loss: -41.057925
KL Loss: 14.974500
Y Loss: 0.797530
T Loss: 12.837195
X Loss: -54.293883
Epoch 2799 
Overall Loss: -25.806870
Rec Loss: -40.691712
KL Loss: 14.884842
Y Loss: 0.805161
T Loss: 12.834241
X Loss: -53.928534
Epoch 2849 
Overall Loss: -25.672335
Rec Loss: -40.663458
KL Loss: 14.991123
Y Loss: 0.795101
T Loss: 12.826258
X Loss: -53.887265
Epoch 2899 
Overall Loss: -26.436882
Rec Loss: -41.516171
KL Loss: 15.079289
Y Loss: 0.762055
T Loss: 12.830646
X Loss: -54.727846
Epoch 2949 
Overall Loss: -26.518959
Rec Loss: -41.574980
KL Loss: 15.056021
Y Loss: 0.807248
T Loss: 12.829977
X Loss: -54.808581
Epoch 2999 
Overall Loss: -26.479452
Rec Loss: -41.563449
KL Loss: 15.083996
Y Loss: 0.788213
T Loss: 12.828978
X Loss: -54.786532
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 3.008531
Epoch 99
Rec Loss: 3.005546
Epoch 149
Rec Loss: 2.997476
Epoch 199
Rec Loss: 2.987020
Epoch 249
Rec Loss: 2.991541
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.001996
Epoch 99
Rec Loss: 0.001007
Epoch 149
Rec Loss: 0.000809
Epoch 199
Rec Loss: 0.000742
Epoch 249
Rec Loss: 0.000509
Epoch 299
Rec Loss: 0.000834
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.349554
Insample Error 2.014591
[34m== Direct Regression: Training all ==[0m
Epoch 49 
Prediction Loss: 7.071885
Epoch 99 
Prediction Loss: 6.752579
Epoch 149 
Prediction Loss: 6.613440
Epoch 199 
Prediction Loss: 6.545900
Epoch 249 
Prediction Loss: 6.546226
Epoch 299 
Prediction Loss: 6.439002
Epoch 349 
Prediction Loss: 6.395293
Epoch 399 
Prediction Loss: 6.396602
Epoch 449 
Prediction Loss: 6.336597
Epoch 499 
Prediction Loss: 6.324203
Epoch 549 
Prediction Loss: 6.278077
Epoch 599 
Prediction Loss: 6.233164
Epoch 649 
Prediction Loss: 6.210799
Epoch 699 
Prediction Loss: 6.160324
Epoch 749 
Prediction Loss: 6.174942
Epoch 799 
Prediction Loss: 6.141410
Epoch 849 
Prediction Loss: 6.083096
Epoch 899 
Prediction Loss: 6.055321
Epoch 949 
Prediction Loss: 6.058230
Epoch 999 
Prediction Loss: 6.009983
Epoch 1049 
Prediction Loss: 5.952387
Epoch 1099 
Prediction Loss: 5.952856
Epoch 1149 
Prediction Loss: 5.928999
Epoch 1199 
Prediction Loss: 5.881386
Epoch 1249 
Prediction Loss: 5.849240
Epoch 1299 
Prediction Loss: 5.872757
Epoch 1349 
Prediction Loss: 5.801177
Epoch 1399 
Prediction Loss: 5.805095
Epoch 1449 
Prediction Loss: 5.773218
Epoch 1499 
Prediction Loss: 5.757053
Epoch 1549 
Prediction Loss: 5.710030
Epoch 1599 
Prediction Loss: 5.683156
Epoch 1649 
Prediction Loss: 5.647180
Epoch 1699 
Prediction Loss: 5.600193
Epoch 1749 
Prediction Loss: 5.576968
Epoch 1799 
Prediction Loss: 5.681852
Epoch 1849 
Prediction Loss: 5.513596
Epoch 1899 
Prediction Loss: 5.505590
Epoch 1949 
Prediction Loss: 5.461973
Epoch 1999 
Prediction Loss: 5.459966
Epoch 2049 
Prediction Loss: 5.412099
Epoch 2099 
Prediction Loss: 5.426602
Epoch 2149 
Prediction Loss: 5.366137
Epoch 2199 
Prediction Loss: 5.386929
Epoch 2249 
Prediction Loss: 5.340354
Epoch 2299 
Prediction Loss: 5.313167
Epoch 2349 
Prediction Loss: 5.241512
Epoch 2399 
Prediction Loss: 5.215945
Epoch 2449 
Prediction Loss: 5.190841
Epoch 2499 
Prediction Loss: 5.183253
Epoch 2549 
Prediction Loss: 5.189031
Epoch 2599 
Prediction Loss: 5.151822
Epoch 2649 
Prediction Loss: 5.106184
Epoch 2699 
Prediction Loss: 5.157915
Epoch 2749 
Prediction Loss: 5.074336
Epoch 2799 
Prediction Loss: 5.064246
Epoch 2849 
Prediction Loss: 5.039316
Epoch 2899 
Prediction Loss: 5.045623
Epoch 2949 
Prediction Loss: 4.967094
Epoch 2999 
Prediction Loss: 5.017238
Epoch 3049 
Prediction Loss: 4.960144
Epoch 3099 
Prediction Loss: 4.935251
Epoch 3149 
Prediction Loss: 4.934640
Epoch 3199 
Prediction Loss: 4.938142
Epoch 3249 
Prediction Loss: 4.862803
Epoch 3299 
Prediction Loss: 4.857221
Epoch 3349 
Prediction Loss: 4.858336
Epoch 3399 
Prediction Loss: 4.835750
Epoch 3449 
Prediction Loss: 4.809932
Epoch 3499 
Prediction Loss: 4.854798
Epoch 3549 
Prediction Loss: 4.951192
Epoch 3599 
Prediction Loss: 4.744308
Epoch 3649 
Prediction Loss: 4.727894
Epoch 3699 
Prediction Loss: 4.723467
Epoch 3749 
Prediction Loss: 4.715918
Epoch 3799 
Prediction Loss: 4.744496
Epoch 3849 
Prediction Loss: 4.728636
Epoch 3899 
Prediction Loss: 4.729356
Epoch 3949 
Prediction Loss: 4.757812
Epoch 3999 
Prediction Loss: 4.681028
Epoch 4049 
Prediction Loss: 4.635224
Epoch 4099 
Prediction Loss: 4.624064
Epoch 4149 
Prediction Loss: 4.619831
Epoch 4199 
Prediction Loss: 4.643882
Epoch 4249 
Prediction Loss: 4.592861
Epoch 4299 
Prediction Loss: 4.714969
Epoch 4349 
Prediction Loss: 4.581194
Epoch 4399 
Prediction Loss: 4.542366
Epoch 4449 
Prediction Loss: 4.510594
Epoch 4499 
Prediction Loss: 4.556857
Epoch 4549 
Prediction Loss: 4.528000
Epoch 4599 
Prediction Loss: 4.590398
Epoch 4649 
Prediction Loss: 4.565428
Epoch 4699 
Prediction Loss: 4.457156
Epoch 4749 
Prediction Loss: 4.428415
Epoch 4799 
Prediction Loss: 4.420107
Epoch 4849 
Prediction Loss: 4.412683
Epoch 4899 
Prediction Loss: 4.390041
Epoch 4949 
Prediction Loss: 4.405304
Epoch 4999 
Prediction Loss: 4.403436
Epoch 5049 
Prediction Loss: 4.397055
Epoch 5099 
Prediction Loss: 4.347127
Epoch 5149 
Prediction Loss: 4.373928
Epoch 5199 
Prediction Loss: 4.337953
Epoch 5249 
Prediction Loss: 4.316171
Epoch 5299 
Prediction Loss: 4.341930
Epoch 5349 
Prediction Loss: 4.322103
Epoch 5399 
Prediction Loss: 4.308152
Epoch 5449 
Prediction Loss: 4.277720
Epoch 5499 
Prediction Loss: 4.269095
Epoch 5549 
Prediction Loss: 4.237991
Epoch 5599 
Prediction Loss: 4.252708
Epoch 5649 
Prediction Loss: 4.268443
Epoch 5699 
Prediction Loss: 4.228951
Epoch 5749 
Prediction Loss: 4.212701
Epoch 5799 
Prediction Loss: 4.183197
Epoch 5849 
Prediction Loss: 4.194614
Epoch 5899 
Prediction Loss: 4.151123
Epoch 5949 
Prediction Loss: 4.158823
Epoch 5999 
Prediction Loss: 4.207894
[34m== Direct Regression: Testing in sample performance ==[0m
Train Error 2.052269
Insample Error 4.654131
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.543517
Rec Loss: 12.695702
KL Loss: 1.847816
Y Loss: 1.020348
T Loss: 12.185528
Epoch 99 
Overall Loss: 14.462074
Rec Loss: 12.506535
KL Loss: 1.955539
Y Loss: 1.015133
T Loss: 11.998968
Epoch 149 
Overall Loss: 14.427534
Rec Loss: 12.313135
KL Loss: 2.114400
Y Loss: 1.017933
T Loss: 11.804168
Epoch 199 
Overall Loss: 14.408316
Rec Loss: 12.288458
KL Loss: 2.119858
Y Loss: 0.985475
T Loss: 11.795720
Epoch 249 
Overall Loss: 14.393761
Rec Loss: 12.287858
KL Loss: 2.105903
Y Loss: 1.018440
T Loss: 11.778638
Epoch 299 
Overall Loss: 14.401367
Rec Loss: 12.301260
KL Loss: 2.100107
Y Loss: 1.015268
T Loss: 11.793626
Epoch 349 
Overall Loss: 14.402546
Rec Loss: 12.300286
KL Loss: 2.102260
Y Loss: 1.033905
T Loss: 11.783333
Epoch 399 
Overall Loss: 14.381033
Rec Loss: 12.283095
KL Loss: 2.097938
Y Loss: 1.011890
T Loss: 11.777150
Epoch 449 
Overall Loss: 14.375186
Rec Loss: 12.264114
KL Loss: 2.111072
Y Loss: 0.995437
T Loss: 11.766395
Epoch 499 
Overall Loss: 14.372256
Rec Loss: 12.274688
KL Loss: 2.097569
Y Loss: 0.996888
T Loss: 11.776243
Epoch 549 
Overall Loss: 14.368886
Rec Loss: 12.282433
KL Loss: 2.086452
Y Loss: 1.004210
T Loss: 11.780328
Epoch 599 
Overall Loss: 14.374810
Rec Loss: 12.274431
KL Loss: 2.100379
Y Loss: 0.981190
T Loss: 11.783836
Epoch 649 
Overall Loss: 14.385912
Rec Loss: 12.298442
KL Loss: 2.087469
Y Loss: 1.021323
T Loss: 11.787781
Epoch 699 
Overall Loss: 14.360778
Rec Loss: 12.269466
KL Loss: 2.091312
Y Loss: 1.004832
T Loss: 11.767051
Epoch 749 
Overall Loss: 14.355607
Rec Loss: 12.253813
KL Loss: 2.101794
Y Loss: 0.991052
T Loss: 11.758287
Epoch 799 
Overall Loss: 14.362126
Rec Loss: 12.278228
KL Loss: 2.083898
Y Loss: 1.025213
T Loss: 11.765621
Epoch 849 
Overall Loss: 14.362791
Rec Loss: 12.277588
KL Loss: 2.085202
Y Loss: 1.003633
T Loss: 11.775772
Epoch 899 
Overall Loss: 14.356387
Rec Loss: 12.256972
KL Loss: 2.099415
Y Loss: 1.017673
T Loss: 11.748136
Epoch 949 
Overall Loss: 14.350205
Rec Loss: 12.288457
KL Loss: 2.061747
Y Loss: 1.068521
T Loss: 11.754197
Epoch 999 
Overall Loss: 14.350437
Rec Loss: 12.259472
KL Loss: 2.090965
Y Loss: 1.011079
T Loss: 11.753932
Epoch 1049 
Overall Loss: 14.372047
Rec Loss: 12.271142
KL Loss: 2.100905
Y Loss: 0.987943
T Loss: 11.777171
Epoch 1099 
Overall Loss: 14.360813
Rec Loss: 12.272424
KL Loss: 2.088389
Y Loss: 1.017837
T Loss: 11.763505
Epoch 1149 
Overall Loss: 14.381776
Rec Loss: 12.271791
KL Loss: 2.109984
Y Loss: 1.034397
T Loss: 11.754593
Epoch 1199 
Overall Loss: 14.341746
Rec Loss: 12.251226
KL Loss: 2.090520
Y Loss: 1.022757
T Loss: 11.739848
Epoch 1249 
Overall Loss: 14.320095
Rec Loss: 12.239695
KL Loss: 2.080399
Y Loss: 0.986558
T Loss: 11.746417
Epoch 1299 
Overall Loss: 14.349528
Rec Loss: 12.246783
KL Loss: 2.102746
Y Loss: 0.996437
T Loss: 11.748564
Epoch 1349 
Overall Loss: 14.324218
Rec Loss: 12.236846
KL Loss: 2.087372
Y Loss: 0.992236
T Loss: 11.740728
Epoch 1399 
Overall Loss: 14.343669
Rec Loss: 12.249219
KL Loss: 2.094451
Y Loss: 0.979022
T Loss: 11.759707
Epoch 1449 
Overall Loss: 14.342672
Rec Loss: 12.257948
KL Loss: 2.084723
Y Loss: 1.002261
T Loss: 11.756818
Epoch 1499 
Overall Loss: 14.360586
Rec Loss: 12.252221
KL Loss: 2.108365
Y Loss: 1.001798
T Loss: 11.751322
Epoch 1549 
Overall Loss: 14.332301
Rec Loss: 12.259652
KL Loss: 2.072648
Y Loss: 1.026486
T Loss: 11.746409
Epoch 1599 
Overall Loss: 14.328236
Rec Loss: 12.260004
KL Loss: 2.068232
Y Loss: 1.016499
T Loss: 11.751755
Epoch 1649 
Overall Loss: 14.327452
Rec Loss: 12.258652
KL Loss: 2.068799
Y Loss: 1.009012
T Loss: 11.754146
Epoch 1699 
Overall Loss: 14.345254
Rec Loss: 12.243960
KL Loss: 2.101294
Y Loss: 1.006029
T Loss: 11.740946
Epoch 1749 
Overall Loss: 14.336375
Rec Loss: 12.247511
KL Loss: 2.088864
Y Loss: 1.007217
T Loss: 11.743902
Epoch 1799 
Overall Loss: 14.346166
Rec Loss: 12.259370
KL Loss: 2.086797
Y Loss: 1.029263
T Loss: 11.744738
Epoch 1849 
Overall Loss: 14.341772
Rec Loss: 12.264846
KL Loss: 2.076926
Y Loss: 0.993473
T Loss: 11.768110
Epoch 1899 
Overall Loss: 14.335199
Rec Loss: 12.246259
KL Loss: 2.088940
Y Loss: 0.996527
T Loss: 11.747995
Epoch 1949 
Overall Loss: 14.325047
Rec Loss: 12.243597
KL Loss: 2.081450
Y Loss: 1.013393
T Loss: 11.736901
Epoch 1999 
Overall Loss: 14.323941
Rec Loss: 12.237697
KL Loss: 2.086244
Y Loss: 1.010517
T Loss: 11.732438
Epoch 2049 
Overall Loss: 14.339169
Rec Loss: 12.268844
KL Loss: 2.070325
Y Loss: 1.013171
T Loss: 11.762258
Epoch 2099 
Overall Loss: 14.338412
Rec Loss: 12.251925
KL Loss: 2.086487
Y Loss: 1.012126
T Loss: 11.745862
Epoch 2149 
Overall Loss: 14.333226
Rec Loss: 12.265731
KL Loss: 2.067496
Y Loss: 1.032792
T Loss: 11.749335
Epoch 2199 
Overall Loss: 14.333037
Rec Loss: 12.257761
KL Loss: 2.075275
Y Loss: 1.034830
T Loss: 11.740346
Epoch 2249 
Overall Loss: 14.314100
Rec Loss: 12.220095
KL Loss: 2.094006
Y Loss: 0.974167
T Loss: 11.733011
Epoch 2299 
Overall Loss: 14.316222
Rec Loss: 12.223969
KL Loss: 2.092254
Y Loss: 1.001099
T Loss: 11.723419
Epoch 2349 
Overall Loss: 14.312225
Rec Loss: 12.242181
KL Loss: 2.070044
Y Loss: 0.994759
T Loss: 11.744801
Epoch 2399 
Overall Loss: 14.329611
Rec Loss: 12.224256
KL Loss: 2.105355
Y Loss: 0.993756
T Loss: 11.727378
Epoch 2449 
Overall Loss: 14.345236
Rec Loss: 12.237578
KL Loss: 2.107659
Y Loss: 0.994113
T Loss: 11.740521
Epoch 2499 
Overall Loss: 14.316315
Rec Loss: 12.220760
KL Loss: 2.095556
Y Loss: 0.993379
T Loss: 11.724070
Epoch 2549 
Overall Loss: 14.302065
Rec Loss: 12.218256
KL Loss: 2.083809
Y Loss: 0.994025
T Loss: 11.721243
Epoch 2599 
Overall Loss: 14.324013
Rec Loss: 12.203042
KL Loss: 2.120971
Y Loss: 0.977726
T Loss: 11.714179
Epoch 2649 
Overall Loss: 14.295355
Rec Loss: 12.234918
KL Loss: 2.060437
Y Loss: 1.011745
T Loss: 11.729045
Epoch 2699 
Overall Loss: 14.325528
Rec Loss: 12.228601
KL Loss: 2.096927
Y Loss: 0.997141
T Loss: 11.730030
Epoch 2749 
Overall Loss: 14.325845
Rec Loss: 12.228704
KL Loss: 2.097140
Y Loss: 0.982714
T Loss: 11.737348
Epoch 2799 
Overall Loss: 14.328529
Rec Loss: 12.239512
KL Loss: 2.089018
Y Loss: 1.003425
T Loss: 11.737799
Epoch 2849 
Overall Loss: 14.312562
Rec Loss: 12.208499
KL Loss: 2.104063
Y Loss: 0.985049
T Loss: 11.715974
Epoch 2899 
Overall Loss: 14.318389
Rec Loss: 12.226435
KL Loss: 2.091954
Y Loss: 1.002549
T Loss: 11.725161
Epoch 2949 
Overall Loss: 14.310234
Rec Loss: 12.235837
KL Loss: 2.074398
Y Loss: 0.994110
T Loss: 11.738781
Epoch 2999 
Overall Loss: 14.307038
Rec Loss: 12.211491
KL Loss: 2.095547
Y Loss: 0.985368
T Loss: 11.718807
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.519775
Epoch 99
Rec Loss: 1.526980
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.882295
Epoch 99
Rec Loss: 9.866128
Epoch 149
Rec Loss: 9.860214
Epoch 199
Rec Loss: 9.847062
Epoch 249
Rec Loss: 9.839394
Epoch 299
Rec Loss: 9.835096
Epoch 349
Rec Loss: 9.839081
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.441761
Insample Error: 1.336966
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 18.407814
Rec Loss: 14.718877
KL Loss: 3.688938
Y Loss: 6.695825
T Loss: 13.411446
X Loss: -2.040482
Epoch 99 
Overall Loss: 3.376208
Rec Loss: -6.120409
KL Loss: 9.496617
Y Loss: 3.045529
T Loss: 13.306984
X Loss: -20.950157
Epoch 149 
Overall Loss: -2.383676
Rec Loss: -13.262898
KL Loss: 10.879223
Y Loss: 2.142715
T Loss: 13.295686
X Loss: -27.629942
Epoch 199 
Overall Loss: -6.676546
Rec Loss: -17.963109
KL Loss: 11.286563
Y Loss: 1.377742
T Loss: 13.284604
X Loss: -31.936583
Epoch 249 
Overall Loss: -10.080430
Rec Loss: -21.518491
KL Loss: 11.438061
Y Loss: 1.156294
T Loss: 13.276599
X Loss: -35.373237
Epoch 299 
Overall Loss: -11.851787
Rec Loss: -23.782901
KL Loss: 11.931115
Y Loss: 0.992214
T Loss: 13.246805
X Loss: -37.525813
Epoch 349 
Overall Loss: -12.907969
Rec Loss: -25.222908
KL Loss: 12.314939
Y Loss: 0.910039
T Loss: 13.228048
X Loss: -38.905975
Epoch 399 
Overall Loss: -13.747774
Rec Loss: -26.217469
KL Loss: 12.469696
Y Loss: 0.907083
T Loss: 13.202594
X Loss: -39.873606
Epoch 449 
Overall Loss: -14.509472
Rec Loss: -27.244399
KL Loss: 12.734928
Y Loss: 0.868592
T Loss: 13.182374
X Loss: -40.861068
Epoch 499 
Overall Loss: -15.104561
Rec Loss: -27.976286
KL Loss: 12.871725
Y Loss: 0.877655
T Loss: 13.156077
X Loss: -41.571190
Epoch 549 
Overall Loss: -15.567576
Rec Loss: -28.562153
KL Loss: 12.994577
Y Loss: 0.857070
T Loss: 13.121582
X Loss: -42.112271
Epoch 599 
Overall Loss: -16.084659
Rec Loss: -29.323930
KL Loss: 13.239270
Y Loss: 0.824448
T Loss: 13.098607
X Loss: -42.834760
Epoch 649 
Overall Loss: -16.407277
Rec Loss: -29.704850
KL Loss: 13.297573
Y Loss: 0.842440
T Loss: 13.068946
X Loss: -43.195015
Epoch 699 
Overall Loss: -17.009920
Rec Loss: -30.549297
KL Loss: 13.539377
Y Loss: 0.791361
T Loss: 13.043703
X Loss: -43.988681
Epoch 749 
Overall Loss: -17.370816
Rec Loss: -30.941105
KL Loss: 13.570289
Y Loss: 0.787882
T Loss: 13.015144
X Loss: -44.350190
Epoch 799 
Overall Loss: -17.718894
Rec Loss: -31.400073
KL Loss: 13.681179
Y Loss: 0.792014
T Loss: 12.990296
X Loss: -44.786376
Epoch 849 
Overall Loss: -18.063966
Rec Loss: -31.825874
KL Loss: 13.761906
Y Loss: 0.729067
T Loss: 12.975776
X Loss: -45.166182
Epoch 899 
Overall Loss: -18.016317
Rec Loss: -31.746446
KL Loss: 13.730130
Y Loss: 0.745965
T Loss: 12.963324
X Loss: -45.082754
Epoch 949 
Overall Loss: -18.505332
Rec Loss: -32.428501
KL Loss: 13.923169
Y Loss: 0.700224
T Loss: 12.943619
X Loss: -45.722232
Epoch 999 
Overall Loss: -18.634672
Rec Loss: -32.574222
KL Loss: 13.939550
Y Loss: 0.711675
T Loss: 12.939439
X Loss: -45.869499
Epoch 1049 
Overall Loss: -19.110551
Rec Loss: -33.193662
KL Loss: 14.083111
Y Loss: 0.688199
T Loss: 12.925162
X Loss: -46.462924
Epoch 1099 
Overall Loss: -19.106778
Rec Loss: -33.324767
KL Loss: 14.217989
Y Loss: 0.683006
T Loss: 12.915820
X Loss: -46.582090
Epoch 1149 
Overall Loss: -19.563004
Rec Loss: -33.786974
KL Loss: 14.223969
Y Loss: 0.687139
T Loss: 12.905860
X Loss: -47.036403
Epoch 1199 
Overall Loss: -19.332122
Rec Loss: -33.488833
KL Loss: 14.156710
Y Loss: 0.661317
T Loss: 12.899978
X Loss: -46.719469
Epoch 1249 
Overall Loss: -19.283305
Rec Loss: -33.604667
KL Loss: 14.321361
Y Loss: 0.633976
T Loss: 12.878033
X Loss: -46.799688
Epoch 1299 
Overall Loss: -20.001864
Rec Loss: -34.324175
KL Loss: 14.322310
Y Loss: 0.666053
T Loss: 12.877406
X Loss: -47.534606
Epoch 1349 
Overall Loss: -19.812427
Rec Loss: -34.252733
KL Loss: 14.440307
Y Loss: 0.628967
T Loss: 12.862767
X Loss: -47.429985
Epoch 1399 
Overall Loss: -20.541983
Rec Loss: -34.993646
KL Loss: 14.451662
Y Loss: 0.623574
T Loss: 12.868320
X Loss: -48.173753
Epoch 1449 
Overall Loss: -20.306010
Rec Loss: -34.738793
KL Loss: 14.432782
Y Loss: 0.648620
T Loss: 12.870320
X Loss: -47.933421
Epoch 1499 
Overall Loss: -20.063252
Rec Loss: -34.340865
KL Loss: 14.277611
Y Loss: 0.651529
T Loss: 12.862995
X Loss: -47.529624
Epoch 1549 
Overall Loss: -21.023264
Rec Loss: -35.651980
KL Loss: 14.628716
Y Loss: 0.611388
T Loss: 12.845784
X Loss: -48.803459
Epoch 1599 
Overall Loss: -20.663392
Rec Loss: -35.353625
KL Loss: 14.690233
Y Loss: 0.606433
T Loss: 12.840802
X Loss: -48.497643
Epoch 1649 
Overall Loss: -20.921602
Rec Loss: -35.345381
KL Loss: 14.423779
Y Loss: 0.619737
T Loss: 12.839955
X Loss: -48.495206
Epoch 1699 
Overall Loss: -21.139504
Rec Loss: -35.813032
KL Loss: 14.673528
Y Loss: 0.602486
T Loss: 12.826187
X Loss: -48.940463
Epoch 1749 
Overall Loss: -20.588713
Rec Loss: -35.287901
KL Loss: 14.699188
Y Loss: 0.587355
T Loss: 12.822896
X Loss: -48.404473
Epoch 1799 
Overall Loss: -21.719736
Rec Loss: -36.217795
KL Loss: 14.498059
Y Loss: 0.614551
T Loss: 12.833404
X Loss: -49.358475
Epoch 1849 
Overall Loss: -21.212888
Rec Loss: -35.865074
KL Loss: 14.652185
Y Loss: 0.558619
T Loss: 12.826487
X Loss: -48.970870
Epoch 1899 
Overall Loss: -20.930653
Rec Loss: -35.695239
KL Loss: 14.764586
Y Loss: 0.572991
T Loss: 12.825429
X Loss: -48.807164
Epoch 1949 
Overall Loss: -22.016956
Rec Loss: -36.879921
KL Loss: 14.862964
Y Loss: 0.544809
T Loss: 12.806947
X Loss: -49.959271
Epoch 1999 
Overall Loss: -22.204823
Rec Loss: -37.001520
KL Loss: 14.796697
Y Loss: 0.532385
T Loss: 12.806316
X Loss: -50.074029
Epoch 2049 
Overall Loss: -22.315737
Rec Loss: -37.226830
KL Loss: 14.911093
Y Loss: 0.519475
T Loss: 12.807355
X Loss: -50.293923
Epoch 2099 
Overall Loss: -22.496400
Rec Loss: -37.322674
KL Loss: 14.826274
Y Loss: 0.522316
T Loss: 12.799860
X Loss: -50.383693
Epoch 2149 
Overall Loss: -22.615463
Rec Loss: -37.452374
KL Loss: 14.836911
Y Loss: 0.511567
T Loss: 12.807145
X Loss: -50.515302
Epoch 2199 
Overall Loss: -22.795825
Rec Loss: -37.655515
KL Loss: 14.859691
Y Loss: 0.498634
T Loss: 12.811300
X Loss: -50.716132
Epoch 2249 
Overall Loss: -22.465037
Rec Loss: -37.258585
KL Loss: 14.793548
Y Loss: 0.467700
T Loss: 12.808604
X Loss: -50.301040
Epoch 2299 
Overall Loss: -22.791236
Rec Loss: -37.615580
KL Loss: 14.824345
Y Loss: 0.471426
T Loss: 12.809131
X Loss: -50.660424
Epoch 2349 
Overall Loss: -22.787698
Rec Loss: -37.576396
KL Loss: 14.788699
Y Loss: 0.471681
T Loss: 12.821150
X Loss: -50.633387
Epoch 2399 
Overall Loss: -23.107097
Rec Loss: -37.899831
KL Loss: 14.792733
Y Loss: 0.457851
T Loss: 12.825649
X Loss: -50.954406
Epoch 2449 
Overall Loss: -22.776183
Rec Loss: -37.724373
KL Loss: 14.948189
Y Loss: 0.428278
T Loss: 12.809068
X Loss: -50.747579
Epoch 2499 
Overall Loss: -23.397842
Rec Loss: -38.303512
KL Loss: 14.905671
Y Loss: 0.438111
T Loss: 12.805511
X Loss: -51.328078
Epoch 2549 
Overall Loss: -23.274813
Rec Loss: -37.973680
KL Loss: 14.698868
Y Loss: 0.423526
T Loss: 12.816588
X Loss: -51.002031
Epoch 2599 
Overall Loss: -23.601397
Rec Loss: -38.411709
KL Loss: 14.810312
Y Loss: 0.425991
T Loss: 12.821832
X Loss: -51.446536
Epoch 2649 
Overall Loss: -23.559149
Rec Loss: -38.176024
KL Loss: 14.616875
Y Loss: 0.432704
T Loss: 12.823443
X Loss: -51.215818
Epoch 2699 
Overall Loss: -23.537583
Rec Loss: -38.428349
KL Loss: 14.890764
Y Loss: 0.418147
T Loss: 12.810012
X Loss: -51.447433
Epoch 2749 
Overall Loss: -23.486544
Rec Loss: -38.373840
KL Loss: 14.887296
Y Loss: 0.404822
T Loss: 12.806351
X Loss: -51.382603
Epoch 2799 
Overall Loss: -23.906191
Rec Loss: -38.517528
KL Loss: 14.611338
Y Loss: 0.424975
T Loss: 12.820843
X Loss: -51.550858
Epoch 2849 
Overall Loss: -24.026544
Rec Loss: -38.884997
KL Loss: 14.858452
Y Loss: 0.396565
T Loss: 12.794403
X Loss: -51.877682
Epoch 2899 
Overall Loss: -24.084686
Rec Loss: -38.848339
KL Loss: 14.763653
Y Loss: 0.402101
T Loss: 12.813187
X Loss: -51.862577
Epoch 2949 
Overall Loss: -24.034874
Rec Loss: -38.842008
KL Loss: 14.807132
Y Loss: 0.404854
T Loss: 12.809235
X Loss: -51.853669
Epoch 2999 
Overall Loss: -24.206588
Rec Loss: -39.336001
KL Loss: 15.129413
Y Loss: 0.381700
T Loss: 12.780862
X Loss: -52.307713
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.894809
Epoch 99
Rec Loss: 2.890571
Epoch 149
Rec Loss: 2.892616
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.005218
Epoch 99
Rec Loss: 0.002954
Epoch 149
Rec Loss: 0.001489
Epoch 199
Rec Loss: 0.001150
Epoch 249
Rec Loss: 0.001154
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.337531
Insample Error 2.666626
[34m== Direct Regression: Training all ==[0m
Epoch 49 
Prediction Loss: 7.241638
Epoch 99 
Prediction Loss: 6.940279
Epoch 149 
Prediction Loss: 6.706209
Epoch 199 
Prediction Loss: 6.534630
Epoch 249 
Prediction Loss: 6.446121
Epoch 299 
Prediction Loss: 6.392249
Epoch 349 
Prediction Loss: 6.318020
Epoch 399 
Prediction Loss: 6.260097
Epoch 449 
Prediction Loss: 6.207846
Epoch 499 
Prediction Loss: 6.142235
Epoch 549 
Prediction Loss: 6.103525
Epoch 599 
Prediction Loss: 6.052463
Epoch 649 
Prediction Loss: 6.037535
Epoch 699 
Prediction Loss: 5.958539
Epoch 749 
Prediction Loss: 5.935824
Epoch 799 
Prediction Loss: 5.883898
Epoch 849 
Prediction Loss: 5.817221
Epoch 899 
Prediction Loss: 5.735523
Epoch 949 
Prediction Loss: 5.681618
Epoch 999 
Prediction Loss: 5.629684
Epoch 1049 
Prediction Loss: 5.606160
Epoch 1099 
Prediction Loss: 5.511685
Epoch 1149 
Prediction Loss: 5.469592
Epoch 1199 
Prediction Loss: 5.437211
Epoch 1249 
Prediction Loss: 5.400394
Epoch 1299 
Prediction Loss: 5.321882
Epoch 1349 
Prediction Loss: 5.277895
Epoch 1399 
Prediction Loss: 5.218358
Epoch 1449 
Prediction Loss: 5.165312
Epoch 1499 
Prediction Loss: 5.131846
Epoch 1549 
Prediction Loss: 5.114234
Epoch 1599 
Prediction Loss: 5.081871
Epoch 1649 
Prediction Loss: 5.038946
Epoch 1699 
Prediction Loss: 5.000003
Epoch 1749 
Prediction Loss: 4.987944
Epoch 1799 
Prediction Loss: 4.911055
Epoch 1849 
Prediction Loss: 5.003690
Epoch 1899 
Prediction Loss: 4.854073
Epoch 1949 
Prediction Loss: 4.835563
Epoch 1999 
Prediction Loss: 4.841027
Epoch 2049 
Prediction Loss: 4.769682
Epoch 2099 
Prediction Loss: 4.785134
Epoch 2149 
Prediction Loss: 4.715254
Epoch 2199 
Prediction Loss: 4.667123
Epoch 2249 
Prediction Loss: 4.629087
Epoch 2299 
Prediction Loss: 4.614799
Epoch 2349 
Prediction Loss: 4.623580
Epoch 2399 
Prediction Loss: 4.616321
Epoch 2449 
Prediction Loss: 4.595307
Epoch 2499 
Prediction Loss: 4.512063
Epoch 2549 
Prediction Loss: 4.465464
Epoch 2599 
Prediction Loss: 4.454710
Epoch 2649 
Prediction Loss: 4.452449
Epoch 2699 
Prediction Loss: 4.403505
Epoch 2749 
Prediction Loss: 4.446376
Epoch 2799 
Prediction Loss: 4.352689
Epoch 2849 
Prediction Loss: 4.344372
Epoch 2899 
Prediction Loss: 4.318499
Epoch 2949 
Prediction Loss: 4.335566
Epoch 2999 
Prediction Loss: 4.313062
Epoch 3049 
Prediction Loss: 4.283792
Epoch 3099 
Prediction Loss: 4.226841
Epoch 3149 
Prediction Loss: 4.259355
Epoch 3199 
Prediction Loss: 4.205575
Epoch 3249 
Prediction Loss: 4.243480
Epoch 3299 
Prediction Loss: 4.176378
Epoch 3349 
Prediction Loss: 4.171060
Epoch 3399 
Prediction Loss: 4.143218
Epoch 3449 
Prediction Loss: 4.097603
Epoch 3499 
Prediction Loss: 4.111315
Epoch 3549 
Prediction Loss: 4.087045
Epoch 3599 
Prediction Loss: 4.104263
Epoch 3649 
Prediction Loss: 4.101170
Epoch 3699 
Prediction Loss: 4.062387
Epoch 3749 
Prediction Loss: 4.007505
Epoch 3799 
Prediction Loss: 3.998780
Epoch 3849 
Prediction Loss: 3.983406
Epoch 3899 
Prediction Loss: 3.947560
Epoch 3949 
Prediction Loss: 3.956336
Epoch 3999 
Prediction Loss: 3.934983
Epoch 4049 
Prediction Loss: 3.919717
Epoch 4099 
Prediction Loss: 3.963306
Epoch 4149 
Prediction Loss: 3.912476
Epoch 4199 
Prediction Loss: 3.875348
Epoch 4249 
Prediction Loss: 3.875320
Epoch 4299 
Prediction Loss: 3.842080
Epoch 4349 
Prediction Loss: 3.839550
Epoch 4399 
Prediction Loss: 3.866103
Epoch 4449 
Prediction Loss: 3.847286
Epoch 4499 
Prediction Loss: 3.815186
Epoch 4549 
Prediction Loss: 3.782712
Epoch 4599 
Prediction Loss: 3.801457
Epoch 4649 
Prediction Loss: 3.807437
Epoch 4699 
Prediction Loss: 3.784999
Epoch 4749 
Prediction Loss: 3.771413
Epoch 4799 
Prediction Loss: 3.729201
Epoch 4849 
Prediction Loss: 3.718225
Epoch 4899 
Prediction Loss: 3.707198
Epoch 4949 
Prediction Loss: 3.703032
Epoch 4999 
Prediction Loss: 3.764177
Epoch 5049 
Prediction Loss: 3.678680
Epoch 5099 
Prediction Loss: 3.688041
Epoch 5149 
Prediction Loss: 3.721024
Epoch 5199 
Prediction Loss: 3.648879
Epoch 5249 
Prediction Loss: 3.645024
Epoch 5299 
Prediction Loss: 3.616094
Epoch 5349 
Prediction Loss: 3.650804
Epoch 5399 
Prediction Loss: 3.632032
Epoch 5449 
Prediction Loss: 3.603025
Epoch 5499 
Prediction Loss: 3.577146
Epoch 5549 
Prediction Loss: 3.569082
Epoch 5599 
Prediction Loss: 3.628117
Epoch 5649 
Prediction Loss: 3.566751
Epoch 5699 
Prediction Loss: 3.540293
Epoch 5749 
Prediction Loss: 3.550346
Epoch 5799 
Prediction Loss: 3.548580
Epoch 5849 
Prediction Loss: 3.546607
Epoch 5899 
Prediction Loss: 3.508097
Epoch 5949 
Prediction Loss: 3.576631
Epoch 5999 
Prediction Loss: 3.558615
[34m== Direct Regression: Testing in sample performance ==[0m
Train Error 1.859904
Insample Error 4.714120
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.513010
Rec Loss: 12.651591
KL Loss: 1.861419
Y Loss: 1.006319
T Loss: 12.148431
Epoch 99 
Overall Loss: 14.437690
Rec Loss: 12.329298
KL Loss: 2.108392
Y Loss: 0.991649
T Loss: 11.833473
Epoch 149 
Overall Loss: 14.430562
Rec Loss: 12.302864
KL Loss: 2.127697
Y Loss: 0.986011
T Loss: 11.809859
Epoch 199 
Overall Loss: 14.413415
Rec Loss: 12.297295
KL Loss: 2.116120
Y Loss: 0.999485
T Loss: 11.797553
Epoch 249 
Overall Loss: 14.417837
Rec Loss: 12.304532
KL Loss: 2.113305
Y Loss: 0.998215
T Loss: 11.805425
Epoch 299 
Overall Loss: 14.406457
Rec Loss: 12.293081
KL Loss: 2.113376
Y Loss: 1.003537
T Loss: 11.791312
Epoch 349 
Overall Loss: 14.376825
Rec Loss: 12.279569
KL Loss: 2.097256
Y Loss: 1.009335
T Loss: 11.774901
Epoch 399 
Overall Loss: 14.396440
Rec Loss: 12.293494
KL Loss: 2.102946
Y Loss: 1.006833
T Loss: 11.790077
Epoch 449 
Overall Loss: 14.370335
Rec Loss: 12.269922
KL Loss: 2.100413
Y Loss: 0.970291
T Loss: 11.784777
Epoch 499 
Overall Loss: 14.376766
Rec Loss: 12.272028
KL Loss: 2.104738
Y Loss: 1.004568
T Loss: 11.769744
Epoch 549 
Overall Loss: 14.369371
Rec Loss: 12.268132
KL Loss: 2.101240
Y Loss: 0.989210
T Loss: 11.773527
Epoch 599 
Overall Loss: 14.375813
Rec Loss: 12.278545
KL Loss: 2.097269
Y Loss: 0.995754
T Loss: 11.780668
Epoch 649 
Overall Loss: 14.373947
Rec Loss: 12.282195
KL Loss: 2.091751
Y Loss: 1.015216
T Loss: 11.774588
Epoch 699 
Overall Loss: 14.369159
Rec Loss: 12.283274
KL Loss: 2.085885
Y Loss: 1.026992
T Loss: 11.769778
Epoch 749 
Overall Loss: 14.365085
Rec Loss: 12.280155
KL Loss: 2.084930
Y Loss: 1.018165
T Loss: 11.771072
Epoch 799 
Overall Loss: 14.377594
Rec Loss: 12.286448
KL Loss: 2.091146
Y Loss: 1.023788
T Loss: 11.774554
Epoch 849 
Overall Loss: 14.349456
Rec Loss: 12.257450
KL Loss: 2.092006
Y Loss: 0.996070
T Loss: 11.759415
Epoch 899 
Overall Loss: 14.358836
Rec Loss: 12.265880
KL Loss: 2.092956
Y Loss: 1.004617
T Loss: 11.763571
Epoch 949 
Overall Loss: 14.371447
Rec Loss: 12.285277
KL Loss: 2.086170
Y Loss: 1.015679
T Loss: 11.777437
Epoch 999 
Overall Loss: 14.340968
Rec Loss: 12.261515
KL Loss: 2.079453
Y Loss: 0.996615
T Loss: 11.763208
Epoch 1049 
Overall Loss: 14.340094
Rec Loss: 12.275223
KL Loss: 2.064871
Y Loss: 1.015869
T Loss: 11.767288
Epoch 1099 
Overall Loss: 14.354686
Rec Loss: 12.273014
KL Loss: 2.081673
Y Loss: 0.983838
T Loss: 11.781094
Epoch 1149 
Overall Loss: 14.349887
Rec Loss: 12.269594
KL Loss: 2.080293
Y Loss: 1.018272
T Loss: 11.760458
Epoch 1199 
Overall Loss: 14.349603
Rec Loss: 12.271086
KL Loss: 2.078517
Y Loss: 1.016421
T Loss: 11.762875
Epoch 1249 
Overall Loss: 14.352538
Rec Loss: 12.268542
KL Loss: 2.083996
Y Loss: 0.984790
T Loss: 11.776147
Epoch 1299 
Overall Loss: 14.364800
Rec Loss: 12.272256
KL Loss: 2.092545
Y Loss: 1.033344
T Loss: 11.755584
Epoch 1349 
Overall Loss: 14.361937
Rec Loss: 12.265491
KL Loss: 2.096446
Y Loss: 1.001299
T Loss: 11.764841
Epoch 1399 
Overall Loss: 14.359202
Rec Loss: 12.255724
KL Loss: 2.103478
Y Loss: 0.977425
T Loss: 11.767012
Epoch 1449 
Overall Loss: 14.333993
Rec Loss: 12.277795
KL Loss: 2.056198
Y Loss: 1.039120
T Loss: 11.758235
Epoch 1499 
Overall Loss: 14.334276
Rec Loss: 12.253110
KL Loss: 2.081165
Y Loss: 1.005916
T Loss: 11.750152
Epoch 1549 
Overall Loss: 14.366371
Rec Loss: 12.283335
KL Loss: 2.083035
Y Loss: 1.009606
T Loss: 11.778532
Epoch 1599 
Overall Loss: 14.322375
Rec Loss: 12.249748
KL Loss: 2.072627
Y Loss: 1.003316
T Loss: 11.748090
Epoch 1649 
Overall Loss: 14.329967
Rec Loss: 12.242890
KL Loss: 2.087076
Y Loss: 1.009051
T Loss: 11.738365
Epoch 1699 
Overall Loss: 14.343310
Rec Loss: 12.244401
KL Loss: 2.098909
Y Loss: 0.997805
T Loss: 11.745498
Epoch 1749 
Overall Loss: 14.335508
Rec Loss: 12.267244
KL Loss: 2.068264
Y Loss: 1.034304
T Loss: 11.750092
Epoch 1799 
Overall Loss: 14.340426
Rec Loss: 12.251599
KL Loss: 2.088827
Y Loss: 0.975682
T Loss: 11.763758
Epoch 1849 
Overall Loss: 14.357549
Rec Loss: 12.267102
KL Loss: 2.090447
Y Loss: 1.016848
T Loss: 11.758678
Epoch 1899 
Overall Loss: 14.344815
Rec Loss: 12.250836
KL Loss: 2.093979
Y Loss: 1.015508
T Loss: 11.743082
Epoch 1949 
Overall Loss: 14.321852
Rec Loss: 12.225317
KL Loss: 2.096535
Y Loss: 0.974757
T Loss: 11.737938
Epoch 1999 
Overall Loss: 14.330344
Rec Loss: 12.257457
KL Loss: 2.072887
Y Loss: 1.005136
T Loss: 11.754889
Epoch 2049 
Overall Loss: 14.325693
Rec Loss: 12.259049
KL Loss: 2.066644
Y Loss: 1.021140
T Loss: 11.748479
Epoch 2099 
Overall Loss: 14.322777
Rec Loss: 12.245458
KL Loss: 2.077319
Y Loss: 1.014438
T Loss: 11.738239
Epoch 2149 
Overall Loss: 14.335373
Rec Loss: 12.261023
KL Loss: 2.074350
Y Loss: 1.015529
T Loss: 11.753258
Epoch 2199 
Overall Loss: 14.368119
Rec Loss: 12.250545
KL Loss: 2.117574
Y Loss: 1.005404
T Loss: 11.747843
Epoch 2249 
Overall Loss: 14.323046
Rec Loss: 12.239870
KL Loss: 2.083176
Y Loss: 1.015827
T Loss: 11.731957
Epoch 2299 
Overall Loss: 14.335114
Rec Loss: 12.234157
KL Loss: 2.100957
Y Loss: 1.002846
T Loss: 11.732735
Epoch 2349 
Overall Loss: 14.319045
Rec Loss: 12.230890
KL Loss: 2.088155
Y Loss: 1.016539
T Loss: 11.722621
Epoch 2399 
Overall Loss: 14.322703
Rec Loss: 12.235398
KL Loss: 2.087306
Y Loss: 0.985718
T Loss: 11.742538
Epoch 2449 
Overall Loss: 14.328520
Rec Loss: 12.264897
KL Loss: 2.063623
Y Loss: 1.019944
T Loss: 11.754925
Epoch 2499 
Overall Loss: 14.335867
Rec Loss: 12.254027
KL Loss: 2.081840
Y Loss: 0.999696
T Loss: 11.754179
Epoch 2549 
Overall Loss: 14.326943
Rec Loss: 12.229912
KL Loss: 2.097031
Y Loss: 1.004828
T Loss: 11.727498
Epoch 2599 
Overall Loss: 14.332941
Rec Loss: 12.233088
KL Loss: 2.099853
Y Loss: 0.983658
T Loss: 11.741259
Epoch 2649 
Overall Loss: 14.336981
Rec Loss: 12.241900
KL Loss: 2.095082
Y Loss: 1.008144
T Loss: 11.737828
Epoch 2699 
Overall Loss: 14.322413
Rec Loss: 12.240294
KL Loss: 2.082119
Y Loss: 1.025238
T Loss: 11.727675
Epoch 2749 
Overall Loss: 14.312688
Rec Loss: 12.233825
KL Loss: 2.078862
Y Loss: 0.993977
T Loss: 11.736837
Epoch 2799 
Overall Loss: 14.324099
Rec Loss: 12.238192
KL Loss: 2.085907
Y Loss: 0.994702
T Loss: 11.740840
Epoch 2849 
Overall Loss: 14.330544
Rec Loss: 12.242935
KL Loss: 2.087610
Y Loss: 1.019188
T Loss: 11.733341
Epoch 2899 
Overall Loss: 14.312893
Rec Loss: 12.231829
KL Loss: 2.081064
Y Loss: 0.995780
T Loss: 11.733939
Epoch 2949 
Overall Loss: 14.325522
Rec Loss: 12.238173
KL Loss: 2.087350
Y Loss: 1.011197
T Loss: 11.732574
Epoch 2999 
Overall Loss: 14.326191
Rec Loss: 12.229146
KL Loss: 2.097045
Y Loss: 0.991267
T Loss: 11.733512
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.530694
Epoch 99
Rec Loss: 1.525461
Epoch 149
Rec Loss: 1.522147
Epoch 199
Rec Loss: 1.512919
Epoch 249
Rec Loss: 1.521594
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.883375
Epoch 99
Rec Loss: 9.846396
Epoch 149
Rec Loss: 9.842056
Epoch 199
Rec Loss: 9.853803
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.430794
Insample Error: 1.290544
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 18.316860
Rec Loss: 14.895000
KL Loss: 3.421860
Y Loss: 9.066022
T Loss: 13.516443
X Loss: -3.154454
Epoch 99 
Overall Loss: -1.383332
Rec Loss: -10.046549
KL Loss: 8.663218
Y Loss: 2.659596
T Loss: 13.366256
X Loss: -24.742604
Epoch 149 
Overall Loss: -7.222995
Rec Loss: -17.157740
KL Loss: 9.934745
Y Loss: 1.958048
T Loss: 13.351264
X Loss: -31.488028
Epoch 199 
Overall Loss: -10.612651
Rec Loss: -21.619294
KL Loss: 11.006643
Y Loss: 1.459313
T Loss: 13.342301
X Loss: -35.691252
Epoch 249 
Overall Loss: -12.494319
Rec Loss: -24.050517
KL Loss: 11.556198
Y Loss: 1.213641
T Loss: 13.327951
X Loss: -37.985290
Epoch 299 
Overall Loss: -13.802883
Rec Loss: -25.711967
KL Loss: 11.909085
Y Loss: 1.076527
T Loss: 13.315690
X Loss: -39.565921
Epoch 349 
Overall Loss: -14.593733
Rec Loss: -26.738899
KL Loss: 12.145167
Y Loss: 0.982497
T Loss: 13.300506
X Loss: -40.530654
Epoch 399 
Overall Loss: -15.626495
Rec Loss: -27.994734
KL Loss: 12.368239
Y Loss: 0.878704
T Loss: 13.280300
X Loss: -41.714387
Epoch 449 
Overall Loss: -16.137256
Rec Loss: -28.701635
KL Loss: 12.564379
Y Loss: 0.864388
T Loss: 13.258753
X Loss: -42.392582
Epoch 499 
Overall Loss: -16.878076
Rec Loss: -29.659546
KL Loss: 12.781469
Y Loss: 0.793675
T Loss: 13.220275
X Loss: -43.276657
Epoch 549 
Overall Loss: -17.463572
Rec Loss: -30.354234
KL Loss: 12.890662
Y Loss: 0.825601
T Loss: 13.191215
X Loss: -43.958251
Epoch 599 
Overall Loss: -17.827487
Rec Loss: -30.940584
KL Loss: 13.113098
Y Loss: 0.798786
T Loss: 13.148831
X Loss: -44.488808
Epoch 649 
Overall Loss: -18.049404
Rec Loss: -31.293158
KL Loss: 13.243754
Y Loss: 0.789044
T Loss: 13.117332
X Loss: -44.805012
Epoch 699 
Overall Loss: -18.786002
Rec Loss: -32.183364
KL Loss: 13.397361
Y Loss: 0.771374
T Loss: 13.061451
X Loss: -45.630502
Epoch 749 
Overall Loss: -19.166374
Rec Loss: -32.724345
KL Loss: 13.557972
Y Loss: 0.746799
T Loss: 13.010963
X Loss: -46.108709
Epoch 799 
Overall Loss: -19.570676
Rec Loss: -33.199947
KL Loss: 13.629271
Y Loss: 0.741752
T Loss: 12.948731
X Loss: -46.519553
Epoch 849 
Overall Loss: -19.889335
Rec Loss: -33.630158
KL Loss: 13.740824
Y Loss: 0.725815
T Loss: 12.887015
X Loss: -46.880081
Epoch 899 
Overall Loss: -20.219930
Rec Loss: -34.139156
KL Loss: 13.919226
Y Loss: 0.741935
T Loss: 12.836881
X Loss: -47.347006
Epoch 949 
Overall Loss: -19.893956
Rec Loss: -33.885606
KL Loss: 13.991651
Y Loss: 0.727378
T Loss: 12.790329
X Loss: -47.039625
Epoch 999 
Overall Loss: -20.667165
Rec Loss: -34.745014
KL Loss: 14.077849
Y Loss: 0.707881
T Loss: 12.749688
X Loss: -47.848644
Epoch 1049 
Overall Loss: -20.645086
Rec Loss: -34.785624
KL Loss: 14.140538
Y Loss: 0.724387
T Loss: 12.722299
X Loss: -47.870116
Epoch 1099 
Overall Loss: -21.230590
Rec Loss: -35.490051
KL Loss: 14.259461
Y Loss: 0.685209
T Loss: 12.673934
X Loss: -48.506590
Epoch 1149 
Overall Loss: -21.424161
Rec Loss: -35.759721
KL Loss: 14.335560
Y Loss: 0.712408
T Loss: 12.645417
X Loss: -48.761344
Epoch 1199 
Overall Loss: -21.492148
Rec Loss: -35.989455
KL Loss: 14.497307
Y Loss: 0.674741
T Loss: 12.612569
X Loss: -48.939394
Epoch 1249 
Overall Loss: -21.849279
Rec Loss: -36.386549
KL Loss: 14.537271
Y Loss: 0.671804
T Loss: 12.593646
X Loss: -49.316097
Epoch 1299 
Overall Loss: -21.903302
Rec Loss: -36.451725
KL Loss: 14.548423
Y Loss: 0.692822
T Loss: 12.577487
X Loss: -49.375623
Epoch 1349 
Overall Loss: -22.429846
Rec Loss: -37.039130
KL Loss: 14.609285
Y Loss: 0.674172
T Loss: 12.546905
X Loss: -49.923122
Epoch 1399 
Overall Loss: -21.887079
Rec Loss: -36.613272
KL Loss: 14.726194
Y Loss: 0.658560
T Loss: 12.553409
X Loss: -49.495962
Epoch 1449 
Overall Loss: -22.436260
Rec Loss: -37.174108
KL Loss: 14.737848
Y Loss: 0.661352
T Loss: 12.524767
X Loss: -50.029550
Epoch 1499 
Overall Loss: -22.295736
Rec Loss: -37.046505
KL Loss: 14.750769
Y Loss: 0.664777
T Loss: 12.512922
X Loss: -49.891816
Epoch 1549 
Overall Loss: -22.961364
Rec Loss: -37.880377
KL Loss: 14.919014
Y Loss: 0.663542
T Loss: 12.496911
X Loss: -50.709060
Epoch 1599 
Overall Loss: -23.108049
Rec Loss: -37.978139
KL Loss: 14.870090
Y Loss: 0.658690
T Loss: 12.480422
X Loss: -50.787906
Epoch 1649 
Overall Loss: -23.078699
Rec Loss: -37.816113
KL Loss: 14.737415
Y Loss: 0.698556
T Loss: 12.495089
X Loss: -50.660480
Epoch 1699 
Overall Loss: -23.321362
Rec Loss: -38.201512
KL Loss: 14.880148
Y Loss: 0.654273
T Loss: 12.471632
X Loss: -51.000278
Epoch 1749 
Overall Loss: -23.493419
Rec Loss: -38.421682
KL Loss: 14.928262
Y Loss: 0.676112
T Loss: 12.462689
X Loss: -51.222427
Epoch 1799 
Overall Loss: -23.604436
Rec Loss: -38.689590
KL Loss: 15.085154
Y Loss: 0.667063
T Loss: 12.455172
X Loss: -51.478293
Epoch 1849 
Overall Loss: -23.568988
Rec Loss: -38.671326
KL Loss: 15.102338
Y Loss: 0.648662
T Loss: 12.454635
X Loss: -51.450293
Epoch 1899 
Overall Loss: -23.486310
Rec Loss: -38.556285
KL Loss: 15.069976
Y Loss: 0.654459
T Loss: 12.436471
X Loss: -51.319986
Epoch 1949 
Overall Loss: -23.910170
Rec Loss: -39.001706
KL Loss: 15.091536
Y Loss: 0.675246
T Loss: 12.441225
X Loss: -51.780556
Epoch 1999 
Overall Loss: -24.213304
Rec Loss: -39.417210
KL Loss: 15.203907
Y Loss: 0.664466
T Loss: 12.437125
X Loss: -52.186567
Epoch 2049 
Overall Loss: -24.221207
Rec Loss: -39.241236
KL Loss: 15.020027
Y Loss: 0.683450
T Loss: 12.436536
X Loss: -52.019496
Epoch 2099 
Overall Loss: -23.841052
Rec Loss: -38.984976
KL Loss: 15.143923
Y Loss: 0.664085
T Loss: 12.426631
X Loss: -51.743649
Epoch 2149 
Overall Loss: -24.227409
Rec Loss: -39.445856
KL Loss: 15.218446
Y Loss: 0.675472
T Loss: 12.415368
X Loss: -52.198961
Epoch 2199 
Overall Loss: -24.495001
Rec Loss: -39.858466
KL Loss: 15.363466
Y Loss: 0.644865
T Loss: 12.409785
X Loss: -52.590684
Epoch 2249 
Overall Loss: -24.395082
Rec Loss: -39.710094
KL Loss: 15.315012
Y Loss: 0.644133
T Loss: 12.408496
X Loss: -52.440657
Epoch 2299 
Overall Loss: -24.832140
Rec Loss: -40.018204
KL Loss: 15.186063
Y Loss: 0.677460
T Loss: 12.429491
X Loss: -52.786424
Epoch 2349 
Overall Loss: -24.104424
Rec Loss: -39.308581
KL Loss: 15.204156
Y Loss: 0.672356
T Loss: 12.398503
X Loss: -52.043262
Epoch 2399 
Overall Loss: -24.719286
Rec Loss: -40.027461
KL Loss: 15.308174
Y Loss: 0.664979
T Loss: 12.394727
X Loss: -52.754677
Epoch 2449 
Overall Loss: -25.000636
Rec Loss: -40.316731
KL Loss: 15.316094
Y Loss: 0.658952
T Loss: 12.387684
X Loss: -53.033890
Epoch 2499 
Overall Loss: -24.971998
Rec Loss: -40.353373
KL Loss: 15.381374
Y Loss: 0.660314
T Loss: 12.395981
X Loss: -53.079510
Epoch 2549 
Overall Loss: -25.163461
Rec Loss: -40.602790
KL Loss: 15.439328
Y Loss: 0.649773
T Loss: 12.385028
X Loss: -53.312704
Epoch 2599 
Overall Loss: -25.339113
Rec Loss: -40.610324
KL Loss: 15.271212
Y Loss: 0.706502
T Loss: 12.394414
X Loss: -53.357989
Epoch 2649 
Overall Loss: -24.553133
Rec Loss: -40.003920
KL Loss: 15.450788
Y Loss: 0.653170
T Loss: 12.373004
X Loss: -52.703509
Epoch 2699 
Overall Loss: -25.407902
Rec Loss: -40.887864
KL Loss: 15.479962
Y Loss: 0.640248
T Loss: 12.372226
X Loss: -53.580214
Epoch 2749 
Overall Loss: -25.290488
Rec Loss: -40.761093
KL Loss: 15.470604
Y Loss: 0.674700
T Loss: 12.361015
X Loss: -53.459457
Epoch 2799 
Overall Loss: -24.833016
Rec Loss: -40.110853
KL Loss: 15.277837
Y Loss: 0.687292
T Loss: 12.386869
X Loss: -52.841367
Epoch 2849 
Overall Loss: -25.256397
Rec Loss: -40.451294
KL Loss: 15.194897
Y Loss: 0.711505
T Loss: 12.389147
X Loss: -53.196192
Epoch 2899 
Overall Loss: -25.578736
Rec Loss: -41.148584
KL Loss: 15.569848
Y Loss: 0.657411
T Loss: 12.343008
X Loss: -53.820297
Epoch 2949 
Overall Loss: -25.601319
Rec Loss: -41.167781
KL Loss: 15.566462
Y Loss: 0.664954
T Loss: 12.361653
X Loss: -53.861912
Epoch 2999 
Overall Loss: -25.597244
Rec Loss: -41.069318
KL Loss: 15.472074
Y Loss: 0.675784
T Loss: 12.363448
X Loss: -53.770658
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.807701
Epoch 99
Rec Loss: 2.779907
Epoch 149
Rec Loss: 2.771554
Epoch 199
Rec Loss: 2.778080
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.003197
Epoch 99
Rec Loss: 0.001904
Epoch 149
Rec Loss: 0.001589
Epoch 199
Rec Loss: 0.001082
Epoch 249
Rec Loss: 0.000920
Epoch 299
Rec Loss: 0.001154
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.313215
Insample Error 1.975943
[34m== Direct Regression: Training all ==[0m
Epoch 49 
Prediction Loss: 7.236104
Epoch 99 
Prediction Loss: 6.780098
Epoch 149 
Prediction Loss: 6.569509
Epoch 199 
Prediction Loss: 6.546931
Epoch 249 
Prediction Loss: 6.486790
Epoch 299 
Prediction Loss: 6.499071
Epoch 349 
Prediction Loss: 6.389538
Epoch 399 
Prediction Loss: 6.403004
Epoch 449 
Prediction Loss: 6.338789
Epoch 499 
Prediction Loss: 6.298437
Epoch 549 
Prediction Loss: 6.441883
Epoch 599 
Prediction Loss: 6.263735
Epoch 649 
Prediction Loss: 6.229247
Epoch 699 
Prediction Loss: 6.217456
Epoch 749 
Prediction Loss: 6.195798
Epoch 799 
Prediction Loss: 6.151743
Epoch 849 
Prediction Loss: 6.134512
Epoch 899 
Prediction Loss: 6.095305
Epoch 949 
Prediction Loss: 6.101189
Epoch 999 
Prediction Loss: 6.050551
Epoch 1049 
Prediction Loss: 6.028346
Epoch 1099 
Prediction Loss: 6.028178
Epoch 1149 
Prediction Loss: 5.970655
Epoch 1199 
Prediction Loss: 5.951848
Epoch 1249 
Prediction Loss: 5.949045
Epoch 1299 
Prediction Loss: 5.944131
Epoch 1349 
Prediction Loss: 5.862288
Epoch 1399 
Prediction Loss: 5.887907
Epoch 1449 
Prediction Loss: 5.827418
Epoch 1499 
Prediction Loss: 5.893227
Epoch 1549 
Prediction Loss: 5.808871
Epoch 1599 
Prediction Loss: 5.767763
Epoch 1649 
Prediction Loss: 5.702761
Epoch 1699 
Prediction Loss: 5.686450
Epoch 1749 
Prediction Loss: 5.677217
Epoch 1799 
Prediction Loss: 5.700327
Epoch 1849 
Prediction Loss: 5.587230
Epoch 1899 
Prediction Loss: 5.575167
Epoch 1949 
Prediction Loss: 5.536177
Epoch 1999 
Prediction Loss: 5.561867
Epoch 2049 
Prediction Loss: 5.498186
Epoch 2099 
Prediction Loss: 5.480909
Epoch 2149 
Prediction Loss: 5.461335
Epoch 2199 
Prediction Loss: 5.429032
Epoch 2249 
Prediction Loss: 5.417289
Epoch 2299 
Prediction Loss: 5.368653
Epoch 2349 
Prediction Loss: 5.427749
Epoch 2399 
Prediction Loss: 5.390421
Epoch 2449 
Prediction Loss: 5.307204
Epoch 2499 
Prediction Loss: 5.311096
Epoch 2549 
Prediction Loss: 5.273220
Epoch 2599 
Prediction Loss: 5.269394
Epoch 2649 
Prediction Loss: 5.216298
Epoch 2699 
Prediction Loss: 5.205465
Epoch 2749 
Prediction Loss: 5.172621
Epoch 2799 
Prediction Loss: 5.159223
Epoch 2849 
Prediction Loss: 5.139255
Epoch 2899 
Prediction Loss: 5.122926
Epoch 2949 
Prediction Loss: 5.174670
Epoch 2999 
Prediction Loss: 5.108515
Epoch 3049 
Prediction Loss: 5.099925
Epoch 3099 
Prediction Loss: 5.029915
Epoch 3149 
Prediction Loss: 5.089445
Epoch 3199 
Prediction Loss: 5.050451
Epoch 3249 
Prediction Loss: 4.972317
Epoch 3299 
Prediction Loss: 4.959987
Epoch 3349 
Prediction Loss: 4.985853
Epoch 3399 
Prediction Loss: 4.940163
Epoch 3449 
Prediction Loss: 4.965492
Epoch 3499 
Prediction Loss: 4.926114
Epoch 3549 
Prediction Loss: 4.925066
Epoch 3599 
Prediction Loss: 4.889417
Epoch 3649 
Prediction Loss: 4.863594
Epoch 3699 
Prediction Loss: 4.811872
Epoch 3749 
Prediction Loss: 4.836900
Epoch 3799 
Prediction Loss: 4.812969
Epoch 3849 
Prediction Loss: 4.798602
Epoch 3899 
Prediction Loss: 4.797953
Epoch 3949 
Prediction Loss: 4.762102
Epoch 3999 
Prediction Loss: 4.829535
Epoch 4049 
Prediction Loss: 4.715992
Epoch 4099 
Prediction Loss: 4.739692
Epoch 4149 
Prediction Loss: 4.691745
Epoch 4199 
Prediction Loss: 4.672831
Epoch 4249 
Prediction Loss: 4.696604
Epoch 4299 
Prediction Loss: 4.644781
Epoch 4349 
Prediction Loss: 4.666409
Epoch 4399 
Prediction Loss: 4.670139
Epoch 4449 
Prediction Loss: 4.583088
Epoch 4499 
Prediction Loss: 4.591659
Epoch 4549 
Prediction Loss: 4.559389
Epoch 4599 
Prediction Loss: 4.534190
Epoch 4649 
Prediction Loss: 4.527040
Epoch 4699 
Prediction Loss: 4.534521
Epoch 4749 
Prediction Loss: 4.550487
Epoch 4799 
Prediction Loss: 4.600449
Epoch 4849 
Prediction Loss: 4.510525
Epoch 4899 
Prediction Loss: 4.536458
Epoch 4949 
Prediction Loss: 4.458583
Epoch 4999 
Prediction Loss: 4.442918
Epoch 5049 
Prediction Loss: 4.433679
Epoch 5099 
Prediction Loss: 4.471159
Epoch 5149 
Prediction Loss: 4.418728
Epoch 5199 
Prediction Loss: 4.442032
Epoch 5249 
Prediction Loss: 4.421969
Epoch 5299 
Prediction Loss: 4.370649
Epoch 5349 
Prediction Loss: 4.372514
Epoch 5399 
Prediction Loss: 4.483204
Epoch 5449 
Prediction Loss: 4.369961
Epoch 5499 
Prediction Loss: 4.313891
Epoch 5549 
Prediction Loss: 4.323832
Epoch 5599 
Prediction Loss: 4.293628
Epoch 5649 
Prediction Loss: 4.456797
Epoch 5699 
Prediction Loss: 4.275215
Epoch 5749 
Prediction Loss: 4.306095
Epoch 5799 
Prediction Loss: 4.307813
Epoch 5849 
Prediction Loss: 4.320001
Epoch 5899 
Prediction Loss: 4.213069
Epoch 5949 
Prediction Loss: 4.250593
Epoch 5999 
Prediction Loss: 4.215326
[34m== Direct Regression: Testing in sample performance ==[0m
Train Error 2.046201
Insample Error 4.560425
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.564849
Rec Loss: 12.679087
KL Loss: 1.885762
Y Loss: 1.036077
T Loss: 12.161049
Epoch 99 
Overall Loss: 14.472986
Rec Loss: 12.398543
KL Loss: 2.074443
Y Loss: 1.032530
T Loss: 11.882278
Epoch 149 
Overall Loss: 14.446845
Rec Loss: 12.307593
KL Loss: 2.139253
Y Loss: 1.001031
T Loss: 11.807077
Epoch 199 
Overall Loss: 14.422961
Rec Loss: 12.300816
KL Loss: 2.122145
Y Loss: 0.980360
T Loss: 11.810636
Epoch 249 
Overall Loss: 14.427431
Rec Loss: 12.296731
KL Loss: 2.130701
Y Loss: 1.012023
T Loss: 11.790719
Epoch 299 
Overall Loss: 14.432472
Rec Loss: 12.293203
KL Loss: 2.139269
Y Loss: 0.999985
T Loss: 11.793211
Epoch 349 
Overall Loss: 14.385512
Rec Loss: 12.258783
KL Loss: 2.126729
Y Loss: 1.011572
T Loss: 11.752997
Epoch 399 
Overall Loss: 14.385325
Rec Loss: 12.270382
KL Loss: 2.114943
Y Loss: 0.999156
T Loss: 11.770804
Epoch 449 
Overall Loss: 14.385563
Rec Loss: 12.251815
KL Loss: 2.133748
Y Loss: 0.982008
T Loss: 11.760811
Epoch 499 
Overall Loss: 14.365973
Rec Loss: 12.285517
KL Loss: 2.080456
Y Loss: 1.001602
T Loss: 11.784716
Epoch 549 
Overall Loss: 14.376236
Rec Loss: 12.243511
KL Loss: 2.132725
Y Loss: 0.956291
T Loss: 11.765366
Epoch 599 
Overall Loss: 14.364259
Rec Loss: 12.266546
KL Loss: 2.097712
Y Loss: 1.010991
T Loss: 11.761051
Epoch 649 
Overall Loss: 14.385262
Rec Loss: 12.283847
KL Loss: 2.101415
Y Loss: 1.007522
T Loss: 11.780086
Epoch 699 
Overall Loss: 14.362234
Rec Loss: 12.270793
KL Loss: 2.091441
Y Loss: 1.001445
T Loss: 11.770070
Epoch 749 
Overall Loss: 14.377862
Rec Loss: 12.285326
KL Loss: 2.092537
Y Loss: 1.021595
T Loss: 11.774528
Epoch 799 
Overall Loss: 14.356261
Rec Loss: 12.254518
KL Loss: 2.101744
Y Loss: 0.991376
T Loss: 11.758830
Epoch 849 
Overall Loss: 14.361969
Rec Loss: 12.250511
KL Loss: 2.111458
Y Loss: 0.985179
T Loss: 11.757921
Epoch 899 
Overall Loss: 14.364913
Rec Loss: 12.278680
KL Loss: 2.086233
Y Loss: 1.027704
T Loss: 11.764829
Epoch 949 
Overall Loss: 14.361038
Rec Loss: 12.260752
KL Loss: 2.100286
Y Loss: 0.996785
T Loss: 11.762360
Epoch 999 
Overall Loss: 14.331313
Rec Loss: 12.250738
KL Loss: 2.080574
Y Loss: 0.993052
T Loss: 11.754212
Epoch 1049 
Overall Loss: 14.343861
Rec Loss: 12.255034
KL Loss: 2.088828
Y Loss: 1.008621
T Loss: 11.750724
Epoch 1099 
Overall Loss: 14.367225
Rec Loss: 12.266100
KL Loss: 2.101124
Y Loss: 1.002074
T Loss: 11.765063
Epoch 1149 
Overall Loss: 14.347013
Rec Loss: 12.267827
KL Loss: 2.079187
Y Loss: 1.038398
T Loss: 11.748628
Epoch 1199 
Overall Loss: 14.342852
Rec Loss: 12.256045
KL Loss: 2.086807
Y Loss: 0.993737
T Loss: 11.759176
Epoch 1249 
Overall Loss: 14.352663
Rec Loss: 12.253606
KL Loss: 2.099058
Y Loss: 1.005995
T Loss: 11.750608
Epoch 1299 
Overall Loss: 14.349043
Rec Loss: 12.249925
KL Loss: 2.099118
Y Loss: 0.966887
T Loss: 11.766482
Epoch 1349 
Overall Loss: 14.347380
Rec Loss: 12.268423
KL Loss: 2.078957
Y Loss: 1.017411
T Loss: 11.759718
Epoch 1399 
Overall Loss: 14.318529
Rec Loss: 12.238952
KL Loss: 2.079577
Y Loss: 1.001900
T Loss: 11.738002
Epoch 1449 
Overall Loss: 14.335676
Rec Loss: 12.251802
KL Loss: 2.083874
Y Loss: 1.011580
T Loss: 11.746012
Epoch 1499 
Overall Loss: 14.342484
Rec Loss: 12.240991
KL Loss: 2.101493
Y Loss: 0.997909
T Loss: 11.742036
Epoch 1549 
Overall Loss: 14.339647
Rec Loss: 12.241820
KL Loss: 2.097827
Y Loss: 1.004728
T Loss: 11.739456
Epoch 1599 
Overall Loss: 14.326535
Rec Loss: 12.248848
KL Loss: 2.077687
Y Loss: 0.995651
T Loss: 11.751022
Epoch 1649 
Overall Loss: 14.336511
Rec Loss: 12.260716
KL Loss: 2.075795
Y Loss: 0.997019
T Loss: 11.762206
Epoch 1699 
Overall Loss: 14.331635
Rec Loss: 12.255085
KL Loss: 2.076550
Y Loss: 1.004702
T Loss: 11.752734
Epoch 1749 
Overall Loss: 14.328584
Rec Loss: 12.239358
KL Loss: 2.089226
Y Loss: 1.005032
T Loss: 11.736842
Epoch 1799 
Overall Loss: 14.324924
Rec Loss: 12.249045
KL Loss: 2.075879
Y Loss: 0.989070
T Loss: 11.754509
Epoch 1849 
Overall Loss: 14.331556
Rec Loss: 12.251911
KL Loss: 2.079645
Y Loss: 1.006903
T Loss: 11.748459
Epoch 1899 
Overall Loss: 14.333215
Rec Loss: 12.236881
KL Loss: 2.096335
Y Loss: 0.999229
T Loss: 11.737266
Epoch 1949 
Overall Loss: 14.330763
Rec Loss: 12.258488
KL Loss: 2.072275
Y Loss: 1.016858
T Loss: 11.750059
Epoch 1999 
Overall Loss: 14.328344
Rec Loss: 12.241522
KL Loss: 2.086822
Y Loss: 1.011353
T Loss: 11.735846
Epoch 2049 
Overall Loss: 14.322784
Rec Loss: 12.249694
KL Loss: 2.073090
Y Loss: 1.025114
T Loss: 11.737137
Epoch 2099 
Overall Loss: 14.335400
Rec Loss: 12.248911
KL Loss: 2.086488
Y Loss: 0.996287
T Loss: 11.750767
Epoch 2149 
Overall Loss: 14.324747
Rec Loss: 12.218589
KL Loss: 2.106158
Y Loss: 0.968575
T Loss: 11.734302
Epoch 2199 
Overall Loss: 14.336191
Rec Loss: 12.237181
KL Loss: 2.099010
Y Loss: 0.975672
T Loss: 11.749345
Epoch 2249 
Overall Loss: 14.316330
Rec Loss: 12.213965
KL Loss: 2.102365
Y Loss: 0.981706
T Loss: 11.723112
Epoch 2299 
Overall Loss: 14.318594
Rec Loss: 12.235556
KL Loss: 2.083039
Y Loss: 0.999723
T Loss: 11.735694
Epoch 2349 
Overall Loss: 14.315891
Rec Loss: 12.211918
KL Loss: 2.103973
Y Loss: 0.986380
T Loss: 11.718728
Epoch 2399 
Overall Loss: 14.321584
Rec Loss: 12.229990
KL Loss: 2.091594
Y Loss: 0.996271
T Loss: 11.731855
Epoch 2449 
Overall Loss: 14.334775
Rec Loss: 12.221754
KL Loss: 2.113021
Y Loss: 1.013554
T Loss: 11.714977
Epoch 2499 
Overall Loss: 14.301530
Rec Loss: 12.203637
KL Loss: 2.097893
Y Loss: 0.980302
T Loss: 11.713486
Epoch 2549 
Overall Loss: 14.318451
Rec Loss: 12.235194
KL Loss: 2.083257
Y Loss: 0.998034
T Loss: 11.736176
Epoch 2599 
Overall Loss: 14.320806
Rec Loss: 12.240601
KL Loss: 2.080205
Y Loss: 1.022968
T Loss: 11.729117
Epoch 2649 
Overall Loss: 14.308316
Rec Loss: 12.211864
KL Loss: 2.096452
Y Loss: 0.980499
T Loss: 11.721614
Epoch 2699 
Overall Loss: 14.322345
Rec Loss: 12.245683
KL Loss: 2.076662
Y Loss: 1.008788
T Loss: 11.741289
Epoch 2749 
Overall Loss: 14.319505
Rec Loss: 12.237283
KL Loss: 2.082222
Y Loss: 1.006425
T Loss: 11.734070
Epoch 2799 
Overall Loss: 14.309408
Rec Loss: 12.226099
KL Loss: 2.083310
Y Loss: 1.030902
T Loss: 11.710647
Epoch 2849 
Overall Loss: 14.312776
Rec Loss: 12.207620
KL Loss: 2.105156
Y Loss: 0.989812
T Loss: 11.712714
Epoch 2899 
Overall Loss: 14.298671
Rec Loss: 12.229558
KL Loss: 2.069112
Y Loss: 1.007521
T Loss: 11.725797
Epoch 2949 
Overall Loss: 14.333608
Rec Loss: 12.225480
KL Loss: 2.108128
Y Loss: 0.996009
T Loss: 11.727476
Epoch 2999 
Overall Loss: 14.331395
Rec Loss: 12.245115
KL Loss: 2.086279
Y Loss: 1.007887
T Loss: 11.741172
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.519524
Epoch 99
Rec Loss: 1.523471
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.867791
Epoch 99
Rec Loss: 9.867546
Epoch 149
Rec Loss: 9.858423
Epoch 199
Rec Loss: 9.831169
Epoch 249
Rec Loss: 9.836123
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.448172
Insample Error: 1.390411
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 18.598683
Rec Loss: 15.182372
KL Loss: 3.416311
Y Loss: 10.941173
T Loss: 13.602673
X Loss: -3.890888
Epoch 99 
Overall Loss: -0.475768
Rec Loss: -8.965922
KL Loss: 8.490154
Y Loss: 3.667679
T Loss: 13.397269
X Loss: -24.197030
Epoch 149 
Overall Loss: -6.242587
Rec Loss: -16.085315
KL Loss: 9.842727
Y Loss: 2.539087
T Loss: 13.397254
X Loss: -30.752113
Epoch 199 
Overall Loss: -9.229932
Rec Loss: -20.023753
KL Loss: 10.793820
Y Loss: 1.791101
T Loss: 13.378180
X Loss: -34.297482
Epoch 249 
Overall Loss: -11.019105
Rec Loss: -22.398728
KL Loss: 11.379623
Y Loss: 1.454556
T Loss: 13.358600
X Loss: -36.484606
Epoch 299 
Overall Loss: -12.134445
Rec Loss: -23.912691
KL Loss: 11.778247
Y Loss: 1.295040
T Loss: 13.345883
X Loss: -37.906094
Epoch 349 
Overall Loss: -13.266458
Rec Loss: -25.297505
KL Loss: 12.031047
Y Loss: 1.195358
T Loss: 13.320399
X Loss: -39.215583
Epoch 399 
Overall Loss: -13.863194
Rec Loss: -26.096356
KL Loss: 12.233162
Y Loss: 1.122084
T Loss: 13.314694
X Loss: -39.972092
Epoch 449 
Overall Loss: -14.651124
Rec Loss: -27.167260
KL Loss: 12.516136
Y Loss: 1.018703
T Loss: 13.296362
X Loss: -40.972973
Epoch 499 
Overall Loss: -15.362287
Rec Loss: -27.976822
KL Loss: 12.614535
Y Loss: 0.952532
T Loss: 13.287350
X Loss: -41.740438
Epoch 549 
Overall Loss: -15.837799
Rec Loss: -28.660173
KL Loss: 12.822374
Y Loss: 0.882041
T Loss: 13.286365
X Loss: -42.387558
Epoch 599 
Overall Loss: -16.380764
Rec Loss: -29.365577
KL Loss: 12.984813
Y Loss: 0.839437
T Loss: 13.270697
X Loss: -43.055994
Epoch 649 
Overall Loss: -16.620755
Rec Loss: -29.688975
KL Loss: 13.068219
Y Loss: 0.845300
T Loss: 13.264559
X Loss: -43.376183
Epoch 699 
Overall Loss: -17.268144
Rec Loss: -30.484478
KL Loss: 13.216334
Y Loss: 0.777816
T Loss: 13.250718
X Loss: -44.124103
Epoch 749 
Overall Loss: -17.659210
Rec Loss: -30.968140
KL Loss: 13.308929
Y Loss: 0.755550
T Loss: 13.244986
X Loss: -44.590901
Epoch 799 
Overall Loss: -18.136955
Rec Loss: -31.606640
KL Loss: 13.469685
Y Loss: 0.719336
T Loss: 13.242200
X Loss: -45.208508
Epoch 849 
Overall Loss: -18.430326
Rec Loss: -32.017985
KL Loss: 13.587659
Y Loss: 0.688358
T Loss: 13.232067
X Loss: -45.594232
Epoch 899 
Overall Loss: -18.454305
Rec Loss: -32.087907
KL Loss: 13.633603
Y Loss: 0.678423
T Loss: 13.229702
X Loss: -45.656821
Epoch 949 
Overall Loss: -18.910986
Rec Loss: -32.582784
KL Loss: 13.671798
Y Loss: 0.667484
T Loss: 13.216963
X Loss: -46.133490
Epoch 999 
Overall Loss: -19.173075
Rec Loss: -32.994677
KL Loss: 13.821604
Y Loss: 0.661431
T Loss: 13.207635
X Loss: -46.533028
Epoch 1049 
Overall Loss: -19.093819
Rec Loss: -33.058220
KL Loss: 13.964400
Y Loss: 0.630585
T Loss: 13.191475
X Loss: -46.564988
Epoch 1099 
Overall Loss: -19.627569
Rec Loss: -33.655547
KL Loss: 14.027977
Y Loss: 0.643439
T Loss: 13.175577
X Loss: -47.152842
Epoch 1149 
Overall Loss: -19.833765
Rec Loss: -33.785498
KL Loss: 13.951733
Y Loss: 0.635752
T Loss: 13.182483
X Loss: -47.285858
Epoch 1199 
Overall Loss: -19.976609
Rec Loss: -34.102619
KL Loss: 14.126010
Y Loss: 0.605823
T Loss: 13.160555
X Loss: -47.566087
Epoch 1249 
Overall Loss: -20.217104
Rec Loss: -34.294504
KL Loss: 14.077400
Y Loss: 0.602511
T Loss: 13.137125
X Loss: -47.732886
Epoch 1299 
Overall Loss: -20.597436
Rec Loss: -34.852686
KL Loss: 14.255250
Y Loss: 0.600332
T Loss: 13.132410
X Loss: -48.285261
Epoch 1349 
Overall Loss: -20.598243
Rec Loss: -34.822016
KL Loss: 14.223773
Y Loss: 0.584709
T Loss: 13.113265
X Loss: -48.227634
Epoch 1399 
Overall Loss: -20.774231
Rec Loss: -35.189208
KL Loss: 14.414977
Y Loss: 0.541848
T Loss: 13.092071
X Loss: -48.552203
Epoch 1449 
Overall Loss: -20.961183
Rec Loss: -35.246199
KL Loss: 14.285015
Y Loss: 0.582608
T Loss: 13.069222
X Loss: -48.606726
Epoch 1499 
Overall Loss: -20.991476
Rec Loss: -35.424253
KL Loss: 14.432778
Y Loss: 0.570164
T Loss: 13.051228
X Loss: -48.760563
Epoch 1549 
Overall Loss: -21.407658
Rec Loss: -35.858921
KL Loss: 14.451263
Y Loss: 0.545323
T Loss: 13.037967
X Loss: -49.169550
Epoch 1599 
Overall Loss: -21.369093
Rec Loss: -35.750918
KL Loss: 14.381825
Y Loss: 0.557083
T Loss: 13.010885
X Loss: -49.040345
Epoch 1649 
Overall Loss: -21.846625
Rec Loss: -36.450368
KL Loss: 14.603743
Y Loss: 0.530713
T Loss: 12.979020
X Loss: -49.694745
Epoch 1699 
Overall Loss: -21.937516
Rec Loss: -36.603769
KL Loss: 14.666252
Y Loss: 0.499203
T Loss: 12.942223
X Loss: -49.795593
Epoch 1749 
Overall Loss: -21.801647
Rec Loss: -36.572163
KL Loss: 14.770516
Y Loss: 0.511756
T Loss: 12.923065
X Loss: -49.751105
Epoch 1799 
Overall Loss: -21.959090
Rec Loss: -36.592858
KL Loss: 14.633767
Y Loss: 0.506736
T Loss: 12.899587
X Loss: -49.745814
Epoch 1849 
Overall Loss: -21.985535
Rec Loss: -36.811416
KL Loss: 14.825881
Y Loss: 0.483391
T Loss: 12.857268
X Loss: -49.910380
Epoch 1899 
Overall Loss: -22.535428
Rec Loss: -37.345672
KL Loss: 14.810245
Y Loss: 0.474335
T Loss: 12.832241
X Loss: -50.415081
Epoch 1949 
Overall Loss: -22.513501
Rec Loss: -37.245382
KL Loss: 14.731882
Y Loss: 0.481849
T Loss: 12.799902
X Loss: -50.286209
Epoch 1999 
Overall Loss: -22.355576
Rec Loss: -37.248231
KL Loss: 14.892655
Y Loss: 0.468749
T Loss: 12.776724
X Loss: -50.259330
Epoch 2049 
Overall Loss: -22.579043
Rec Loss: -37.285605
KL Loss: 14.706563
Y Loss: 0.482971
T Loss: 12.741019
X Loss: -50.268110
Epoch 2099 
Overall Loss: -22.874611
Rec Loss: -37.783007
KL Loss: 14.908398
Y Loss: 0.444599
T Loss: 12.713133
X Loss: -50.718440
Epoch 2149 
Overall Loss: -23.162894
Rec Loss: -38.094791
KL Loss: 14.931896
Y Loss: 0.450579
T Loss: 12.675796
X Loss: -50.995876
Epoch 2199 
Overall Loss: -23.409790
Rec Loss: -38.399839
KL Loss: 14.990050
Y Loss: 0.441910
T Loss: 12.661536
X Loss: -51.282330
Epoch 2249 
Overall Loss: -23.438512
Rec Loss: -38.419542
KL Loss: 14.981030
Y Loss: 0.439665
T Loss: 12.640527
X Loss: -51.279903
Epoch 2299 
Overall Loss: -23.091031
Rec Loss: -38.137173
KL Loss: 15.046140
Y Loss: 0.443430
T Loss: 12.604438
X Loss: -50.963325
Epoch 2349 
Overall Loss: -23.478741
Rec Loss: -38.697114
KL Loss: 15.218373
Y Loss: 0.412770
T Loss: 12.572527
X Loss: -51.476026
Epoch 2399 
Overall Loss: -23.333370
Rec Loss: -38.540085
KL Loss: 15.206714
Y Loss: 0.427485
T Loss: 12.563469
X Loss: -51.317296
Epoch 2449 
Overall Loss: -23.863215
Rec Loss: -39.102663
KL Loss: 15.239446
Y Loss: 0.423581
T Loss: 12.541444
X Loss: -51.855896
Epoch 2499 
Overall Loss: -23.620592
Rec Loss: -38.515736
KL Loss: 14.895144
Y Loss: 0.442914
T Loss: 12.551369
X Loss: -51.288562
Epoch 2549 
Overall Loss: -23.937444
Rec Loss: -39.183259
KL Loss: 15.245814
Y Loss: 0.405594
T Loss: 12.510939
X Loss: -51.896994
Epoch 2599 
Overall Loss: -23.927171
Rec Loss: -39.017897
KL Loss: 15.090727
Y Loss: 0.438895
T Loss: 12.514647
X Loss: -51.751993
Epoch 2649 
Overall Loss: -24.285084
Rec Loss: -39.506516
KL Loss: 15.221433
Y Loss: 0.410970
T Loss: 12.490186
X Loss: -52.202187
Epoch 2699 
Overall Loss: -24.519608
Rec Loss: -39.737956
KL Loss: 15.218348
Y Loss: 0.419607
T Loss: 12.478002
X Loss: -52.425762
Epoch 2749 
Overall Loss: -24.285239
Rec Loss: -39.686132
KL Loss: 15.400893
Y Loss: 0.402975
T Loss: 12.461209
X Loss: -52.348829
Epoch 2799 
Overall Loss: -24.155006
Rec Loss: -39.655741
KL Loss: 15.500733
Y Loss: 0.390294
T Loss: 12.431027
X Loss: -52.281913
Epoch 2849 
Overall Loss: -23.413421
Rec Loss: -38.778152
KL Loss: 15.364731
Y Loss: 0.412598
T Loss: 12.429676
X Loss: -51.414127
Epoch 2899 
Overall Loss: -24.343860
Rec Loss: -39.698504
KL Loss: 15.354645
Y Loss: 0.406190
T Loss: 12.432423
X Loss: -52.334023
Epoch 2949 
Overall Loss: -24.327545
Rec Loss: -39.825119
KL Loss: 15.497575
Y Loss: 0.397146
T Loss: 12.407603
X Loss: -52.431296
Epoch 2999 
Overall Loss: -24.215750
Rec Loss: -39.554835
KL Loss: 15.339086
Y Loss: 0.415308
T Loss: 12.412241
X Loss: -52.174731
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.598213
Epoch 99
Rec Loss: 2.571741
Epoch 149
Rec Loss: 2.568729
Epoch 199
Rec Loss: 2.552911
Epoch 249
Rec Loss: 2.564472
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.004597
Epoch 99
Rec Loss: 0.001983
Epoch 149
Rec Loss: 0.001527
Epoch 199
Rec Loss: 0.001196
Epoch 249
Rec Loss: 0.001235
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.229388
Insample Error 2.665756
[34m== Direct Regression: Training all ==[0m
Epoch 49 
Prediction Loss: 7.095725
Epoch 99 
Prediction Loss: 6.853514
Epoch 149 
Prediction Loss: 6.628841
Epoch 199 
Prediction Loss: 6.571050
Epoch 249 
Prediction Loss: 6.437812
Epoch 299 
Prediction Loss: 6.399700
Epoch 349 
Prediction Loss: 6.412990
Epoch 399 
Prediction Loss: 6.329542
Epoch 449 
Prediction Loss: 6.297288
Epoch 499 
Prediction Loss: 6.279428
Epoch 549 
Prediction Loss: 6.228734
Epoch 599 
Prediction Loss: 6.199931
Epoch 649 
Prediction Loss: 6.156549
Epoch 699 
Prediction Loss: 6.140627
Epoch 749 
Prediction Loss: 6.074586
Epoch 799 
Prediction Loss: 6.067397
Epoch 849 
Prediction Loss: 6.016187
Epoch 899 
Prediction Loss: 5.991132
Epoch 949 
Prediction Loss: 5.951116
Epoch 999 
Prediction Loss: 5.913273
Epoch 1049 
Prediction Loss: 5.895942
Epoch 1099 
Prediction Loss: 5.839501
Epoch 1149 
Prediction Loss: 5.853443
Epoch 1199 
Prediction Loss: 5.777057
Epoch 1249 
Prediction Loss: 5.753538
Epoch 1299 
Prediction Loss: 5.728806
Epoch 1349 
Prediction Loss: 5.726597
Epoch 1399 
Prediction Loss: 5.698499
Epoch 1449 
Prediction Loss: 5.633585
Epoch 1499 
Prediction Loss: 5.611168
Epoch 1549 
Prediction Loss: 5.576590
Epoch 1599 
Prediction Loss: 5.557962
Epoch 1649 
Prediction Loss: 5.549473
Epoch 1699 
Prediction Loss: 5.507887
Epoch 1749 
Prediction Loss: 5.447366
Epoch 1799 
Prediction Loss: 5.430930
Epoch 1849 
Prediction Loss: 5.429269
Epoch 1899 
Prediction Loss: 5.385002
Epoch 1949 
Prediction Loss: 5.373165
Epoch 1999 
Prediction Loss: 5.313844
Epoch 2049 
Prediction Loss: 5.322289
Epoch 2099 
Prediction Loss: 5.333723
Epoch 2149 
Prediction Loss: 5.257115
Epoch 2199 
Prediction Loss: 5.232330
Epoch 2249 
Prediction Loss: 5.235391
Epoch 2299 
Prediction Loss: 5.166007
Epoch 2349 
Prediction Loss: 5.170603
Epoch 2399 
Prediction Loss: 5.187328
Epoch 2449 
Prediction Loss: 5.107031
Epoch 2499 
Prediction Loss: 5.147202
Epoch 2549 
Prediction Loss: 5.085263
Epoch 2599 
Prediction Loss: 5.097569
Epoch 2649 
Prediction Loss: 5.034376
Epoch 2699 
Prediction Loss: 5.050524
Epoch 2749 
Prediction Loss: 4.995272
Epoch 2799 
Prediction Loss: 4.983652
Epoch 2849 
Prediction Loss: 4.940928
Epoch 2899 
Prediction Loss: 4.954176
Epoch 2949 
Prediction Loss: 4.934527
Epoch 2999 
Prediction Loss: 4.913250
Epoch 3049 
Prediction Loss: 4.871132
Epoch 3099 
Prediction Loss: 4.843313
Epoch 3149 
Prediction Loss: 4.891449
Epoch 3199 
Prediction Loss: 4.813435
Epoch 3249 
Prediction Loss: 4.813964
Epoch 3299 
Prediction Loss: 4.776131
Epoch 3349 
Prediction Loss: 4.760398
Epoch 3399 
Prediction Loss: 4.730511
Epoch 3449 
Prediction Loss: 4.730243
Epoch 3499 
Prediction Loss: 4.763712
Epoch 3549 
Prediction Loss: 4.704566
Epoch 3599 
Prediction Loss: 4.699708
Epoch 3649 
Prediction Loss: 4.672256
Epoch 3699 
Prediction Loss: 4.653158
Epoch 3749 
Prediction Loss: 4.670505
Epoch 3799 
Prediction Loss: 4.616519
Epoch 3849 
Prediction Loss: 4.620293
Epoch 3899 
Prediction Loss: 4.634141
Epoch 3949 
Prediction Loss: 4.586241
Epoch 3999 
Prediction Loss: 4.630898
Epoch 4049 
Prediction Loss: 4.517094
Epoch 4099 
Prediction Loss: 4.549598
Epoch 4149 
Prediction Loss: 4.597961
Epoch 4199 
Prediction Loss: 4.506908
Epoch 4249 
Prediction Loss: 4.456170
Epoch 4299 
Prediction Loss: 4.469030
Epoch 4349 
Prediction Loss: 4.434653
Epoch 4399 
Prediction Loss: 4.511319
Epoch 4449 
Prediction Loss: 4.436207
Epoch 4499 
Prediction Loss: 4.444160
Epoch 4549 
Prediction Loss: 4.422597
Epoch 4599 
Prediction Loss: 4.372831
Epoch 4649 
Prediction Loss: 4.371954
Epoch 4699 
Prediction Loss: 4.346229
Epoch 4749 
Prediction Loss: 4.362011
Epoch 4799 
Prediction Loss: 4.409199
Epoch 4849 
Prediction Loss: 4.315903
Epoch 4899 
Prediction Loss: 4.305724
Epoch 4949 
Prediction Loss: 4.318968
Epoch 4999 
Prediction Loss: 4.304746
Epoch 5049 
Prediction Loss: 4.275570
Epoch 5099 
Prediction Loss: 4.319062
Epoch 5149 
Prediction Loss: 4.274915
Epoch 5199 
Prediction Loss: 4.232180
Epoch 5249 
Prediction Loss: 4.346151
Epoch 5299 
Prediction Loss: 4.188368
Epoch 5349 
Prediction Loss: 4.200461
Epoch 5399 
Prediction Loss: 4.161487
Epoch 5449 
Prediction Loss: 4.155343
Epoch 5499 
Prediction Loss: 4.142489
Epoch 5549 
Prediction Loss: 4.147565
Epoch 5599 
Prediction Loss: 4.164898
Epoch 5649 
Prediction Loss: 4.106149
Epoch 5699 
Prediction Loss: 4.110367
Epoch 5749 
Prediction Loss: 4.072434
Epoch 5799 
Prediction Loss: 4.098552
Epoch 5849 
Prediction Loss: 4.098471
Epoch 5899 
Prediction Loss: 4.061859
Epoch 5949 
Prediction Loss: 4.057686
Epoch 5999 
Prediction Loss: 4.042114
[34m== Direct Regression: Testing in sample performance ==[0m
Train Error 2.003649
Insample Error 4.660164
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.561147
Rec Loss: 12.755951
KL Loss: 1.805196
Y Loss: 1.031907
T Loss: 12.239997
Epoch 99 
Overall Loss: 14.467170
Rec Loss: 12.429373
KL Loss: 2.037797
Y Loss: 0.985790
T Loss: 11.936478
Epoch 149 
Overall Loss: 14.422947
Rec Loss: 12.356308
KL Loss: 2.066639
Y Loss: 0.987227
T Loss: 11.862695
Epoch 199 
Overall Loss: 14.402095
Rec Loss: 12.319470
KL Loss: 2.082625
Y Loss: 1.000304
T Loss: 11.819318
Epoch 249 
Overall Loss: 14.407927
Rec Loss: 12.306521
KL Loss: 2.101406
Y Loss: 0.994726
T Loss: 11.809158
Epoch 299 
Overall Loss: 14.391906
Rec Loss: 12.282604
KL Loss: 2.109302
Y Loss: 0.987515
T Loss: 11.788846
Epoch 349 
Overall Loss: 14.389410
Rec Loss: 12.289145
KL Loss: 2.100265
Y Loss: 1.002802
T Loss: 11.787744
Epoch 399 
Overall Loss: 14.368263
Rec Loss: 12.294685
KL Loss: 2.073579
Y Loss: 1.034914
T Loss: 11.777228
Epoch 449 
Overall Loss: 14.380278
Rec Loss: 12.268120
KL Loss: 2.112158
Y Loss: 1.007565
T Loss: 11.764338
Epoch 499 
Overall Loss: 14.369103
Rec Loss: 12.260500
KL Loss: 2.108604
Y Loss: 1.005714
T Loss: 11.757643
Epoch 549 
Overall Loss: 14.359375
Rec Loss: 12.279796
KL Loss: 2.079580
Y Loss: 1.018294
T Loss: 11.770649
Epoch 599 
Overall Loss: 14.371603
Rec Loss: 12.264204
KL Loss: 2.107399
Y Loss: 0.985561
T Loss: 11.771424
Epoch 649 
Overall Loss: 14.361940
Rec Loss: 12.264668
KL Loss: 2.097271
Y Loss: 1.003117
T Loss: 11.763110
Epoch 699 
Overall Loss: 14.360156
Rec Loss: 12.293078
KL Loss: 2.067077
Y Loss: 1.031039
T Loss: 11.777559
Epoch 749 
Overall Loss: 14.382509
Rec Loss: 12.269281
KL Loss: 2.113228
Y Loss: 0.994846
T Loss: 11.771858
Epoch 799 
Overall Loss: 14.362698
Rec Loss: 12.270581
KL Loss: 2.092117
Y Loss: 1.009747
T Loss: 11.765707
Epoch 849 
Overall Loss: 14.352940
Rec Loss: 12.258343
KL Loss: 2.094597
Y Loss: 1.018649
T Loss: 11.749018
Epoch 899 
Overall Loss: 14.352186
Rec Loss: 12.260716
KL Loss: 2.091470
Y Loss: 1.012925
T Loss: 11.754254
Epoch 949 
Overall Loss: 14.379610
Rec Loss: 12.272578
KL Loss: 2.107032
Y Loss: 1.025696
T Loss: 11.759730
Epoch 999 
Overall Loss: 14.337807
Rec Loss: 12.268714
KL Loss: 2.069092
Y Loss: 1.001683
T Loss: 11.767873
Epoch 1049 
Overall Loss: 14.331134
Rec Loss: 12.257937
KL Loss: 2.073197
Y Loss: 1.012117
T Loss: 11.751878
Epoch 1099 
Overall Loss: 14.338692
Rec Loss: 12.256499
KL Loss: 2.082194
Y Loss: 1.025744
T Loss: 11.743627
Epoch 1149 
Overall Loss: 14.342909
Rec Loss: 12.253280
KL Loss: 2.089629
Y Loss: 1.007270
T Loss: 11.749645
Epoch 1199 
Overall Loss: 14.338166
Rec Loss: 12.240293
KL Loss: 2.097873
Y Loss: 0.993348
T Loss: 11.743619
Epoch 1249 
Overall Loss: 14.360191
Rec Loss: 12.268228
KL Loss: 2.091963
Y Loss: 1.014466
T Loss: 11.760995
Epoch 1299 
Overall Loss: 14.346293
Rec Loss: 12.257430
KL Loss: 2.088863
Y Loss: 1.004573
T Loss: 11.755144
Epoch 1349 
Overall Loss: 14.353842
Rec Loss: 12.264444
KL Loss: 2.089398
Y Loss: 1.003323
T Loss: 11.762782
Epoch 1399 
Overall Loss: 14.363642
Rec Loss: 12.266388
KL Loss: 2.097254
Y Loss: 1.008401
T Loss: 11.762188
Epoch 1449 
Overall Loss: 14.323395
Rec Loss: 12.266557
KL Loss: 2.056838
Y Loss: 1.023168
T Loss: 11.754972
Epoch 1499 
Overall Loss: 14.335439
Rec Loss: 12.235645
KL Loss: 2.099794
Y Loss: 1.006118
T Loss: 11.732586
Epoch 1549 
Overall Loss: 14.348751
Rec Loss: 12.279788
KL Loss: 2.068963
Y Loss: 1.011479
T Loss: 11.774049
Epoch 1599 
Overall Loss: 14.338161
Rec Loss: 12.252100
KL Loss: 2.086060
Y Loss: 1.019728
T Loss: 11.742236
Epoch 1649 
Overall Loss: 14.353458
Rec Loss: 12.294425
KL Loss: 2.059032
Y Loss: 1.054094
T Loss: 11.767378
Epoch 1699 
Overall Loss: 14.340723
Rec Loss: 12.260445
KL Loss: 2.080278
Y Loss: 1.021100
T Loss: 11.749896
Epoch 1749 
Overall Loss: 14.337895
Rec Loss: 12.250208
KL Loss: 2.087687
Y Loss: 1.007363
T Loss: 11.746526
Epoch 1799 
Overall Loss: 14.323218
Rec Loss: 12.237408
KL Loss: 2.085810
Y Loss: 1.001833
T Loss: 11.736491
Epoch 1849 
Overall Loss: 14.326811
Rec Loss: 12.257376
KL Loss: 2.069435
Y Loss: 1.027382
T Loss: 11.743685
Epoch 1899 
Overall Loss: 14.349824
Rec Loss: 12.266677
KL Loss: 2.083147
Y Loss: 1.027489
T Loss: 11.752933
Epoch 1949 
Overall Loss: 14.328827
Rec Loss: 12.249065
KL Loss: 2.079762
Y Loss: 1.017236
T Loss: 11.740448
Epoch 1999 
Overall Loss: 14.310652
Rec Loss: 12.233697
KL Loss: 2.076955
Y Loss: 0.984228
T Loss: 11.741583
Epoch 2049 
Overall Loss: 14.335725
Rec Loss: 12.248977
KL Loss: 2.086748
Y Loss: 1.000462
T Loss: 11.748746
Epoch 2099 
Overall Loss: 14.335211
Rec Loss: 12.239524
KL Loss: 2.095687
Y Loss: 0.985867
T Loss: 11.746591
Epoch 2149 
Overall Loss: 14.343687
Rec Loss: 12.246629
KL Loss: 2.097058
Y Loss: 1.004653
T Loss: 11.744302
Epoch 2199 
Overall Loss: 14.337577
Rec Loss: 12.251605
KL Loss: 2.085972
Y Loss: 1.004501
T Loss: 11.749355
Epoch 2249 
Overall Loss: 14.327688
Rec Loss: 12.249661
KL Loss: 2.078027
Y Loss: 0.995171
T Loss: 11.752076
Epoch 2299 
Overall Loss: 14.309165
Rec Loss: 12.239349
KL Loss: 2.069816
Y Loss: 0.998604
T Loss: 11.740047
Epoch 2349 
Overall Loss: 14.323812
Rec Loss: 12.237646
KL Loss: 2.086166
Y Loss: 1.022988
T Loss: 11.726152
Epoch 2399 
Overall Loss: 14.318291
Rec Loss: 12.228594
KL Loss: 2.089697
Y Loss: 0.997619
T Loss: 11.729784
Epoch 2449 
Overall Loss: 14.351508
Rec Loss: 12.233633
KL Loss: 2.117875
Y Loss: 0.982545
T Loss: 11.742361
Epoch 2499 
Overall Loss: 14.325373
Rec Loss: 12.222243
KL Loss: 2.103130
Y Loss: 0.995995
T Loss: 11.724246
Epoch 2549 
Overall Loss: 14.332041
Rec Loss: 12.235965
KL Loss: 2.096077
Y Loss: 1.012337
T Loss: 11.729796
Epoch 2599 
Overall Loss: 14.309011
Rec Loss: 12.235519
KL Loss: 2.073491
Y Loss: 1.009734
T Loss: 11.730652
Epoch 2649 
Overall Loss: 14.311271
Rec Loss: 12.220341
KL Loss: 2.090929
Y Loss: 0.989986
T Loss: 11.725349
Epoch 2699 
Overall Loss: 14.315361
Rec Loss: 12.230211
KL Loss: 2.085150
Y Loss: 1.012532
T Loss: 11.723945
Epoch 2749 
Overall Loss: 14.302390
Rec Loss: 12.232465
KL Loss: 2.069924
Y Loss: 1.029427
T Loss: 11.717752
Epoch 2799 
Overall Loss: 14.306267
Rec Loss: 12.218767
KL Loss: 2.087500
Y Loss: 0.995834
T Loss: 11.720850
Epoch 2849 
Overall Loss: 14.317610
Rec Loss: 12.255184
KL Loss: 2.062426
Y Loss: 1.052778
T Loss: 11.728795
Epoch 2899 
Overall Loss: 14.346513
Rec Loss: 12.237061
KL Loss: 2.109452
Y Loss: 0.986297
T Loss: 11.743912
Epoch 2949 
Overall Loss: 14.312450
Rec Loss: 12.228684
KL Loss: 2.083766
Y Loss: 1.028757
T Loss: 11.714305
Epoch 2999 
Overall Loss: 14.332151
Rec Loss: 12.249011
KL Loss: 2.083140
Y Loss: 1.029581
T Loss: 11.734220
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.527794
Epoch 99
Rec Loss: 1.516127
Epoch 149
Rec Loss: 1.525764
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.857117
Epoch 99
Rec Loss: 9.856711
Epoch 149
Rec Loss: 9.842118
Epoch 199
Rec Loss: 9.850150
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.489824
Insample Error: 1.374909
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 15.579887
Rec Loss: 10.934918
KL Loss: 4.644969
Y Loss: 5.609219
T Loss: 13.390362
X Loss: -5.260053
Epoch 99 
Overall Loss: -1.412973
Rec Loss: -10.838151
KL Loss: 9.425178
Y Loss: 2.128939
T Loss: 13.319403
X Loss: -25.222023
Epoch 149 
Overall Loss: -6.819601
Rec Loss: -17.518486
KL Loss: 10.698886
Y Loss: 1.427816
T Loss: 13.316665
X Loss: -31.549059
Epoch 199 
Overall Loss: -9.752493
Rec Loss: -21.345716
KL Loss: 11.593224
Y Loss: 1.118511
T Loss: 13.307007
X Loss: -35.211978
Epoch 249 
Overall Loss: -11.207412
Rec Loss: -23.321825
KL Loss: 12.114413
Y Loss: 1.013971
T Loss: 13.289110
X Loss: -37.117921
Epoch 299 
Overall Loss: -12.457427
Rec Loss: -24.919835
KL Loss: 12.462408
Y Loss: 0.947907
T Loss: 13.268121
X Loss: -38.661910
Epoch 349 
Overall Loss: -13.514636
Rec Loss: -26.237804
KL Loss: 12.723168
Y Loss: 0.930382
T Loss: 13.249497
X Loss: -39.952492
Epoch 399 
Overall Loss: -14.246568
Rec Loss: -27.120539
KL Loss: 12.873971
Y Loss: 0.942666
T Loss: 13.211534
X Loss: -40.803406
Epoch 449 
Overall Loss: -14.905379
Rec Loss: -28.013837
KL Loss: 13.108458
Y Loss: 0.918100
T Loss: 13.174709
X Loss: -41.647596
Epoch 499 
Overall Loss: -15.720428
Rec Loss: -28.969483
KL Loss: 13.249054
Y Loss: 0.911304
T Loss: 13.138338
X Loss: -42.563474
Epoch 549 
Overall Loss: -16.366801
Rec Loss: -29.714402
KL Loss: 13.347601
Y Loss: 0.911500
T Loss: 13.088961
X Loss: -43.259113
Epoch 599 
Overall Loss: -16.885462
Rec Loss: -30.404626
KL Loss: 13.519163
Y Loss: 0.883861
T Loss: 13.040820
X Loss: -43.887376
Epoch 649 
Overall Loss: -17.342309
Rec Loss: -30.965112
KL Loss: 13.622803
Y Loss: 0.911838
T Loss: 13.000228
X Loss: -44.421259
Epoch 699 
Overall Loss: -17.745442
Rec Loss: -31.403174
KL Loss: 13.657732
Y Loss: 0.897114
T Loss: 12.955937
X Loss: -44.807667
Epoch 749 
Overall Loss: -18.217928
Rec Loss: -32.035239
KL Loss: 13.817311
Y Loss: 0.914374
T Loss: 12.922333
X Loss: -45.414759
Epoch 799 
Overall Loss: -18.692717
Rec Loss: -32.591970
KL Loss: 13.899253
Y Loss: 0.893786
T Loss: 12.905873
X Loss: -45.944736
Epoch 849 
Overall Loss: -18.904565
Rec Loss: -32.888851
KL Loss: 13.984286
Y Loss: 0.861068
T Loss: 12.888239
X Loss: -46.207625
Epoch 899 
Overall Loss: -19.156552
Rec Loss: -33.212510
KL Loss: 14.055959
Y Loss: 0.865202
T Loss: 12.875086
X Loss: -46.520198
Epoch 949 
Overall Loss: -19.614895
Rec Loss: -33.787256
KL Loss: 14.172360
Y Loss: 0.882673
T Loss: 12.873148
X Loss: -47.101740
Epoch 999 
Overall Loss: -19.803504
Rec Loss: -33.977740
KL Loss: 14.174235
Y Loss: 0.846317
T Loss: 12.866913
X Loss: -47.267811
Epoch 1049 
Overall Loss: -20.189539
Rec Loss: -34.465426
KL Loss: 14.275887
Y Loss: 0.841780
T Loss: 12.852877
X Loss: -47.739193
Epoch 1099 
Overall Loss: -20.379032
Rec Loss: -34.722269
KL Loss: 14.343238
Y Loss: 0.848367
T Loss: 12.839506
X Loss: -47.985959
Epoch 1149 
Overall Loss: -20.460570
Rec Loss: -34.888191
KL Loss: 14.427621
Y Loss: 0.815201
T Loss: 12.837165
X Loss: -48.132956
Epoch 1199 
Overall Loss: -20.753791
Rec Loss: -35.224058
KL Loss: 14.470267
Y Loss: 0.835329
T Loss: 12.830250
X Loss: -48.471972
Epoch 1249 
Overall Loss: -20.899680
Rec Loss: -35.355502
KL Loss: 14.455823
Y Loss: 0.872548
T Loss: 12.822452
X Loss: -48.614229
Epoch 1299 
Overall Loss: -20.907222
Rec Loss: -35.372823
KL Loss: 14.465600
Y Loss: 0.874991
T Loss: 12.816829
X Loss: -48.627148
Epoch 1349 
Overall Loss: -21.078162
Rec Loss: -35.660112
KL Loss: 14.581950
Y Loss: 0.831267
T Loss: 12.799229
X Loss: -48.874974
Epoch 1399 
Overall Loss: -21.562476
Rec Loss: -36.103199
KL Loss: 14.540723
Y Loss: 0.849590
T Loss: 12.793920
X Loss: -49.321914
Epoch 1449 
Overall Loss: -21.713103
Rec Loss: -36.408292
KL Loss: 14.695190
Y Loss: 0.800448
T Loss: 12.769422
X Loss: -49.577938
Epoch 1499 
Overall Loss: -21.709788
Rec Loss: -36.467461
KL Loss: 14.757673
Y Loss: 0.847045
T Loss: 12.760102
X Loss: -49.651085
Epoch 1549 
Overall Loss: -21.949241
Rec Loss: -36.663407
KL Loss: 14.714166
Y Loss: 0.852102
T Loss: 12.747250
X Loss: -49.836709
Epoch 1599 
Overall Loss: -22.296032
Rec Loss: -37.087473
KL Loss: 14.791441
Y Loss: 0.829095
T Loss: 12.733669
X Loss: -50.235689
Epoch 1649 
Overall Loss: -22.362130
Rec Loss: -37.166803
KL Loss: 14.804672
Y Loss: 0.828857
T Loss: 12.717633
X Loss: -50.298864
Epoch 1699 
Overall Loss: -22.458435
Rec Loss: -37.188421
KL Loss: 14.729987
Y Loss: 0.835994
T Loss: 12.698770
X Loss: -50.305189
Epoch 1749 
Overall Loss: -22.640565
Rec Loss: -37.549064
KL Loss: 14.908500
Y Loss: 0.809169
T Loss: 12.680162
X Loss: -50.633811
Epoch 1799 
Overall Loss: -22.808951
Rec Loss: -37.714380
KL Loss: 14.905429
Y Loss: 0.838671
T Loss: 12.668803
X Loss: -50.802519
Epoch 1849 
Overall Loss: -21.676244
Rec Loss: -36.656518
KL Loss: 14.980274
Y Loss: 0.822359
T Loss: 12.635981
X Loss: -49.703678
Epoch 1899 
Overall Loss: -22.791394
Rec Loss: -37.795900
KL Loss: 15.004506
Y Loss: 0.827812
T Loss: 12.617250
X Loss: -50.827057
Epoch 1949 
Overall Loss: -23.245001
Rec Loss: -38.313842
KL Loss: 15.068841
Y Loss: 0.790432
T Loss: 12.591090
X Loss: -51.300148
Epoch 1999 
Overall Loss: -22.900160
Rec Loss: -38.000559
KL Loss: 15.100399
Y Loss: 0.806498
T Loss: 12.569435
X Loss: -50.973242
Epoch 2049 
Overall Loss: -23.491741
Rec Loss: -38.665671
KL Loss: 15.173930
Y Loss: 0.821133
T Loss: 12.546448
X Loss: -51.622685
Epoch 2099 
Overall Loss: -23.519548
Rec Loss: -38.711420
KL Loss: 15.191874
Y Loss: 0.804067
T Loss: 12.532683
X Loss: -51.646138
Epoch 2149 
Overall Loss: -23.541112
Rec Loss: -38.762180
KL Loss: 15.221066
Y Loss: 0.802490
T Loss: 12.506173
X Loss: -51.669598
Epoch 2199 
Overall Loss: -23.429636
Rec Loss: -38.565497
KL Loss: 15.135862
Y Loss: 0.840534
T Loss: 12.513564
X Loss: -51.499329
Epoch 2249 
Overall Loss: -23.844869
Rec Loss: -39.163931
KL Loss: 15.319062
Y Loss: 0.800626
T Loss: 12.462437
X Loss: -52.026682
Epoch 2299 
Overall Loss: -23.970334
Rec Loss: -39.302466
KL Loss: 15.332132
Y Loss: 0.774702
T Loss: 12.458920
X Loss: -52.148736
Epoch 2349 
Overall Loss: -24.112314
Rec Loss: -39.436840
KL Loss: 15.324526
Y Loss: 0.791411
T Loss: 12.434269
X Loss: -52.266814
Epoch 2399 
Overall Loss: -24.266823
Rec Loss: -39.678241
KL Loss: 15.411418
Y Loss: 0.780136
T Loss: 12.408653
X Loss: -52.476962
Epoch 2449 
Overall Loss: -23.856679
Rec Loss: -39.231804
KL Loss: 15.375126
Y Loss: 0.801310
T Loss: 12.416245
X Loss: -52.048704
Epoch 2499 
Overall Loss: -24.510551
Rec Loss: -39.670153
KL Loss: 15.159602
Y Loss: 0.810786
T Loss: 12.396696
X Loss: -52.472241
Epoch 2549 
Overall Loss: -24.378371
Rec Loss: -39.795155
KL Loss: 15.416784
Y Loss: 0.785067
T Loss: 12.377584
X Loss: -52.565273
Epoch 2599 
Overall Loss: -24.536041
Rec Loss: -39.884528
KL Loss: 15.348486
Y Loss: 0.799829
T Loss: 12.352622
X Loss: -52.637064
Epoch 2649 
Overall Loss: -23.858625
Rec Loss: -39.280338
KL Loss: 15.421712
Y Loss: 0.767380
T Loss: 12.345567
X Loss: -52.009594
Epoch 2699 
Overall Loss: -24.819849
Rec Loss: -40.349044
KL Loss: 15.529196
Y Loss: 0.763198
T Loss: 12.338474
X Loss: -53.069116
Epoch 2749 
Overall Loss: -24.846953
Rec Loss: -40.471428
KL Loss: 15.624474
Y Loss: 0.746317
T Loss: 12.301570
X Loss: -53.146156
Epoch 2799 
Overall Loss: -24.996755
Rec Loss: -40.441781
KL Loss: 15.445027
Y Loss: 0.780949
T Loss: 12.309903
X Loss: -53.142159
Epoch 2849 
Overall Loss: -24.271529
Rec Loss: -39.707930
KL Loss: 15.436402
Y Loss: 0.783967
T Loss: 12.305699
X Loss: -52.405613
Epoch 2899 
Overall Loss: -25.075431
Rec Loss: -40.753856
KL Loss: 15.678427
Y Loss: 0.743159
T Loss: 12.274344
X Loss: -53.399782
Epoch 2949 
Overall Loss: -24.924862
Rec Loss: -40.465158
KL Loss: 15.540296
Y Loss: 0.776636
T Loss: 12.265664
X Loss: -53.119140
Epoch 2999 
Overall Loss: -25.415900
Rec Loss: -40.977839
KL Loss: 15.561938
Y Loss: 0.769955
T Loss: 12.265088
X Loss: -53.627904
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.725946
Epoch 99
Rec Loss: 2.724063
Epoch 149
Rec Loss: 2.717239
Epoch 199
Rec Loss: 2.707391
Epoch 249
Rec Loss: 2.706548
Epoch 299
Rec Loss: 2.706695
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.003818
Epoch 99
Rec Loss: 0.001651
Epoch 149
Rec Loss: 0.001345
Epoch 199
Rec Loss: 0.001157
Epoch 249
Rec Loss: 0.001322
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.406765
Insample Error 2.045189
[34m== Direct Regression: Training all ==[0m
Epoch 49 
Prediction Loss: 7.097797
Epoch 99 
Prediction Loss: 6.797788
Epoch 149 
Prediction Loss: 6.631644
Epoch 199 
Prediction Loss: 6.527884
Epoch 249 
Prediction Loss: 6.461029
Epoch 299 
Prediction Loss: 6.412145
Epoch 349 
Prediction Loss: 6.390574
Epoch 399 
Prediction Loss: 6.317408
Epoch 449 
Prediction Loss: 6.286318
Epoch 499 
Prediction Loss: 6.268390
Epoch 549 
Prediction Loss: 6.230523
Epoch 599 
Prediction Loss: 6.182943
Epoch 649 
Prediction Loss: 6.222418
Epoch 699 
Prediction Loss: 6.094385
Epoch 749 
Prediction Loss: 6.066284
Epoch 799 
Prediction Loss: 6.024989
Epoch 849 
Prediction Loss: 6.017813
Epoch 899 
Prediction Loss: 5.975403
Epoch 949 
Prediction Loss: 5.963365
Epoch 999 
Prediction Loss: 5.909880
Epoch 1049 
Prediction Loss: 5.882559
Epoch 1099 
Prediction Loss: 5.829291
Epoch 1149 
Prediction Loss: 5.835294
Epoch 1199 
Prediction Loss: 5.762487
Epoch 1249 
Prediction Loss: 5.775351
Epoch 1299 
Prediction Loss: 5.721202
Epoch 1349 
Prediction Loss: 5.663233
Epoch 1399 
Prediction Loss: 5.621326
Epoch 1449 
Prediction Loss: 5.586868
Epoch 1499 
Prediction Loss: 5.555832
Epoch 1549 
Prediction Loss: 5.503677
Epoch 1599 
Prediction Loss: 5.485754
Epoch 1649 
Prediction Loss: 5.470653
Epoch 1699 
Prediction Loss: 5.418214
Epoch 1749 
Prediction Loss: 5.381870
Epoch 1799 
Prediction Loss: 5.354804
Epoch 1849 
Prediction Loss: 5.307369
Epoch 1899 
Prediction Loss: 5.305214
Epoch 1949 
Prediction Loss: 5.244321
Epoch 1999 
Prediction Loss: 5.226157
Epoch 2049 
Prediction Loss: 5.225150
Epoch 2099 
Prediction Loss: 5.190074
Epoch 2149 
Prediction Loss: 5.271271
Epoch 2199 
Prediction Loss: 5.085623
Epoch 2249 
Prediction Loss: 5.076965
Epoch 2299 
Prediction Loss: 5.059332
Epoch 2349 
Prediction Loss: 5.020786
Epoch 2399 
Prediction Loss: 5.006300
Epoch 2449 
Prediction Loss: 4.986278
Epoch 2499 
Prediction Loss: 5.026971
Epoch 2549 
Prediction Loss: 4.883195
Epoch 2599 
Prediction Loss: 4.846115
Epoch 2649 
Prediction Loss: 4.827326
Epoch 2699 
Prediction Loss: 4.826009
Epoch 2749 
Prediction Loss: 4.800871
Epoch 2799 
Prediction Loss: 4.785064
Epoch 2849 
Prediction Loss: 4.763320
Epoch 2899 
Prediction Loss: 4.753612
Epoch 2949 
Prediction Loss: 4.847026
Epoch 2999 
Prediction Loss: 4.716065
Epoch 3049 
Prediction Loss: 4.704229
Epoch 3099 
Prediction Loss: 4.648057
Epoch 3149 
Prediction Loss: 4.660850
Epoch 3199 
Prediction Loss: 4.613334
Epoch 3249 
Prediction Loss: 4.581230
Epoch 3299 
Prediction Loss: 4.573851
Epoch 3349 
Prediction Loss: 4.585005
Epoch 3399 
Prediction Loss: 4.554338
Epoch 3449 
Prediction Loss: 4.521452
Epoch 3499 
Prediction Loss: 4.533293
Epoch 3549 
Prediction Loss: 4.556291
Epoch 3599 
Prediction Loss: 4.434660
Epoch 3649 
Prediction Loss: 4.429430
Epoch 3699 
Prediction Loss: 4.432687
Epoch 3749 
Prediction Loss: 4.391412
Epoch 3799 
Prediction Loss: 4.384114
Epoch 3849 
Prediction Loss: 4.356416
Epoch 3899 
Prediction Loss: 4.388081
Epoch 3949 
Prediction Loss: 4.385495
Epoch 3999 
Prediction Loss: 4.370107
Epoch 4049 
Prediction Loss: 4.329239
Epoch 4099 
Prediction Loss: 4.289524
Epoch 4149 
Prediction Loss: 4.346985
Epoch 4199 
Prediction Loss: 4.263804
Epoch 4249 
Prediction Loss: 4.278536
Epoch 4299 
Prediction Loss: 4.240852
Epoch 4349 
Prediction Loss: 4.258081
Epoch 4399 
Prediction Loss: 4.228249
Epoch 4449 
Prediction Loss: 4.227247
Epoch 4499 
Prediction Loss: 4.213456
Epoch 4549 
Prediction Loss: 4.178029
Epoch 4599 
Prediction Loss: 4.163025
Epoch 4649 
Prediction Loss: 4.200125
Epoch 4699 
Prediction Loss: 4.173259
Epoch 4749 
Prediction Loss: 4.165232
Epoch 4799 
Prediction Loss: 4.133450
Epoch 4849 
Prediction Loss: 4.111016
Epoch 4899 
Prediction Loss: 4.091043
Epoch 4949 
Prediction Loss: 4.116227
Epoch 4999 
Prediction Loss: 4.086048
Epoch 5049 
Prediction Loss: 4.055034
Epoch 5099 
Prediction Loss: 4.076463
Epoch 5149 
Prediction Loss: 4.057583
Epoch 5199 
Prediction Loss: 4.030221
Epoch 5249 
Prediction Loss: 4.029193
Epoch 5299 
Prediction Loss: 3.968880
Epoch 5349 
Prediction Loss: 3.987339
Epoch 5399 
Prediction Loss: 3.975187
Epoch 5449 
Prediction Loss: 3.942137
Epoch 5499 
Prediction Loss: 3.956880
Epoch 5549 
Prediction Loss: 4.084811
Epoch 5599 
Prediction Loss: 3.943602
Epoch 5649 
Prediction Loss: 3.901032
Epoch 5699 
Prediction Loss: 3.894035
Epoch 5749 
Prediction Loss: 3.882970
Epoch 5799 
Prediction Loss: 3.963033
Epoch 5849 
Prediction Loss: 3.869473
Epoch 5899 
Prediction Loss: 3.890613
Epoch 5949 
Prediction Loss: 3.865881
Epoch 5999 
Prediction Loss: 3.866432
[34m== Direct Regression: Testing in sample performance ==[0m
Train Error 1.956382
Insample Error 4.708225
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.557046
Rec Loss: 12.708352
KL Loss: 1.848694
Y Loss: 1.026196
T Loss: 12.195254
Epoch 99 
Overall Loss: 14.456114
Rec Loss: 12.376568
KL Loss: 2.079546
Y Loss: 0.992670
T Loss: 11.880233
Epoch 149 
Overall Loss: 14.422552
Rec Loss: 12.314471
KL Loss: 2.108081
Y Loss: 0.988671
T Loss: 11.820135
Epoch 199 
Overall Loss: 14.405181
Rec Loss: 12.297866
KL Loss: 2.107316
Y Loss: 1.014317
T Loss: 11.790707
Epoch 249 
Overall Loss: 14.407986
Rec Loss: 12.302368
KL Loss: 2.105618
Y Loss: 1.013363
T Loss: 11.795687
Epoch 299 
Overall Loss: 14.412117
Rec Loss: 12.300183
KL Loss: 2.111934
Y Loss: 1.013264
T Loss: 11.793551
Epoch 349 
Overall Loss: 14.385165
Rec Loss: 12.291024
KL Loss: 2.094141
Y Loss: 1.008092
T Loss: 11.786978
Epoch 399 
Overall Loss: 14.388891
Rec Loss: 12.278709
KL Loss: 2.110182
Y Loss: 1.020955
T Loss: 11.768231
Epoch 449 
Overall Loss: 14.368162
Rec Loss: 12.277631
KL Loss: 2.090531
Y Loss: 0.997057
T Loss: 11.779103
Epoch 499 
Overall Loss: 14.374052
Rec Loss: 12.268811
KL Loss: 2.105241
Y Loss: 0.997378
T Loss: 11.770122
Epoch 549 
Overall Loss: 14.380938
Rec Loss: 12.282628
KL Loss: 2.098310
Y Loss: 1.003316
T Loss: 11.780970
Epoch 599 
Overall Loss: 14.384048
Rec Loss: 12.292055
KL Loss: 2.091993
Y Loss: 1.027854
T Loss: 11.778128
Epoch 649 
Overall Loss: 14.371576
Rec Loss: 12.278922
KL Loss: 2.092654
Y Loss: 1.009902
T Loss: 11.773971
Epoch 699 
Overall Loss: 14.359046
Rec Loss: 12.270322
KL Loss: 2.088724
Y Loss: 1.024767
T Loss: 11.757938
Epoch 749 
Overall Loss: 14.373321
Rec Loss: 12.258037
KL Loss: 2.115284
Y Loss: 1.000277
T Loss: 11.757899
Epoch 799 
Overall Loss: 14.372145
Rec Loss: 12.270028
KL Loss: 2.102117
Y Loss: 1.022358
T Loss: 11.758849
Epoch 849 
Overall Loss: 14.349704
Rec Loss: 12.246244
KL Loss: 2.103460
Y Loss: 1.010306
T Loss: 11.741091
Epoch 899 
Overall Loss: 14.359088
Rec Loss: 12.258596
KL Loss: 2.100492
Y Loss: 0.991294
T Loss: 11.762949
Epoch 949 
Overall Loss: 14.339637
Rec Loss: 12.272579
KL Loss: 2.067059
Y Loss: 1.022542
T Loss: 11.761308
Epoch 999 
Overall Loss: 14.353278
Rec Loss: 12.267012
KL Loss: 2.086266
Y Loss: 1.012407
T Loss: 11.760809
Epoch 1049 
Overall Loss: 14.354940
Rec Loss: 12.264672
KL Loss: 2.090269
Y Loss: 1.034275
T Loss: 11.747534
Epoch 1099 
Overall Loss: 14.359320
Rec Loss: 12.271921
KL Loss: 2.087399
Y Loss: 1.020362
T Loss: 11.761740
Epoch 1149 
Overall Loss: 14.353643
Rec Loss: 12.275775
KL Loss: 2.077868
Y Loss: 1.011850
T Loss: 11.769850
Epoch 1199 
Overall Loss: 14.329296
Rec Loss: 12.244743
KL Loss: 2.084553
Y Loss: 0.993167
T Loss: 11.748159
Epoch 1249 
Overall Loss: 14.347089
Rec Loss: 12.263092
KL Loss: 2.083997
Y Loss: 0.973172
T Loss: 11.776506
Epoch 1299 
Overall Loss: 14.341219
Rec Loss: 12.236673
KL Loss: 2.104546
Y Loss: 1.001783
T Loss: 11.735782
Epoch 1349 
Overall Loss: 14.344093
Rec Loss: 12.271942
KL Loss: 2.072151
Y Loss: 1.013440
T Loss: 11.765222
Epoch 1399 
Overall Loss: 14.327841
Rec Loss: 12.263056
KL Loss: 2.064784
Y Loss: 1.029665
T Loss: 11.748223
Epoch 1449 
Overall Loss: 14.330541
Rec Loss: 12.233328
KL Loss: 2.097213
Y Loss: 0.968954
T Loss: 11.748851
Epoch 1499 
Overall Loss: 14.323027
Rec Loss: 12.257291
KL Loss: 2.065736
Y Loss: 1.014220
T Loss: 11.750181
Epoch 1549 
Overall Loss: 14.325577
Rec Loss: 12.250398
KL Loss: 2.075179
Y Loss: 1.007351
T Loss: 11.746723
Epoch 1599 
Overall Loss: 14.333863
Rec Loss: 12.230414
KL Loss: 2.103449
Y Loss: 0.982781
T Loss: 11.739024
Epoch 1649 
Overall Loss: 14.353947
Rec Loss: 12.240966
KL Loss: 2.112981
Y Loss: 0.982176
T Loss: 11.749878
Epoch 1699 
Overall Loss: 14.348376
Rec Loss: 12.261911
KL Loss: 2.086464
Y Loss: 1.009477
T Loss: 11.757173
Epoch 1749 
Overall Loss: 14.350220
Rec Loss: 12.219170
KL Loss: 2.131050
Y Loss: 0.981259
T Loss: 11.728541
Epoch 1799 
Overall Loss: 14.331291
Rec Loss: 12.237367
KL Loss: 2.093924
Y Loss: 1.007473
T Loss: 11.733631
Epoch 1849 
Overall Loss: 14.349847
Rec Loss: 12.271894
KL Loss: 2.077953
Y Loss: 1.036672
T Loss: 11.753558
Epoch 1899 
Overall Loss: 14.317422
Rec Loss: 12.258453
KL Loss: 2.058969
Y Loss: 1.009476
T Loss: 11.753715
Epoch 1949 
Overall Loss: 14.330773
Rec Loss: 12.282573
KL Loss: 2.048201
Y Loss: 1.032784
T Loss: 11.766180
Epoch 1999 
Overall Loss: 14.308775
Rec Loss: 12.221745
KL Loss: 2.087029
Y Loss: 0.994370
T Loss: 11.724561
Epoch 2049 
Overall Loss: 14.336447
Rec Loss: 12.251958
KL Loss: 2.084488
Y Loss: 0.983835
T Loss: 11.760041
Epoch 2099 
Overall Loss: 14.331720
Rec Loss: 12.258097
KL Loss: 2.073622
Y Loss: 1.027472
T Loss: 11.744361
Epoch 2149 
Overall Loss: 14.351953
Rec Loss: 12.245655
KL Loss: 2.106298
Y Loss: 1.017971
T Loss: 11.736669
Epoch 2199 
Overall Loss: 14.328230
Rec Loss: 12.231198
KL Loss: 2.097031
Y Loss: 1.012745
T Loss: 11.724825
Epoch 2249 
Overall Loss: 14.334608
Rec Loss: 12.249053
KL Loss: 2.085556
Y Loss: 1.014477
T Loss: 11.741814
Epoch 2299 
Overall Loss: 14.337414
Rec Loss: 12.245797
KL Loss: 2.091617
Y Loss: 0.999239
T Loss: 11.746178
Epoch 2349 
Overall Loss: 14.307496
Rec Loss: 12.226885
KL Loss: 2.080611
Y Loss: 0.973041
T Loss: 11.740365
Epoch 2399 
Overall Loss: 14.354376
Rec Loss: 12.254137
KL Loss: 2.100239
Y Loss: 1.013940
T Loss: 11.747167
Epoch 2449 
Overall Loss: 14.326957
Rec Loss: 12.221753
KL Loss: 2.105204
Y Loss: 1.006096
T Loss: 11.718705
Epoch 2499 
Overall Loss: 14.350348
Rec Loss: 12.228815
KL Loss: 2.121534
Y Loss: 0.971014
T Loss: 11.743307
Epoch 2549 
Overall Loss: 14.319031
Rec Loss: 12.243303
KL Loss: 2.075729
Y Loss: 1.028281
T Loss: 11.729162
Epoch 2599 
Overall Loss: 14.311046
Rec Loss: 12.227722
KL Loss: 2.083325
Y Loss: 1.000594
T Loss: 11.727425
Epoch 2649 
Overall Loss: 14.340476
Rec Loss: 12.221352
KL Loss: 2.119124
Y Loss: 0.972518
T Loss: 11.735093
Epoch 2699 
Overall Loss: 14.322360
Rec Loss: 12.254127
KL Loss: 2.068234
Y Loss: 1.047872
T Loss: 11.730191
Epoch 2749 
Overall Loss: 14.333470
Rec Loss: 12.256637
KL Loss: 2.076832
Y Loss: 1.024501
T Loss: 11.744387
Epoch 2799 
Overall Loss: 14.343614
Rec Loss: 12.251251
KL Loss: 2.092364
Y Loss: 1.010916
T Loss: 11.745793
Epoch 2849 
Overall Loss: 14.327271
Rec Loss: 12.217502
KL Loss: 2.109770
Y Loss: 0.974130
T Loss: 11.730437
Epoch 2899 
Overall Loss: 14.324075
Rec Loss: 12.219520
KL Loss: 2.104556
Y Loss: 0.978856
T Loss: 11.730091
Epoch 2949 
Overall Loss: 14.309874
Rec Loss: 12.222711
KL Loss: 2.087164
Y Loss: 1.016676
T Loss: 11.714372
Epoch 2999 
Overall Loss: 14.333723
Rec Loss: 12.240568
KL Loss: 2.093155
Y Loss: 1.027386
T Loss: 11.726875
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.513828
Epoch 99
Rec Loss: 1.522037
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.866115
Epoch 99
Rec Loss: 9.857604
Epoch 149
Rec Loss: 9.853856
Epoch 199
Rec Loss: 9.853909
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.422680
Insample Error: 1.265495
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 18.460983
Rec Loss: 14.920407
KL Loss: 3.540575
Y Loss: 11.104193
T Loss: 13.575671
X Loss: -4.207361
Epoch 99 
Overall Loss: 0.426307
Rec Loss: -8.222889
KL Loss: 8.649196
Y Loss: 4.318043
T Loss: 13.348467
X Loss: -23.730378
Epoch 149 
Overall Loss: -5.303560
Rec Loss: -15.056777
KL Loss: 9.753217
Y Loss: 2.714253
T Loss: 13.335771
X Loss: -29.749675
Epoch 199 
Overall Loss: -8.956652
Rec Loss: -19.643359
KL Loss: 10.686707
Y Loss: 1.682690
T Loss: 13.326127
X Loss: -33.810830
Epoch 249 
Overall Loss: -11.039993
Rec Loss: -22.434273
KL Loss: 11.394281
Y Loss: 1.043650
T Loss: 13.317923
X Loss: -36.274020
Epoch 299 
Overall Loss: -12.260878
Rec Loss: -24.042880
KL Loss: 11.782002
Y Loss: 0.820017
T Loss: 13.310103
X Loss: -37.762992
Epoch 349 
Overall Loss: -13.081660
Rec Loss: -25.199287
KL Loss: 12.117628
Y Loss: 0.757324
T Loss: 13.297502
X Loss: -38.875450
Epoch 399 
Overall Loss: -13.870450
Rec Loss: -26.234518
KL Loss: 12.364067
Y Loss: 0.741662
T Loss: 13.281917
X Loss: -39.887266
Epoch 449 
Overall Loss: -14.749391
Rec Loss: -27.279928
KL Loss: 12.530536
Y Loss: 0.729545
T Loss: 13.270853
X Loss: -40.915552
Epoch 499 
Overall Loss: -15.187681
Rec Loss: -27.853810
KL Loss: 12.666129
Y Loss: 0.711065
T Loss: 13.252941
X Loss: -41.462284
Epoch 549 
Overall Loss: -15.895683
Rec Loss: -28.767102
KL Loss: 12.871419
Y Loss: 0.673813
T Loss: 13.220800
X Loss: -42.324809
Epoch 599 
Overall Loss: -16.475966
Rec Loss: -29.530596
KL Loss: 13.054630
Y Loss: 0.672059
T Loss: 13.205544
X Loss: -43.072170
Epoch 649 
Overall Loss: -16.937936
Rec Loss: -30.082226
KL Loss: 13.144290
Y Loss: 0.687255
T Loss: 13.167551
X Loss: -43.593404
Epoch 699 
Overall Loss: -17.326457
Rec Loss: -30.582343
KL Loss: 13.255885
Y Loss: 0.678665
T Loss: 13.139587
X Loss: -44.061263
Epoch 749 
Overall Loss: -17.696435
Rec Loss: -31.159824
KL Loss: 13.463390
Y Loss: 0.640151
T Loss: 13.098233
X Loss: -44.578132
Epoch 799 
Overall Loss: -18.095660
Rec Loss: -31.609875
KL Loss: 13.514215
Y Loss: 0.667630
T Loss: 13.075211
X Loss: -45.018900
Epoch 849 
Overall Loss: -18.384843
Rec Loss: -32.024130
KL Loss: 13.639287
Y Loss: 0.657342
T Loss: 13.040010
X Loss: -45.392810
Epoch 899 
Overall Loss: -18.882838
Rec Loss: -32.600444
KL Loss: 13.717606
Y Loss: 0.658292
T Loss: 13.007039
X Loss: -45.936629
Epoch 949 
Overall Loss: -19.055486
Rec Loss: -32.834480
KL Loss: 13.778994
Y Loss: 0.639732
T Loss: 12.982225
X Loss: -46.136571
Epoch 999 
Overall Loss: -19.378608
Rec Loss: -33.223197
KL Loss: 13.844588
Y Loss: 0.655599
T Loss: 12.952667
X Loss: -46.503663
Epoch 1049 
Overall Loss: -19.680426
Rec Loss: -33.499804
KL Loss: 13.819378
Y Loss: 0.670596
T Loss: 12.939541
X Loss: -46.774643
Epoch 1099 
Overall Loss: -19.879463
Rec Loss: -33.867140
KL Loss: 13.987677
Y Loss: 0.671468
T Loss: 12.934543
X Loss: -47.137415
Epoch 1149 
Overall Loss: -19.742132
Rec Loss: -33.813892
KL Loss: 14.071761
Y Loss: 0.662731
T Loss: 12.919353
X Loss: -47.064612
Epoch 1199 
Overall Loss: -20.253376
Rec Loss: -34.318303
KL Loss: 14.064927
Y Loss: 0.671606
T Loss: 12.909446
X Loss: -47.563551
Epoch 1249 
Overall Loss: -20.398887
Rec Loss: -34.565992
KL Loss: 14.167105
Y Loss: 0.664626
T Loss: 12.893535
X Loss: -47.791840
Epoch 1299 
Overall Loss: -20.588823
Rec Loss: -34.532118
KL Loss: 13.943296
Y Loss: 0.688534
T Loss: 12.896763
X Loss: -47.773149
Epoch 1349 
Overall Loss: -20.877190
Rec Loss: -35.133509
KL Loss: 14.256319
Y Loss: 0.697344
T Loss: 12.883322
X Loss: -48.365503
Epoch 1399 
Overall Loss: -21.258326
Rec Loss: -35.544204
KL Loss: 14.285879
Y Loss: 0.673731
T Loss: 12.885120
X Loss: -48.766190
Epoch 1449 
Overall Loss: -21.411987
Rec Loss: -35.653635
KL Loss: 14.241649
Y Loss: 0.700864
T Loss: 12.870122
X Loss: -48.874190
Epoch 1499 
Overall Loss: -21.593400
Rec Loss: -35.937083
KL Loss: 14.343682
Y Loss: 0.708205
T Loss: 12.861341
X Loss: -49.152527
Epoch 1549 
Overall Loss: -21.772675
Rec Loss: -36.195943
KL Loss: 14.423268
Y Loss: 0.705453
T Loss: 12.857045
X Loss: -49.405714
Epoch 1599 
Overall Loss: -21.970377
Rec Loss: -36.450439
KL Loss: 14.480061
Y Loss: 0.704219
T Loss: 12.846623
X Loss: -49.649172
Epoch 1649 
Overall Loss: -22.072949
Rec Loss: -36.435149
KL Loss: 14.362199
Y Loss: 0.730531
T Loss: 12.844827
X Loss: -49.645240
Epoch 1699 
Overall Loss: -22.045316
Rec Loss: -36.481408
KL Loss: 14.436093
Y Loss: 0.714825
T Loss: 12.840830
X Loss: -49.679652
Epoch 1749 
Overall Loss: -21.736480
Rec Loss: -36.038542
KL Loss: 14.302061
Y Loss: 0.735732
T Loss: 12.838811
X Loss: -49.245217
Epoch 1799 
Overall Loss: -22.598031
Rec Loss: -37.197949
KL Loss: 14.599919
Y Loss: 0.713793
T Loss: 12.819978
X Loss: -50.374824
Epoch 1849 
Overall Loss: -22.450892
Rec Loss: -37.025658
KL Loss: 14.574766
Y Loss: 0.723244
T Loss: 12.817375
X Loss: -50.204654
Epoch 1899 
Overall Loss: -22.770484
Rec Loss: -37.332269
KL Loss: 14.561785
Y Loss: 0.710461
T Loss: 12.807526
X Loss: -50.495025
Epoch 1949 
Overall Loss: -22.822882
Rec Loss: -37.463900
KL Loss: 14.641020
Y Loss: 0.737256
T Loss: 12.803157
X Loss: -50.635686
Epoch 1999 
Overall Loss: -22.908030
Rec Loss: -37.537542
KL Loss: 14.629511
Y Loss: 0.717031
T Loss: 12.802236
X Loss: -50.698292
Epoch 2049 
Overall Loss: -23.093112
Rec Loss: -37.799860
KL Loss: 14.706748
Y Loss: 0.720179
T Loss: 12.790122
X Loss: -50.950071
Epoch 2099 
Overall Loss: -23.382965
Rec Loss: -38.057980
KL Loss: 14.675013
Y Loss: 0.719802
T Loss: 12.782958
X Loss: -51.200838
Epoch 2149 
Overall Loss: -23.553356
Rec Loss: -38.302633
KL Loss: 14.749277
Y Loss: 0.741393
T Loss: 12.773806
X Loss: -51.447136
Epoch 2199 
Overall Loss: -23.499265
Rec Loss: -38.199885
KL Loss: 14.700621
Y Loss: 0.726713
T Loss: 12.771096
X Loss: -51.334338
Epoch 2249 
Overall Loss: -23.746504
Rec Loss: -38.464808
KL Loss: 14.718304
Y Loss: 0.726699
T Loss: 12.761394
X Loss: -51.589552
Epoch 2299 
Overall Loss: -23.884486
Rec Loss: -38.673348
KL Loss: 14.788861
Y Loss: 0.720153
T Loss: 12.753631
X Loss: -51.787055
Epoch 2349 
Overall Loss: -23.823083
Rec Loss: -38.631276
KL Loss: 14.808194
Y Loss: 0.721898
T Loss: 12.747025
X Loss: -51.739250
Epoch 2399 
Overall Loss: -23.649167
Rec Loss: -38.564894
KL Loss: 14.915727
Y Loss: 0.706686
T Loss: 12.737984
X Loss: -51.656222
Epoch 2449 
Overall Loss: -24.265025
Rec Loss: -39.219580
KL Loss: 14.954555
Y Loss: 0.680202
T Loss: 12.719429
X Loss: -52.279111
Epoch 2499 
Overall Loss: -23.905961
Rec Loss: -38.621006
KL Loss: 14.715045
Y Loss: 0.726172
T Loss: 12.718238
X Loss: -51.702332
Epoch 2549 
Overall Loss: -24.493835
Rec Loss: -39.320402
KL Loss: 14.826567
Y Loss: 0.727734
T Loss: 12.704488
X Loss: -52.388757
Epoch 2599 
Overall Loss: -24.327376
Rec Loss: -39.260803
KL Loss: 14.933428
Y Loss: 0.718175
T Loss: 12.709679
X Loss: -52.329570
Epoch 2649 
Overall Loss: -24.370495
Rec Loss: -39.261353
KL Loss: 14.890857
Y Loss: 0.730175
T Loss: 12.706123
X Loss: -52.332563
Epoch 2699 
Overall Loss: -24.613407
Rec Loss: -39.653177
KL Loss: 15.039769
Y Loss: 0.716366
T Loss: 12.690104
X Loss: -52.701464
Epoch 2749 
Overall Loss: -24.249985
Rec Loss: -39.217364
KL Loss: 14.967381
Y Loss: 0.708390
T Loss: 12.670006
X Loss: -52.241566
Epoch 2799 
Overall Loss: -24.944409
Rec Loss: -39.877702
KL Loss: 14.933292
Y Loss: 0.706762
T Loss: 12.651825
X Loss: -52.882908
Epoch 2849 
Overall Loss: -24.949580
Rec Loss: -39.928695
KL Loss: 14.979114
Y Loss: 0.698637
T Loss: 12.648581
X Loss: -52.926594
Epoch 2899 
Overall Loss: -24.710021
Rec Loss: -39.718963
KL Loss: 15.008942
Y Loss: 0.688445
T Loss: 12.639365
X Loss: -52.702552
Epoch 2949 
Overall Loss: -25.241950
Rec Loss: -40.383579
KL Loss: 15.141628
Y Loss: 0.680834
T Loss: 12.608613
X Loss: -53.332609
Epoch 2999 
Overall Loss: -25.045375
Rec Loss: -40.136061
KL Loss: 15.090687
Y Loss: 0.691563
T Loss: 12.600146
X Loss: -53.081990
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.813091
Epoch 99
Rec Loss: 2.806997
Epoch 149
Rec Loss: 2.767721
Epoch 199
Rec Loss: 2.772941
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.002486
Epoch 99
Rec Loss: 0.001814
Epoch 149
Rec Loss: 0.001110
Epoch 199
Rec Loss: 0.001325
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.323863
Insample Error 2.319169
[34m== Direct Regression: Training all ==[0m
Epoch 49 
Prediction Loss: 7.187749
Epoch 99 
Prediction Loss: 6.870922
Epoch 149 
Prediction Loss: 6.660327
Epoch 199 
Prediction Loss: 6.575469
Epoch 249 
Prediction Loss: 6.460483
Epoch 299 
Prediction Loss: 6.416030
Epoch 349 
Prediction Loss: 6.336734
Epoch 399 
Prediction Loss: 6.295570
Epoch 449 
Prediction Loss: 6.250508
Epoch 499 
Prediction Loss: 6.233515
Epoch 549 
Prediction Loss: 6.197293
Epoch 599 
Prediction Loss: 6.123510
Epoch 649 
Prediction Loss: 6.098668
Epoch 699 
Prediction Loss: 6.048308
Epoch 749 
Prediction Loss: 5.996733
Epoch 799 
Prediction Loss: 5.961299
Epoch 849 
Prediction Loss: 5.895288
Epoch 899 
Prediction Loss: 5.923868
Epoch 949 
Prediction Loss: 5.844723
Epoch 999 
Prediction Loss: 5.797960
Epoch 1049 
Prediction Loss: 5.725446
Epoch 1099 
Prediction Loss: 5.687916
Epoch 1149 
Prediction Loss: 5.658802
Epoch 1199 
Prediction Loss: 5.546188
Epoch 1249 
Prediction Loss: 5.542123
Epoch 1299 
Prediction Loss: 5.476482
Epoch 1349 
Prediction Loss: 5.424508
Epoch 1399 
Prediction Loss: 5.402634
Epoch 1449 
Prediction Loss: 5.358471
Epoch 1499 
Prediction Loss: 5.305380
Epoch 1549 
Prediction Loss: 5.240481
Epoch 1599 
Prediction Loss: 5.185714
Epoch 1649 
Prediction Loss: 5.259986
Epoch 1699 
Prediction Loss: 5.095745
Epoch 1749 
Prediction Loss: 5.127525
Epoch 1799 
Prediction Loss: 5.018314
Epoch 1849 
Prediction Loss: 5.006630
Epoch 1899 
Prediction Loss: 4.958513
Epoch 1949 
Prediction Loss: 4.907207
Epoch 1999 
Prediction Loss: 4.859599
Epoch 2049 
Prediction Loss: 4.852736
Epoch 2099 
Prediction Loss: 4.795074
Epoch 2149 
Prediction Loss: 4.764143
Epoch 2199 
Prediction Loss: 4.748861
Epoch 2249 
Prediction Loss: 4.664242
Epoch 2299 
Prediction Loss: 4.665933
Epoch 2349 
Prediction Loss: 4.636192
Epoch 2399 
Prediction Loss: 4.621434
Epoch 2449 
Prediction Loss: 4.601585
Epoch 2499 
Prediction Loss: 4.523435
Epoch 2549 
Prediction Loss: 4.494786
Epoch 2599 
Prediction Loss: 4.499379
Epoch 2649 
Prediction Loss: 4.460056
Epoch 2699 
Prediction Loss: 4.423779
Epoch 2749 
Prediction Loss: 4.407486
Epoch 2799 
Prediction Loss: 4.396401
Epoch 2849 
Prediction Loss: 4.444357
Epoch 2899 
Prediction Loss: 4.358200
Epoch 2949 
Prediction Loss: 4.306673
Epoch 2999 
Prediction Loss: 4.280189
Epoch 3049 
Prediction Loss: 4.348481
Epoch 3099 
Prediction Loss: 4.248387
Epoch 3149 
Prediction Loss: 4.196621
Epoch 3199 
Prediction Loss: 4.188149
Epoch 3249 
Prediction Loss: 4.199054
Epoch 3299 
Prediction Loss: 4.141405
Epoch 3349 
Prediction Loss: 4.161513
Epoch 3399 
Prediction Loss: 4.141042
Epoch 3449 
Prediction Loss: 4.088487
Epoch 3499 
Prediction Loss: 4.065525
Epoch 3549 
Prediction Loss: 4.043758
Epoch 3599 
Prediction Loss: 4.099118
Epoch 3649 
Prediction Loss: 4.038899
Epoch 3699 
Prediction Loss: 4.012253
Epoch 3749 
Prediction Loss: 4.032477
Epoch 3799 
Prediction Loss: 4.001135
Epoch 3849 
Prediction Loss: 4.004489
Epoch 3899 
Prediction Loss: 3.925790
Epoch 3949 
Prediction Loss: 3.904784
Epoch 3999 
Prediction Loss: 3.901024
Epoch 4049 
Prediction Loss: 3.936184
Epoch 4099 
Prediction Loss: 3.866312
Epoch 4149 
Prediction Loss: 3.889200
Epoch 4199 
Prediction Loss: 3.864888
Epoch 4249 
Prediction Loss: 3.853089
Epoch 4299 
Prediction Loss: 3.805896
Epoch 4349 
Prediction Loss: 3.800497
Epoch 4399 
Prediction Loss: 3.787411
Epoch 4449 
Prediction Loss: 3.765654
Epoch 4499 
Prediction Loss: 3.782322
Epoch 4549 
Prediction Loss: 3.766527
Epoch 4599 
Prediction Loss: 3.716834
Epoch 4649 
Prediction Loss: 3.725304
Epoch 4699 
Prediction Loss: 3.703098
Epoch 4749 
Prediction Loss: 3.727604
Epoch 4799 
Prediction Loss: 3.662868
Epoch 4849 
Prediction Loss: 3.733091
Epoch 4899 
Prediction Loss: 3.631779
Epoch 4949 
Prediction Loss: 3.653252
Epoch 4999 
Prediction Loss: 3.755042
Epoch 5049 
Prediction Loss: 3.601972
Epoch 5099 
Prediction Loss: 3.673859
Epoch 5149 
Prediction Loss: 3.582298
Epoch 5199 
Prediction Loss: 3.566069
Epoch 5249 
Prediction Loss: 3.601545
Epoch 5299 
Prediction Loss: 3.571848
Epoch 5349 
Prediction Loss: 3.551855
Epoch 5399 
Prediction Loss: 3.536134
Epoch 5449 
Prediction Loss: 3.535110
Epoch 5499 
Prediction Loss: 3.507371
Epoch 5549 
Prediction Loss: 3.508552
Epoch 5599 
Prediction Loss: 3.526630
Epoch 5649 
Prediction Loss: 3.492349
Epoch 5699 
Prediction Loss: 3.488305
Epoch 5749 
Prediction Loss: 3.478703
Epoch 5799 
Prediction Loss: 3.463740
Epoch 5849 
Prediction Loss: 3.440359
Epoch 5899 
Prediction Loss: 3.469049
Epoch 5949 
Prediction Loss: 3.461099
Epoch 5999 
Prediction Loss: 3.404205
[34m== Direct Regression: Testing in sample performance ==[0m
Train Error 1.836170
Insample Error 4.740777
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 14.535462
Rec Loss: 12.603879
KL Loss: 1.931583
Y Loss: 1.057058
T Loss: 12.075350
Epoch 99 
Overall Loss: 14.444867
Rec Loss: 12.315117
KL Loss: 2.129750
Y Loss: 1.000664
T Loss: 11.814786
Epoch 149 
Overall Loss: 14.440100
Rec Loss: 12.306369
KL Loss: 2.133731
Y Loss: 1.012227
T Loss: 11.800255
Epoch 199 
Overall Loss: 14.415860
Rec Loss: 12.296843
KL Loss: 2.119016
Y Loss: 1.001085
T Loss: 11.796301
Epoch 249 
Overall Loss: 14.416004
Rec Loss: 12.262009
KL Loss: 2.153996
Y Loss: 0.970225
T Loss: 11.776896
Epoch 299 
Overall Loss: 14.409002
Rec Loss: 12.294035
KL Loss: 2.114967
Y Loss: 1.017410
T Loss: 11.785330
Epoch 349 
Overall Loss: 14.381233
Rec Loss: 12.299880
KL Loss: 2.081353
Y Loss: 1.034049
T Loss: 11.782856
Epoch 399 
Overall Loss: 14.378299
Rec Loss: 12.289155
KL Loss: 2.089144
Y Loss: 1.011847
T Loss: 11.783232
Epoch 449 
Overall Loss: 14.414168
Rec Loss: 12.271742
KL Loss: 2.142425
Y Loss: 0.989925
T Loss: 11.776780
Epoch 499 
Overall Loss: 14.388921
Rec Loss: 12.288133
KL Loss: 2.100789
Y Loss: 1.018168
T Loss: 11.779049
Epoch 549 
Overall Loss: 14.385713
Rec Loss: 12.289004
KL Loss: 2.096708
Y Loss: 1.001625
T Loss: 11.788192
Epoch 599 
Overall Loss: 14.357759
Rec Loss: 12.265254
KL Loss: 2.092506
Y Loss: 1.015614
T Loss: 11.757446
Epoch 649 
Overall Loss: 14.370847
Rec Loss: 12.237075
KL Loss: 2.133772
Y Loss: 0.981259
T Loss: 11.746445
Epoch 699 
Overall Loss: 14.360074
Rec Loss: 12.273065
KL Loss: 2.087009
Y Loss: 1.032034
T Loss: 11.757049
Epoch 749 
Overall Loss: 14.349147
Rec Loss: 12.256088
KL Loss: 2.093059
Y Loss: 1.006821
T Loss: 11.752678
Epoch 799 
Overall Loss: 14.363992
Rec Loss: 12.246756
KL Loss: 2.117236
Y Loss: 0.980861
T Loss: 11.756325
Epoch 849 
Overall Loss: 14.362467
Rec Loss: 12.259621
KL Loss: 2.102846
Y Loss: 1.000274
T Loss: 11.759485
Epoch 899 
Overall Loss: 14.372872
Rec Loss: 12.286961
KL Loss: 2.085911
Y Loss: 1.019909
T Loss: 11.777006
Epoch 949 
Overall Loss: 14.355440
Rec Loss: 12.258213
KL Loss: 2.097226
Y Loss: 1.032973
T Loss: 11.741727
Epoch 999 
Overall Loss: 14.372397
Rec Loss: 12.262352
KL Loss: 2.110046
Y Loss: 0.995781
T Loss: 11.764461
Epoch 1049 
Overall Loss: 14.337423
Rec Loss: 12.254008
KL Loss: 2.083415
Y Loss: 1.025070
T Loss: 11.741472
Epoch 1099 
Overall Loss: 14.374479
Rec Loss: 12.262479
KL Loss: 2.112000
Y Loss: 1.010967
T Loss: 11.756995
Epoch 1149 
Overall Loss: 14.351254
Rec Loss: 12.271624
KL Loss: 2.079630
Y Loss: 0.993315
T Loss: 11.774967
Epoch 1199 
Overall Loss: 14.345402
Rec Loss: 12.269003
KL Loss: 2.076399
Y Loss: 1.033705
T Loss: 11.752150
Epoch 1249 
Overall Loss: 14.340406
Rec Loss: 12.251828
KL Loss: 2.088578
Y Loss: 1.013378
T Loss: 11.745139
Epoch 1299 
Overall Loss: 14.348923
Rec Loss: 12.264099
KL Loss: 2.084824
Y Loss: 1.003334
T Loss: 11.762432
Epoch 1349 
Overall Loss: 14.343927
Rec Loss: 12.258739
KL Loss: 2.085189
Y Loss: 1.012439
T Loss: 11.752519
Epoch 1399 
Overall Loss: 14.349591
Rec Loss: 12.253050
KL Loss: 2.096540
Y Loss: 1.000316
T Loss: 11.752892
Epoch 1449 
Overall Loss: 14.328574
Rec Loss: 12.246470
KL Loss: 2.082104
Y Loss: 1.005577
T Loss: 11.743681
Epoch 1499 
Overall Loss: 14.319272
Rec Loss: 12.229760
KL Loss: 2.089512
Y Loss: 0.981043
T Loss: 11.739238
Epoch 1549 
Overall Loss: 14.347899
Rec Loss: 12.247994
KL Loss: 2.099906
Y Loss: 0.981043
T Loss: 11.757472
Epoch 1599 
Overall Loss: 14.356243
Rec Loss: 12.255183
KL Loss: 2.101060
Y Loss: 1.019711
T Loss: 11.745328
Epoch 1649 
Overall Loss: 14.318166
Rec Loss: 12.240911
KL Loss: 2.077255
Y Loss: 0.985025
T Loss: 11.748399
Epoch 1699 
Overall Loss: 14.336056
Rec Loss: 12.254821
KL Loss: 2.081234
Y Loss: 1.034800
T Loss: 11.737421
Epoch 1749 
Overall Loss: 14.345295
Rec Loss: 12.262316
KL Loss: 2.082979
Y Loss: 1.050479
T Loss: 11.737077
Epoch 1799 
Overall Loss: 14.344244
Rec Loss: 12.252302
KL Loss: 2.091942
Y Loss: 0.995858
T Loss: 11.754373
Epoch 1849 
Overall Loss: 14.339570
Rec Loss: 12.227408
KL Loss: 2.112162
Y Loss: 0.993398
T Loss: 11.730709
Epoch 1899 
Overall Loss: 14.338646
Rec Loss: 12.222403
KL Loss: 2.116242
Y Loss: 0.976586
T Loss: 11.734110
Epoch 1949 
Overall Loss: 14.345928
Rec Loss: 12.259960
KL Loss: 2.085968
Y Loss: 0.992385
T Loss: 11.763767
Epoch 1999 
Overall Loss: 14.311137
Rec Loss: 12.233735
KL Loss: 2.077402
Y Loss: 1.006250
T Loss: 11.730610
Epoch 2049 
Overall Loss: 14.345540
Rec Loss: 12.261608
KL Loss: 2.083931
Y Loss: 1.023254
T Loss: 11.749981
Epoch 2099 
Overall Loss: 14.351143
Rec Loss: 12.243914
KL Loss: 2.107229
Y Loss: 1.009201
T Loss: 11.739313
Epoch 2149 
Overall Loss: 14.335506
Rec Loss: 12.248907
KL Loss: 2.086598
Y Loss: 1.005252
T Loss: 11.746281
Epoch 2199 
Overall Loss: 14.341818
Rec Loss: 12.245977
KL Loss: 2.095841
Y Loss: 1.016146
T Loss: 11.737904
Epoch 2249 
Overall Loss: 14.324871
Rec Loss: 12.231173
KL Loss: 2.093697
Y Loss: 0.984876
T Loss: 11.738735
Epoch 2299 
Overall Loss: 14.332353
Rec Loss: 12.214933
KL Loss: 2.117420
Y Loss: 0.991315
T Loss: 11.719276
Epoch 2349 
Overall Loss: 14.328067
Rec Loss: 12.246416
KL Loss: 2.081652
Y Loss: 1.000011
T Loss: 11.746410
Epoch 2399 
Overall Loss: 14.325750
Rec Loss: 12.234636
KL Loss: 2.091115
Y Loss: 0.996313
T Loss: 11.736479
Epoch 2449 
Overall Loss: 14.323481
Rec Loss: 12.244318
KL Loss: 2.079163
Y Loss: 1.002375
T Loss: 11.743131
Epoch 2499 
Overall Loss: 14.329066
Rec Loss: 12.213639
KL Loss: 2.115426
Y Loss: 0.997013
T Loss: 11.715133
Epoch 2549 
Overall Loss: 14.323401
Rec Loss: 12.233873
KL Loss: 2.089528
Y Loss: 0.996629
T Loss: 11.735559
Epoch 2599 
Overall Loss: 14.322980
Rec Loss: 12.223847
KL Loss: 2.099133
Y Loss: 0.990912
T Loss: 11.728391
Epoch 2649 
Overall Loss: 14.313886
Rec Loss: 12.252819
KL Loss: 2.061068
Y Loss: 1.018608
T Loss: 11.743514
Epoch 2699 
Overall Loss: 14.326762
Rec Loss: 12.227269
KL Loss: 2.099493
Y Loss: 0.997660
T Loss: 11.728439
Epoch 2749 
Overall Loss: 14.319389
Rec Loss: 12.236482
KL Loss: 2.082907
Y Loss: 1.008485
T Loss: 11.732240
Epoch 2799 
Overall Loss: 14.286419
Rec Loss: 12.226620
KL Loss: 2.059799
Y Loss: 1.019654
T Loss: 11.716793
Epoch 2849 
Overall Loss: 14.342298
Rec Loss: 12.243364
KL Loss: 2.098935
Y Loss: 1.012247
T Loss: 11.737240
Epoch 2899 
Overall Loss: 14.307529
Rec Loss: 12.217452
KL Loss: 2.090077
Y Loss: 1.018898
T Loss: 11.708003
Epoch 2949 
Overall Loss: 14.349830
Rec Loss: 12.221700
KL Loss: 2.128130
Y Loss: 0.987313
T Loss: 11.728043
Epoch 2999 
Overall Loss: 14.329106
Rec Loss: 12.232809
KL Loss: 2.096298
Y Loss: 0.999869
T Loss: 11.732874
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.527949
Epoch 99
Rec Loss: 1.524344
Epoch 149
Rec Loss: 1.530677
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.877186
Epoch 99
Rec Loss: 9.857304
Epoch 149
Rec Loss: 9.839199
Epoch 199
Rec Loss: 9.860396
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.434932
Insample Error: 1.377463
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 19.280137
Rec Loss: 15.805222
KL Loss: 3.474916
Y Loss: 8.344265
T Loss: 13.413156
X Loss: -1.780067
Epoch 99 
Overall Loss: 1.314237
Rec Loss: -9.276478
KL Loss: 10.590714
Y Loss: 2.674553
T Loss: 13.299573
X Loss: -23.913327
Epoch 149 
Overall Loss: -3.941142
Rec Loss: -15.902482
KL Loss: 11.961340
Y Loss: 1.761918
T Loss: 13.272930
X Loss: -30.056371
Epoch 199 
Overall Loss: -7.439143
Rec Loss: -20.634593
KL Loss: 13.195449
Y Loss: 1.057389
T Loss: 13.250233
X Loss: -34.413520
Epoch 249 
Overall Loss: -9.106073
Rec Loss: -23.117096
KL Loss: 14.011023
Y Loss: 0.654023
T Loss: 13.225045
X Loss: -36.669153
Epoch 299 
Overall Loss: -10.448166
Rec Loss: -24.914150
KL Loss: 14.465984
Y Loss: 0.462505
T Loss: 13.195799
X Loss: -38.341201
Epoch 349 
Overall Loss: -11.476762
Rec Loss: -26.280992
KL Loss: 14.804230
Y Loss: 0.347889
T Loss: 13.174809
X Loss: -39.629745
Epoch 399 
Overall Loss: -12.245101
Rec Loss: -27.263024
KL Loss: 15.017923
Y Loss: 0.313119
T Loss: 13.139319
X Loss: -40.558902
Epoch 449 
Overall Loss: -12.913089
Rec Loss: -28.101289
KL Loss: 15.188200
Y Loss: 0.302011
T Loss: 13.095160
X Loss: -41.347453
Epoch 499 
Overall Loss: -13.391940
Rec Loss: -28.709140
KL Loss: 15.317200
Y Loss: 0.233493
T Loss: 13.034723
X Loss: -41.860610
Epoch 549 
Overall Loss: -13.928206
Rec Loss: -29.491872
KL Loss: 15.563667
Y Loss: 0.224441
T Loss: 12.965412
X Loss: -42.569504
Epoch 599 
Overall Loss: -14.423989
Rec Loss: -30.197668
KL Loss: 15.773678
Y Loss: 0.204449
T Loss: 12.878356
X Loss: -43.178248
Epoch 649 
Overall Loss: -14.860910
Rec Loss: -30.710238
KL Loss: 15.849328
Y Loss: 0.232104
T Loss: 12.810861
X Loss: -43.637151
Epoch 699 
Overall Loss: -15.269752
Rec Loss: -31.304972
KL Loss: 16.035219
Y Loss: 0.191600
T Loss: 12.730394
X Loss: -44.131165
Epoch 749 
Overall Loss: -15.704561
Rec Loss: -31.836597
KL Loss: 16.132036
Y Loss: 0.180272
T Loss: 12.655170
X Loss: -44.581902
Epoch 799 
Overall Loss: -15.876574
Rec Loss: -32.168145
KL Loss: 16.291571
Y Loss: 0.183986
T Loss: 12.586341
X Loss: -44.846479
Epoch 849 
Overall Loss: -16.186648
Rec Loss: -32.654526
KL Loss: 16.467879
Y Loss: 0.161572
T Loss: 12.513156
X Loss: -45.248469
Epoch 899 
Overall Loss: -16.616362
Rec Loss: -33.108860
KL Loss: 16.492498
Y Loss: 0.157686
T Loss: 12.444765
X Loss: -45.632468
Epoch 949 
Overall Loss: -16.804353
Rec Loss: -33.533114
KL Loss: 16.728761
Y Loss: 0.139633
T Loss: 12.361766
X Loss: -45.964696
Epoch 999 
Overall Loss: -17.065476
Rec Loss: -34.023346
KL Loss: 16.957870
Y Loss: 0.144211
T Loss: 12.289019
X Loss: -46.384470
Epoch 1049 
Overall Loss: -17.497555
Rec Loss: -34.363761
KL Loss: 16.866207
Y Loss: 0.147873
T Loss: 12.239457
X Loss: -46.677157
Epoch 1099 
Overall Loss: -17.490295
Rec Loss: -34.617661
KL Loss: 17.127366
Y Loss: 0.127463
T Loss: 12.197319
X Loss: -46.878713
Epoch 1149 
Overall Loss: -17.742917
Rec Loss: -34.942974
KL Loss: 17.200057
Y Loss: 0.129069
T Loss: 12.159963
X Loss: -47.167471
Epoch 1199 
Overall Loss: -17.840265
Rec Loss: -35.113821
KL Loss: 17.273555
Y Loss: 0.125287
T Loss: 12.139651
X Loss: -47.316114
Epoch 1249 
Overall Loss: -18.261482
Rec Loss: -35.591644
KL Loss: 17.330162
Y Loss: 0.113957
T Loss: 12.114921
X Loss: -47.763543
Epoch 1299 
Overall Loss: -18.238812
Rec Loss: -35.692794
KL Loss: 17.453982
Y Loss: 0.106786
T Loss: 12.100921
X Loss: -47.847108
Epoch 1349 
Overall Loss: -18.511706
Rec Loss: -36.035453
KL Loss: 17.523747
Y Loss: 0.108611
T Loss: 12.078355
X Loss: -48.168113
Epoch 1399 
Overall Loss: -18.756058
Rec Loss: -36.260037
KL Loss: 17.503979
Y Loss: 0.110116
T Loss: 12.084512
X Loss: -48.399607
Epoch 1449 
Overall Loss: -18.938996
Rec Loss: -36.575180
KL Loss: 17.636185
Y Loss: 0.111925
T Loss: 12.063161
X Loss: -48.694305
Epoch 1499 
Overall Loss: -18.848650
Rec Loss: -36.530616
KL Loss: 17.681966
Y Loss: 0.102346
T Loss: 12.052241
X Loss: -48.634030
Epoch 1549 
Overall Loss: -18.982129
Rec Loss: -36.588994
KL Loss: 17.606864
Y Loss: 0.108614
T Loss: 12.039435
X Loss: -48.682736
Epoch 1599 
Overall Loss: -19.180473
Rec Loss: -36.996171
KL Loss: 17.815697
Y Loss: 0.090767
T Loss: 12.031399
X Loss: -49.072952
Epoch 1649 
Overall Loss: -19.508210
Rec Loss: -37.358349
KL Loss: 17.850139
Y Loss: 0.105250
T Loss: 12.026719
X Loss: -49.437693
Epoch 1699 
Overall Loss: -19.672130
Rec Loss: -37.473147
KL Loss: 17.801017
Y Loss: 0.099640
T Loss: 12.025091
X Loss: -49.548058
Epoch 1749 
Overall Loss: -19.585929
Rec Loss: -37.592802
KL Loss: 18.006873
Y Loss: 0.088588
T Loss: 12.020740
X Loss: -49.657836
Epoch 1799 
Overall Loss: -19.543654
Rec Loss: -37.435557
KL Loss: 17.891904
Y Loss: 0.090162
T Loss: 11.998095
X Loss: -49.478733
Epoch 1849 
Overall Loss: -19.930594
Rec Loss: -37.924666
KL Loss: 17.994073
Y Loss: 0.101288
T Loss: 11.995542
X Loss: -49.970853
Epoch 1899 
Overall Loss: -20.198098
Rec Loss: -38.242110
KL Loss: 18.044013
Y Loss: 0.095095
T Loss: 11.978381
X Loss: -50.268039
Epoch 1949 
Overall Loss: -20.379475
Rec Loss: -38.454469
KL Loss: 18.074993
Y Loss: 0.094510
T Loss: 11.969538
X Loss: -50.471262
Epoch 1999 
Overall Loss: -20.082366
Rec Loss: -38.233405
KL Loss: 18.151040
Y Loss: 0.085757
T Loss: 11.959934
X Loss: -50.236218
Epoch 2049 
Overall Loss: -20.412072
Rec Loss: -38.661127
KL Loss: 18.249055
Y Loss: 0.082354
T Loss: 11.944392
X Loss: -50.646695
Epoch 2099 
Overall Loss: -20.636075
Rec Loss: -38.957114
KL Loss: 18.321040
Y Loss: 0.087384
T Loss: 11.951281
X Loss: -50.952087
Epoch 2149 
Overall Loss: -20.561401
Rec Loss: -38.936401
KL Loss: 18.375001
Y Loss: 0.082212
T Loss: 11.954423
X Loss: -50.931930
Epoch 2199 
Overall Loss: -20.997181
Rec Loss: -39.361839
KL Loss: 18.364659
Y Loss: 0.083788
T Loss: 11.945271
X Loss: -51.349005
Epoch 2249 
Overall Loss: -20.936155
Rec Loss: -39.342863
KL Loss: 18.406708
Y Loss: 0.085514
T Loss: 11.932464
X Loss: -51.318084
Epoch 2299 
Overall Loss: -21.194816
Rec Loss: -39.702245
KL Loss: 18.507428
Y Loss: 0.083975
T Loss: 11.933358
X Loss: -51.677591
Epoch 2349 
Overall Loss: -21.069972
Rec Loss: -39.448139
KL Loss: 18.378168
Y Loss: 0.088239
T Loss: 11.934180
X Loss: -51.426439
Epoch 2399 
Overall Loss: -21.264994
Rec Loss: -39.684303
KL Loss: 18.419308
Y Loss: 0.085472
T Loss: 11.932514
X Loss: -51.659553
Epoch 2449 
Overall Loss: -21.333621
Rec Loss: -39.824446
KL Loss: 18.490825
Y Loss: 0.084840
T Loss: 11.920573
X Loss: -51.787440
Epoch 2499 
Overall Loss: -21.421582
Rec Loss: -39.942151
KL Loss: 18.520569
Y Loss: 0.081788
T Loss: 11.933418
X Loss: -51.916463
Epoch 2549 
Overall Loss: -21.581713
Rec Loss: -39.946666
KL Loss: 18.364953
Y Loss: 0.083617
T Loss: 11.927265
X Loss: -51.915739
Epoch 2599 
Overall Loss: -21.721333
Rec Loss: -40.185604
KL Loss: 18.464271
Y Loss: 0.084219
T Loss: 11.913157
X Loss: -52.140871
Epoch 2649 
Overall Loss: -21.313473
Rec Loss: -39.945762
KL Loss: 18.632290
Y Loss: 0.081603
T Loss: 11.904953
X Loss: -51.891517
Epoch 2699 
Overall Loss: -21.967485
Rec Loss: -40.617334
KL Loss: 18.649847
Y Loss: 0.081705
T Loss: 11.908553
X Loss: -52.566740
Epoch 2749 
Overall Loss: -21.898204
Rec Loss: -40.441436
KL Loss: 18.543233
Y Loss: 0.082109
T Loss: 11.905074
X Loss: -52.387565
Epoch 2799 
Overall Loss: -21.911085
Rec Loss: -40.589473
KL Loss: 18.678387
Y Loss: 0.086162
T Loss: 11.887861
X Loss: -52.520414
Epoch 2849 
Overall Loss: -22.049364
Rec Loss: -40.771347
KL Loss: 18.721982
Y Loss: 0.083557
T Loss: 11.880865
X Loss: -52.693990
Epoch 2899 
Overall Loss: -21.919824
Rec Loss: -40.547536
KL Loss: 18.627711
Y Loss: 0.084213
T Loss: 11.888201
X Loss: -52.477843
Epoch 2949 
Overall Loss: -21.886781
Rec Loss: -40.559275
KL Loss: 18.672494
Y Loss: 0.085025
T Loss: 11.896410
X Loss: -52.498197
Epoch 2999 
Overall Loss: -22.198047
Rec Loss: -40.948034
KL Loss: 18.749986
Y Loss: 0.087241
T Loss: 11.882956
X Loss: -52.874612
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.485950
Epoch 99
Rec Loss: 2.470290
Epoch 149
Rec Loss: 2.459088
Epoch 199
Rec Loss: 2.458908
Epoch 249
Rec Loss: 2.438655
Epoch 299
Rec Loss: 2.453938
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.003035
Epoch 99
Rec Loss: 0.001438
Epoch 149
Rec Loss: 0.001062
Epoch 199
Rec Loss: 0.000764
Epoch 249
Rec Loss: 0.000773
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.216184
Insample Error 2.173143
[34m== Direct Regression: Training all ==[0m
Epoch 49 
Prediction Loss: 7.102397
Epoch 99 
Prediction Loss: 6.820785
Epoch 149 
Prediction Loss: 6.661394
Epoch 199 
Prediction Loss: 6.546707
Epoch 249 
Prediction Loss: 6.485024
Epoch 299 
Prediction Loss: 6.403411
Epoch 349 
Prediction Loss: 6.349722
Epoch 399 
Prediction Loss: 6.375521
Epoch 449 
Prediction Loss: 6.263451
Epoch 499 
Prediction Loss: 6.208098
Epoch 549 
Prediction Loss: 6.188165
Epoch 599 
Prediction Loss: 6.156848
Epoch 649 
Prediction Loss: 6.066111
Epoch 699 
Prediction Loss: 6.029885
Epoch 749 
Prediction Loss: 5.971317
Epoch 799 
Prediction Loss: 5.987129
Epoch 849 
Prediction Loss: 5.905574
Epoch 899 
Prediction Loss: 5.880595
Epoch 949 
Prediction Loss: 5.798403
Epoch 999 
Prediction Loss: 5.791295
Epoch 1049 
Prediction Loss: 5.733528
Epoch 1099 
Prediction Loss: 5.692777
Epoch 1149 
Prediction Loss: 5.624743
Epoch 1199 
Prediction Loss: 5.571011
Epoch 1249 
Prediction Loss: 5.587120
Epoch 1299 
Prediction Loss: 5.517218
Epoch 1349 
Prediction Loss: 5.456011
Epoch 1399 
Prediction Loss: 5.478260
Epoch 1449 
Prediction Loss: 5.386100
Epoch 1499 
Prediction Loss: 5.339048
Epoch 1549 
Prediction Loss: 5.313770
Epoch 1599 
Prediction Loss: 5.405730
Epoch 1649 
Prediction Loss: 5.312383
Epoch 1699 
Prediction Loss: 5.193610
Epoch 1749 
Prediction Loss: 5.174986
Epoch 1799 
Prediction Loss: 5.086892
Epoch 1849 
Prediction Loss: 5.097126
Epoch 1899 
Prediction Loss: 5.033183
Epoch 1949 
Prediction Loss: 5.027348
Epoch 1999 
Prediction Loss: 5.028488
Epoch 2049 
Prediction Loss: 4.941337
Epoch 2099 
Prediction Loss: 4.924707
Epoch 2149 
Prediction Loss: 4.877169
Epoch 2199 
Prediction Loss: 4.833579
Epoch 2249 
Prediction Loss: 4.827304
Epoch 2299 
Prediction Loss: 4.818499
Epoch 2349 
Prediction Loss: 4.724729
Epoch 2399 
Prediction Loss: 4.755321
Epoch 2449 
Prediction Loss: 4.749327
Epoch 2499 
Prediction Loss: 4.675894
Epoch 2549 
Prediction Loss: 4.629410
Epoch 2599 
Prediction Loss: 4.658510
Epoch 2649 
Prediction Loss: 4.580530
Epoch 2699 
Prediction Loss: 4.576713
Epoch 2749 
Prediction Loss: 4.503116
Epoch 2799 
Prediction Loss: 4.501120
Epoch 2849 
Prediction Loss: 4.516010
Epoch 2899 
Prediction Loss: 4.437463
Epoch 2949 
Prediction Loss: 4.457708
Epoch 2999 
Prediction Loss: 4.404742
Epoch 3049 
Prediction Loss: 4.439189
Epoch 3099 
Prediction Loss: 4.348119
Epoch 3149 
Prediction Loss: 4.315395
Epoch 3199 
Prediction Loss: 4.335970
Epoch 3249 
Prediction Loss: 4.374102
Epoch 3299 
Prediction Loss: 4.264544
Epoch 3349 
Prediction Loss: 4.257774
Epoch 3399 
Prediction Loss: 4.270425
Epoch 3449 
Prediction Loss: 4.254426
Epoch 3499 
Prediction Loss: 4.202885
Epoch 3549 
Prediction Loss: 4.225886
Epoch 3599 
Prediction Loss: 4.161196
Epoch 3649 
Prediction Loss: 4.164803
Epoch 3699 
Prediction Loss: 4.196640
Epoch 3749 
Prediction Loss: 4.163794
Epoch 3799 
Prediction Loss: 4.095537
Epoch 3849 
Prediction Loss: 4.068161
Epoch 3899 
Prediction Loss: 4.042047
Epoch 3949 
Prediction Loss: 4.083473
Epoch 3999 
Prediction Loss: 4.041203
Epoch 4049 
Prediction Loss: 4.018907
Epoch 4099 
Prediction Loss: 3.994032
Epoch 4149 
Prediction Loss: 3.980974
Epoch 4199 
Prediction Loss: 3.965761
Epoch 4249 
Prediction Loss: 3.960908
Epoch 4299 
Prediction Loss: 3.948395
Epoch 4349 
Prediction Loss: 3.955517
Epoch 4399 
Prediction Loss: 3.897265
Epoch 4449 
Prediction Loss: 3.925147
Epoch 4499 
Prediction Loss: 3.902098
Epoch 4549 
Prediction Loss: 3.878949
Epoch 4599 
Prediction Loss: 3.870523
Epoch 4649 
Prediction Loss: 3.833344
Epoch 4699 
Prediction Loss: 3.871342
Epoch 4749 
Prediction Loss: 3.846107
Epoch 4799 
Prediction Loss: 3.804324
Epoch 4849 
Prediction Loss: 3.825628
Epoch 4899 
Prediction Loss: 3.751027
Epoch 4949 
Prediction Loss: 3.779868
Epoch 4999 
Prediction Loss: 3.780265
Epoch 5049 
Prediction Loss: 3.718347
Epoch 5099 
Prediction Loss: 3.722256
Epoch 5149 
Prediction Loss: 3.746739
Epoch 5199 
Prediction Loss: 3.676517
Epoch 5249 
Prediction Loss: 3.668627
Epoch 5299 
Prediction Loss: 3.675787
Epoch 5349 
Prediction Loss: 3.639272
Epoch 5399 
Prediction Loss: 3.710348
Epoch 5449 
Prediction Loss: 3.625404
Epoch 5499 
Prediction Loss: 3.659269
Epoch 5549 
Prediction Loss: 3.620416
Epoch 5599 
Prediction Loss: 3.579426
Epoch 5649 
Prediction Loss: 3.580367
Epoch 5699 
Prediction Loss: 3.556144
Epoch 5749 
Prediction Loss: 3.567680
Epoch 5799 
Prediction Loss: 3.572026
Epoch 5849 
Prediction Loss: 3.541151
Epoch 5899 
Prediction Loss: 3.546482
Epoch 5949 
Prediction Loss: 3.520133
Epoch 5999 
Prediction Loss: 3.518300
[34m== Direct Regression: Testing in sample performance ==[0m
Train Error 1.863762
Insample Error 4.731836
Ours, Train RMSE
0.5258, 
0.4591, 
0.4695, 
0.5602, 
0.4418, 
0.4308, 
0.4482, 
0.4898, 
0.4227, 
0.4349, 
CEVAE, Train RMSE
0.3781, 
0.2081, 
0.1770, 
0.3496, 
0.3375, 
0.3132, 
0.2294, 
0.4068, 
0.3239, 
0.2162, 
Ours, Insample RMSE
1.3899, 
1.3479, 
1.3785, 
1.2442, 
1.3370, 
1.2905, 
1.3904, 
1.3749, 
1.2655, 
1.3775, 
CEVAE, Insample RMSE
2.1869, 
2.2556, 
2.6795, 
2.0146, 
2.6666, 
1.9759, 
2.6658, 
2.0452, 
2.3192, 
2.1731, 
Direct Regression, Insample RMSE
4.8294, 
4.7608, 
4.6862, 
4.6541, 
4.7141, 
4.5604, 
4.6602, 
4.7082, 
4.7408, 
4.7318, 
Train, RMSE mean 0.4683 std 0.0424
CEVAE, RMSE mean 0.2940 std 0.0757
Ours, RMSE mean 1.3396 std 0.0514, reconstruct confounder 1.5196 (0.0069) noise 9.8454 (0.0093)
CEVAE, RMSE mean 2.2983 std 0.2636, reconstruct confounder 2.7352 (0.1487) noise 0.0011 (0.0004)
Direct Regression, RMSE mean 4.7046 std 0.0682
Experiment Start!
Namespace(cevaelr=5e-05, decay=0.0, l=5e-05, latdim=4, mask=0, nlayer=50, obsm=1, stop=20, ycof=0.5, ylayer=50)
Y Mean 1.037543, Std 4.233836 
Test Y Mean 0.042888, Std 4.254001 
Observe confounder 1, Noise 10 dimension
Learning Rate 0.000050
[31m========== repeat time 1 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.014222
Rec Loss: 15.532490
KL Loss: 1.481732
Y Loss: 4.352705
T Loss: 13.356137
Epoch 99 
Overall Loss: 15.516502
Rec Loss: 14.302891
KL Loss: 1.213611
Y Loss: 1.933590
T Loss: 13.336096
Epoch 149 
Overall Loss: 15.160799
Rec Loss: 13.805543
KL Loss: 1.355256
Y Loss: 1.566118
T Loss: 13.022484
Epoch 199 
Overall Loss: 14.985989
Rec Loss: 13.573159
KL Loss: 1.412830
Y Loss: 1.387898
T Loss: 12.879210
Epoch 249 
Overall Loss: 14.877175
Rec Loss: 13.426687
KL Loss: 1.450488
Y Loss: 1.296169
T Loss: 12.778603
Epoch 299 
Overall Loss: 14.705382
Rec Loss: 13.040310
KL Loss: 1.665072
Y Loss: 1.161334
T Loss: 12.459643
Epoch 349 
Overall Loss: 14.629991
Rec Loss: 12.898868
KL Loss: 1.731123
Y Loss: 1.086813
T Loss: 12.355462
Epoch 399 
Overall Loss: 14.594799
Rec Loss: 12.807958
KL Loss: 1.786841
Y Loss: 1.058959
T Loss: 12.278478
Epoch 449 
Overall Loss: 14.569643
Rec Loss: 12.761769
KL Loss: 1.807874
Y Loss: 1.036659
T Loss: 12.243440
Epoch 499 
Overall Loss: 14.547462
Rec Loss: 12.724226
KL Loss: 1.823235
Y Loss: 1.032316
T Loss: 12.208069
Epoch 549 
Overall Loss: 14.533654
Rec Loss: 12.695504
KL Loss: 1.838150
Y Loss: 1.004119
T Loss: 12.193445
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 1.966465
Epoch 99
Rec Loss: 1.967131
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.897586
Epoch 99
Rec Loss: 9.877649
Epoch 149
Rec Loss: 9.885933
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.427905
Insample Error: 2.028079
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 18.243015
Rec Loss: 14.657701
KL Loss: 3.585314
Y Loss: 5.832297
T Loss: 13.398631
X Loss: -1.657078
Epoch 99 
Overall Loss: -0.384040
Rec Loss: -8.579098
KL Loss: 8.195058
Y Loss: 2.229916
T Loss: 13.325769
X Loss: -23.019826
Epoch 149 
Overall Loss: -6.603381
Rec Loss: -15.894958
KL Loss: 9.291577
Y Loss: 1.454522
T Loss: 13.325467
X Loss: -29.947686
Epoch 199 
Overall Loss: -9.879597
Rec Loss: -20.329235
KL Loss: 10.449638
Y Loss: 0.918879
T Loss: 13.306981
X Loss: -34.095656
Epoch 249 
Overall Loss: -11.941722
Rec Loss: -23.193793
KL Loss: 11.252071
Y Loss: 0.747580
T Loss: 13.294745
X Loss: -36.862329
Epoch 299 
Overall Loss: -13.263567
Rec Loss: -24.977620
KL Loss: 11.714053
Y Loss: 0.694542
T Loss: 13.278612
X Loss: -38.603504
Epoch 349 
Overall Loss: -14.145537
Rec Loss: -26.211792
KL Loss: 12.066255
Y Loss: 0.667191
T Loss: 13.262747
X Loss: -39.808136
Epoch 399 
Overall Loss: -14.904506
Rec Loss: -27.232496
KL Loss: 12.327990
Y Loss: 0.692075
T Loss: 13.239871
X Loss: -40.818405
Epoch 449 
Overall Loss: -15.577438
Rec Loss: -28.167114
KL Loss: 12.589677
Y Loss: 0.686871
T Loss: 13.209482
X Loss: -41.720032
Epoch 499 
Overall Loss: -16.251088
Rec Loss: -29.005793
KL Loss: 12.754705
Y Loss: 0.736837
T Loss: 13.176007
X Loss: -42.550220
Epoch 549 
Overall Loss: -16.841351
Rec Loss: -29.797577
KL Loss: 12.956226
Y Loss: 0.715328
T Loss: 13.139663
X Loss: -43.294904
Epoch 599 
Overall Loss: -17.432578
Rec Loss: -30.482221
KL Loss: 13.049643
Y Loss: 0.756020
T Loss: 13.092270
X Loss: -43.952501
Epoch 649 
Overall Loss: -17.879097
Rec Loss: -31.197496
KL Loss: 13.318399
Y Loss: 0.748987
T Loss: 13.035942
X Loss: -44.607931
Epoch 699 
Overall Loss: -18.433193
Rec Loss: -31.880560
KL Loss: 13.447367
Y Loss: 0.754544
T Loss: 12.989954
X Loss: -45.247786
Epoch 749 
Overall Loss: -18.855681
Rec Loss: -32.382587
KL Loss: 13.526907
Y Loss: 0.760588
T Loss: 12.943017
X Loss: -45.705899
Epoch 799 
Overall Loss: -19.175772
Rec Loss: -32.866993
KL Loss: 13.691220
Y Loss: 0.758098
T Loss: 12.910034
X Loss: -46.156075
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.965380
Epoch 99
Rec Loss: 2.959583
Epoch 149
Rec Loss: 2.958877
Epoch 199
Rec Loss: 2.962088
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.008045
Epoch 99
Rec Loss: 0.013280
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.387970
Insample Error 1.935967
[34m== Direct Regression: Training all ==[0m
Epoch 49 
Prediction Loss: 7.173071
Epoch 99 
Prediction Loss: 6.819553
Epoch 149 
Prediction Loss: 6.581262
Epoch 199 
Prediction Loss: 6.454806
Epoch 249 
Prediction Loss: 6.402800
Epoch 299 
Prediction Loss: 6.324995
Epoch 349 
Prediction Loss: 6.274848
Epoch 399 
Prediction Loss: 6.291612
Epoch 449 
Prediction Loss: 6.190923
Epoch 499 
Prediction Loss: 6.134678
Epoch 549 
Prediction Loss: 6.117543
Epoch 599 
Prediction Loss: 6.021643
Epoch 649 
Prediction Loss: 5.994863
Epoch 699 
Prediction Loss: 5.991081
Epoch 749 
Prediction Loss: 5.884805
Epoch 799 
Prediction Loss: 5.810490
Epoch 849 
Prediction Loss: 5.746401
Epoch 899 
Prediction Loss: 5.702848
Epoch 949 
Prediction Loss: 5.620504
Epoch 999 
Prediction Loss: 5.627114
Epoch 1049 
Prediction Loss: 5.548723
Epoch 1099 
Prediction Loss: 5.470579
[34m== Direct Regression: Testing in sample performance ==[0m
Train Error 2.329427
Insample Error 4.359909
[31m========== repeat time 2 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.138685
Rec Loss: 15.805551
KL Loss: 1.333133
Y Loss: 4.899171
T Loss: 13.355966
Epoch 99 
Overall Loss: 15.752648
Rec Loss: 14.521325
KL Loss: 1.231323
Y Loss: 2.439055
T Loss: 13.301798
Epoch 149 
Overall Loss: 15.217115
Rec Loss: 13.765241
KL Loss: 1.451873
Y Loss: 1.746519
T Loss: 12.891982
Epoch 199 
Overall Loss: 15.023543
Rec Loss: 13.567507
KL Loss: 1.456036
Y Loss: 1.498620
T Loss: 12.818198
Epoch 249 
Overall Loss: 14.916511
Rec Loss: 13.450850
KL Loss: 1.465662
Y Loss: 1.298910
T Loss: 12.801394
Epoch 299 
Overall Loss: 14.796099
Rec Loss: 13.299263
KL Loss: 1.496835
Y Loss: 1.216040
T Loss: 12.691243
Epoch 349 
Overall Loss: 14.656966
Rec Loss: 12.978022
KL Loss: 1.678944
Y Loss: 1.139228
T Loss: 12.408408
Epoch 399 
Overall Loss: 14.590477
Rec Loss: 12.798488
KL Loss: 1.791989
Y Loss: 1.068206
T Loss: 12.264385
Epoch 449 
Overall Loss: 14.584290
Rec Loss: 12.756536
KL Loss: 1.827755
Y Loss: 1.069716
T Loss: 12.221678
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.098067
Epoch 99
Rec Loss: 2.090603
Epoch 149
Rec Loss: 2.094353
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.900103
Epoch 99
Rec Loss: 9.893542
Epoch 149
Rec Loss: 9.889825
Epoch 199
Rec Loss: 9.880443
Epoch 249
Rec Loss: 9.878147
Epoch 299
Rec Loss: 9.874851
Epoch 349
Rec Loss: 9.893129
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.450025
Insample Error: 2.552749
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 18.006209
Rec Loss: 14.188592
KL Loss: 3.817617
Y Loss: 5.635245
T Loss: 13.391635
X Loss: -2.020666
Epoch 99 
Overall Loss: -0.239701
Rec Loss: -9.137392
KL Loss: 8.897691
Y Loss: 2.225719
T Loss: 13.304558
X Loss: -23.554809
Epoch 149 
Overall Loss: -6.822168
Rec Loss: -16.918165
KL Loss: 10.095996
Y Loss: 1.333698
T Loss: 13.303514
X Loss: -30.888527
Epoch 199 
Overall Loss: -10.001423
Rec Loss: -21.114654
KL Loss: 11.113232
Y Loss: 0.743023
T Loss: 13.298454
X Loss: -34.784622
Epoch 249 
Overall Loss: -11.560243
Rec Loss: -23.065202
KL Loss: 11.504959
Y Loss: 0.539537
T Loss: 13.292209
X Loss: -36.627180
Epoch 299 
Overall Loss: -12.752957
Rec Loss: -24.673979
KL Loss: 11.921023
Y Loss: 0.458865
T Loss: 13.269269
X Loss: -38.172681
Epoch 349 
Overall Loss: -13.784609
Rec Loss: -25.967435
KL Loss: 12.182825
Y Loss: 0.439167
T Loss: 13.245969
X Loss: -39.432987
Epoch 399 
Overall Loss: -14.487943
Rec Loss: -26.933084
KL Loss: 12.445141
Y Loss: 0.437610
T Loss: 13.212361
X Loss: -40.364250
Epoch 449 
Overall Loss: -15.048842
Rec Loss: -27.644070
KL Loss: 12.595227
Y Loss: 0.393379
T Loss: 13.174811
X Loss: -41.015571
Epoch 499 
Overall Loss: -15.604460
Rec Loss: -28.444078
KL Loss: 12.839618
Y Loss: 0.385604
T Loss: 13.136633
X Loss: -41.773514
Epoch 549 
Overall Loss: -16.116382
Rec Loss: -29.038222
KL Loss: 12.921838
Y Loss: 0.378178
T Loss: 13.092494
X Loss: -42.319804
Epoch 599 
Overall Loss: -16.876274
Rec Loss: -30.088799
KL Loss: 13.212525
Y Loss: 0.353914
T Loss: 13.047989
X Loss: -43.313745
Epoch 649 
Overall Loss: -17.109563
Rec Loss: -30.463110
KL Loss: 13.353545
Y Loss: 0.335473
T Loss: 13.003384
X Loss: -43.634229
Epoch 699 
Overall Loss: -17.569146
Rec Loss: -31.017970
KL Loss: 13.448825
Y Loss: 0.324911
T Loss: 12.966227
X Loss: -44.146652
Epoch 749 
Overall Loss: -18.022966
Rec Loss: -31.701394
KL Loss: 13.678428
Y Loss: 0.293695
T Loss: 12.936283
X Loss: -44.784525
Epoch 799 
Overall Loss: -18.267325
Rec Loss: -31.953015
KL Loss: 13.685690
Y Loss: 0.292108
T Loss: 12.908917
X Loss: -45.007987
Epoch 849 
Overall Loss: -18.592722
Rec Loss: -32.345808
KL Loss: 13.753087
Y Loss: 0.283072
T Loss: 12.891686
X Loss: -45.379029
Epoch 899 
Overall Loss: -18.894580
Rec Loss: -32.856244
KL Loss: 13.961664
Y Loss: 0.260814
T Loss: 12.866958
X Loss: -45.853609
Epoch 949 
Overall Loss: -19.126060
Rec Loss: -33.231930
KL Loss: 14.105869
Y Loss: 0.248630
T Loss: 12.853869
X Loss: -46.210112
Epoch 999 
Overall Loss: -19.324412
Rec Loss: -33.459049
KL Loss: 14.134637
Y Loss: 0.238975
T Loss: 12.838933
X Loss: -46.417471
Epoch 1049 
Overall Loss: -19.720478
Rec Loss: -33.885290
KL Loss: 14.164812
Y Loss: 0.236442
T Loss: 12.825488
X Loss: -46.828998
Epoch 1099 
Overall Loss: -19.715025
Rec Loss: -33.913138
KL Loss: 14.198114
Y Loss: 0.236472
T Loss: 12.816225
X Loss: -46.847600
Epoch 1149 
Overall Loss: -20.099805
Rec Loss: -34.314209
KL Loss: 14.214403
Y Loss: 0.235595
T Loss: 12.803489
X Loss: -47.235495
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.912303
Epoch 99
Rec Loss: 2.895562
Epoch 149
Rec Loss: 2.893928
Epoch 199
Rec Loss: 2.888395
Epoch 249
Rec Loss: 2.886088
Epoch 299
Rec Loss: 2.887447
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.004122
Epoch 99
Rec Loss: 0.002857
Epoch 149
Rec Loss: 0.002388
Epoch 199
Rec Loss: 0.002325
Epoch 249
Rec Loss: 0.002798
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.231229
Insample Error 1.949152
[34m== Direct Regression: Training all ==[0m
Epoch 49 
Prediction Loss: 7.151070
Epoch 99 
Prediction Loss: 6.841324
Epoch 149 
Prediction Loss: 6.597011
Epoch 199 
Prediction Loss: 6.489216
Epoch 249 
Prediction Loss: 6.440514
Epoch 299 
Prediction Loss: 6.390168
Epoch 349 
Prediction Loss: 6.346802
Epoch 399 
Prediction Loss: 6.279311
Epoch 449 
Prediction Loss: 6.258662
[34m== Direct Regression: Testing in sample performance ==[0m
Train Error 2.497564
Insample Error 4.365889
[31m========== repeat time 3 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.906748
Rec Loss: 15.414771
KL Loss: 1.491977
Y Loss: 4.063179
T Loss: 13.383182
Epoch 99 
Overall Loss: 15.665022
Rec Loss: 14.460866
KL Loss: 1.204156
Y Loss: 2.163313
T Loss: 13.379209
Epoch 149 
Overall Loss: 15.173822
Rec Loss: 13.875950
KL Loss: 1.297872
Y Loss: 1.637153
T Loss: 13.057374
Epoch 199 
Overall Loss: 14.997168
Rec Loss: 13.659353
KL Loss: 1.337815
Y Loss: 1.418242
T Loss: 12.950232
Epoch 249 
Overall Loss: 14.915114
Rec Loss: 13.548842
KL Loss: 1.366272
Y Loss: 1.266156
T Loss: 12.915764
Epoch 299 
Overall Loss: 14.832804
Rec Loss: 13.440538
KL Loss: 1.392266
Y Loss: 1.174370
T Loss: 12.853353
Epoch 349 
Overall Loss: 14.782266
Rec Loss: 13.339095
KL Loss: 1.443171
Y Loss: 1.160954
T Loss: 12.758618
Epoch 399 
Overall Loss: 14.678996
Rec Loss: 13.089321
KL Loss: 1.589675
Y Loss: 1.081632
T Loss: 12.548505
Epoch 449 
Overall Loss: 14.620463
Rec Loss: 12.892932
KL Loss: 1.727532
Y Loss: 1.063206
T Loss: 12.361329
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.096241
Epoch 99
Rec Loss: 2.102001
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.779929
Epoch 99
Rec Loss: 9.839817
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.435305
Insample Error: 2.480388
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 18.979058
Rec Loss: 15.386272
KL Loss: 3.592786
Y Loss: 8.109521
T Loss: 13.451003
X Loss: -2.119492
Epoch 99 
Overall Loss: 1.991735
Rec Loss: -7.642374
KL Loss: 9.634108
Y Loss: 3.086674
T Loss: 13.305164
X Loss: -22.490874
Epoch 149 
Overall Loss: -3.214276
Rec Loss: -13.992430
KL Loss: 10.778155
Y Loss: 1.921619
T Loss: 13.301194
X Loss: -28.254433
Epoch 199 
Overall Loss: -6.874051
Rec Loss: -18.718480
KL Loss: 11.844429
Y Loss: 1.001549
T Loss: 13.299025
X Loss: -32.518281
Epoch 249 
Overall Loss: -9.344022
Rec Loss: -21.924543
KL Loss: 12.580521
Y Loss: 0.570510
T Loss: 13.289659
X Loss: -35.499457
Epoch 299 
Overall Loss: -10.986557
Rec Loss: -24.107199
KL Loss: 13.120642
Y Loss: 0.431901
T Loss: 13.274715
X Loss: -37.597865
Epoch 349 
Overall Loss: -12.071122
Rec Loss: -25.549014
KL Loss: 13.477893
Y Loss: 0.372339
T Loss: 13.256910
X Loss: -38.992094
Epoch 399 
Overall Loss: -12.941160
Rec Loss: -26.722909
KL Loss: 13.781749
Y Loss: 0.351221
T Loss: 13.243997
X Loss: -40.142517
Epoch 449 
Overall Loss: -13.782397
Rec Loss: -27.794552
KL Loss: 14.012155
Y Loss: 0.342680
T Loss: 13.219568
X Loss: -41.185462
Epoch 499 
Overall Loss: -14.478526
Rec Loss: -28.679658
KL Loss: 14.201133
Y Loss: 0.344588
T Loss: 13.194604
X Loss: -42.046557
Epoch 549 
Overall Loss: -14.945004
Rec Loss: -29.280223
KL Loss: 14.335218
Y Loss: 0.328744
T Loss: 13.168939
X Loss: -42.613533
Epoch 599 
Overall Loss: -15.552094
Rec Loss: -29.993406
KL Loss: 14.441312
Y Loss: 0.326012
T Loss: 13.128112
X Loss: -43.284525
Epoch 649 
Overall Loss: -15.546447
Rec Loss: -30.244382
KL Loss: 14.697936
Y Loss: 0.312275
T Loss: 13.098517
X Loss: -43.499037
Epoch 699 
Overall Loss: -16.372674
Rec Loss: -31.138149
KL Loss: 14.765476
Y Loss: 0.312607
T Loss: 13.057408
X Loss: -44.351862
Epoch 749 
Overall Loss: -16.778251
Rec Loss: -31.663795
KL Loss: 14.885545
Y Loss: 0.299025
T Loss: 13.017164
X Loss: -44.830472
Epoch 799 
Overall Loss: -17.169665
Rec Loss: -31.952425
KL Loss: 14.782759
Y Loss: 0.296873
T Loss: 12.990145
X Loss: -45.091007
Epoch 849 
Overall Loss: -17.525641
Rec Loss: -32.569641
KL Loss: 15.044000
Y Loss: 0.281053
T Loss: 12.955072
X Loss: -45.665240
Epoch 899 
Overall Loss: -17.540802
Rec Loss: -32.476585
KL Loss: 14.935783
Y Loss: 0.272270
T Loss: 12.932970
X Loss: -45.545690
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.975845
Epoch 99
Rec Loss: 2.960930
Epoch 149
Rec Loss: 2.961656
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.005901
Epoch 99
Rec Loss: 0.003103
Epoch 149
Rec Loss: 0.002976
Epoch 199
Rec Loss: 0.002040
Epoch 249
Rec Loss: 0.002363
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.356082
Insample Error 2.023188
[34m== Direct Regression: Training all ==[0m
Epoch 49 
Prediction Loss: 7.167573
Epoch 99 
Prediction Loss: 6.773479
Epoch 149 
Prediction Loss: 6.540634
Epoch 199 
Prediction Loss: 6.457028
Epoch 249 
Prediction Loss: 6.410731
Epoch 299 
Prediction Loss: 6.366221
Epoch 349 
Prediction Loss: 6.373254
[34m== Direct Regression: Testing in sample performance ==[0m
Train Error 2.514896
Insample Error 4.356768
[31m========== repeat time 4 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.093391
Rec Loss: 15.655998
KL Loss: 1.437394
Y Loss: 4.577194
T Loss: 13.367401
Epoch 99 
Overall Loss: 15.849996
Rec Loss: 14.612177
KL Loss: 1.237820
Y Loss: 2.560347
T Loss: 13.332003
Epoch 149 
Overall Loss: 15.150396
Rec Loss: 13.719365
KL Loss: 1.431031
Y Loss: 1.718160
T Loss: 12.860285
Epoch 199 
Overall Loss: 14.945116
Rec Loss: 13.442630
KL Loss: 1.502485
Y Loss: 1.457289
T Loss: 12.713985
Epoch 249 
Overall Loss: 14.742451
Rec Loss: 13.055819
KL Loss: 1.686632
Y Loss: 1.274606
T Loss: 12.418516
Epoch 299 
Overall Loss: 14.659007
Rec Loss: 12.935190
KL Loss: 1.723818
Y Loss: 1.190143
T Loss: 12.340118
Epoch 349 
Overall Loss: 14.616718
Rec Loss: 12.865328
KL Loss: 1.751390
Y Loss: 1.139381
T Loss: 12.295638
Epoch 399 
Overall Loss: 14.604483
Rec Loss: 12.825759
KL Loss: 1.778724
Y Loss: 1.088316
T Loss: 12.281601
Epoch 449 
Overall Loss: 14.565914
Rec Loss: 12.776625
KL Loss: 1.789290
Y Loss: 1.099092
T Loss: 12.227079
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.043837
Epoch 99
Rec Loss: 2.051520
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.882515
Epoch 99
Rec Loss: 9.867185
Epoch 149
Rec Loss: 9.868971
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.483928
Insample Error: 2.087295
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 17.310868
Rec Loss: 13.580267
KL Loss: 3.730600
Y Loss: 6.122562
T Loss: 13.423326
X Loss: -2.904339
Epoch 99 
Overall Loss: -1.150247
Rec Loss: -9.461071
KL Loss: 8.310825
Y Loss: 2.857159
T Loss: 13.375849
X Loss: -24.265500
Epoch 149 
Overall Loss: -6.732049
Rec Loss: -16.068693
KL Loss: 9.336644
Y Loss: 2.240201
T Loss: 13.366547
X Loss: -30.555341
Epoch 199 
Overall Loss: -10.195291
Rec Loss: -20.658578
KL Loss: 10.463287
Y Loss: 1.722862
T Loss: 13.340556
X Loss: -34.860565
Epoch 249 
Overall Loss: -12.085638
Rec Loss: -23.296544
KL Loss: 11.210906
Y Loss: 1.415278
T Loss: 13.321861
X Loss: -37.326044
Epoch 299 
Overall Loss: -13.600123
Rec Loss: -25.305418
KL Loss: 11.705294
Y Loss: 1.195960
T Loss: 13.289656
X Loss: -39.193054
Epoch 349 
Overall Loss: -14.742107
Rec Loss: -26.890596
KL Loss: 12.148489
Y Loss: 1.051076
T Loss: 13.263573
X Loss: -40.679707
Epoch 399 
Overall Loss: -15.820560
Rec Loss: -28.249977
KL Loss: 12.429417
Y Loss: 1.004600
T Loss: 13.229345
X Loss: -41.981621
Epoch 449 
Overall Loss: -16.302718
Rec Loss: -28.973644
KL Loss: 12.670925
Y Loss: 0.994760
T Loss: 13.184113
X Loss: -42.655136
Epoch 499 
Overall Loss: -17.087003
Rec Loss: -29.902076
KL Loss: 12.815073
Y Loss: 1.000549
T Loss: 13.143634
X Loss: -43.545984
Epoch 549 
Overall Loss: -17.701788
Rec Loss: -30.670113
KL Loss: 12.968325
Y Loss: 0.965674
T Loss: 13.088950
X Loss: -44.241900
Epoch 599 
Overall Loss: -18.263844
Rec Loss: -31.377520
KL Loss: 13.113675
Y Loss: 0.936044
T Loss: 13.042070
X Loss: -44.887613
Epoch 649 
Overall Loss: -18.791030
Rec Loss: -31.949961
KL Loss: 13.158931
Y Loss: 0.935680
T Loss: 12.993477
X Loss: -45.411278
Epoch 699 
Overall Loss: -19.277564
Rec Loss: -32.566098
KL Loss: 13.288533
Y Loss: 0.932703
T Loss: 12.956818
X Loss: -45.989266
Epoch 749 
Overall Loss: -19.538677
Rec Loss: -32.967590
KL Loss: 13.428914
Y Loss: 0.908932
T Loss: 12.938812
X Loss: -46.360868
Epoch 799 
Overall Loss: -19.896002
Rec Loss: -33.446226
KL Loss: 13.550224
Y Loss: 0.883130
T Loss: 12.918517
X Loss: -46.806309
Epoch 849 
Overall Loss: -20.401145
Rec Loss: -34.036972
KL Loss: 13.635827
Y Loss: 0.876039
T Loss: 12.912684
X Loss: -47.387675
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 3.026994
Epoch 99
Rec Loss: 3.021769
Epoch 149
Rec Loss: 3.013310
Epoch 199
Rec Loss: 3.013259
Epoch 249
Rec Loss: 3.011810
Epoch 299
Rec Loss: 3.008860
Epoch 349
Rec Loss: 3.004812
Epoch 399
Rec Loss: 3.003100
Epoch 449
Rec Loss: 3.009488
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.004580
Epoch 99
Rec Loss: 0.002198
Epoch 149
Rec Loss: 0.001555
Epoch 199
Rec Loss: 0.001703
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.400155
Insample Error 2.076857
[34m== Direct Regression: Training all ==[0m
Epoch 49 
Prediction Loss: 7.071885
Epoch 99 
Prediction Loss: 6.752579
Epoch 149 
Prediction Loss: 6.613440
Epoch 199 
Prediction Loss: 6.545900
Epoch 249 
Prediction Loss: 6.546226
Epoch 299 
Prediction Loss: 6.439002
Epoch 349 
Prediction Loss: 6.395293
Epoch 399 
Prediction Loss: 6.396602
Epoch 449 
Prediction Loss: 6.336597
Epoch 499 
Prediction Loss: 6.324203
Epoch 549 
Prediction Loss: 6.278077
Epoch 599 
Prediction Loss: 6.233164
[34m== Direct Regression: Testing in sample performance ==[0m
Train Error 2.490996
Insample Error 4.334866
[31m========== repeat time 5 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.382795
Rec Loss: 15.925210
KL Loss: 1.457585
Y Loss: 5.110214
T Loss: 13.370104
Epoch 99 
Overall Loss: 15.666581
Rec Loss: 14.442646
KL Loss: 1.223935
Y Loss: 2.213344
T Loss: 13.335974
Epoch 149 
Overall Loss: 15.163439
Rec Loss: 13.767182
KL Loss: 1.396257
Y Loss: 1.619574
T Loss: 12.957395
Epoch 199 
Overall Loss: 15.010501
Rec Loss: 13.599952
KL Loss: 1.410549
Y Loss: 1.419596
T Loss: 12.890154
Epoch 249 
Overall Loss: 14.845937
Rec Loss: 13.353119
KL Loss: 1.492819
Y Loss: 1.274453
T Loss: 12.715892
Epoch 299 
Overall Loss: 14.712670
Rec Loss: 13.023663
KL Loss: 1.689007
Y Loss: 1.172342
T Loss: 12.437492
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.134546
Epoch 99
Rec Loss: 2.130184
Epoch 149
Rec Loss: 2.131448
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.880796
Epoch 99
Rec Loss: 9.880732
Epoch 149
Rec Loss: 9.876209
Epoch 199
Rec Loss: 9.894299
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.536260
Insample Error: 2.069268
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 18.407814
Rec Loss: 14.718877
KL Loss: 3.688938
Y Loss: 6.695825
T Loss: 13.411446
X Loss: -2.040482
Epoch 99 
Overall Loss: 3.376208
Rec Loss: -6.120409
KL Loss: 9.496617
Y Loss: 3.045529
T Loss: 13.306984
X Loss: -20.950157
Epoch 149 
Overall Loss: -2.383676
Rec Loss: -13.262898
KL Loss: 10.879223
Y Loss: 2.142715
T Loss: 13.295686
X Loss: -27.629942
Epoch 199 
Overall Loss: -6.676546
Rec Loss: -17.963109
KL Loss: 11.286563
Y Loss: 1.377742
T Loss: 13.284604
X Loss: -31.936583
Epoch 249 
Overall Loss: -10.080430
Rec Loss: -21.518491
KL Loss: 11.438061
Y Loss: 1.156294
T Loss: 13.276599
X Loss: -35.373237
Epoch 299 
Overall Loss: -11.851787
Rec Loss: -23.782901
KL Loss: 11.931115
Y Loss: 0.992214
T Loss: 13.246805
X Loss: -37.525813
Epoch 349 
Overall Loss: -12.907969
Rec Loss: -25.222908
KL Loss: 12.314939
Y Loss: 0.910039
T Loss: 13.228048
X Loss: -38.905975
Epoch 399 
Overall Loss: -13.747774
Rec Loss: -26.217469
KL Loss: 12.469696
Y Loss: 0.907083
T Loss: 13.202594
X Loss: -39.873606
Epoch 449 
Overall Loss: -14.509472
Rec Loss: -27.244399
KL Loss: 12.734928
Y Loss: 0.868592
T Loss: 13.182374
X Loss: -40.861068
Epoch 499 
Overall Loss: -15.104561
Rec Loss: -27.976286
KL Loss: 12.871725
Y Loss: 0.877655
T Loss: 13.156077
X Loss: -41.571190
Epoch 549 
Overall Loss: -15.567576
Rec Loss: -28.562153
KL Loss: 12.994577
Y Loss: 0.857070
T Loss: 13.121582
X Loss: -42.112271
Epoch 599 
Overall Loss: -16.084659
Rec Loss: -29.323930
KL Loss: 13.239270
Y Loss: 0.824448
T Loss: 13.098607
X Loss: -42.834760
Epoch 649 
Overall Loss: -16.407277
Rec Loss: -29.704850
KL Loss: 13.297573
Y Loss: 0.842440
T Loss: 13.068946
X Loss: -43.195015
Epoch 699 
Overall Loss: -17.009920
Rec Loss: -30.549297
KL Loss: 13.539377
Y Loss: 0.791361
T Loss: 13.043703
X Loss: -43.988681
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 3.015621
Epoch 99
Rec Loss: 3.008618
Epoch 149
Rec Loss: 3.002941
Epoch 199
Rec Loss: 3.000612
Epoch 249
Rec Loss: 2.993973
Epoch 299
Rec Loss: 3.002469
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.013885
Epoch 99
Rec Loss: 0.006024
Epoch 149
Rec Loss: 0.006368
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.412036
Insample Error 1.867416
[34m== Direct Regression: Training all ==[0m
Epoch 49 
Prediction Loss: 7.241638
Epoch 99 
Prediction Loss: 6.940279
Epoch 149 
Prediction Loss: 6.706209
Epoch 199 
Prediction Loss: 6.534630
Epoch 249 
Prediction Loss: 6.446121
Epoch 299 
Prediction Loss: 6.392249
Epoch 349 
Prediction Loss: 6.318020
Epoch 399 
Prediction Loss: 6.260097
[34m== Direct Regression: Testing in sample performance ==[0m
Train Error 2.493716
Insample Error 4.317207
[31m========== repeat time 6 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.901257
Rec Loss: 15.446724
KL Loss: 1.454534
Y Loss: 4.266037
T Loss: 13.313705
Epoch 99 
Overall Loss: 15.302339
Rec Loss: 13.958901
KL Loss: 1.343438
Y Loss: 1.969750
T Loss: 12.974026
Epoch 149 
Overall Loss: 15.078260
Rec Loss: 13.667233
KL Loss: 1.411027
Y Loss: 1.561081
T Loss: 12.886693
Epoch 199 
Overall Loss: 14.973009
Rec Loss: 13.567597
KL Loss: 1.405411
Y Loss: 1.382556
T Loss: 12.876319
Epoch 249 
Overall Loss: 14.873213
Rec Loss: 13.443706
KL Loss: 1.429507
Y Loss: 1.227803
T Loss: 12.829804
Epoch 299 
Overall Loss: 14.724263
Rec Loss: 13.143401
KL Loss: 1.580862
Y Loss: 1.191100
T Loss: 12.547851
Epoch 349 
Overall Loss: 14.607959
Rec Loss: 12.873279
KL Loss: 1.734680
Y Loss: 1.121895
T Loss: 12.312332
Epoch 399 
Overall Loss: 14.583259
Rec Loss: 12.813117
KL Loss: 1.770142
Y Loss: 1.069290
T Loss: 12.278473
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.000466
Epoch 99
Rec Loss: 1.982366
Epoch 149
Rec Loss: 1.987824
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.901606
Epoch 99
Rec Loss: 9.906697
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.452247
Insample Error: 2.161515
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 18.316860
Rec Loss: 14.895000
KL Loss: 3.421860
Y Loss: 9.066022
T Loss: 13.516443
X Loss: -3.154454
Epoch 99 
Overall Loss: -1.383332
Rec Loss: -10.046549
KL Loss: 8.663218
Y Loss: 2.659596
T Loss: 13.366256
X Loss: -24.742604
Epoch 149 
Overall Loss: -7.222995
Rec Loss: -17.157740
KL Loss: 9.934745
Y Loss: 1.958048
T Loss: 13.351264
X Loss: -31.488028
Epoch 199 
Overall Loss: -10.612651
Rec Loss: -21.619294
KL Loss: 11.006643
Y Loss: 1.459313
T Loss: 13.342301
X Loss: -35.691252
Epoch 249 
Overall Loss: -12.494319
Rec Loss: -24.050517
KL Loss: 11.556198
Y Loss: 1.213641
T Loss: 13.327951
X Loss: -37.985290
Epoch 299 
Overall Loss: -13.802883
Rec Loss: -25.711967
KL Loss: 11.909085
Y Loss: 1.076527
T Loss: 13.315690
X Loss: -39.565921
Epoch 349 
Overall Loss: -14.593733
Rec Loss: -26.738899
KL Loss: 12.145167
Y Loss: 0.982497
T Loss: 13.300506
X Loss: -40.530654
Epoch 399 
Overall Loss: -15.626495
Rec Loss: -27.994734
KL Loss: 12.368239
Y Loss: 0.878704
T Loss: 13.280300
X Loss: -41.714387
Epoch 449 
Overall Loss: -16.137256
Rec Loss: -28.701635
KL Loss: 12.564379
Y Loss: 0.864388
T Loss: 13.258753
X Loss: -42.392582
Epoch 499 
Overall Loss: -16.878076
Rec Loss: -29.659546
KL Loss: 12.781469
Y Loss: 0.793675
T Loss: 13.220275
X Loss: -43.276657
Epoch 549 
Overall Loss: -17.463572
Rec Loss: -30.354234
KL Loss: 12.890662
Y Loss: 0.825601
T Loss: 13.191215
X Loss: -43.958251
Epoch 599 
Overall Loss: -17.827487
Rec Loss: -30.940584
KL Loss: 13.113098
Y Loss: 0.798786
T Loss: 13.148831
X Loss: -44.488808
Epoch 649 
Overall Loss: -18.049404
Rec Loss: -31.293158
KL Loss: 13.243754
Y Loss: 0.789044
T Loss: 13.117332
X Loss: -44.805012
Epoch 699 
Overall Loss: -18.786002
Rec Loss: -32.183364
KL Loss: 13.397361
Y Loss: 0.771374
T Loss: 13.061451
X Loss: -45.630502
Epoch 749 
Overall Loss: -19.166374
Rec Loss: -32.724345
KL Loss: 13.557972
Y Loss: 0.746799
T Loss: 13.010963
X Loss: -46.108709
Epoch 799 
Overall Loss: -19.570676
Rec Loss: -33.199947
KL Loss: 13.629271
Y Loss: 0.741752
T Loss: 12.948731
X Loss: -46.519553
Epoch 849 
Overall Loss: -19.889335
Rec Loss: -33.630158
KL Loss: 13.740824
Y Loss: 0.725815
T Loss: 12.887015
X Loss: -46.880081
Epoch 899 
Overall Loss: -20.219930
Rec Loss: -34.139156
KL Loss: 13.919226
Y Loss: 0.741935
T Loss: 12.836881
X Loss: -47.347006
Epoch 949 
Overall Loss: -19.893956
Rec Loss: -33.885606
KL Loss: 13.991651
Y Loss: 0.727378
T Loss: 12.790329
X Loss: -47.039625
Epoch 999 
Overall Loss: -20.667165
Rec Loss: -34.745014
KL Loss: 14.077849
Y Loss: 0.707881
T Loss: 12.749688
X Loss: -47.848644
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.936948
Epoch 99
Rec Loss: 2.934128
Epoch 149
Rec Loss: 2.920833
Epoch 199
Rec Loss: 2.919573
Epoch 249
Rec Loss: 2.909970
Epoch 299
Rec Loss: 2.909310
Epoch 349
Rec Loss: 2.914890
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.006437
Epoch 99
Rec Loss: 0.002722
Epoch 149
Rec Loss: 0.002190
Epoch 199
Rec Loss: 0.001860
Epoch 249
Rec Loss: 0.002146
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.328385
Insample Error 2.021566
[34m== Direct Regression: Training all ==[0m
Epoch 49 
Prediction Loss: 7.236104
Epoch 99 
Prediction Loss: 6.780098
Epoch 149 
Prediction Loss: 6.569509
Epoch 199 
Prediction Loss: 6.546931
Epoch 249 
Prediction Loss: 6.486790
Epoch 299 
Prediction Loss: 6.499071
Epoch 349 
Prediction Loss: 6.389538
Epoch 399 
Prediction Loss: 6.403004
[34m== Direct Regression: Testing in sample performance ==[0m
Train Error 2.545301
Insample Error 4.391111
[31m========== repeat time 7 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 16.889552
Rec Loss: 15.377283
KL Loss: 1.512268
Y Loss: 4.086955
T Loss: 13.333806
Epoch 99 
Overall Loss: 15.609921
Rec Loss: 14.398861
KL Loss: 1.211060
Y Loss: 2.081311
T Loss: 13.358205
Epoch 149 
Overall Loss: 15.221713
Rec Loss: 13.921978
KL Loss: 1.299735
Y Loss: 1.535084
T Loss: 13.154436
Epoch 199 
Overall Loss: 14.973161
Rec Loss: 13.530637
KL Loss: 1.442524
Y Loss: 1.343266
T Loss: 12.859003
Epoch 249 
Overall Loss: 14.856174
Rec Loss: 13.340628
KL Loss: 1.515545
Y Loss: 1.255910
T Loss: 12.712673
Epoch 299 
Overall Loss: 14.699461
Rec Loss: 12.962933
KL Loss: 1.736528
Y Loss: 1.155013
T Loss: 12.385427
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.137838
Epoch 99
Rec Loss: 2.138714
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.880826
Epoch 99
Rec Loss: 9.868235
Epoch 149
Rec Loss: 9.890841
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.529120
Insample Error: 2.137298
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 18.598683
Rec Loss: 15.182372
KL Loss: 3.416311
Y Loss: 10.941173
T Loss: 13.602673
X Loss: -3.890888
Epoch 99 
Overall Loss: -0.475768
Rec Loss: -8.965922
KL Loss: 8.490154
Y Loss: 3.667679
T Loss: 13.397269
X Loss: -24.197030
Epoch 149 
Overall Loss: -6.242587
Rec Loss: -16.085315
KL Loss: 9.842727
Y Loss: 2.539087
T Loss: 13.397254
X Loss: -30.752113
Epoch 199 
Overall Loss: -9.229932
Rec Loss: -20.023753
KL Loss: 10.793820
Y Loss: 1.791101
T Loss: 13.378180
X Loss: -34.297482
Epoch 249 
Overall Loss: -11.019105
Rec Loss: -22.398728
KL Loss: 11.379623
Y Loss: 1.454556
T Loss: 13.358600
X Loss: -36.484606
Epoch 299 
Overall Loss: -12.134445
Rec Loss: -23.912691
KL Loss: 11.778247
Y Loss: 1.295040
T Loss: 13.345883
X Loss: -37.906094
Epoch 349 
Overall Loss: -13.266458
Rec Loss: -25.297505
KL Loss: 12.031047
Y Loss: 1.195358
T Loss: 13.320399
X Loss: -39.215583
Epoch 399 
Overall Loss: -13.863194
Rec Loss: -26.096356
KL Loss: 12.233162
Y Loss: 1.122084
T Loss: 13.314694
X Loss: -39.972092
Epoch 449 
Overall Loss: -14.651124
Rec Loss: -27.167260
KL Loss: 12.516136
Y Loss: 1.018703
T Loss: 13.296362
X Loss: -40.972973
Epoch 499 
Overall Loss: -15.362287
Rec Loss: -27.976822
KL Loss: 12.614535
Y Loss: 0.952532
T Loss: 13.287350
X Loss: -41.740438
Epoch 549 
Overall Loss: -15.837799
Rec Loss: -28.660173
KL Loss: 12.822374
Y Loss: 0.882041
T Loss: 13.286365
X Loss: -42.387558
Epoch 599 
Overall Loss: -16.380764
Rec Loss: -29.365577
KL Loss: 12.984813
Y Loss: 0.839437
T Loss: 13.270697
X Loss: -43.055994
Epoch 649 
Overall Loss: -16.620755
Rec Loss: -29.688975
KL Loss: 13.068219
Y Loss: 0.845300
T Loss: 13.264559
X Loss: -43.376183
Epoch 699 
Overall Loss: -17.268144
Rec Loss: -30.484478
KL Loss: 13.216334
Y Loss: 0.777816
T Loss: 13.250718
X Loss: -44.124103
Epoch 749 
Overall Loss: -17.659210
Rec Loss: -30.968140
KL Loss: 13.308929
Y Loss: 0.755550
T Loss: 13.244986
X Loss: -44.590901
Epoch 799 
Overall Loss: -18.136955
Rec Loss: -31.606640
KL Loss: 13.469685
Y Loss: 0.719336
T Loss: 13.242200
X Loss: -45.208508
Epoch 849 
Overall Loss: -18.430326
Rec Loss: -32.017985
KL Loss: 13.587659
Y Loss: 0.688358
T Loss: 13.232067
X Loss: -45.594232
Epoch 899 
Overall Loss: -18.454305
Rec Loss: -32.087907
KL Loss: 13.633603
Y Loss: 0.678423
T Loss: 13.229702
X Loss: -45.656821
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 3.031886
Epoch 99
Rec Loss: 2.995473
Epoch 149
Rec Loss: 2.982847
Epoch 199
Rec Loss: 2.976623
Epoch 249
Rec Loss: 2.965204
Epoch 299
Rec Loss: 2.970071
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.007296
Epoch 99
Rec Loss: 0.004258
Epoch 149
Rec Loss: 0.005281
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.325596
Insample Error 2.614385
[34m== Direct Regression: Training all ==[0m
Epoch 49 
Prediction Loss: 7.095725
Epoch 99 
Prediction Loss: 6.853514
Epoch 149 
Prediction Loss: 6.628841
Epoch 199 
Prediction Loss: 6.571050
Epoch 249 
Prediction Loss: 6.437812
Epoch 299 
Prediction Loss: 6.399700
Epoch 349 
Prediction Loss: 6.412990
Epoch 399 
Prediction Loss: 6.329542
Epoch 449 
Prediction Loss: 6.297288
Epoch 499 
Prediction Loss: 6.279428
Epoch 549 
Prediction Loss: 6.228734
Epoch 599 
Prediction Loss: 6.199931
Epoch 649 
Prediction Loss: 6.156549
[34m== Direct Regression: Testing in sample performance ==[0m
Train Error 2.475556
Insample Error 4.318096
[31m========== repeat time 8 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.227965
Rec Loss: 15.688288
KL Loss: 1.539676
Y Loss: 4.589396
T Loss: 13.393590
Epoch 99 
Overall Loss: 15.933843
Rec Loss: 14.638617
KL Loss: 1.295226
Y Loss: 2.493627
T Loss: 13.391803
Epoch 149 
Overall Loss: 15.519811
Rec Loss: 14.137185
KL Loss: 1.382626
Y Loss: 2.129048
T Loss: 13.072661
Epoch 199 
Overall Loss: 15.176520
Rec Loss: 13.835133
KL Loss: 1.341387
Y Loss: 1.746306
T Loss: 12.961980
Epoch 249 
Overall Loss: 15.002649
Rec Loss: 13.663122
KL Loss: 1.339526
Y Loss: 1.453478
T Loss: 12.936383
Epoch 299 
Overall Loss: 14.869370
Rec Loss: 13.478172
KL Loss: 1.391198
Y Loss: 1.256797
T Loss: 12.849773
Epoch 349 
Overall Loss: 14.696891
Rec Loss: 13.134943
KL Loss: 1.561947
Y Loss: 1.131617
T Loss: 12.569135
Epoch 399 
Overall Loss: 14.613537
Rec Loss: 12.900514
KL Loss: 1.713023
Y Loss: 1.076728
T Loss: 12.362150
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.010894
Epoch 99
Rec Loss: 1.993706
Epoch 149
Rec Loss: 1.998646
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.880276
Epoch 99
Rec Loss: 9.872823
Epoch 149
Rec Loss: 9.878955
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.458933
Insample Error: 2.094240
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 15.579887
Rec Loss: 10.934918
KL Loss: 4.644969
Y Loss: 5.609219
T Loss: 13.390362
X Loss: -5.260053
Epoch 99 
Overall Loss: -1.412973
Rec Loss: -10.838151
KL Loss: 9.425178
Y Loss: 2.128939
T Loss: 13.319403
X Loss: -25.222023
Epoch 149 
Overall Loss: -6.819601
Rec Loss: -17.518486
KL Loss: 10.698886
Y Loss: 1.427816
T Loss: 13.316665
X Loss: -31.549059
Epoch 199 
Overall Loss: -9.752493
Rec Loss: -21.345716
KL Loss: 11.593224
Y Loss: 1.118511
T Loss: 13.307007
X Loss: -35.211978
Epoch 249 
Overall Loss: -11.207412
Rec Loss: -23.321825
KL Loss: 12.114413
Y Loss: 1.013971
T Loss: 13.289110
X Loss: -37.117921
Epoch 299 
Overall Loss: -12.457427
Rec Loss: -24.919835
KL Loss: 12.462408
Y Loss: 0.947907
T Loss: 13.268121
X Loss: -38.661910
Epoch 349 
Overall Loss: -13.514636
Rec Loss: -26.237804
KL Loss: 12.723168
Y Loss: 0.930382
T Loss: 13.249497
X Loss: -39.952492
Epoch 399 
Overall Loss: -14.246568
Rec Loss: -27.120539
KL Loss: 12.873971
Y Loss: 0.942666
T Loss: 13.211534
X Loss: -40.803406
Epoch 449 
Overall Loss: -14.905379
Rec Loss: -28.013837
KL Loss: 13.108458
Y Loss: 0.918100
T Loss: 13.174709
X Loss: -41.647596
Epoch 499 
Overall Loss: -15.720428
Rec Loss: -28.969483
KL Loss: 13.249054
Y Loss: 0.911304
T Loss: 13.138338
X Loss: -42.563474
Epoch 549 
Overall Loss: -16.366801
Rec Loss: -29.714402
KL Loss: 13.347601
Y Loss: 0.911500
T Loss: 13.088961
X Loss: -43.259113
Epoch 599 
Overall Loss: -16.885462
Rec Loss: -30.404626
KL Loss: 13.519163
Y Loss: 0.883861
T Loss: 13.040820
X Loss: -43.887376
Epoch 649 
Overall Loss: -17.342309
Rec Loss: -30.965112
KL Loss: 13.622803
Y Loss: 0.911838
T Loss: 13.000228
X Loss: -44.421259
Epoch 699 
Overall Loss: -17.745442
Rec Loss: -31.403174
KL Loss: 13.657732
Y Loss: 0.897114
T Loss: 12.955937
X Loss: -44.807667
Epoch 749 
Overall Loss: -18.217928
Rec Loss: -32.035239
KL Loss: 13.817311
Y Loss: 0.914374
T Loss: 12.922333
X Loss: -45.414759
Epoch 799 
Overall Loss: -18.692717
Rec Loss: -32.591970
KL Loss: 13.899253
Y Loss: 0.893786
T Loss: 12.905873
X Loss: -45.944736
Epoch 849 
Overall Loss: -18.904565
Rec Loss: -32.888851
KL Loss: 13.984286
Y Loss: 0.861068
T Loss: 12.888239
X Loss: -46.207625
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 3.025407
Epoch 99
Rec Loss: 3.022805
Epoch 149
Rec Loss: 3.008028
Epoch 199
Rec Loss: 3.008040
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.005004
Epoch 99
Rec Loss: 0.003104
Epoch 149
Rec Loss: 0.004182
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.425411
Insample Error 2.069844
[34m== Direct Regression: Training all ==[0m
Epoch 49 
Prediction Loss: 7.097797
Epoch 99 
Prediction Loss: 6.797788
Epoch 149 
Prediction Loss: 6.631644
Epoch 199 
Prediction Loss: 6.527884
Epoch 249 
Prediction Loss: 6.461029
Epoch 299 
Prediction Loss: 6.412145
Epoch 349 
Prediction Loss: 6.390574
Epoch 399 
Prediction Loss: 6.317408
Epoch 449 
Prediction Loss: 6.286318
Epoch 499 
Prediction Loss: 6.268390
Epoch 549 
Prediction Loss: 6.230523
Epoch 599 
Prediction Loss: 6.182943
Epoch 649 
Prediction Loss: 6.222418
Epoch 699 
Prediction Loss: 6.094385
Epoch 749 
Prediction Loss: 6.066284
Epoch 799 
Prediction Loss: 6.024989
[34m== Direct Regression: Testing in sample performance ==[0m
Train Error 2.449084
Insample Error 4.336654
[31m========== repeat time 9 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.559807
Rec Loss: 16.142535
KL Loss: 1.417272
Y Loss: 5.508514
T Loss: 13.388279
Epoch 99 
Overall Loss: 15.549108
Rec Loss: 14.349404
KL Loss: 1.199705
Y Loss: 1.886780
T Loss: 13.406013
Epoch 149 
Overall Loss: 15.279554
Rec Loss: 14.072330
KL Loss: 1.207224
Y Loss: 1.474942
T Loss: 13.334859
Epoch 199 
Overall Loss: 15.001603
Rec Loss: 13.661747
KL Loss: 1.339857
Y Loss: 1.326175
T Loss: 12.998659
Epoch 249 
Overall Loss: 14.900515
Rec Loss: 13.518964
KL Loss: 1.381550
Y Loss: 1.216239
T Loss: 12.910845
Epoch 299 
Overall Loss: 14.741560
Rec Loss: 13.169217
KL Loss: 1.572342
Y Loss: 1.147919
T Loss: 12.595258
Epoch 349 
Overall Loss: 14.625069
Rec Loss: 12.868456
KL Loss: 1.756612
Y Loss: 1.075161
T Loss: 12.330876
Epoch 399 
Overall Loss: 14.580472
Rec Loss: 12.794983
KL Loss: 1.785490
Y Loss: 1.046694
T Loss: 12.271635
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.014019
Epoch 99
Rec Loss: 2.012235
Epoch 149
Rec Loss: 2.018725
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.857228
Epoch 99
Rec Loss: 9.864226
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.453369
Insample Error: 2.069638
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 18.460983
Rec Loss: 14.920407
KL Loss: 3.540575
Y Loss: 11.104193
T Loss: 13.575671
X Loss: -4.207361
Epoch 99 
Overall Loss: 0.426307
Rec Loss: -8.222889
KL Loss: 8.649196
Y Loss: 4.318043
T Loss: 13.348467
X Loss: -23.730378
Epoch 149 
Overall Loss: -5.303560
Rec Loss: -15.056777
KL Loss: 9.753217
Y Loss: 2.714253
T Loss: 13.335771
X Loss: -29.749675
Epoch 199 
Overall Loss: -8.956652
Rec Loss: -19.643359
KL Loss: 10.686707
Y Loss: 1.682690
T Loss: 13.326127
X Loss: -33.810830
Epoch 249 
Overall Loss: -11.039993
Rec Loss: -22.434273
KL Loss: 11.394281
Y Loss: 1.043650
T Loss: 13.317923
X Loss: -36.274020
Epoch 299 
Overall Loss: -12.260878
Rec Loss: -24.042880
KL Loss: 11.782002
Y Loss: 0.820017
T Loss: 13.310103
X Loss: -37.762992
Epoch 349 
Overall Loss: -13.081660
Rec Loss: -25.199287
KL Loss: 12.117628
Y Loss: 0.757324
T Loss: 13.297502
X Loss: -38.875450
Epoch 399 
Overall Loss: -13.870450
Rec Loss: -26.234518
KL Loss: 12.364067
Y Loss: 0.741662
T Loss: 13.281917
X Loss: -39.887266
Epoch 449 
Overall Loss: -14.749391
Rec Loss: -27.279928
KL Loss: 12.530536
Y Loss: 0.729545
T Loss: 13.270853
X Loss: -40.915552
Epoch 499 
Overall Loss: -15.187681
Rec Loss: -27.853810
KL Loss: 12.666129
Y Loss: 0.711065
T Loss: 13.252941
X Loss: -41.462284
Epoch 549 
Overall Loss: -15.895683
Rec Loss: -28.767102
KL Loss: 12.871419
Y Loss: 0.673813
T Loss: 13.220800
X Loss: -42.324809
Epoch 599 
Overall Loss: -16.475966
Rec Loss: -29.530596
KL Loss: 13.054630
Y Loss: 0.672059
T Loss: 13.205544
X Loss: -43.072170
Epoch 649 
Overall Loss: -16.937936
Rec Loss: -30.082226
KL Loss: 13.144290
Y Loss: 0.687255
T Loss: 13.167551
X Loss: -43.593404
Epoch 699 
Overall Loss: -17.326457
Rec Loss: -30.582343
KL Loss: 13.255885
Y Loss: 0.678665
T Loss: 13.139587
X Loss: -44.061263
Epoch 749 
Overall Loss: -17.696435
Rec Loss: -31.159824
KL Loss: 13.463390
Y Loss: 0.640151
T Loss: 13.098233
X Loss: -44.578132
Epoch 799 
Overall Loss: -18.095660
Rec Loss: -31.609875
KL Loss: 13.514215
Y Loss: 0.667630
T Loss: 13.075211
X Loss: -45.018900
Epoch 849 
Overall Loss: -18.384843
Rec Loss: -32.024130
KL Loss: 13.639287
Y Loss: 0.657342
T Loss: 13.040010
X Loss: -45.392810
Epoch 899 
Overall Loss: -18.882838
Rec Loss: -32.600444
KL Loss: 13.717606
Y Loss: 0.658292
T Loss: 13.007039
X Loss: -45.936629
Epoch 949 
Overall Loss: -19.055486
Rec Loss: -32.834480
KL Loss: 13.778994
Y Loss: 0.639732
T Loss: 12.982225
X Loss: -46.136571
Epoch 999 
Overall Loss: -19.378608
Rec Loss: -33.223197
KL Loss: 13.844588
Y Loss: 0.655599
T Loss: 12.952667
X Loss: -46.503663
Epoch 1049 
Overall Loss: -19.680426
Rec Loss: -33.499804
KL Loss: 13.819378
Y Loss: 0.670596
T Loss: 12.939541
X Loss: -46.774643
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 3.019291
Epoch 99
Rec Loss: 3.003062
Epoch 149
Rec Loss: 3.000490
Epoch 199
Rec Loss: 2.979824
Epoch 249
Rec Loss: 2.973757
Epoch 299
Rec Loss: 2.967993
Epoch 349
Rec Loss: 2.980647
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.005979
Epoch 99
Rec Loss: 0.003335
Epoch 149
Rec Loss: 0.003968
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.321586
Insample Error 2.085519
[34m== Direct Regression: Training all ==[0m
Epoch 49 
Prediction Loss: 7.187749
Epoch 99 
Prediction Loss: 6.870922
Epoch 149 
Prediction Loss: 6.660327
Epoch 199 
Prediction Loss: 6.575469
Epoch 249 
Prediction Loss: 6.460483
Epoch 299 
Prediction Loss: 6.416030
Epoch 349 
Prediction Loss: 6.336734
Epoch 399 
Prediction Loss: 6.295570
Epoch 449 
Prediction Loss: 6.250508
Epoch 499 
Prediction Loss: 6.233515
Epoch 549 
Prediction Loss: 6.197293
Epoch 599 
Prediction Loss: 6.123510
Epoch 649 
Prediction Loss: 6.098668
Epoch 699 
Prediction Loss: 6.048308
Epoch 749 
Prediction Loss: 5.996733
Epoch 799 
Prediction Loss: 5.961299
Epoch 849 
Prediction Loss: 5.895288
Epoch 899 
Prediction Loss: 5.923868
[34m== Direct Regression: Testing in sample performance ==[0m
Train Error 2.410566
Insample Error 4.320035
[31m========== repeat time 10 ==========[0m
[34m== Ours: Training all ==[0m
Epoch 49 
Overall Loss: 17.270478
Rec Loss: 15.826906
KL Loss: 1.443572
Y Loss: 4.920792
T Loss: 13.366510
Epoch 99 
Overall Loss: 15.800580
Rec Loss: 14.526399
KL Loss: 1.274181
Y Loss: 2.379068
T Loss: 13.336865
Epoch 149 
Overall Loss: 15.246418
Rec Loss: 13.869388
KL Loss: 1.377030
Y Loss: 1.830783
T Loss: 12.953996
Epoch 199 
Overall Loss: 14.999487
Rec Loss: 13.586656
KL Loss: 1.412830
Y Loss: 1.516576
T Loss: 12.828368
Epoch 249 
Overall Loss: 14.762757
Rec Loss: 13.083872
KL Loss: 1.678885
Y Loss: 1.327788
T Loss: 12.419978
Epoch 299 
Overall Loss: 14.663542
Rec Loss: 12.891337
KL Loss: 1.772206
Y Loss: 1.187913
T Loss: 12.297380
Epoch 349 
Overall Loss: 14.607707
Rec Loss: 12.816117
KL Loss: 1.791590
Y Loss: 1.114745
T Loss: 12.258744
[34m== Ours: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.034023
Epoch 99
Rec Loss: 2.043084
[34m== Ours: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 9.874033
Epoch 99
Rec Loss: 9.866871
Epoch 149
Rec Loss: 9.848840
Epoch 199
Rec Loss: 9.873482
[34m== Ours: Testing in sample performance ==[0m
Train Error: 0.491530
Insample Error: 2.015025
[34m== CEVAE: Training all ==[0m
Epoch 49 
Overall Loss: 19.280137
Rec Loss: 15.805222
KL Loss: 3.474916
Y Loss: 8.344265
T Loss: 13.413156
X Loss: -1.780067
Epoch 99 
Overall Loss: 1.314237
Rec Loss: -9.276478
KL Loss: 10.590714
Y Loss: 2.674553
T Loss: 13.299573
X Loss: -23.913327
Epoch 149 
Overall Loss: -3.941142
Rec Loss: -15.902482
KL Loss: 11.961340
Y Loss: 1.761918
T Loss: 13.272930
X Loss: -30.056371
Epoch 199 
Overall Loss: -7.439143
Rec Loss: -20.634593
KL Loss: 13.195449
Y Loss: 1.057389
T Loss: 13.250233
X Loss: -34.413520
Epoch 249 
Overall Loss: -9.106073
Rec Loss: -23.117096
KL Loss: 14.011023
Y Loss: 0.654023
T Loss: 13.225045
X Loss: -36.669153
Epoch 299 
Overall Loss: -10.448166
Rec Loss: -24.914150
KL Loss: 14.465984
Y Loss: 0.462505
T Loss: 13.195799
X Loss: -38.341201
Epoch 349 
Overall Loss: -11.476762
Rec Loss: -26.280992
KL Loss: 14.804230
Y Loss: 0.347889
T Loss: 13.174809
X Loss: -39.629745
Epoch 399 
Overall Loss: -12.245101
Rec Loss: -27.263024
KL Loss: 15.017923
Y Loss: 0.313119
T Loss: 13.139319
X Loss: -40.558902
Epoch 449 
Overall Loss: -12.913089
Rec Loss: -28.101289
KL Loss: 15.188200
Y Loss: 0.302011
T Loss: 13.095160
X Loss: -41.347453
Epoch 499 
Overall Loss: -13.391940
Rec Loss: -28.709140
KL Loss: 15.317200
Y Loss: 0.233493
T Loss: 13.034723
X Loss: -41.860610
Epoch 549 
Overall Loss: -13.928206
Rec Loss: -29.491872
KL Loss: 15.563667
Y Loss: 0.224441
T Loss: 12.965412
X Loss: -42.569504
Epoch 599 
Overall Loss: -14.423989
Rec Loss: -30.197668
KL Loss: 15.773678
Y Loss: 0.204449
T Loss: 12.878356
X Loss: -43.178248
Epoch 649 
Overall Loss: -14.860910
Rec Loss: -30.710238
KL Loss: 15.849328
Y Loss: 0.232104
T Loss: 12.810861
X Loss: -43.637151
Epoch 699 
Overall Loss: -15.269752
Rec Loss: -31.304972
KL Loss: 16.035219
Y Loss: 0.191600
T Loss: 12.730394
X Loss: -44.131165
[34m== CEVAE: Reconstructing confounder ==[0m
Epoch 49
Rec Loss: 2.838062
Epoch 99
Rec Loss: 2.830081
Epoch 149
Rec Loss: 2.807418
Epoch 199
Rec Loss: 2.811954
[34m== CEVAE: Reconstructing noise ==[0m
Epoch 49
Rec Loss: 0.007094
Epoch 99
Rec Loss: 0.004361
Epoch 149
Rec Loss: 0.003043
Epoch 199
Rec Loss: 0.003539
[34m== CEVAE: Testing in sample performance ==[0m
Train Error 0.374366
Insample Error 2.169489
[34m== Direct Regression: Training all ==[0m
Epoch 49 
Prediction Loss: 7.102397
Epoch 99 
Prediction Loss: 6.820785
Epoch 149 
Prediction Loss: 6.661394
Epoch 199 
Prediction Loss: 6.546707
Epoch 249 
Prediction Loss: 6.485024
Epoch 299 
Prediction Loss: 6.403411
Epoch 349 
Prediction Loss: 6.349722
Epoch 399 
Prediction Loss: 6.375521
Epoch 449 
Prediction Loss: 6.263451
Epoch 499 
Prediction Loss: 6.208098
[34m== Direct Regression: Testing in sample performance ==[0m
Train Error 2.485559
Insample Error 4.309270
Ours, Train RMSE
0.4279, 
0.4500, 
0.4353, 
0.4839, 
0.5363, 
0.4522, 
0.5291, 
0.4589, 
0.4534, 
0.4915, 
CEVAE, Train RMSE
0.3880, 
0.2312, 
0.3561, 
0.4002, 
0.4120, 
0.3284, 
0.3256, 
0.4254, 
0.3216, 
0.3744, 
Ours, Insample RMSE
2.0281, 
2.5527, 
2.4804, 
2.0873, 
2.0693, 
2.1615, 
2.1373, 
2.0942, 
2.0696, 
2.0150, 
CEVAE, Insample RMSE
1.9360, 
1.9492, 
2.0232, 
2.0769, 
1.8674, 
2.0216, 
2.6144, 
2.0698, 
2.0855, 
2.1695, 
Direct Regression, Insample RMSE
4.3599, 
4.3659, 
4.3568, 
4.3349, 
4.3172, 
4.3911, 
4.3181, 
4.3367, 
4.3200, 
4.3093, 
Train, RMSE mean 0.4719 std 0.0355
CEVAE, RMSE mean 0.3563 std 0.0545
Ours, RMSE mean 2.1695 std 0.1791, reconstruct confounder 2.0487 (0.0586) noise 9.8625 (0.0305)
CEVAE, RMSE mean 2.0813 std 0.1958, reconstruct confounder 2.9461 (0.0590) noise 0.0036 (0.0019)
Direct Regression, RMSE mean 4.3410 std 0.0252
